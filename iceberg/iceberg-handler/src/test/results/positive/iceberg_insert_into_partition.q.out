PREHOOK: query: create external table ice_parquet_int(
  strcol string,
  intcol integer
) partitioned by (pcol int)
stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_int
POSTHOOK: query: create external table ice_parquet_int(
  strcol string,
  intcol integer
) partitioned by (pcol int)
stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_int
PREHOOK: query: explain insert into table ice_parquet_int partition(pcol = 1) values ('ABC', 1), ('DEF', 2)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_int@pcol=1
POSTHOOK: query: explain insert into table ice_parquet_int partition(pcol = 1) values ('ABC', 1), ('DEF', 2)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_int@pcol=1
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('ABC',1),const struct('DEF',2)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int), 1 (type: int)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_int
                        Select Operator
                          expressions: _col0 (type: string), _col1 (type: int), _col2 (type: int)
                          outputColumnNames: strcol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: max(length(strcol)), avg(COALESCE(length(strcol),0)), count(1), count(strcol), compute_bit_vector_hll(strcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: int), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 492 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'LONG' (type: string), UDFToLong(_col9) (type: bigint), UDFToLong(_col10) (type: bigint), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 794 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 794 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_int

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: strcol, intcol, pcol
          Column Types: string, int, int
          Table: default.ice_parquet_int

PREHOOK: query: insert into table ice_parquet_int partition(pcol = 1) values ('ABC', 1), ('DEF', 2)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_int@pcol=1
POSTHOOK: query: insert into table ice_parquet_int partition(pcol = 1) values ('ABC', 1), ('DEF', 2)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_int@pcol=1
PREHOOK: query: explain insert into table ice_parquet_int partition(pCOL = 2) values ('ABC', 1), ('DEF', 2)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_int@pcol=2
POSTHOOK: query: explain insert into table ice_parquet_int partition(pCOL = 2) values ('ABC', 1), ('DEF', 2)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_int@pcol=2
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('ABC',1),const struct('DEF',2)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int), 2 (type: int)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_int
                        Select Operator
                          expressions: _col0 (type: string), _col1 (type: int), _col2 (type: int)
                          outputColumnNames: strcol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: max(length(strcol)), avg(COALESCE(length(strcol),0)), count(1), count(strcol), compute_bit_vector_hll(strcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: int), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 492 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'LONG' (type: string), UDFToLong(_col9) (type: bigint), UDFToLong(_col10) (type: bigint), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 794 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 794 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_int

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: strcol, intcol, pcol
          Column Types: string, int, int
          Table: default.ice_parquet_int

PREHOOK: query: insert into table ice_parquet_int partition(pcol = 2) values ('ABC', 1), ('DEF', 2)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_int@pcol=2
POSTHOOK: query: insert into table ice_parquet_int partition(pcol = 2) values ('ABC', 1), ('DEF', 2)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_int@pcol=2
PREHOOK: query: explain insert into table ice_parquet_int partition(pcol = 3) select strcol, intcol from ice_parquet_int where pcol = 2
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: default@ice_parquet_int@pcol=3
POSTHOOK: query: explain insert into table ice_parquet_int partition(pcol = 3) select strcol, intcol from ice_parquet_int where pcol = 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: default@ice_parquet_int@pcol=3
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_int
                  filterExpr: (pcol = 2) (type: boolean)
                  Statistics: Num rows: 4 Data size: 380 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (pcol = 2) (type: boolean)
                    Statistics: Num rows: 2 Data size: 190 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: strcol (type: string), intcol (type: int), 3 (type: int)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 2 Data size: 190 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        Statistics: Num rows: 2 Data size: 190 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                            output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                            serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                            name: default.ice_parquet_int
                      Select Operator
                        expressions: _col0 (type: string), _col1 (type: int), _col2 (type: int)
                        outputColumnNames: strcol, intcol, pcol
                        Statistics: Num rows: 2 Data size: 190 Basic stats: COMPLETE Column stats: COMPLETE
                        Group By Operator
                          aggregations: max(length(strcol)), avg(COALESCE(length(strcol),0)), count(1), count(strcol), compute_bit_vector_hll(strcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                          minReductionHashAggr: 0.5
                          mode: hash
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                          Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            null sort order: 
                            sort order: 
                            Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: int), _col11 (type: bigint), _col12 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 492 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'LONG' (type: string), UDFToLong(_col9) (type: bigint), UDFToLong(_col10) (type: bigint), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 794 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 794 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_int

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: strcol, intcol, pcol
          Column Types: string, int, int
          Table: default.ice_parquet_int

PREHOOK: query: insert into table ice_parquet_int partition(pcol = 3) select strcol, intcol from ice_parquet_int where pcol = 2
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: default@ice_parquet_int@pcol=3
POSTHOOK: query: insert into table ice_parquet_int partition(pcol = 3) select strcol, intcol from ice_parquet_int where pcol = 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: default@ice_parquet_int@pcol=3
PREHOOK: query: explain insert into table ice_parquet_int partition(pcol = 04) select strcol, intcol from ice_parquet_int where pcol = 2
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: default@ice_parquet_int@pcol=04
POSTHOOK: query: explain insert into table ice_parquet_int partition(pcol = 04) select strcol, intcol from ice_parquet_int where pcol = 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: default@ice_parquet_int@pcol=04
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_int
                  filterExpr: (pcol = 2) (type: boolean)
                  Statistics: Num rows: 6 Data size: 570 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (pcol = 2) (type: boolean)
                    Statistics: Num rows: 3 Data size: 285 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: strcol (type: string), intcol (type: int), 4 (type: int)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 3 Data size: 285 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        Statistics: Num rows: 3 Data size: 285 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                            output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                            serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                            name: default.ice_parquet_int
                      Select Operator
                        expressions: _col0 (type: string), _col1 (type: int), _col2 (type: int)
                        outputColumnNames: strcol, intcol, pcol
                        Statistics: Num rows: 3 Data size: 285 Basic stats: COMPLETE Column stats: COMPLETE
                        Group By Operator
                          aggregations: max(length(strcol)), avg(COALESCE(length(strcol),0)), count(1), count(strcol), compute_bit_vector_hll(strcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                          minReductionHashAggr: 0.6666666
                          mode: hash
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                          Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            null sort order: 
                            sort order: 
                            Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: int), _col11 (type: bigint), _col12 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 492 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'LONG' (type: string), UDFToLong(_col9) (type: bigint), UDFToLong(_col10) (type: bigint), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 794 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 794 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_int

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: strcol, intcol, pcol
          Column Types: string, int, int
          Table: default.ice_parquet_int

PREHOOK: query: insert into table ice_parquet_int partition(pcol = 04) select strcol, intcol from ice_parquet_int where pcol = 2
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: default@ice_parquet_int@pcol=04
POSTHOOK: query: insert into table ice_parquet_int partition(pcol = 04) select strcol, intcol from ice_parquet_int where pcol = 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: default@ice_parquet_int@pcol=04
PREHOOK: query: describe formatted ice_parquet_int
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_int
POSTHOOK: query: describe formatted ice_parquet_int
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_int
# col_name            	data_type           	comment             
strcol              	string              	                    
intcol              	int                 	                    
pcol                	int                 	                    
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
pcol                	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"intcol\":\"true\",\"pcol\":\"true\",\"strcol\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"strcol\",\"required\":false,\"type\":\"string\"},{\"id\":2,\"name\":\"intcol\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"pcol\",\"required\":false,\"type\":\"int\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"added-data-files\":\"1\",\"added-records\":\"2\",\"added-files-size\":\"#Masked#\",\"changed-partition-count\":\"1\",\"total-records\":\"8\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"pcol\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                   
	numRows             	8                   
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	4                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#                
#### A masked pattern was here ####
	uuid                	#Masked#
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_int
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_int
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: hdfs://### HDFS PATH ###
ABC	1	1
ABC	1	2
ABC	1	3
ABC	1	4
DEF	2	1
DEF	2	2
DEF	2	3
DEF	2	4
PREHOOK: query: create table ice_parquet_string (name string, age int) partitioned by (country string, state string) stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: create table ice_parquet_string (name string, age int) partitioned by (country string, state string) stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_string
PREHOOK: query: explain insert into ice_parquet_string partition (state='CA', country='USA') values ('John Doe', 23), ('Jane Doe', 22)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_string@country=USA/state=CA
POSTHOOK: query: explain insert into ice_parquet_string partition (state='CA', country='USA') values ('John Doe', 23), ('Jane Doe', 22)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_string@country=USA/state=CA
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('John Doe',23),const struct('Jane Doe',22)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int), 'USA' (type: string), 'CA' (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_string
                        Select Operator
                          expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                          outputColumnNames: name, age, country, state
                          Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                            Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: struct<count:bigint,sum:double,input:int>), _col11 (type: bigint), _col12 (type: binary), _col13 (type: int), _col14 (type: struct<count:bigint,sum:double,input:int>), _col15 (type: bigint), _col16 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                Statistics: Num rows: 1 Data size: 660 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col9,0)) (type: bigint), COALESCE(_col10,0) (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col13,0)) (type: bigint), COALESCE(_col14,0) (type: double), (_col2 - _col15) (type: bigint), COALESCE(ndv_compute_bit_vector(_col16),0) (type: bigint), _col16 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                  Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert into ice_parquet_string partition (state='CA', country='USA') values ('John Doe', 23), ('Jane Doe', 22)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_string@country=USA/state=CA
POSTHOOK: query: insert into ice_parquet_string partition (state='CA', country='USA') values ('John Doe', 23), ('Jane Doe', 22)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_string@country=USA/state=CA
PREHOOK: query: explain insert into ice_parquet_string partition (country='USA', state='CA') values ('Mark Cage', 38), ('Mirna Cage', 37)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_string@country=USA/state=CA
POSTHOOK: query: explain insert into ice_parquet_string partition (country='USA', state='CA') values ('Mark Cage', 38), ('Mirna Cage', 37)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_string@country=USA/state=CA
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('Mark Cage',38),const struct('Mirna Cage',37)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int), 'USA' (type: string), 'CA' (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_string
                        Select Operator
                          expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                          outputColumnNames: name, age, country, state
                          Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                            Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: struct<count:bigint,sum:double,input:int>), _col11 (type: bigint), _col12 (type: binary), _col13 (type: int), _col14 (type: struct<count:bigint,sum:double,input:int>), _col15 (type: bigint), _col16 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                Statistics: Num rows: 1 Data size: 660 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col9,0)) (type: bigint), COALESCE(_col10,0) (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col13,0)) (type: bigint), COALESCE(_col14,0) (type: double), (_col2 - _col15) (type: bigint), COALESCE(ndv_compute_bit_vector(_col16),0) (type: bigint), _col16 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                  Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert into ice_parquet_string partition (country='USA', state='CA') values ('Mark Cage', 38), ('Mirna Cage', 37)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_string@country=USA/state=CA
POSTHOOK: query: insert into ice_parquet_string partition (country='USA', state='CA') values ('Mark Cage', 38), ('Mirna Cage', 37)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_string@country=USA/state=CA
PREHOOK: query: explain insert into ice_parquet_string partition (country='USA', state='TX') values ('Bill Rose', 52), ('Maria Full', 50)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_string@country=USA/state=TX
POSTHOOK: query: explain insert into ice_parquet_string partition (country='USA', state='TX') values ('Bill Rose', 52), ('Maria Full', 50)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_string@country=USA/state=TX
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('Bill Rose',52),const struct('Maria Full',50)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int), 'USA' (type: string), 'TX' (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_string
                        Select Operator
                          expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                          outputColumnNames: name, age, country, state
                          Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                            Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: struct<count:bigint,sum:double,input:int>), _col11 (type: bigint), _col12 (type: binary), _col13 (type: int), _col14 (type: struct<count:bigint,sum:double,input:int>), _col15 (type: bigint), _col16 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                Statistics: Num rows: 1 Data size: 660 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col9,0)) (type: bigint), COALESCE(_col10,0) (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col13,0)) (type: bigint), COALESCE(_col14,0) (type: double), (_col2 - _col15) (type: bigint), COALESCE(ndv_compute_bit_vector(_col16),0) (type: bigint), _col16 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                  Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert into ice_parquet_string partition (country='USA', state='TX') values ('Bill Rose', 52), ('Maria Full', 50)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_string@country=USA/state=TX
POSTHOOK: query: insert into ice_parquet_string partition (country='USA', state='TX') values ('Bill Rose', 52), ('Maria Full', 50)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_string@country=USA/state=TX
PREHOOK: query: select * from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: hdfs://### HDFS PATH ###
Bill Rose	52	USA	TX
Jane Doe	22	USA	CA
John Doe	23	USA	CA
Maria Full	50	USA	TX
Mark Cage	38	USA	CA
Mirna Cage	37	USA	CA
PREHOOK: query: explain insert into table ice_parquet_string partition(country, state) select * from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: explain insert into table ice_parquet_string partition(country, state) select * from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 6 Data size: 1626 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), age (type: int), country (type: string), state (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 6 Data size: 1626 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: aa
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 6 Data size: 1626 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 6 Data size: 1626 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        minReductionHashAggr: 0.8333333
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                        Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: struct<count:bigint,sum:double,input:int>), _col11 (type: bigint), _col12 (type: binary), _col13 (type: int), _col14 (type: struct<count:bigint,sum:double,input:int>), _col15 (type: bigint), _col16 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 6 Data size: 1626 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                Statistics: Num rows: 1 Data size: 660 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col9,0)) (type: bigint), COALESCE(_col10,0) (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col13,0)) (type: bigint), COALESCE(_col14,0) (type: double), (_col2 - _col15) (type: bigint), COALESCE(ndv_compute_bit_vector(_col16),0) (type: bigint), _col16 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                  Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert into table ice_parquet_string partition(country, state) select * from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: insert into table ice_parquet_string partition(country, state) select * from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
PREHOOK: query: explain insert into table ice_parquet_string partition(country='USA', state) select name, age, state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: explain insert into table ice_parquet_string partition(country='USA', state) select name, age, state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 12 Data size: 2208 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), age (type: int), 'USA' (type: string), state (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 12 Data size: 3252 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: aa
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 12 Data size: 3252 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 12 Data size: 3252 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        minReductionHashAggr: 0.9166667
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                        Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: struct<count:bigint,sum:double,input:int>), _col11 (type: bigint), _col12 (type: binary), _col13 (type: int), _col14 (type: struct<count:bigint,sum:double,input:int>), _col15 (type: bigint), _col16 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 12 Data size: 3252 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                Statistics: Num rows: 1 Data size: 660 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col9,0)) (type: bigint), COALESCE(_col10,0) (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col13,0)) (type: bigint), COALESCE(_col14,0) (type: double), (_col2 - _col15) (type: bigint), COALESCE(ndv_compute_bit_vector(_col16),0) (type: bigint), _col16 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                  Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert into table ice_parquet_string partition(country='USA', state) select name, age, state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: insert into table ice_parquet_string partition(country='USA', state) select name, age, state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
PREHOOK: query: explain insert into table ice_parquet_string partition(state='CA', country) select name, age, country from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: explain insert into table ice_parquet_string partition(state='CA', country) select name, age, country from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 24 Data size: 4440 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), age (type: int), country (type: string), 'CA' (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 24 Data size: 6504 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: aa
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 24 Data size: 6504 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 24 Data size: 6504 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        minReductionHashAggr: 0.9583333
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                        Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: struct<count:bigint,sum:double,input:int>), _col11 (type: bigint), _col12 (type: binary), _col13 (type: int), _col14 (type: struct<count:bigint,sum:double,input:int>), _col15 (type: bigint), _col16 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 24 Data size: 6504 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                Statistics: Num rows: 1 Data size: 660 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col9,0)) (type: bigint), COALESCE(_col10,0) (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col13,0)) (type: bigint), COALESCE(_col14,0) (type: double), (_col2 - _col15) (type: bigint), COALESCE(ndv_compute_bit_vector(_col16),0) (type: bigint), _col16 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                  Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert into table ice_parquet_string partition(state='CA', country) select name, age, country from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: insert into table ice_parquet_string partition(state='CA', country) select name, age, country from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
PREHOOK: query: explain insert into table ice_parquet_string partition(state='TX') select name, age, country from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@state=TX
POSTHOOK: query: explain insert into table ice_parquet_string partition(state='TX') select name, age, country from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@state=TX
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 48 Data size: 8880 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), age (type: int), country (type: string), 'TX' (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 48 Data size: 13008 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: aa
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 48 Data size: 13008 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 48 Data size: 13008 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        minReductionHashAggr: 0.9791667
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                        Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: struct<count:bigint,sum:double,input:int>), _col11 (type: bigint), _col12 (type: binary), _col13 (type: int), _col14 (type: struct<count:bigint,sum:double,input:int>), _col15 (type: bigint), _col16 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 48 Data size: 13008 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                Statistics: Num rows: 1 Data size: 660 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col9,0)) (type: bigint), COALESCE(_col10,0) (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col13,0)) (type: bigint), COALESCE(_col14,0) (type: double), (_col2 - _col15) (type: bigint), COALESCE(ndv_compute_bit_vector(_col16),0) (type: bigint), _col16 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                  Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert into table ice_parquet_string partition(state='TX') select name, age, country from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@state=TX
POSTHOOK: query: insert into table ice_parquet_string partition(state='TX') select name, age, country from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@state=TX
PREHOOK: query: explain insert into table ice_parquet_string partition(country='India') select name, age, state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@country=India
POSTHOOK: query: explain insert into table ice_parquet_string partition(country='India') select name, age, state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@country=India
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 96 Data size: 17664 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), age (type: int), 'India' (type: string), state (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 96 Data size: 26208 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: aa
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 96 Data size: 26208 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 96 Data size: 26208 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        minReductionHashAggr: 0.9895833
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                        Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: struct<count:bigint,sum:double,input:int>), _col11 (type: bigint), _col12 (type: binary), _col13 (type: int), _col14 (type: struct<count:bigint,sum:double,input:int>), _col15 (type: bigint), _col16 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 96 Data size: 26208 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                Statistics: Num rows: 1 Data size: 660 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col9,0)) (type: bigint), COALESCE(_col10,0) (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col13,0)) (type: bigint), COALESCE(_col14,0) (type: double), (_col2 - _col15) (type: bigint), COALESCE(ndv_compute_bit_vector(_col16),0) (type: bigint), _col16 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                  Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert into table ice_parquet_string partition(country='India') select name, age, state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@country=India
POSTHOOK: query: insert into table ice_parquet_string partition(country='India') select name, age, state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@country=India
PREHOOK: query: explain insert into table ice_parquet_string partition(country='India') select name, '0054', state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@country=India
POSTHOOK: query: explain insert into table ice_parquet_string partition(country='India') select name, '0054', state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@country=India
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 192 Data size: 34560 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), 54 (type: int), 'India' (type: string), state (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 192 Data size: 52416 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: aa
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 192 Data size: 52416 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 192 Data size: 52416 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        minReductionHashAggr: 0.99
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                        Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 864 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: int), _col10 (type: struct<count:bigint,sum:double,input:int>), _col11 (type: bigint), _col12 (type: binary), _col13 (type: int), _col14 (type: struct<count:bigint,sum:double,input:int>), _col15 (type: bigint), _col16 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 192 Data size: 52416 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16
                Statistics: Num rows: 1 Data size: 660 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col9,0)) (type: bigint), COALESCE(_col10,0) (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col13,0)) (type: bigint), COALESCE(_col14,0) (type: double), (_col2 - _col15) (type: bigint), COALESCE(ndv_compute_bit_vector(_col16),0) (type: bigint), _col16 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                  Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1062 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert into table ice_parquet_string partition(country='India') select name, '0054', state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@country=India
POSTHOOK: query: insert into table ice_parquet_string partition(country='India') select name, '0054', state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@country=India
PREHOOK: query: describe formatted ice_parquet_string
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_string
POSTHOOK: query: describe formatted ice_parquet_string
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_string
# col_name            	data_type           	comment             
name                	string              	                    
age                 	int                 	                    
country             	string              	                    
state               	string              	                    
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
country             	IDENTITY            	 
state               	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"age\":\"true\",\"country\":\"true\",\"name\":\"true\",\"state\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"name\",\"required\":false,\"type\":\"string\"},{\"id\":2,\"name\":\"age\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"country\",\"required\":false,\"type\":\"string\"},{\"id\":4,\"name\":\"state\",\"required\":false,\"type\":\"string\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"added-data-files\":\"2\",\"added-records\":\"192\",\"added-files-size\":\"#Masked#\",\"changed-partition-count\":\"2\",\"total-records\":\"384\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"country\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000},{\"name\":\"state\",\"transform\":\"identity\",\"source-id\":4,\"field-id\":1001}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                  
	numRows             	384                 
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	9                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#               
#### A masked pattern was here ####
	uuid                	#Masked#
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: hdfs://### HDFS PATH ###
Bill Rose	52	India	CA
Bill Rose	52	India	CA
Bill Rose	52	India	CA
Bill Rose	52	India	CA
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	India	TX
Bill Rose	52	USA	CA
Bill Rose	52	USA	CA
Bill Rose	52	USA	CA
Bill Rose	52	USA	CA
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	54	India	CA
Bill Rose	54	India	CA
Bill Rose	54	India	CA
Bill Rose	54	India	CA
Bill Rose	54	India	CA
Bill Rose	54	India	CA
Bill Rose	54	India	CA
Bill Rose	54	India	CA
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Jane Doe	22	India	CA
Jane Doe	22	India	CA
Jane Doe	22	India	CA
Jane Doe	22	India	CA
Jane Doe	22	India	CA
Jane Doe	22	India	CA
Jane Doe	22	India	CA
Jane Doe	22	India	CA
Jane Doe	22	India	TX
Jane Doe	22	India	TX
Jane Doe	22	India	TX
Jane Doe	22	India	TX
Jane Doe	22	India	TX
Jane Doe	22	India	TX
Jane Doe	22	India	TX
Jane Doe	22	India	TX
Jane Doe	22	USA	CA
Jane Doe	22	USA	CA
Jane Doe	22	USA	CA
Jane Doe	22	USA	CA
Jane Doe	22	USA	CA
Jane Doe	22	USA	CA
Jane Doe	22	USA	CA
Jane Doe	22	USA	CA
Jane Doe	22	USA	TX
Jane Doe	22	USA	TX
Jane Doe	22	USA	TX
Jane Doe	22	USA	TX
Jane Doe	22	USA	TX
Jane Doe	22	USA	TX
Jane Doe	22	USA	TX
Jane Doe	22	USA	TX
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	CA
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
Jane Doe	54	India	TX
John Doe	23	India	CA
John Doe	23	India	CA
John Doe	23	India	CA
John Doe	23	India	CA
John Doe	23	India	CA
John Doe	23	India	CA
John Doe	23	India	CA
John Doe	23	India	CA
John Doe	23	India	TX
John Doe	23	India	TX
John Doe	23	India	TX
John Doe	23	India	TX
John Doe	23	India	TX
John Doe	23	India	TX
John Doe	23	India	TX
John Doe	23	India	TX
John Doe	23	USA	CA
John Doe	23	USA	CA
John Doe	23	USA	CA
John Doe	23	USA	CA
John Doe	23	USA	CA
John Doe	23	USA	CA
John Doe	23	USA	CA
John Doe	23	USA	CA
John Doe	23	USA	TX
John Doe	23	USA	TX
John Doe	23	USA	TX
John Doe	23	USA	TX
John Doe	23	USA	TX
John Doe	23	USA	TX
John Doe	23	USA	TX
John Doe	23	USA	TX
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	CA
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
John Doe	54	India	TX
Maria Full	50	India	CA
Maria Full	50	India	CA
Maria Full	50	India	CA
Maria Full	50	India	CA
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	India	TX
Maria Full	50	USA	CA
Maria Full	50	USA	CA
Maria Full	50	USA	CA
Maria Full	50	USA	CA
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	54	India	CA
Maria Full	54	India	CA
Maria Full	54	India	CA
Maria Full	54	India	CA
Maria Full	54	India	CA
Maria Full	54	India	CA
Maria Full	54	India	CA
Maria Full	54	India	CA
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Mark Cage	38	India	CA
Mark Cage	38	India	CA
Mark Cage	38	India	CA
Mark Cage	38	India	CA
Mark Cage	38	India	CA
Mark Cage	38	India	CA
Mark Cage	38	India	CA
Mark Cage	38	India	CA
Mark Cage	38	India	TX
Mark Cage	38	India	TX
Mark Cage	38	India	TX
Mark Cage	38	India	TX
Mark Cage	38	India	TX
Mark Cage	38	India	TX
Mark Cage	38	India	TX
Mark Cage	38	India	TX
Mark Cage	38	USA	CA
Mark Cage	38	USA	CA
Mark Cage	38	USA	CA
Mark Cage	38	USA	CA
Mark Cage	38	USA	CA
Mark Cage	38	USA	CA
Mark Cage	38	USA	CA
Mark Cage	38	USA	CA
Mark Cage	38	USA	TX
Mark Cage	38	USA	TX
Mark Cage	38	USA	TX
Mark Cage	38	USA	TX
Mark Cage	38	USA	TX
Mark Cage	38	USA	TX
Mark Cage	38	USA	TX
Mark Cage	38	USA	TX
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mirna Cage	37	India	CA
Mirna Cage	37	India	CA
Mirna Cage	37	India	CA
Mirna Cage	37	India	CA
Mirna Cage	37	India	CA
Mirna Cage	37	India	CA
Mirna Cage	37	India	CA
Mirna Cage	37	India	CA
Mirna Cage	37	India	TX
Mirna Cage	37	India	TX
Mirna Cage	37	India	TX
Mirna Cage	37	India	TX
Mirna Cage	37	India	TX
Mirna Cage	37	India	TX
Mirna Cage	37	India	TX
Mirna Cage	37	India	TX
Mirna Cage	37	USA	CA
Mirna Cage	37	USA	CA
Mirna Cage	37	USA	CA
Mirna Cage	37	USA	CA
Mirna Cage	37	USA	CA
Mirna Cage	37	USA	CA
Mirna Cage	37	USA	CA
Mirna Cage	37	USA	CA
Mirna Cage	37	USA	TX
Mirna Cage	37	USA	TX
Mirna Cage	37	USA	TX
Mirna Cage	37	USA	TX
Mirna Cage	37	USA	TX
Mirna Cage	37	USA	TX
Mirna Cage	37	USA	TX
Mirna Cage	37	USA	TX
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
PREHOOK: query: create external table ice_parquet_date(
  bigintcol bigint,
  intcol integer
) partitioned by (pcol date)
stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_date
POSTHOOK: query: create external table ice_parquet_date(
  bigintcol bigint,
  intcol integer
) partitioned by (pcol date)
stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_date
PREHOOK: query: explain insert into table ice_parquet_date partition (pcol = '1999-12-31') values (1234567890123345, 2), (23456789012345678, 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
POSTHOOK: query: explain insert into table ice_parquet_date partition (pcol = '1999-12-31') values (1234567890123345, 2), (23456789012345678, 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(1234567890123345L,2),const struct(23456789012345678L,4)) (type: array<struct<col1:bigint,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: bigint), col2 (type: int), DATE'1999-12-31' (type: date)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_date
                        Select Operator
                          expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: date)
                          outputColumnNames: bigintcol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(bigintcol), max(bigintcol), count(1), count(bigintcol), compute_bit_vector_hll(bigintcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: date), _col10 (type: date), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), _col0 (type: bigint), _col1 (type: bigint), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DATE' (type: string), _col9 (type: date), _col10 (type: date), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_date

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: bigintcol, intcol, pcol
          Column Types: bigint, int, date
          Table: default.ice_parquet_date

PREHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-31') values (1234567890123345, 2), (23456789012345678, 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
POSTHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-31') values (1234567890123345, 2), (23456789012345678, 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
PREHOOK: query: explain insert into table ice_parquet_date partition (pcol = '1999-12-26') values (1234567890123345, 3), (23456789012345678, 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-26
POSTHOOK: query: explain insert into table ice_parquet_date partition (pcol = '1999-12-26') values (1234567890123345, 3), (23456789012345678, 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-26
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(1234567890123345L,3),const struct(23456789012345678L,5)) (type: array<struct<col1:bigint,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: bigint), col2 (type: int), DATE'1999-12-26' (type: date)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_date
                        Select Operator
                          expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: date)
                          outputColumnNames: bigintcol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(bigintcol), max(bigintcol), count(1), count(bigintcol), compute_bit_vector_hll(bigintcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: date), _col10 (type: date), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), _col0 (type: bigint), _col1 (type: bigint), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DATE' (type: string), _col9 (type: date), _col10 (type: date), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_date

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: bigintcol, intcol, pcol
          Column Types: bigint, int, date
          Table: default.ice_parquet_date

PREHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-26') values (1234567890123345, 3), (23456789012345678, 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-26
POSTHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-26') values (1234567890123345, 3), (23456789012345678, 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-26
PREHOOK: query: explain insert into table ice_parquet_date partition (pcol = '1999-12-12') values (3456789012345678, 4), (34567890123456789, 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-12
POSTHOOK: query: explain insert into table ice_parquet_date partition (pcol = '1999-12-12') values (3456789012345678, 4), (34567890123456789, 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-12
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(3456789012345678L,4),const struct(34567890123456789L,6)) (type: array<struct<col1:bigint,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: bigint), col2 (type: int), DATE'1999-12-12' (type: date)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_date
                        Select Operator
                          expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: date)
                          outputColumnNames: bigintcol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(bigintcol), max(bigintcol), count(1), count(bigintcol), compute_bit_vector_hll(bigintcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: date), _col10 (type: date), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), _col0 (type: bigint), _col1 (type: bigint), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DATE' (type: string), _col9 (type: date), _col10 (type: date), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_date

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: bigintcol, intcol, pcol
          Column Types: bigint, int, date
          Table: default.ice_parquet_date

PREHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-12') values (3456789012345678, 4), (34567890123456789, 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-12
POSTHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-12') values (3456789012345678, 4), (34567890123456789, 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-12
PREHOOK: query: select * from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: hdfs://### HDFS PATH ###
1234567890123345	2	1999-12-31
1234567890123345	3	1999-12-26
23456789012345678	4	1999-12-31
23456789012345678	5	1999-12-26
3456789012345678	4	1999-12-12
34567890123456789	6	1999-12-12
PREHOOK: query: explain insert into table ice_parquet_date partition (pcol = '1999-12-13') select bigintcol, intcol from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-13
POSTHOOK: query: explain insert into table ice_parquet_date partition (pcol = '1999-12-13') select bigintcol, intcol from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-13
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_date
                  Statistics: Num rows: 6 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: bigintcol (type: bigint), intcol (type: int), DATE'1999-12-13' (type: date)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_date
                    Select Operator
                      expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: date)
                      outputColumnNames: bigintcol, intcol, pcol
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(bigintcol), max(bigintcol), count(1), count(bigintcol), compute_bit_vector_hll(bigintcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        minReductionHashAggr: 0.8333333
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                        Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: date), _col10 (type: date), _col11 (type: bigint), _col12 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), _col0 (type: bigint), _col1 (type: bigint), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DATE' (type: string), _col9 (type: date), _col10 (type: date), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_date

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: bigintcol, intcol, pcol
          Column Types: bigint, int, date
          Table: default.ice_parquet_date

PREHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-13') select bigintcol, intcol from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-13
POSTHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-13') select bigintcol, intcol from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-13
PREHOOK: query: explain insert into table ice_parquet_date partition (pcol = '1999-12-02') select 234675894076895090, intcol from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-02
POSTHOOK: query: explain insert into table ice_parquet_date partition (pcol = '1999-12-02') select 234675894076895090, intcol from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-02
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_date
                  Statistics: Num rows: 12 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: 234675894076895090L (type: bigint), intcol (type: int), DATE'1999-12-02' (type: date)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 12 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 12 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_date
                    Select Operator
                      expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: date)
                      outputColumnNames: bigintcol, intcol, pcol
                      Statistics: Num rows: 12 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(bigintcol), max(bigintcol), count(1), count(bigintcol), compute_bit_vector_hll(bigintcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        minReductionHashAggr: 0.9166667
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                        Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: date), _col10 (type: date), _col11 (type: bigint), _col12 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), _col0 (type: bigint), _col1 (type: bigint), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DATE' (type: string), _col9 (type: date), _col10 (type: date), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_date

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: bigintcol, intcol, pcol
          Column Types: bigint, int, date
          Table: default.ice_parquet_date

PREHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-02') select 234675894076895090, intcol from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-02
POSTHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-02') select 234675894076895090, intcol from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-02
PREHOOK: query: describe formatted ice_parquet_string
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_string
POSTHOOK: query: describe formatted ice_parquet_string
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_string
# col_name            	data_type           	comment             
name                	string              	                    
age                 	int                 	                    
country             	string              	                    
state               	string              	                    
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
country             	IDENTITY            	 
state               	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"age\":\"true\",\"country\":\"true\",\"name\":\"true\",\"state\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"name\",\"required\":false,\"type\":\"string\"},{\"id\":2,\"name\":\"age\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"country\",\"required\":false,\"type\":\"string\"},{\"id\":4,\"name\":\"state\",\"required\":false,\"type\":\"string\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"added-data-files\":\"2\",\"added-records\":\"192\",\"added-files-size\":\"#Masked#\",\"changed-partition-count\":\"2\",\"total-records\":\"384\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"country\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000},{\"name\":\"state\",\"transform\":\"identity\",\"source-id\":4,\"field-id\":1001}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                  
	numRows             	384                 
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	9                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#               
#### A masked pattern was here ####
	uuid                	#Masked#
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: hdfs://### HDFS PATH ###
1234567890123345	2	1999-12-13
1234567890123345	2	1999-12-31
1234567890123345	3	1999-12-13
1234567890123345	3	1999-12-26
23456789012345678	4	1999-12-13
23456789012345678	4	1999-12-31
23456789012345678	5	1999-12-13
23456789012345678	5	1999-12-26
234675894076895090	2	1999-12-02
234675894076895090	2	1999-12-02
234675894076895090	3	1999-12-02
234675894076895090	3	1999-12-02
234675894076895090	4	1999-12-02
234675894076895090	4	1999-12-02
234675894076895090	4	1999-12-02
234675894076895090	4	1999-12-02
234675894076895090	5	1999-12-02
234675894076895090	5	1999-12-02
234675894076895090	6	1999-12-02
234675894076895090	6	1999-12-02
3456789012345678	4	1999-12-12
3456789012345678	4	1999-12-13
34567890123456789	6	1999-12-12
34567890123456789	6	1999-12-13
PREHOOK: query: create external table ice_parquet_bigint(
  datecol date,
  intcol integer
) partitioned by (pcol bigint)
stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_bigint
POSTHOOK: query: create external table ice_parquet_bigint(
  datecol date,
  intcol integer
) partitioned by (pcol bigint)
stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_bigint
PREHOOK: query: explain insert into table ice_parquet_bigint partition (pcol = 34567890123456787) values ('2022-08-07', 2), ('2022-08-09', 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
POSTHOOK: query: explain insert into table ice_parquet_bigint partition (pcol = 34567890123456787) values ('2022-08-07', 2), ('2022-08-09', 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-08-07',2),const struct('2022-08-09',4)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 34567890123456787L (type: bigint)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_bigint
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: bigint)
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: bigint), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'LONG' (type: string), _col9 (type: bigint), _col10 (type: bigint), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_bigint

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, bigint
          Table: default.ice_parquet_bigint

PREHOOK: query: insert into table ice_parquet_bigint partition (pcol = 34567890123456787) values ('2022-08-07', 2), ('2022-08-09', 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
POSTHOOK: query: insert into table ice_parquet_bigint partition (pcol = 34567890123456787) values ('2022-08-07', 2), ('2022-08-09', 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
PREHOOK: query: explain insert into table ice_parquet_bigint partition (pcol = 12346577399277578) values ('2022-08-16', 3), ('2022-07-09', 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
POSTHOOK: query: explain insert into table ice_parquet_bigint partition (pcol = 12346577399277578) values ('2022-08-16', 3), ('2022-07-09', 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-08-16',3),const struct('2022-07-09',5)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 12346577399277578L (type: bigint)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_bigint
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: bigint)
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: bigint), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'LONG' (type: string), _col9 (type: bigint), _col10 (type: bigint), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_bigint

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, bigint
          Table: default.ice_parquet_bigint

PREHOOK: query: insert into table ice_parquet_bigint partition (pcol = 12346577399277578) values ('2022-08-16', 3), ('2022-07-09', 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
POSTHOOK: query: insert into table ice_parquet_bigint partition (pcol = 12346577399277578) values ('2022-08-16', 3), ('2022-07-09', 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
PREHOOK: query: explain insert into table ice_parquet_bigint partition (pcol = 45637829068876994) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_bigint@pcol=45637829068876994
POSTHOOK: query: explain insert into table ice_parquet_bigint partition (pcol = 45637829068876994) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_bigint@pcol=45637829068876994
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-07-21',4),const struct('2022-05-29',6)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 45637829068876994L (type: bigint)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_bigint
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: bigint)
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: bigint), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'LONG' (type: string), _col9 (type: bigint), _col10 (type: bigint), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_bigint

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, bigint
          Table: default.ice_parquet_bigint

PREHOOK: query: insert into table ice_parquet_bigint partition (pcol = 45637829068876994) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_bigint@pcol=45637829068876994
POSTHOOK: query: insert into table ice_parquet_bigint partition (pcol = 45637829068876994) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_bigint@pcol=45637829068876994
PREHOOK: query: select * from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-05-29	6	45637829068876994
2022-07-09	5	12346577399277578
2022-07-21	4	45637829068876994
2022-08-07	2	34567890123456787
2022-08-09	4	34567890123456787
2022-08-16	3	12346577399277578
PREHOOK: query: explain insert into table ice_parquet_bigint partition (pcol = 45637829068876994) select datecol, intcol from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: default@ice_parquet_bigint@pcol=45637829068876994
POSTHOOK: query: explain insert into table ice_parquet_bigint partition (pcol = 45637829068876994) select datecol, intcol from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: default@ice_parquet_bigint@pcol=45637829068876994
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_bigint
                  Statistics: Num rows: 6 Data size: 360 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: datecol (type: date), intcol (type: int), 45637829068876994L (type: bigint)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_bigint
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: bigint)
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        minReductionHashAggr: 0.8333333
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                        Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: bigint), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'LONG' (type: string), _col9 (type: bigint), _col10 (type: bigint), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_bigint

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, bigint
          Table: default.ice_parquet_bigint

PREHOOK: query: insert into table ice_parquet_bigint partition (pcol = 45637829068876994) select datecol, intcol from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: default@ice_parquet_bigint@pcol=45637829068876994
POSTHOOK: query: insert into table ice_parquet_bigint partition (pcol = 45637829068876994) select datecol, intcol from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: default@ice_parquet_bigint@pcol=45637829068876994
PREHOOK: query: explain insert into table ice_parquet_bigint partition (pcol = 12346577399277578) select '2022-01-25', intcol from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
POSTHOOK: query: explain insert into table ice_parquet_bigint partition (pcol = 12346577399277578) select '2022-01-25', intcol from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_bigint
                  Statistics: Num rows: 12 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: DATE'2022-01-25' (type: date), intcol (type: int), 12346577399277578L (type: bigint)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 12 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 12 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_bigint
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: bigint)
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 12 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        minReductionHashAggr: 0.9166667
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                        Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: bigint), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'LONG' (type: string), _col9 (type: bigint), _col10 (type: bigint), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_bigint

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, bigint
          Table: default.ice_parquet_bigint

PREHOOK: query: insert into table ice_parquet_bigint partition (pcol = 12346577399277578) select '2022-01-25', intcol from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
POSTHOOK: query: insert into table ice_parquet_bigint partition (pcol = 12346577399277578) select '2022-01-25', intcol from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
PREHOOK: query: describe formatted ice_parquet_bigint
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_bigint
POSTHOOK: query: describe formatted ice_parquet_bigint
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_bigint
# col_name            	data_type           	comment             
datecol             	date                	                    
intcol              	int                 	                    
pcol                	bigint              	                    
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
pcol                	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"datecol\":\"true\",\"intcol\":\"true\",\"pcol\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"datecol\",\"required\":false,\"type\":\"date\"},{\"id\":2,\"name\":\"intcol\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"pcol\",\"required\":false,\"type\":\"long\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"added-data-files\":\"1\",\"added-records\":\"12\",\"added-files-size\":\"#Masked#\",\"changed-partition-count\":\"1\",\"total-records\":\"24\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"pcol\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                   
	numRows             	24                  
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	5                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#                
#### A masked pattern was here ####
	uuid                	#Masked#
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-01-25	2	12346577399277578
2022-01-25	2	12346577399277578
2022-01-25	3	12346577399277578
2022-01-25	3	12346577399277578
2022-01-25	4	12346577399277578
2022-01-25	4	12346577399277578
2022-01-25	4	12346577399277578
2022-01-25	4	12346577399277578
2022-01-25	5	12346577399277578
2022-01-25	5	12346577399277578
2022-01-25	6	12346577399277578
2022-01-25	6	12346577399277578
2022-05-29	6	45637829068876994
2022-05-29	6	45637829068876994
2022-07-09	5	12346577399277578
2022-07-09	5	45637829068876994
2022-07-21	4	45637829068876994
2022-07-21	4	45637829068876994
2022-08-07	2	34567890123456787
2022-08-07	2	45637829068876994
2022-08-09	4	34567890123456787
2022-08-09	4	45637829068876994
2022-08-16	3	12346577399277578
2022-08-16	3	45637829068876994
PREHOOK: query: create external table ice_parquet_double(
  datecol date,
  intcol integer
) partitioned by (pcol double)
stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_double
POSTHOOK: query: create external table ice_parquet_double(
  datecol date,
  intcol integer
) partitioned by (pcol double)
stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_double
PREHOOK: query: explain insert into table ice_parquet_double partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_double@pcol=3.14786
POSTHOOK: query: explain insert into table ice_parquet_double partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_double@pcol=3.14786
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-08-07',2),const struct('2022-08-09',4)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 3.14786D (type: double)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_double
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: double)
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: double), _col10 (type: double), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DOUBLE' (type: string), _col9 (type: double), _col10 (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_double

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, double
          Table: default.ice_parquet_double

PREHOOK: query: insert into table ice_parquet_double partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_double@pcol=3.14786
POSTHOOK: query: insert into table ice_parquet_double partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_double@pcol=3.14786
PREHOOK: query: explain insert into table ice_parquet_double partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_double@pcol=3.189
POSTHOOK: query: explain insert into table ice_parquet_double partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_double@pcol=3.189
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-08-16',3),const struct('2022-07-09',5)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 3.189D (type: double)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_double
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: double)
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: double), _col10 (type: double), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DOUBLE' (type: string), _col9 (type: double), _col10 (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_double

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, double
          Table: default.ice_parquet_double

PREHOOK: query: insert into table ice_parquet_double partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_double@pcol=3.189
POSTHOOK: query: insert into table ice_parquet_double partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_double@pcol=3.189
PREHOOK: query: explain insert into table ice_parquet_double partition (pcol = 45.789) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_double@pcol=45.789
POSTHOOK: query: explain insert into table ice_parquet_double partition (pcol = 45.789) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_double@pcol=45.789
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-07-21',4),const struct('2022-05-29',6)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 45.789D (type: double)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_double
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: double)
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: double), _col10 (type: double), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DOUBLE' (type: string), _col9 (type: double), _col10 (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_double

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, double
          Table: default.ice_parquet_double

PREHOOK: query: insert into table ice_parquet_double partition (pcol = 45.789) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_double@pcol=45.789
POSTHOOK: query: insert into table ice_parquet_double partition (pcol = 45.789) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_double@pcol=45.789
PREHOOK: query: select * from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-05-29	6	45.789
2022-07-09	5	3.189
2022-07-21	4	45.789
2022-08-07	2	3.14786
2022-08-09	4	3.14786
2022-08-16	3	3.189
PREHOOK: query: explain insert into table ice_parquet_double partition (pcol = 3.14786) select datecol, intcol from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: default@ice_parquet_double@pcol=3.14786
POSTHOOK: query: explain insert into table ice_parquet_double partition (pcol = 3.14786) select datecol, intcol from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: default@ice_parquet_double@pcol=3.14786
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_double
                  Statistics: Num rows: 6 Data size: 360 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: datecol (type: date), intcol (type: int), 3.14786D (type: double)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_double
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: double)
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        minReductionHashAggr: 0.8333333
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                        Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: double), _col10 (type: double), _col11 (type: bigint), _col12 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DOUBLE' (type: string), _col9 (type: double), _col10 (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_double

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, double
          Table: default.ice_parquet_double

PREHOOK: query: insert into table ice_parquet_double partition (pcol = 3.14786) select datecol, intcol from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: default@ice_parquet_double@pcol=3.14786
POSTHOOK: query: insert into table ice_parquet_double partition (pcol = 3.14786) select datecol, intcol from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: default@ice_parquet_double@pcol=3.14786
PREHOOK: query: explain insert into table ice_parquet_double partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: default@ice_parquet_double@pcol=3.189
POSTHOOK: query: explain insert into table ice_parquet_double partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: default@ice_parquet_double@pcol=3.189
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_double
                  Statistics: Num rows: 12 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: DATE'2022-01-25' (type: date), intcol (type: int), 3.189D (type: double)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 12 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 12 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_double
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: double)
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 12 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        minReductionHashAggr: 0.9166667
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                        Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: double), _col10 (type: double), _col11 (type: bigint), _col12 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DOUBLE' (type: string), _col9 (type: double), _col10 (type: double), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_double

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, double
          Table: default.ice_parquet_double

PREHOOK: query: insert into table ice_parquet_double partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: default@ice_parquet_double@pcol=3.189
POSTHOOK: query: insert into table ice_parquet_double partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: default@ice_parquet_double@pcol=3.189
PREHOOK: query: describe formatted ice_parquet_double
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_double
POSTHOOK: query: describe formatted ice_parquet_double
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_double
# col_name            	data_type           	comment             
datecol             	date                	                    
intcol              	int                 	                    
pcol                	double              	                    
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
pcol                	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"datecol\":\"true\",\"intcol\":\"true\",\"pcol\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"datecol\",\"required\":false,\"type\":\"date\"},{\"id\":2,\"name\":\"intcol\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"pcol\",\"required\":false,\"type\":\"double\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"added-data-files\":\"1\",\"added-records\":\"12\",\"added-files-size\":\"#Masked#\",\"changed-partition-count\":\"1\",\"total-records\":\"24\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"pcol\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                   
	numRows             	24                  
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	5                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#                
#### A masked pattern was here ####
	uuid                	#Masked#
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-01-25	2	3.189
2022-01-25	2	3.189
2022-01-25	3	3.189
2022-01-25	3	3.189
2022-01-25	4	3.189
2022-01-25	4	3.189
2022-01-25	4	3.189
2022-01-25	4	3.189
2022-01-25	5	3.189
2022-01-25	5	3.189
2022-01-25	6	3.189
2022-01-25	6	3.189
2022-05-29	6	3.14786
2022-05-29	6	45.789
2022-07-09	5	3.14786
2022-07-09	5	3.189
2022-07-21	4	3.14786
2022-07-21	4	45.789
2022-08-07	2	3.14786
2022-08-07	2	3.14786
2022-08-09	4	3.14786
2022-08-09	4	3.14786
2022-08-16	3	3.14786
2022-08-16	3	3.189
PREHOOK: query: create external table ice_parquet_decimal(
  datecol date,
  intcol integer
) partitioned by (pcol decimal(10,6))
stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_decimal
POSTHOOK: query: create external table ice_parquet_decimal(
  datecol date,
  intcol integer
) partitioned by (pcol decimal(10,6))
stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_decimal
PREHOOK: query: explain insert into table ice_parquet_decimal partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
POSTHOOK: query: explain insert into table ice_parquet_decimal partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-08-07',2),const struct('2022-08-09',4)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 3.14786 (type: decimal(10,6))
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_decimal
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: decimal(10,6))
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: decimal(10,6)), _col10 (type: decimal(10,6)), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DECIMAL' (type: string), _col9 (type: decimal(10,6)), _col10 (type: decimal(10,6)), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 1099 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1099 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_decimal

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, decimal(10,6)
          Table: default.ice_parquet_decimal

PREHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
POSTHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
PREHOOK: query: explain insert into table ice_parquet_decimal partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.189
POSTHOOK: query: explain insert into table ice_parquet_decimal partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.189
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-08-16',3),const struct('2022-07-09',5)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 3.189 (type: decimal(10,6))
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_decimal
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: decimal(10,6))
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: decimal(10,6)), _col10 (type: decimal(10,6)), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DECIMAL' (type: string), _col9 (type: decimal(10,6)), _col10 (type: decimal(10,6)), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 1099 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1099 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_decimal

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, decimal(10,6)
          Table: default.ice_parquet_decimal

PREHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.189
POSTHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.189
PREHOOK: query: explain insert into table ice_parquet_decimal partition (pcol = 45.789) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_decimal@pcol=45.789
POSTHOOK: query: explain insert into table ice_parquet_decimal partition (pcol = 45.789) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_decimal@pcol=45.789
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-07-21',4),const struct('2022-05-29',6)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 45.789 (type: decimal(10,6))
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_decimal
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: decimal(10,6))
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                            Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              null sort order: 
                              sort order: 
                              Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: decimal(10,6)), _col10 (type: decimal(10,6)), _col11 (type: bigint), _col12 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DECIMAL' (type: string), _col9 (type: decimal(10,6)), _col10 (type: decimal(10,6)), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 1099 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1099 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_decimal

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, decimal(10,6)
          Table: default.ice_parquet_decimal

PREHOOK: query: insert into table ice_parquet_decimal partition (pcol = 45.789) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_decimal@pcol=45.789
POSTHOOK: query: insert into table ice_parquet_decimal partition (pcol = 45.789) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_decimal@pcol=45.789
PREHOOK: query: select * from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-05-29	6	45.789000
2022-07-09	5	3.189000
2022-07-21	4	45.789000
2022-08-07	2	3.147860
2022-08-09	4	3.147860
2022-08-16	3	3.189000
PREHOOK: query: explain insert into table ice_parquet_decimal partition (pcol = 3.14786) select datecol, intcol from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
POSTHOOK: query: explain insert into table ice_parquet_decimal partition (pcol = 3.14786) select datecol, intcol from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_decimal
                  Statistics: Num rows: 6 Data size: 360 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: datecol (type: date), intcol (type: int), 3.14786 (type: decimal(10,6))
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 6 Data size: 1032 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 6 Data size: 1032 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_decimal
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: decimal(10,6))
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 6 Data size: 1032 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        minReductionHashAggr: 0.8333333
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                        Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: decimal(10,6)), _col10 (type: decimal(10,6)), _col11 (type: bigint), _col12 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DECIMAL' (type: string), _col9 (type: decimal(10,6)), _col10 (type: decimal(10,6)), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 1099 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1099 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_decimal

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, decimal(10,6)
          Table: default.ice_parquet_decimal

PREHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.14786) select datecol, intcol from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
POSTHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.14786) select datecol, intcol from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
PREHOOK: query: explain insert into table ice_parquet_decimal partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.189
POSTHOOK: query: explain insert into table ice_parquet_decimal partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.189
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_decimal
                  Statistics: Num rows: 12 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: DATE'2022-01-25' (type: date), intcol (type: int), 3.189 (type: decimal(10,6))
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 12 Data size: 2064 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 12 Data size: 2064 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_decimal
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: decimal(10,6))
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 12 Data size: 2064 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        minReductionHashAggr: 0.9166667
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                        Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: date), _col1 (type: date), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary), _col9 (type: decimal(10,6)), _col10 (type: decimal(10,6)), _col11 (type: bigint), _col12 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Statistics: Num rows: 1 Data size: 808 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col0 (type: date), _col1 (type: date), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary), 'DECIMAL' (type: string), _col9 (type: decimal(10,6)), _col10 (type: decimal(10,6)), (_col2 - _col11) (type: bigint), COALESCE(ndv_compute_bit_vector(_col12),0) (type: bigint), _col12 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                  Statistics: Num rows: 1 Data size: 1099 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1099 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_decimal

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, decimal(10,6)
          Table: default.ice_parquet_decimal

PREHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.189
POSTHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.189
PREHOOK: query: describe formatted ice_parquet_decimal
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_decimal
POSTHOOK: query: describe formatted ice_parquet_decimal
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_decimal
# col_name            	data_type           	comment             
datecol             	date                	                    
intcol              	int                 	                    
pcol                	decimal(10,6)       	                    
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
pcol                	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"datecol\":\"true\",\"intcol\":\"true\",\"pcol\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"datecol\",\"required\":false,\"type\":\"date\"},{\"id\":2,\"name\":\"intcol\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"pcol\",\"required\":false,\"type\":\"decimal(10, 6)\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"added-data-files\":\"1\",\"added-records\":\"12\",\"added-files-size\":\"#Masked#\",\"changed-partition-count\":\"1\",\"total-records\":\"24\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"pcol\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                   
	numRows             	24                  
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	5                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#                
#### A masked pattern was here ####
	uuid                	#Masked#
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-01-25	2	3.189000
2022-01-25	2	3.189000
2022-01-25	3	3.189000
2022-01-25	3	3.189000
2022-01-25	4	3.189000
2022-01-25	4	3.189000
2022-01-25	4	3.189000
2022-01-25	4	3.189000
2022-01-25	5	3.189000
2022-01-25	5	3.189000
2022-01-25	6	3.189000
2022-01-25	6	3.189000
2022-05-29	6	3.147860
2022-05-29	6	45.789000
2022-07-09	5	3.147860
2022-07-09	5	3.189000
2022-07-21	4	3.147860
2022-07-21	4	45.789000
2022-08-07	2	3.147860
2022-08-07	2	3.147860
2022-08-09	4	3.147860
2022-08-09	4	3.147860
2022-08-16	3	3.147860
2022-08-16	3	3.189000
PREHOOK: query: drop table ice_parquet_int
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_int
POSTHOOK: query: drop table ice_parquet_int
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_int
PREHOOK: query: drop table ice_parquet_bigint
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_bigint
POSTHOOK: query: drop table ice_parquet_bigint
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_bigint
PREHOOK: query: drop table ice_parquet_string
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: drop table ice_parquet_string
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_string
PREHOOK: query: drop table ice_parquet_date
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_date
POSTHOOK: query: drop table ice_parquet_date
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_date
PREHOOK: query: drop table ice_parquet_decimal
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_decimal
POSTHOOK: query: drop table ice_parquet_decimal
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_decimal
PREHOOK: query: drop table ice_parquet_double
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_double
POSTHOOK: query: drop table ice_parquet_double
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_double
