PREHOOK: query: drop table if exists tbl_orc
PREHOOK: type: DROPTABLE
PREHOOK: Output: database:default
POSTHOOK: query: drop table if exists tbl_orc
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: database:default
PREHOOK: query: create external table tbl_orc(a int) partitioned by (b string) stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl_orc
POSTHOOK: query: create external table tbl_orc(a int) partitioned by (b string) stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl_orc
PREHOOK: query: describe formatted tbl_orc
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tbl_orc
POSTHOOK: query: describe formatted tbl_orc
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tbl_orc
# col_name            	data_type           	comment             
a                   	int                 	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
b                   	string              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\"}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	numFiles            	0                   
	numPartitions       	0                   
	numRows             	0                   
	rawDataSize         	0                   
	totalSize           	#Masked#
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: insert into table tbl_orc partition (b='one') values (1), (2), (3)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_orc@b=one
POSTHOOK: query: insert into table tbl_orc partition (b='one') values (1), (2), (3)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_orc@b=one
POSTHOOK: Lineage: tbl_orc PARTITION(b=one).a SCRIPT []
PREHOOK: query: insert into table tbl_orc partition (b='two') values (4), (5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_orc@b=two
POSTHOOK: query: insert into table tbl_orc partition (b='two') values (4), (5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_orc@b=two
POSTHOOK: Lineage: tbl_orc PARTITION(b=two).a SCRIPT []
PREHOOK: query: insert into table tbl_orc partition (b='three') values (6), (7), (8)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_orc@b=three
POSTHOOK: query: insert into table tbl_orc partition (b='three') values (6), (7), (8)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_orc@b=three
POSTHOOK: Lineage: tbl_orc PARTITION(b=three).a SCRIPT []
PREHOOK: query: insert into table tbl_orc partition (b='four') values (9)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_orc@b=four
POSTHOOK: query: insert into table tbl_orc partition (b='four') values (9)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_orc@b=four
POSTHOOK: Lineage: tbl_orc PARTITION(b=four).a SCRIPT []
PREHOOK: query: select * from tbl_orc order by a
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl_orc
PREHOOK: Input: default@tbl_orc@b=four
PREHOOK: Input: default@tbl_orc@b=one
PREHOOK: Input: default@tbl_orc@b=three
PREHOOK: Input: default@tbl_orc@b=two
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from tbl_orc order by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl_orc
POSTHOOK: Input: default@tbl_orc@b=four
POSTHOOK: Input: default@tbl_orc@b=one
POSTHOOK: Input: default@tbl_orc@b=three
POSTHOOK: Input: default@tbl_orc@b=two
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	one
2	one
3	one
4	two
5	two
6	three
7	three
8	three
9	four
PREHOOK: query: explain alter table tbl_orc convert to iceberg
PREHOOK: type: ALTERTABLE_CONVERT
PREHOOK: Input: default@tbl_orc
POSTHOOK: query: explain alter table tbl_orc convert to iceberg
POSTHOOK: type: ALTERTABLE_CONVERT
POSTHOOK: Input: default@tbl_orc
Stage-0
  Convert operation{"table name:":"default.tbl_orc","spec:":"AlterTableConvertSpec{ConvertTo=iceberg, TBLProperties={}}"}

PREHOOK: query: alter table tbl_orc convert to iceberg
PREHOOK: type: ALTERTABLE_CONVERT
PREHOOK: Input: default@tbl_orc
POSTHOOK: query: alter table tbl_orc convert to iceberg
POSTHOOK: type: ALTERTABLE_CONVERT
POSTHOOK: Input: default@tbl_orc
POSTHOOK: Output: default@tbl_orc
PREHOOK: query: describe formatted tbl_orc
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tbl_orc
POSTHOOK: query: describe formatted tbl_orc
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tbl_orc
# col_name            	data_type           	comment             
a                   	int                 	                    
b                   	string              	                    
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
b                   	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	EXTERNAL            	TRUE                
	MIGRATED_TO_ICEBERG 	true                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"a\",\"required\":false,\"type\":\"int\"},{\"id\":2,\"name\":\"b\",\"required\":false,\"type\":\"string\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"added-data-files\":\"4\",\"added-records\":\"9\",\"added-files-size\":\"#Masked#\",\"changed-partition-count\":\"4\",\"total-records\":\"9\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"4\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"b\",\"transform\":\"identity\",\"source-id\":2,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	true                
#### A masked pattern was here ####
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	4                   
	numRows             	9                   
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	schema.name-mapping.default	[ {                 
	                           	  \"field-id\" : 1, 
	                           	  \"names\" : [ \"a\" ]
	                           	}, {                
	                           	  \"field-id\" : 2, 
	                           	  \"names\" : [ \"b\" ]
	                           	} ]                 
	snapshot-count      	1                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#
#### A masked pattern was here ####
	uuid                	#Masked#
	write.format.default	orc                 
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from tbl_orc order by a
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl_orc
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from tbl_orc order by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl_orc
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	one
2	one
3	one
4	two
5	two
6	three
7	three
8	three
9	four
PREHOOK: query: drop table tbl_orc
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tbl_orc
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl_orc
POSTHOOK: query: drop table tbl_orc
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tbl_orc
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl_orc
PREHOOK: query: drop table if exists tbl_parquet
PREHOOK: type: DROPTABLE
PREHOOK: Output: database:default
POSTHOOK: query: drop table if exists tbl_parquet
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: database:default
PREHOOK: query: create external table tbl_parquet(a int) partitioned by (b string) stored as parquet
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl_parquet
POSTHOOK: query: create external table tbl_parquet(a int) partitioned by (b string) stored as parquet
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl_parquet
PREHOOK: query: describe formatted tbl_parquet
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tbl_parquet
POSTHOOK: query: describe formatted tbl_parquet
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tbl_parquet
# col_name            	data_type           	comment             
a                   	int                 	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
b                   	string              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\"}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	numFiles            	0                   
	numPartitions       	0                   
	numRows             	0                   
	rawDataSize         	0                   
	totalSize           	#Masked#
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe	 
InputFormat:        	org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: insert into table tbl_parquet partition (b='one') values (1), (2), (3)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_parquet@b=one
POSTHOOK: query: insert into table tbl_parquet partition (b='one') values (1), (2), (3)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_parquet@b=one
POSTHOOK: Lineage: tbl_parquet PARTITION(b=one).a SCRIPT []
PREHOOK: query: insert into table tbl_parquet partition (b='two') values (4), (5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_parquet@b=two
POSTHOOK: query: insert into table tbl_parquet partition (b='two') values (4), (5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_parquet@b=two
POSTHOOK: Lineage: tbl_parquet PARTITION(b=two).a SCRIPT []
PREHOOK: query: insert into table tbl_parquet partition (b='three') values (6), (7), (8)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_parquet@b=three
POSTHOOK: query: insert into table tbl_parquet partition (b='three') values (6), (7), (8)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_parquet@b=three
POSTHOOK: Lineage: tbl_parquet PARTITION(b=three).a SCRIPT []
PREHOOK: query: insert into table tbl_parquet partition (b='four') values (9)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_parquet@b=four
POSTHOOK: query: insert into table tbl_parquet partition (b='four') values (9)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_parquet@b=four
POSTHOOK: Lineage: tbl_parquet PARTITION(b=four).a SCRIPT []
PREHOOK: query: select * from tbl_parquet order by a
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl_parquet
PREHOOK: Input: default@tbl_parquet@b=four
PREHOOK: Input: default@tbl_parquet@b=one
PREHOOK: Input: default@tbl_parquet@b=three
PREHOOK: Input: default@tbl_parquet@b=two
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from tbl_parquet order by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl_parquet
POSTHOOK: Input: default@tbl_parquet@b=four
POSTHOOK: Input: default@tbl_parquet@b=one
POSTHOOK: Input: default@tbl_parquet@b=three
POSTHOOK: Input: default@tbl_parquet@b=two
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	one
2	one
3	one
4	two
5	two
6	three
7	three
8	three
9	four
PREHOOK: query: explain alter table tbl_parquet convert to iceberg
PREHOOK: type: ALTERTABLE_CONVERT
PREHOOK: Input: default@tbl_parquet
POSTHOOK: query: explain alter table tbl_parquet convert to iceberg
POSTHOOK: type: ALTERTABLE_CONVERT
POSTHOOK: Input: default@tbl_parquet
Stage-0
  Convert operation{"table name:":"default.tbl_parquet","spec:":"AlterTableConvertSpec{ConvertTo=iceberg, TBLProperties={}}"}

PREHOOK: query: alter table tbl_parquet convert to iceberg
PREHOOK: type: ALTERTABLE_CONVERT
PREHOOK: Input: default@tbl_parquet
POSTHOOK: query: alter table tbl_parquet convert to iceberg
POSTHOOK: type: ALTERTABLE_CONVERT
POSTHOOK: Input: default@tbl_parquet
POSTHOOK: Output: default@tbl_parquet
PREHOOK: query: describe formatted tbl_parquet
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tbl_parquet
POSTHOOK: query: describe formatted tbl_parquet
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tbl_parquet
# col_name            	data_type           	comment             
a                   	int                 	                    
b                   	string              	                    
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
b                   	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	EXTERNAL            	TRUE                
	MIGRATED_TO_ICEBERG 	true                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"a\",\"required\":false,\"type\":\"int\"},{\"id\":2,\"name\":\"b\",\"required\":false,\"type\":\"string\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"added-data-files\":\"4\",\"added-records\":\"9\",\"added-files-size\":\"#Masked#\",\"changed-partition-count\":\"4\",\"total-records\":\"9\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"4\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"b\",\"transform\":\"identity\",\"source-id\":2,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
#### A masked pattern was here ####
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	4                   
	numRows             	9                   
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	schema.name-mapping.default	[ {                 
	                           	  \"field-id\" : 1, 
	                           	  \"names\" : [ \"a\" ]
	                           	}, {                
	                           	  \"field-id\" : 2, 
	                           	  \"names\" : [ \"b\" ]
	                           	} ]                 
	snapshot-count      	1                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#
#### A masked pattern was here ####
	uuid                	#Masked#
	write.format.default	parquet             
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from tbl_parquet order by a
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl_parquet
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from tbl_parquet order by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl_parquet
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	one
2	one
3	one
4	two
5	two
6	three
7	three
8	three
9	four
PREHOOK: query: drop table tbl_parquet
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tbl_parquet
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl_parquet
POSTHOOK: query: drop table tbl_parquet
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tbl_parquet
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl_parquet
PREHOOK: query: drop table if exists tbl_avro
PREHOOK: type: DROPTABLE
PREHOOK: Output: database:default
POSTHOOK: query: drop table if exists tbl_avro
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: database:default
PREHOOK: query: create external table tbl_avro(a int) partitioned by (b string) stored as avro
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl_avro
POSTHOOK: query: create external table tbl_avro(a int) partitioned by (b string) stored as avro
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl_avro
PREHOOK: query: describe formatted tbl_avro
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tbl_avro
POSTHOOK: query: describe formatted tbl_avro
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tbl_avro
# col_name            	data_type           	comment             
a                   	int                 	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
b                   	string              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\"}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	numFiles            	0                   
	numPartitions       	0                   
	numRows             	0                   
	rawDataSize         	0                   
	totalSize           	#Masked#
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.avro.AvroSerDe	 
InputFormat:        	org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: insert into table tbl_avro partition (b='one') values (1), (2), (3)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_avro@b=one
POSTHOOK: query: insert into table tbl_avro partition (b='one') values (1), (2), (3)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_avro@b=one
POSTHOOK: Lineage: tbl_avro PARTITION(b=one).a SCRIPT []
PREHOOK: query: insert into table tbl_avro partition (b='two') values (4), (5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_avro@b=two
POSTHOOK: query: insert into table tbl_avro partition (b='two') values (4), (5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_avro@b=two
POSTHOOK: Lineage: tbl_avro PARTITION(b=two).a SCRIPT []
PREHOOK: query: insert into table tbl_avro partition (b='three') values (6), (7), (8)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_avro@b=three
POSTHOOK: query: insert into table tbl_avro partition (b='three') values (6), (7), (8)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_avro@b=three
POSTHOOK: Lineage: tbl_avro PARTITION(b=three).a SCRIPT []
PREHOOK: query: insert into table tbl_avro partition (b='four') values (9)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl_avro@b=four
POSTHOOK: query: insert into table tbl_avro partition (b='four') values (9)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl_avro@b=four
POSTHOOK: Lineage: tbl_avro PARTITION(b=four).a SCRIPT []
PREHOOK: query: select * from tbl_avro order by a
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl_avro
PREHOOK: Input: default@tbl_avro@b=four
PREHOOK: Input: default@tbl_avro@b=one
PREHOOK: Input: default@tbl_avro@b=three
PREHOOK: Input: default@tbl_avro@b=two
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from tbl_avro order by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl_avro
POSTHOOK: Input: default@tbl_avro@b=four
POSTHOOK: Input: default@tbl_avro@b=one
POSTHOOK: Input: default@tbl_avro@b=three
POSTHOOK: Input: default@tbl_avro@b=two
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	one
2	one
3	one
4	two
5	two
6	three
7	three
8	three
9	four
PREHOOK: query: explain alter table tbl_avro convert to iceberg
PREHOOK: type: ALTERTABLE_CONVERT
PREHOOK: Input: default@tbl_avro
POSTHOOK: query: explain alter table tbl_avro convert to iceberg
POSTHOOK: type: ALTERTABLE_CONVERT
POSTHOOK: Input: default@tbl_avro
Stage-0
  Convert operation{"table name:":"default.tbl_avro","spec:":"AlterTableConvertSpec{ConvertTo=iceberg, TBLProperties={}}"}

PREHOOK: query: alter table tbl_avro convert to iceberg
PREHOOK: type: ALTERTABLE_CONVERT
PREHOOK: Input: default@tbl_avro
POSTHOOK: query: alter table tbl_avro convert to iceberg
POSTHOOK: type: ALTERTABLE_CONVERT
POSTHOOK: Input: default@tbl_avro
POSTHOOK: Output: default@tbl_avro
PREHOOK: query: describe formatted tbl_avro
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tbl_avro
POSTHOOK: query: describe formatted tbl_avro
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tbl_avro
# col_name            	data_type           	comment             
a                   	int                 	                    
b                   	string              	                    
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
b                   	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	EXTERNAL            	TRUE                
	MIGRATED_TO_ICEBERG 	true                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"a\",\"required\":false,\"type\":\"int\"},{\"id\":2,\"name\":\"b\",\"required\":false,\"type\":\"string\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"added-data-files\":\"4\",\"added-records\":\"9\",\"added-files-size\":\"#Masked#\",\"changed-partition-count\":\"4\",\"total-records\":\"9\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"4\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"b\",\"transform\":\"identity\",\"source-id\":2,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
#### A masked pattern was here ####
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	4                   
	numRows             	9                   
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	schema.name-mapping.default	[ {                 
	                           	  \"field-id\" : 1, 
	                           	  \"names\" : [ \"a\" ]
	                           	}, {                
	                           	  \"field-id\" : 2, 
	                           	  \"names\" : [ \"b\" ]
	                           	} ]                 
	snapshot-count      	1                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#
#### A masked pattern was here ####
	uuid                	#Masked#
	write.format.default	avro                
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from tbl_avro order by a
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl_avro
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from tbl_avro order by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl_avro
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	one
2	one
3	one
4	two
5	two
6	three
7	three
8	three
9	four
PREHOOK: query: drop table tbl_avro
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tbl_avro
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl_avro
POSTHOOK: query: drop table tbl_avro
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tbl_avro
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl_avro
