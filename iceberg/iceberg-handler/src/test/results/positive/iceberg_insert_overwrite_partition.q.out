PREHOOK: query: create external table ice_parquet_int(
  strcol string,
  intcol integer
) partitioned by (pcol int)
stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_int
POSTHOOK: query: create external table ice_parquet_int(
  strcol string,
  intcol integer
) partitioned by (pcol int)
stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_int
PREHOOK: query: insert into table ice_parquet_int partition(pcol = 1) values ('ABC', 1), ('DEF', 2)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_int@pcol=1
POSTHOOK: query: insert into table ice_parquet_int partition(pcol = 1) values ('ABC', 1), ('DEF', 2)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_int@pcol=1
PREHOOK: query: insert into table ice_parquet_int partition(pcol = 2) values ('GHI', 3), ('JKL', 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_int@pcol=2
POSTHOOK: query: insert into table ice_parquet_int partition(pcol = 2) values ('GHI', 3), ('JKL', 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_int@pcol=2
PREHOOK: query: explain insert overwrite table ice_parquet_int partition(pcol = 1) select strcol, intcol from ice_parquet_int where pcol = 2
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: default@ice_parquet_int@pcol=1
POSTHOOK: query: explain insert overwrite table ice_parquet_int partition(pcol = 1) select strcol, intcol from ice_parquet_int where pcol = 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: default@ice_parquet_int@pcol=1
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_int
                  filterExpr: (pcol = 2) (type: boolean)
                  Statistics: Num rows: 2 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: strcol (type: string), intcol (type: int), 1 (type: int)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 2 Data size: 190 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 2 Data size: 190 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_int
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: int)
                      outputColumnNames: strcol, intcol, pcol
                      Statistics: Num rows: 2 Data size: 190 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(strcol)), avg(COALESCE(length(strcol),0)), count(1), count(strcol), compute_bit_vector_hll(strcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        keys: pcol (type: int)
                        minReductionHashAggr: 0.5
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                        Statistics: Num rows: 1 Data size: 564 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 1 Data size: 564 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: int), _col2 (type: struct<count:bigint,sum:double,input:int>), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: int), _col11 (type: int), _col12 (type: bigint), _col13 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 496 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col1,0)) (type: bigint), COALESCE(_col2,0) (type: double), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), UDFToLong(_col10) (type: bigint), UDFToLong(_col11) (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:int>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 838 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 838 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 1
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_int

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: strcol, intcol, pcol
          Column Types: string, int, int
          Table: default.ice_parquet_int

PREHOOK: query: insert overwrite table ice_parquet_int partition(pcol = 1) select strcol, intcol from ice_parquet_int where pcol = 2
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: default@ice_parquet_int@pcol=1
POSTHOOK: query: insert overwrite table ice_parquet_int partition(pcol = 1) select strcol, intcol from ice_parquet_int where pcol = 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: default@ice_parquet_int@pcol=1
PREHOOK: query: explain insert overwrite table ice_parquet_int partition(pcol = 1) select strcol, intcol from ice_parquet_int where pcol = 2
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: default@ice_parquet_int@pcol=1
POSTHOOK: query: explain insert overwrite table ice_parquet_int partition(pcol = 1) select strcol, intcol from ice_parquet_int where pcol = 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: default@ice_parquet_int@pcol=1
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_int
                  filterExpr: (pcol = 2) (type: boolean)
                  Statistics: Num rows: 2 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: strcol (type: string), intcol (type: int), 1 (type: int)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 2 Data size: 190 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 2 Data size: 190 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_int
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: int)
                      outputColumnNames: strcol, intcol, pcol
                      Statistics: Num rows: 2 Data size: 190 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(strcol)), avg(COALESCE(length(strcol),0)), count(1), count(strcol), compute_bit_vector_hll(strcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        keys: pcol (type: int)
                        minReductionHashAggr: 0.5
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                        Statistics: Num rows: 1 Data size: 564 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 1 Data size: 564 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: int), _col2 (type: struct<count:bigint,sum:double,input:int>), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: int), _col11 (type: int), _col12 (type: bigint), _col13 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 496 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col1,0)) (type: bigint), COALESCE(_col2,0) (type: double), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), UDFToLong(_col10) (type: bigint), UDFToLong(_col11) (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:int>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 838 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 838 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 1
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_int

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: strcol, intcol, pcol
          Column Types: string, int, int
          Table: default.ice_parquet_int

PREHOOK: query: insert overwrite table ice_parquet_int partition(pcol = 01) select strcol, intcol from ice_parquet_int where pcol = 2
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: default@ice_parquet_int@pcol=01
POSTHOOK: query: insert overwrite table ice_parquet_int partition(pcol = 01) select strcol, intcol from ice_parquet_int where pcol = 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: default@ice_parquet_int@pcol=01
PREHOOK: query: describe formatted ice_parquet_int
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_int
POSTHOOK: query: describe formatted ice_parquet_int
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_int
# col_name            	data_type           	comment             
strcol              	string              	                    
intcol              	int                 	                    
pcol                	int                 	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
pcol                	int                 	Transform: identity 
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
pcol                	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"intcol\":\"true\",\"pcol\":\"true\",\"strcol\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"strcol\",\"required\":false,\"type\":\"string\"},{\"id\":2,\"name\":\"intcol\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"pcol\",\"required\":false,\"type\":\"int\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"replace-partitions\":\"true\",\"added-data-files\":\"1\",\"deleted-data-files\":\"1\",\"added-records\":\"2\",\"deleted-records\":\"2\",\"added-files-size\":\"#Masked#\",\"removed-files-size\":\"#Masked#\",\"changed-partition-count\":\"1\",\"total-records\":\"4\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\",\"iceberg-version\":\"#Masked#\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"pcol\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                   
	numPartitions       	2                   
	numRows             	4                   
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	4                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#
#### A masked pattern was here ####
	uuid                	#Masked#
	write.delete.mode   	merge-on-read       
	write.merge.mode    	merge-on-read       
	write.metadata.delete-after-commit.enabled	true                
	write.update.mode   	merge-on-read       
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_int
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_int
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: hdfs://### HDFS PATH ###
GHI	3	1
GHI	3	2
JKL	4	1
JKL	4	2
PREHOOK: query: create table ice_parquet_string (name string, age int) partitioned by (country string, state string) stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: create table ice_parquet_string (name string, age int) partitioned by (country string, state string) stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_string
PREHOOK: query: insert into ice_parquet_string partition (state='CA', country='USA') values ('John Doe', 23), ('Jane Doe', 22)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_string@country=USA/state=CA
POSTHOOK: query: insert into ice_parquet_string partition (state='CA', country='USA') values ('John Doe', 23), ('Jane Doe', 22)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_string@country=USA/state=CA
PREHOOK: query: explain insert overwrite table ice_parquet_string partition (country='USA', state='CA') values ('Mark Cage', 38), ('Mirna Cage', 37)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_string@country=USA/state=CA
POSTHOOK: query: explain insert overwrite table ice_parquet_string partition (country='USA', state='CA') values ('Mark Cage', 38), ('Mirna Cage', 37)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_string@country=USA/state=CA
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('Mark Cage',38),const struct('Mirna Cage',37)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int), 'USA' (type: string), 'CA' (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_string
                        Select Operator
                          expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                          outputColumnNames: name, age, country, state
                          Statistics: Num rows: 1 Data size: 173 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                            keys: country (type: string), state (type: string)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                            Statistics: Num rows: 1 Data size: 1037 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              key expressions: _col0 (type: string), _col1 (type: string)
                              null sort order: zz
                              sort order: ++
                              Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                              Statistics: Num rows: 1 Data size: 1037 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col2 (type: int), _col3 (type: struct<count:bigint,sum:double,input:int>), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: int), _col12 (type: struct<count:bigint,sum:double,input:int>), _col13 (type: bigint), _col14 (type: binary), _col15 (type: int), _col16 (type: struct<count:bigint,sum:double,input:int>), _col17 (type: bigint), _col18 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 1 Data size: 833 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col2,0)) (type: bigint), COALESCE(_col3,0) (type: double), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col11,0)) (type: bigint), COALESCE(_col12,0) (type: double), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col15,0)) (type: bigint), COALESCE(_col16,0) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), named_struct('country',_col0,'state',_col1) (type: struct<country:string,state:string>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            country USA
            state CA
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert overwrite table ice_parquet_string partition (country='USA', state='CA') values ('Mark Cage', 38), ('Mirna Cage', 37)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_string@country=USA/state=CA
POSTHOOK: query: insert overwrite table ice_parquet_string partition (country='USA', state='CA') values ('Mark Cage', 38), ('Mirna Cage', 37)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_string@country=USA/state=CA
PREHOOK: query: insert into ice_parquet_string partition (country='USA', state='TX') values ('Bill Rose', 52), ('Maria Full', 50)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_string@country=USA/state=TX
POSTHOOK: query: insert into ice_parquet_string partition (country='USA', state='TX') values ('Bill Rose', 52), ('Maria Full', 50)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_string@country=USA/state=TX
PREHOOK: query: select * from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: hdfs://### HDFS PATH ###
Bill Rose	52	USA	TX
Maria Full	50	USA	TX
Mark Cage	38	USA	CA
Mirna Cage	37	USA	CA
PREHOOK: query: explain insert overwrite table ice_parquet_string partition(country, state) select * from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: explain insert overwrite table ice_parquet_string partition(country, state) select * from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), age (type: int), country (type: string), state (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        keys: country (type: string), state (type: string)
                        minReductionHashAggr: 0.75
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                        Statistics: Num rows: 1 Data size: 1037 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: string)
                          null sort order: zz
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                          Statistics: Num rows: 1 Data size: 1037 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col2 (type: int), _col3 (type: struct<count:bigint,sum:double,input:int>), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: int), _col12 (type: struct<count:bigint,sum:double,input:int>), _col13 (type: bigint), _col14 (type: binary), _col15 (type: int), _col16 (type: struct<count:bigint,sum:double,input:int>), _col17 (type: bigint), _col18 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 1 Data size: 833 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col2,0)) (type: bigint), COALESCE(_col3,0) (type: double), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col11,0)) (type: bigint), COALESCE(_col12,0) (type: double), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col15,0)) (type: bigint), COALESCE(_col16,0) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), named_struct('country',_col0,'state',_col1) (type: struct<country:string,state:string>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert overwrite table ice_parquet_string partition(country, state) select * from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: insert overwrite table ice_parquet_string partition(country, state) select * from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
PREHOOK: query: explain insert overwrite table ice_parquet_string partition(country='USA', state) select name, age, state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: explain insert overwrite table ice_parquet_string partition(country='USA', state) select name, age, state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 4 Data size: 736 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), age (type: int), 'USA' (type: string), state (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        keys: country (type: string), state (type: string)
                        minReductionHashAggr: 0.75
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                        Statistics: Num rows: 1 Data size: 1037 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: string)
                          null sort order: zz
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                          Statistics: Num rows: 1 Data size: 1037 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col2 (type: int), _col3 (type: struct<count:bigint,sum:double,input:int>), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: int), _col12 (type: struct<count:bigint,sum:double,input:int>), _col13 (type: bigint), _col14 (type: binary), _col15 (type: int), _col16 (type: struct<count:bigint,sum:double,input:int>), _col17 (type: bigint), _col18 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 1 Data size: 833 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col2,0)) (type: bigint), COALESCE(_col3,0) (type: double), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col11,0)) (type: bigint), COALESCE(_col12,0) (type: double), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col15,0)) (type: bigint), COALESCE(_col16,0) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), named_struct('country',_col0,'state',_col1) (type: struct<country:string,state:string>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert overwrite table ice_parquet_string partition(country='USA', state) select name, age, state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: insert overwrite table ice_parquet_string partition(country='USA', state) select name, age, state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
PREHOOK: query: explain insert overwrite table ice_parquet_string partition(state='CA', country) select name, age, country from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: explain insert overwrite table ice_parquet_string partition(state='CA', country) select name, age, country from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 4 Data size: 740 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), age (type: int), country (type: string), 'CA' (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        keys: country (type: string), state (type: string)
                        minReductionHashAggr: 0.75
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                        Statistics: Num rows: 1 Data size: 1037 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: string)
                          null sort order: zz
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                          Statistics: Num rows: 1 Data size: 1037 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col2 (type: int), _col3 (type: struct<count:bigint,sum:double,input:int>), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: int), _col12 (type: struct<count:bigint,sum:double,input:int>), _col13 (type: bigint), _col14 (type: binary), _col15 (type: int), _col16 (type: struct<count:bigint,sum:double,input:int>), _col17 (type: bigint), _col18 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 4 Data size: 1084 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 1 Data size: 833 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col2,0)) (type: bigint), COALESCE(_col3,0) (type: double), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col11,0)) (type: bigint), COALESCE(_col12,0) (type: double), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col15,0)) (type: bigint), COALESCE(_col16,0) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), named_struct('country',_col0,'state',_col1) (type: struct<country:string,state:string>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert overwrite table ice_parquet_string partition(state='CA', country) select name, age, country from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: insert overwrite table ice_parquet_string partition(state='CA', country) select name, age, country from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string
PREHOOK: query: explain insert overwrite table ice_parquet_string partition(state='TX') select name, age, country from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@state=TX
POSTHOOK: query: explain insert overwrite table ice_parquet_string partition(state='TX') select name, age, country from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@state=TX
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 6 Data size: 1110 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), age (type: int), country (type: string), 'TX' (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 6 Data size: 1626 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 6 Data size: 1626 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 6 Data size: 1626 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        keys: country (type: string), state (type: string)
                        minReductionHashAggr: 0.8333333
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                        Statistics: Num rows: 1 Data size: 1037 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: string)
                          null sort order: zz
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                          Statistics: Num rows: 1 Data size: 1037 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col2 (type: int), _col3 (type: struct<count:bigint,sum:double,input:int>), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: int), _col12 (type: struct<count:bigint,sum:double,input:int>), _col13 (type: bigint), _col14 (type: binary), _col15 (type: int), _col16 (type: struct<count:bigint,sum:double,input:int>), _col17 (type: bigint), _col18 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 6 Data size: 1626 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 1 Data size: 833 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col2,0)) (type: bigint), COALESCE(_col3,0) (type: double), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col11,0)) (type: bigint), COALESCE(_col12,0) (type: double), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col15,0)) (type: bigint), COALESCE(_col16,0) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), named_struct('country',_col0,'state',_col1) (type: struct<country:string,state:string>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            state TX
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert overwrite table ice_parquet_string partition(state='TX') select name, age, country from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@state=TX
POSTHOOK: query: insert overwrite table ice_parquet_string partition(state='TX') select name, age, country from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@state=TX
PREHOOK: query: explain insert overwrite table ice_parquet_string partition(country='India') select name, age, state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@country=India
POSTHOOK: query: explain insert overwrite table ice_parquet_string partition(country='India') select name, age, state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@country=India
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 10 Data size: 1840 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), age (type: int), 'India' (type: string), state (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 10 Data size: 2730 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 10 Data size: 2730 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 10 Data size: 2730 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        keys: country (type: string), state (type: string)
                        minReductionHashAggr: 0.9
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                        Statistics: Num rows: 1 Data size: 1039 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: string)
                          null sort order: zz
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                          Statistics: Num rows: 1 Data size: 1039 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col2 (type: int), _col3 (type: struct<count:bigint,sum:double,input:int>), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: int), _col12 (type: struct<count:bigint,sum:double,input:int>), _col13 (type: bigint), _col14 (type: binary), _col15 (type: int), _col16 (type: struct<count:bigint,sum:double,input:int>), _col17 (type: bigint), _col18 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 10 Data size: 2730 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 1 Data size: 835 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col2,0)) (type: bigint), COALESCE(_col3,0) (type: double), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col11,0)) (type: bigint), COALESCE(_col12,0) (type: double), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col15,0)) (type: bigint), COALESCE(_col16,0) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), named_struct('country',_col0,'state',_col1) (type: struct<country:string,state:string>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            country India
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert overwrite table ice_parquet_string partition(country='India') select name, age, state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@country=India
POSTHOOK: query: insert overwrite table ice_parquet_string partition(country='India') select name, age, state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@country=India
PREHOOK: query: explain insert overwrite table ice_parquet_string partition(country='India') select name, '0054', state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@country=India
POSTHOOK: query: explain insert overwrite table ice_parquet_string partition(country='India') select name, '0054', state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@country=India
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_string
                  Statistics: Num rows: 20 Data size: 3600 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: name (type: string), 54 (type: int), 'India' (type: string), state (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 20 Data size: 5460 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col3 (type: string)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col3 (type: string)
                      Statistics: Num rows: 20 Data size: 5460 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string)
                      outputColumnNames: name, age, country, state
                      Statistics: Num rows: 20 Data size: 5460 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(name)), avg(COALESCE(length(name),0)), count(1), count(name), compute_bit_vector_hll(name), min(age), max(age), count(age), compute_bit_vector_hll(age), max(length(country)), avg(COALESCE(length(country),0)), count(country), compute_bit_vector_hll(country), max(length(state)), avg(COALESCE(length(state),0)), count(state), compute_bit_vector_hll(state)
                        keys: country (type: string), state (type: string)
                        minReductionHashAggr: 0.95
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                        Statistics: Num rows: 1 Data size: 1039 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: string)
                          null sort order: zz
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                          Statistics: Num rows: 1 Data size: 1039 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col2 (type: int), _col3 (type: struct<count:bigint,sum:double,input:int>), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: int), _col12 (type: struct<count:bigint,sum:double,input:int>), _col13 (type: bigint), _col14 (type: binary), _col15 (type: int), _col16 (type: struct<count:bigint,sum:double,input:int>), _col17 (type: bigint), _col18 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string), VALUE._col3 (type: string), KEY._col2 (type: string), KEY._col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col2, _col3
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 20 Data size: 5460 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                      output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                      serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                      name: default.ice_parquet_string
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), max(VALUE._col9), avg(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), max(VALUE._col13), avg(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 1 Data size: 835 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col2,0)) (type: bigint), COALESCE(_col3,0) (type: double), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col11,0)) (type: bigint), COALESCE(_col12,0) (type: double), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'STRING' (type: string), UDFToLong(COALESCE(_col15,0)) (type: bigint), COALESCE(_col16,0) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), named_struct('country',_col0,'state',_col1) (type: struct<country:string,state:string>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1478 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            country India
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_string

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: name, age, country, state
          Column Types: string, int, string, string
          Table: default.ice_parquet_string

PREHOOK: query: insert overwrite table ice_parquet_string partition(country='India') select name, '0054', state from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: default@ice_parquet_string@country=India
POSTHOOK: query: insert overwrite table ice_parquet_string partition(country='India') select name, '0054', state from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: default@ice_parquet_string@country=India
PREHOOK: query: describe formatted ice_parquet_string
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_string
POSTHOOK: query: describe formatted ice_parquet_string
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_string
# col_name            	data_type           	comment             
name                	string              	                    
age                 	int                 	                    
country             	string              	                    
state               	string              	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
country             	string              	Transform: identity 
state               	string              	Transform: identity 
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
country             	IDENTITY            	 
state               	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"age\":\"true\",\"country\":\"true\",\"name\":\"true\",\"state\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"name\",\"required\":false,\"type\":\"string\"},{\"id\":2,\"name\":\"age\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"country\",\"required\":false,\"type\":\"string\"},{\"id\":4,\"name\":\"state\",\"required\":false,\"type\":\"string\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"replace-partitions\":\"true\",\"added-data-files\":\"2\",\"deleted-data-files\":\"2\",\"added-records\":\"20\",\"deleted-records\":\"10\",\"added-files-size\":\"#Masked#\",\"removed-files-size\":\"#Masked#\",\"changed-partition-count\":\"2\",\"total-records\":\"30\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\",\"iceberg-version\":\"#Masked#\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"country\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000},{\"name\":\"state\",\"transform\":\"identity\",\"source-id\":4,\"field-id\":1001}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                   
	numPartitions       	4                   
	numRows             	30                  
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	9                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#
#### A masked pattern was here ####
	uuid                	#Masked#
	write.delete.mode   	merge-on-read       
	write.merge.mode    	merge-on-read       
	write.metadata.delete-after-commit.enabled	true                
	write.update.mode   	merge-on-read       
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_string
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_string
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: hdfs://### HDFS PATH ###
Bill Rose	52	USA	CA
Bill Rose	52	USA	TX
Bill Rose	52	USA	TX
Bill Rose	54	India	CA
Bill Rose	54	India	CA
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Bill Rose	54	India	TX
Maria Full	50	USA	CA
Maria Full	50	USA	TX
Maria Full	50	USA	TX
Maria Full	54	India	CA
Maria Full	54	India	CA
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Maria Full	54	India	TX
Mark Cage	38	USA	CA
Mark Cage	38	USA	TX
Mark Cage	54	India	CA
Mark Cage	54	India	CA
Mark Cage	54	India	TX
Mark Cage	54	India	TX
Mirna Cage	37	USA	CA
Mirna Cage	37	USA	TX
Mirna Cage	54	India	CA
Mirna Cage	54	India	CA
Mirna Cage	54	India	TX
Mirna Cage	54	India	TX
PREHOOK: query: create external table ice_parquet_date(
  bigintcol bigint,
  intcol integer
) partitioned by (pcol date)
stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_date
POSTHOOK: query: create external table ice_parquet_date(
  bigintcol bigint,
  intcol integer
) partitioned by (pcol date)
stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_date
PREHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-31') values (1234567890123345, 2), (23456789012345678, 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
POSTHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-31') values (1234567890123345, 2), (23456789012345678, 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
PREHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-26') values (1234567890123345, 3), (23456789012345678, 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-26
POSTHOOK: query: insert into table ice_parquet_date partition (pcol = '1999-12-26') values (1234567890123345, 3), (23456789012345678, 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-26
PREHOOK: query: explain insert overwrite table ice_parquet_date partition (pcol = '1999-12-31') values (3456789012345678, 4), (34567890123456789, 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
POSTHOOK: query: explain insert overwrite table ice_parquet_date partition (pcol = '1999-12-31') values (3456789012345678, 4), (34567890123456789, 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(3456789012345678L,4),const struct(34567890123456789L,6)) (type: array<struct<col1:bigint,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: bigint), col2 (type: int), DATE'1999-12-31' (type: date)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_date
                        Select Operator
                          expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: date)
                          outputColumnNames: bigintcol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(bigintcol), max(bigintcol), count(1), count(bigintcol), compute_bit_vector_hll(bigintcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            keys: pcol (type: date)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                            Statistics: Num rows: 1 Data size: 656 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              key expressions: _col0 (type: date)
                              null sort order: z
                              sort order: +
                              Map-reduce partition columns: _col0 (type: date)
                              Statistics: Num rows: 1 Data size: 656 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col1 (type: bigint), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: date), _col11 (type: date), _col12 (type: bigint), _col13 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: date)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 656 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), _col1 (type: bigint), _col2 (type: bigint), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'DATE' (type: string), _col10 (type: date), _col11 (type: date), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:date>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 984 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 984 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 1999-12-31
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_date

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: bigintcol, intcol, pcol
          Column Types: bigint, int, date
          Table: default.ice_parquet_date

PREHOOK: query: insert overwrite table ice_parquet_date partition (pcol = '1999-12-31') values (3456789012345678, 4), (34567890123456789, 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
POSTHOOK: query: insert overwrite table ice_parquet_date partition (pcol = '1999-12-31') values (3456789012345678, 4), (34567890123456789, 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
PREHOOK: query: select * from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: hdfs://### HDFS PATH ###
1234567890123345	3	1999-12-26
23456789012345678	5	1999-12-26
3456789012345678	4	1999-12-31
34567890123456789	6	1999-12-31
PREHOOK: query: explain insert overwrite table ice_parquet_date partition (pcol = '1999-12-31') select bigintcol, intcol from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
POSTHOOK: query: explain insert overwrite table ice_parquet_date partition (pcol = '1999-12-31') select bigintcol, intcol from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_date
                  Statistics: Num rows: 4 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: bigintcol (type: bigint), intcol (type: int), DATE'1999-12-31' (type: date)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 4 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 4 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_date
                    Select Operator
                      expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: date)
                      outputColumnNames: bigintcol, intcol, pcol
                      Statistics: Num rows: 4 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(bigintcol), max(bigintcol), count(1), count(bigintcol), compute_bit_vector_hll(bigintcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        keys: pcol (type: date)
                        minReductionHashAggr: 0.75
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                        Statistics: Num rows: 1 Data size: 656 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: date)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: date)
                          Statistics: Num rows: 1 Data size: 656 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: bigint), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: date), _col11 (type: date), _col12 (type: bigint), _col13 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: date)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 656 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), _col1 (type: bigint), _col2 (type: bigint), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'DATE' (type: string), _col10 (type: date), _col11 (type: date), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:date>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 984 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 984 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 1999-12-31
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_date

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: bigintcol, intcol, pcol
          Column Types: bigint, int, date
          Table: default.ice_parquet_date

PREHOOK: query: insert overwrite table ice_parquet_date partition (pcol = '1999-12-31') select bigintcol, intcol from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
POSTHOOK: query: insert overwrite table ice_parquet_date partition (pcol = '1999-12-31') select bigintcol, intcol from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-31
PREHOOK: query: explain insert overwrite table ice_parquet_date partition (pcol = '1999-12-26') select 234675894076895090, intcol from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-26
POSTHOOK: query: explain insert overwrite table ice_parquet_date partition (pcol = '1999-12-26') select 234675894076895090, intcol from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-26
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_date
                  Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: 234675894076895090L (type: bigint), intcol (type: int), DATE'1999-12-26' (type: date)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_date
                    Select Operator
                      expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: date)
                      outputColumnNames: bigintcol, intcol, pcol
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(bigintcol), max(bigintcol), count(1), count(bigintcol), compute_bit_vector_hll(bigintcol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        keys: pcol (type: date)
                        minReductionHashAggr: 0.8333333
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                        Statistics: Num rows: 1 Data size: 656 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: date)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: date)
                          Statistics: Num rows: 1 Data size: 656 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: bigint), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: date), _col11 (type: date), _col12 (type: bigint), _col13 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: date)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 656 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), _col1 (type: bigint), _col2 (type: bigint), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'DATE' (type: string), _col10 (type: date), _col11 (type: date), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:date>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 984 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 984 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 1999-12-26
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_date

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: bigintcol, intcol, pcol
          Column Types: bigint, int, date
          Table: default.ice_parquet_date

PREHOOK: query: insert overwrite table ice_parquet_date partition (pcol = '1999-12-26') select 234675894076895090, intcol from ice_parquet_date
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: default@ice_parquet_date@pcol=1999-12-26
POSTHOOK: query: insert overwrite table ice_parquet_date partition (pcol = '1999-12-26') select 234675894076895090, intcol from ice_parquet_date
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: default@ice_parquet_date@pcol=1999-12-26
PREHOOK: query: describe formatted ice_parquet_date
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_date
POSTHOOK: query: describe formatted ice_parquet_date
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_date
# col_name            	data_type           	comment             
bigintcol           	bigint              	                    
intcol              	int                 	                    
pcol                	date                	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
pcol                	date                	Transform: identity 
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
pcol                	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"bigintcol\":\"true\",\"intcol\":\"true\",\"pcol\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"bigintcol\",\"required\":false,\"type\":\"long\"},{\"id\":2,\"name\":\"intcol\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"pcol\",\"required\":false,\"type\":\"date\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"replace-partitions\":\"true\",\"added-data-files\":\"1\",\"deleted-data-files\":\"1\",\"added-records\":\"6\",\"deleted-records\":\"2\",\"added-files-size\":\"#Masked#\",\"removed-files-size\":\"#Masked#\",\"changed-partition-count\":\"1\",\"total-records\":\"10\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\",\"iceberg-version\":\"#Masked#\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"pcol\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                   
	numPartitions       	2                   
	numRows             	10                  
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	5                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#
#### A masked pattern was here ####
	uuid                	#Masked#
	write.delete.mode   	merge-on-read       
	write.merge.mode    	merge-on-read       
	write.metadata.delete-after-commit.enabled	true                
	write.update.mode   	merge-on-read       
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_date where pcol = '1999-12-31'
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_date where pcol = '1999-12-31'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: hdfs://### HDFS PATH ###
1234567890123345	3	1999-12-31
23456789012345678	5	1999-12-31
3456789012345678	4	1999-12-31
34567890123456789	6	1999-12-31
PREHOOK: query: select * from ice_parquet_date where pcol = '1999-12-26'
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_date where pcol = '1999-12-26'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: hdfs://### HDFS PATH ###
234675894076895090	3	1999-12-26
234675894076895090	3	1999-12-26
234675894076895090	4	1999-12-26
234675894076895090	5	1999-12-26
234675894076895090	5	1999-12-26
234675894076895090	6	1999-12-26
PREHOOK: query: create external table ice_parquet_bigint(
  datecol date,
  intcol integer
) partitioned by (pcol bigint)
stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_bigint
POSTHOOK: query: create external table ice_parquet_bigint(
  datecol date,
  intcol integer
) partitioned by (pcol bigint)
stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_bigint
PREHOOK: query: insert into table ice_parquet_bigint partition (pcol = 34567890123456787) values ('2022-08-07', 2), ('2022-08-09', 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
POSTHOOK: query: insert into table ice_parquet_bigint partition (pcol = 34567890123456787) values ('2022-08-07', 2), ('2022-08-09', 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
PREHOOK: query: insert into table ice_parquet_bigint partition (pcol = 12346577399277578) values ('2022-08-16', 3), ('2022-07-09', 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
POSTHOOK: query: insert into table ice_parquet_bigint partition (pcol = 12346577399277578) values ('2022-08-16', 3), ('2022-07-09', 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
PREHOOK: query: explain insert overwrite table ice_parquet_bigint partition (pcol = 34567890123456787) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
POSTHOOK: query: explain insert overwrite table ice_parquet_bigint partition (pcol = 34567890123456787) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-07-21',4),const struct('2022-05-29',6)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 34567890123456787L (type: bigint)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_bigint
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: bigint)
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            keys: pcol (type: bigint)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                            Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              key expressions: _col0 (type: bigint)
                              null sort order: z
                              sort order: +
                              Map-reduce partition columns: _col0 (type: bigint)
                              Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col1 (type: date), _col2 (type: date), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col1 (type: date), _col2 (type: date), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), _col10 (type: bigint), _col11 (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:bigint>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 936 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 936 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 34567890123456787
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_bigint

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, bigint
          Table: default.ice_parquet_bigint

PREHOOK: query: insert overwrite table ice_parquet_bigint partition (pcol = 34567890123456787) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
POSTHOOK: query: insert overwrite table ice_parquet_bigint partition (pcol = 34567890123456787) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
PREHOOK: query: select * from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-05-29	6	34567890123456787
2022-07-09	5	12346577399277578
2022-07-21	4	34567890123456787
2022-08-16	3	12346577399277578
PREHOOK: query: explain insert overwrite table ice_parquet_bigint partition (pcol = 34567890123456787) select datecol, intcol from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
POSTHOOK: query: explain insert overwrite table ice_parquet_bigint partition (pcol = 34567890123456787) select datecol, intcol from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_bigint
                  Statistics: Num rows: 4 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: datecol (type: date), intcol (type: int), 34567890123456787L (type: bigint)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 4 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 4 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_bigint
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: bigint)
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 4 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        keys: pcol (type: bigint)
                        minReductionHashAggr: 0.75
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                        Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: bigint)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: bigint)
                          Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: date), _col2 (type: date), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col1 (type: date), _col2 (type: date), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), _col10 (type: bigint), _col11 (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:bigint>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 936 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 936 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 34567890123456787
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_bigint

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, bigint
          Table: default.ice_parquet_bigint

PREHOOK: query: insert overwrite table ice_parquet_bigint partition (pcol = 34567890123456787) select datecol, intcol from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
POSTHOOK: query: insert overwrite table ice_parquet_bigint partition (pcol = 34567890123456787) select datecol, intcol from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: default@ice_parquet_bigint@pcol=34567890123456787
PREHOOK: query: explain insert overwrite table ice_parquet_bigint partition (pcol = 12346577399277578) select '2022-01-25', intcol from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
POSTHOOK: query: explain insert overwrite table ice_parquet_bigint partition (pcol = 12346577399277578) select '2022-01-25', intcol from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_bigint
                  Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: DATE'2022-01-25' (type: date), intcol (type: int), 12346577399277578L (type: bigint)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_bigint
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: bigint)
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        keys: pcol (type: bigint)
                        minReductionHashAggr: 0.8333333
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                        Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: bigint)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: bigint)
                          Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: date), _col2 (type: date), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col1 (type: date), _col2 (type: date), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), _col10 (type: bigint), _col11 (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:bigint>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 936 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 936 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 12346577399277578
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_bigint

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, bigint
          Table: default.ice_parquet_bigint

PREHOOK: query: insert overwrite table ice_parquet_bigint partition (pcol = 12346577399277578) select '2022-01-25', intcol from ice_parquet_bigint
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
POSTHOOK: query: insert overwrite table ice_parquet_bigint partition (pcol = 12346577399277578) select '2022-01-25', intcol from ice_parquet_bigint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: default@ice_parquet_bigint@pcol=12346577399277578
PREHOOK: query: describe formatted ice_parquet_bigint
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_bigint
POSTHOOK: query: describe formatted ice_parquet_bigint
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_bigint
# col_name            	data_type           	comment             
datecol             	date                	                    
intcol              	int                 	                    
pcol                	bigint              	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
pcol                	bigint              	Transform: identity 
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
pcol                	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"datecol\":\"true\",\"intcol\":\"true\",\"pcol\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"datecol\",\"required\":false,\"type\":\"date\"},{\"id\":2,\"name\":\"intcol\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"pcol\",\"required\":false,\"type\":\"long\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"replace-partitions\":\"true\",\"added-data-files\":\"1\",\"deleted-data-files\":\"1\",\"added-records\":\"6\",\"deleted-records\":\"2\",\"added-files-size\":\"#Masked#\",\"removed-files-size\":\"#Masked#\",\"changed-partition-count\":\"1\",\"total-records\":\"10\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\",\"iceberg-version\":\"#Masked#\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"pcol\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                   
	numPartitions       	2                   
	numRows             	10                  
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	5                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#
#### A masked pattern was here ####
	uuid                	#Masked#
	write.delete.mode   	merge-on-read       
	write.merge.mode    	merge-on-read       
	write.metadata.delete-after-commit.enabled	true                
	write.update.mode   	merge-on-read       
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_bigint where pcol = 34567890123456787
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_bigint where pcol = 34567890123456787
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-05-29	6	34567890123456787
2022-07-09	5	34567890123456787
2022-07-21	4	34567890123456787
2022-08-16	3	34567890123456787
PREHOOK: query: select * from ice_parquet_bigint where pcol = 12346577399277578
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_bigint where pcol = 12346577399277578
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-01-25	3	12346577399277578
2022-01-25	3	12346577399277578
2022-01-25	4	12346577399277578
2022-01-25	5	12346577399277578
2022-01-25	5	12346577399277578
2022-01-25	6	12346577399277578
PREHOOK: query: create external table ice_parquet_double(
  datecol date,
  intcol integer
) partitioned by (pcol double)
stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_double
POSTHOOK: query: create external table ice_parquet_double(
  datecol date,
  intcol integer
) partitioned by (pcol double)
stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_double
PREHOOK: query: insert into table ice_parquet_double partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_double@pcol=3.14786
POSTHOOK: query: insert into table ice_parquet_double partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_double@pcol=3.14786
PREHOOK: query: insert into table ice_parquet_double partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_double@pcol=3.189
POSTHOOK: query: insert into table ice_parquet_double partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_double@pcol=3.189
PREHOOK: query: explain insert overwrite table ice_parquet_double partition (pcol = 3.14786) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_double@pcol=3.14786
POSTHOOK: query: explain insert overwrite table ice_parquet_double partition (pcol = 3.14786) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_double@pcol=3.14786
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-07-21',4),const struct('2022-05-29',6)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 3.14786D (type: double)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_double
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: double)
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 64 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            keys: pcol (type: double)
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                            Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              key expressions: _col0 (type: double)
                              null sort order: z
                              sort order: +
                              Map-reduce partition columns: _col0 (type: double)
                              Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col1 (type: date), _col2 (type: date), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: double), _col11 (type: double), _col12 (type: bigint), _col13 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: double)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col1 (type: date), _col2 (type: date), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'DOUBLE' (type: string), _col10 (type: double), _col11 (type: double), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:double>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 938 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 938 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 3.14786
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_double

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, double
          Table: default.ice_parquet_double

PREHOOK: query: insert overwrite table ice_parquet_double partition (pcol = 3.14786) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_double@pcol=3.14786
POSTHOOK: query: insert overwrite table ice_parquet_double partition (pcol = 3.14786) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_double@pcol=3.14786
PREHOOK: query: select * from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-05-29	6	3.14786
2022-07-09	5	3.189
2022-07-21	4	3.14786
2022-08-16	3	3.189
PREHOOK: query: explain insert overwrite table ice_parquet_double partition (pcol = 3.14786) select datecol, intcol from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: default@ice_parquet_double@pcol=3.14786
POSTHOOK: query: explain insert overwrite table ice_parquet_double partition (pcol = 3.14786) select datecol, intcol from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: default@ice_parquet_double@pcol=3.14786
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_double
                  Statistics: Num rows: 4 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: datecol (type: date), intcol (type: int), 3.14786D (type: double)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 4 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 4 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_double
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: double)
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 4 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        keys: pcol (type: double)
                        minReductionHashAggr: 0.75
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                        Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: double)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: double)
                          Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: date), _col2 (type: date), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: double), _col11 (type: double), _col12 (type: bigint), _col13 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: double)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col1 (type: date), _col2 (type: date), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'DOUBLE' (type: string), _col10 (type: double), _col11 (type: double), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:double>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 938 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 938 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 3.14786
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_double

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, double
          Table: default.ice_parquet_double

PREHOOK: query: insert overwrite table ice_parquet_double partition (pcol = 3.14786) select datecol, intcol from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: default@ice_parquet_double@pcol=3.14786
POSTHOOK: query: insert overwrite table ice_parquet_double partition (pcol = 3.14786) select datecol, intcol from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: default@ice_parquet_double@pcol=3.14786
PREHOOK: query: explain insert overwrite table ice_parquet_double partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: default@ice_parquet_double@pcol=3.189
POSTHOOK: query: explain insert overwrite table ice_parquet_double partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: default@ice_parquet_double@pcol=3.189
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_double
                  Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: DATE'2022-01-25' (type: date), intcol (type: int), 3.189D (type: double)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_double
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: double)
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 6 Data size: 408 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        keys: pcol (type: double)
                        minReductionHashAggr: 0.8333333
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                        Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: double)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: double)
                          Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: date), _col2 (type: date), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: double), _col11 (type: double), _col12 (type: bigint), _col13 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: double)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 608 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col1 (type: date), _col2 (type: date), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'DOUBLE' (type: string), _col10 (type: double), _col11 (type: double), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:double>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 938 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 938 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 3.189
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_double

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, double
          Table: default.ice_parquet_double

PREHOOK: query: insert overwrite table ice_parquet_double partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_double
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: default@ice_parquet_double@pcol=3.189
POSTHOOK: query: insert overwrite table ice_parquet_double partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_double
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: default@ice_parquet_double@pcol=3.189
PREHOOK: query: describe formatted ice_parquet_double
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_double
POSTHOOK: query: describe formatted ice_parquet_double
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_double
# col_name            	data_type           	comment             
datecol             	date                	                    
intcol              	int                 	                    
pcol                	double              	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
pcol                	double              	Transform: identity 
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
pcol                	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"datecol\":\"true\",\"intcol\":\"true\",\"pcol\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"datecol\",\"required\":false,\"type\":\"date\"},{\"id\":2,\"name\":\"intcol\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"pcol\",\"required\":false,\"type\":\"double\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"replace-partitions\":\"true\",\"added-data-files\":\"1\",\"deleted-data-files\":\"1\",\"added-records\":\"6\",\"deleted-records\":\"2\",\"added-files-size\":\"#Masked#\",\"removed-files-size\":\"#Masked#\",\"changed-partition-count\":\"1\",\"total-records\":\"10\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\",\"iceberg-version\":\"#Masked#\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"pcol\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                   
	numPartitions       	2                   
	numRows             	10                  
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	5                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#
#### A masked pattern was here ####
	uuid                	#Masked#
	write.delete.mode   	merge-on-read       
	write.merge.mode    	merge-on-read       
	write.metadata.delete-after-commit.enabled	true                
	write.update.mode   	merge-on-read       
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_double where pcol = 3.14786
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_double where pcol = 3.14786
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-05-29	6	3.14786
2022-07-09	5	3.14786
2022-07-21	4	3.14786
2022-08-16	3	3.14786
PREHOOK: query: select * from ice_parquet_double where pcol = 3.189
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_double where pcol = 3.189
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-01-25	3	3.189
2022-01-25	3	3.189
2022-01-25	4	3.189
2022-01-25	5	3.189
2022-01-25	5	3.189
2022-01-25	6	3.189
PREHOOK: query: create external table ice_parquet_decimal(
  datecol date,
  intcol integer
) partitioned by (pcol decimal(10,6))
stored by iceberg
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_decimal
POSTHOOK: query: create external table ice_parquet_decimal(
  datecol date,
  intcol integer
) partitioned by (pcol decimal(10,6))
stored by iceberg
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_decimal
PREHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
POSTHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.14786) values ('2022-08-07', 2), ('2022-08-09', 4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
PREHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.189
POSTHOOK: query: insert into table ice_parquet_decimal partition (pcol = 3.189) values ('2022-08-16', 3), ('2022-07-09', 5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.189
PREHOOK: query: explain insert overwrite table ice_parquet_decimal partition (pcol = 3.14786) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
POSTHOOK: query: explain insert overwrite table ice_parquet_decimal partition (pcol = 3.14786) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('2022-07-21',4),const struct('2022-05-29',6)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: CAST( col1 AS DATE) (type: date), col2 (type: int), 3.14786 (type: decimal(10,6))
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                              name: default.ice_parquet_decimal
                        Select Operator
                          expressions: _col0 (type: date), _col1 (type: int), _col2 (type: decimal(10,6))
                          outputColumnNames: datecol, intcol, pcol
                          Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                          Group By Operator
                            aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                            keys: pcol (type: decimal(10,6))
                            minReductionHashAggr: 0.4
                            mode: hash
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                            Statistics: Num rows: 1 Data size: 920 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              key expressions: _col0 (type: decimal(10,6))
                              null sort order: z
                              sort order: +
                              Map-reduce partition columns: _col0 (type: decimal(10,6))
                              Statistics: Num rows: 1 Data size: 920 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col1 (type: date), _col2 (type: date), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: decimal(10,6)), _col11 (type: decimal(10,6)), _col12 (type: bigint), _col13 (type: binary)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: decimal(10,6))
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 1 Data size: 920 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'DATE' (type: string), _col1 (type: date), _col2 (type: date), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'DECIMAL' (type: string), _col10 (type: decimal(10,6)), _col11 (type: decimal(10,6)), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:decimal(10,6)>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 1 Data size: 1251 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1251 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 3.14786
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_decimal

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, decimal(10,6)
          Table: default.ice_parquet_decimal

PREHOOK: query: insert overwrite table ice_parquet_decimal partition (pcol = 3.14786) values ('2022-07-21', 4), ('2022-05-29', 6)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
POSTHOOK: query: insert overwrite table ice_parquet_decimal partition (pcol = 3.14786) values ('2022-07-21', 4), ('2022-05-29', 6)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
PREHOOK: query: select * from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-05-29	6	3.147860
2022-07-09	5	3.189000
2022-07-21	4	3.147860
2022-08-16	3	3.189000
PREHOOK: query: explain insert overwrite table ice_parquet_decimal partition (pcol = 3.14786) select datecol, intcol from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
POSTHOOK: query: explain insert overwrite table ice_parquet_decimal partition (pcol = 3.14786) select datecol, intcol from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_decimal
                  Statistics: Num rows: 4 Data size: 240 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: datecol (type: date), intcol (type: int), 3.14786 (type: decimal(10,6))
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 4 Data size: 240 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 4 Data size: 240 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_decimal
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: decimal(10,6))
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 4 Data size: 240 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        keys: pcol (type: decimal(10,6))
                        minReductionHashAggr: 0.99
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                        Statistics: Num rows: 4 Data size: 240 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: decimal(10,6))
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: decimal(10,6))
                          Statistics: Num rows: 4 Data size: 240 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: date), _col2 (type: date), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: decimal(10,6)), _col11 (type: decimal(10,6)), _col12 (type: bigint), _col13 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: decimal(10,6))
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 2 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: 'DATE' (type: string), _col1 (type: date), _col2 (type: date), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'DECIMAL' (type: string), _col10 (type: decimal(10,6)), _col11 (type: decimal(10,6)), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:decimal(10,6)>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 2 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 2 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 3.14786
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_decimal

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, decimal(10,6)
          Table: default.ice_parquet_decimal

PREHOOK: query: insert overwrite table ice_parquet_decimal partition (pcol = 3.14786) select datecol, intcol from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
POSTHOOK: query: insert overwrite table ice_parquet_decimal partition (pcol = 3.14786) select datecol, intcol from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.14786
PREHOOK: query: explain insert overwrite table ice_parquet_decimal partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.189
POSTHOOK: query: explain insert overwrite table ice_parquet_decimal partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.189
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ice_parquet_decimal
                  Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: DATE'2022-01-25' (type: date), intcol (type: int), 3.189 (type: decimal(10,6))
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                          output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
                          serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
                          name: default.ice_parquet_decimal
                    Select Operator
                      expressions: _col0 (type: date), _col1 (type: int), _col2 (type: decimal(10,6))
                      outputColumnNames: datecol, intcol, pcol
                      Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: min(datecol), max(datecol), count(1), count(datecol), compute_bit_vector_hll(datecol), min(intcol), max(intcol), count(intcol), compute_bit_vector_hll(intcol), min(pcol), max(pcol), count(pcol), compute_bit_vector_hll(pcol)
                        keys: pcol (type: decimal(10,6))
                        minReductionHashAggr: 0.99
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                        Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: decimal(10,6))
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: decimal(10,6))
                          Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: date), _col2 (type: date), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: decimal(10,6)), _col11 (type: decimal(10,6)), _col12 (type: bigint), _col13 (type: binary)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12)
                keys: KEY._col0 (type: decimal(10,6))
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                Statistics: Num rows: 3 Data size: 12 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: 'DATE' (type: string), _col1 (type: date), _col2 (type: date), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'DECIMAL' (type: string), _col10 (type: decimal(10,6)), _col11 (type: decimal(10,6)), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), named_struct('pcol',_col0) (type: struct<pcol:decimal(10,6)>)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                  Statistics: Num rows: 3 Data size: 12 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 3 Data size: 12 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            pcol 3.189
          replace: true
          table:
              input format: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
              output format: org.apache.iceberg.mr.hive.HiveIcebergOutputFormat
              serde: org.apache.iceberg.mr.hive.HiveIcebergSerDe
              name: default.ice_parquet_decimal

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: datecol, intcol, pcol
          Column Types: date, int, decimal(10,6)
          Table: default.ice_parquet_decimal

PREHOOK: query: insert overwrite table ice_parquet_decimal partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_decimal
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: default@ice_parquet_decimal@pcol=3.189
POSTHOOK: query: insert overwrite table ice_parquet_decimal partition (pcol = 3.189) select '2022-01-25', intcol from ice_parquet_decimal
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: default@ice_parquet_decimal@pcol=3.189
PREHOOK: query: describe formatted ice_parquet_decimal
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@ice_parquet_decimal
POSTHOOK: query: describe formatted ice_parquet_decimal
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@ice_parquet_decimal
# col_name            	data_type           	comment             
datecol             	date                	                    
intcol              	int                 	                    
pcol                	decimal(10,6)       	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
pcol                	decimal(10,6)       	Transform: identity 
	 	 
# Partition Transform Information	 	 
# col_name            	transform_type      	 
pcol                	IDENTITY            	 
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	EXTERNAL_TABLE      	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"datecol\":\"true\",\"intcol\":\"true\",\"pcol\":\"true\"}}
	EXTERNAL            	TRUE                
	bucketing_version   	2                   
	current-schema      	{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"datecol\",\"required\":false,\"type\":\"date\"},{\"id\":2,\"name\":\"intcol\",\"required\":false,\"type\":\"int\"},{\"id\":3,\"name\":\"pcol\",\"required\":false,\"type\":\"decimal(10, 6)\"}]}
	current-snapshot-id 	#Masked#
	current-snapshot-summary	{\"replace-partitions\":\"true\",\"added-data-files\":\"1\",\"deleted-data-files\":\"1\",\"added-records\":\"6\",\"deleted-records\":\"2\",\"added-files-size\":\"#Masked#\",\"removed-files-size\":\"#Masked#\",\"changed-partition-count\":\"1\",\"total-records\":\"10\",\"total-files-size\":\"#Masked#\",\"total-data-files\":\"#Masked#\",\"total-delete-files\":\"0\",\"total-position-deletes\":\"0\",\"total-equality-deletes\":\"0\",\"iceberg-version\":\"#Masked#\"}
	current-snapshot-timestamp-ms	#Masked#       
	default-partition-spec	{\"spec-id\":0,\"fields\":[{\"name\":\"pcol\",\"transform\":\"identity\",\"source-id\":3,\"field-id\":1000}]}
	format-version      	2                   
	iceberg.orc.files.only	false               
	metadata_location   	hdfs://### HDFS PATH ###
	numFiles            	#Masked#                   
	numPartitions       	2                   
	numRows             	10                  
	parquet.compression 	zstd                
	previous_metadata_location	hdfs://### HDFS PATH ###
	rawDataSize         	0                   
	serialization.format	1                   
	snapshot-count      	5                   
	storage_handler     	org.apache.iceberg.mr.hive.HiveIcebergStorageHandler
	table_type          	ICEBERG             
	totalSize           	#Masked#
#### A masked pattern was here ####
	uuid                	#Masked#
	write.delete.mode   	merge-on-read       
	write.merge.mode    	merge-on-read       
	write.metadata.delete-after-commit.enabled	true                
	write.update.mode   	merge-on-read       
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.iceberg.mr.hive.HiveIcebergSerDe	 
InputFormat:        	org.apache.iceberg.mr.hive.HiveIcebergInputFormat	 
OutputFormat:       	org.apache.iceberg.mr.hive.HiveIcebergOutputFormat	 
Compressed:         	No                  	 
Sort Columns:       	[]                  	 
PREHOOK: query: select * from ice_parquet_decimal where pcol = 3.14786
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_decimal where pcol = 3.14786
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-05-29	6	3.147860
2022-07-09	5	3.147860
2022-07-21	4	3.147860
2022-08-16	3	3.147860
PREHOOK: query: select * from ice_parquet_decimal where pcol = 3.189
PREHOOK: type: QUERY
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from ice_parquet_decimal where pcol = 3.189
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: hdfs://### HDFS PATH ###
2022-01-25	3	3.189000
2022-01-25	3	3.189000
2022-01-25	4	3.189000
2022-01-25	5	3.189000
2022-01-25	5	3.189000
2022-01-25	6	3.189000
PREHOOK: query: drop table ice_parquet_int
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_int
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_int
POSTHOOK: query: drop table ice_parquet_int
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_int
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_int
PREHOOK: query: drop table ice_parquet_bigint
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_bigint
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_bigint
POSTHOOK: query: drop table ice_parquet_bigint
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_bigint
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_bigint
PREHOOK: query: drop table ice_parquet_string
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_string
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_string
POSTHOOK: query: drop table ice_parquet_string
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_string
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_string
PREHOOK: query: drop table ice_parquet_date
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_date
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_date
POSTHOOK: query: drop table ice_parquet_date
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_date
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_date
PREHOOK: query: drop table ice_parquet_decimal
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_decimal
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_decimal
POSTHOOK: query: drop table ice_parquet_decimal
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_decimal
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_decimal
PREHOOK: query: drop table ice_parquet_double
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@ice_parquet_double
PREHOOK: Output: database:default
PREHOOK: Output: default@ice_parquet_double
POSTHOOK: query: drop table ice_parquet_double
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@ice_parquet_double
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ice_parquet_double
