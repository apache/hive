PREHOOK: query: CREATE EXTERNAL TABLE calls (
  s_key bigint, 
  year int
) PARTITIONED BY SPEC (year)  
STORED BY Iceberg STORED AS parquet 
TBLPROPERTIES ('format-version'='2')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@calls
POSTHOOK: query: CREATE EXTERNAL TABLE calls (
  s_key bigint, 
  year int
) PARTITIONED BY SPEC (year)  
STORED BY Iceberg STORED AS parquet 
TBLPROPERTIES ('format-version'='2')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@calls
PREHOOK: query: INSERT INTO calls (s_key, year) VALUES (1090969, 2022)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@calls
POSTHOOK: query: INSERT INTO calls (s_key, year) VALUES (1090969, 2022)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@calls
PREHOOK: query: CREATE EXTERNAL TABLE display (                   
  skey bigint,                                   
  hierarchy_number string,                       
  hierarchy_name string,                         
  language_id int,                               
  hierarchy_display string,                      
  orderby string
)                                
STORED BY Iceberg STORED AS parquet 
TBLPROPERTIES ('format-version'='2')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@display
POSTHOOK: query: CREATE EXTERNAL TABLE display (                   
  skey bigint,                                   
  hierarchy_number string,                       
  hierarchy_name string,                         
  language_id int,                               
  hierarchy_display string,                      
  orderby string
)                                
STORED BY Iceberg STORED AS parquet 
TBLPROPERTIES ('format-version'='2')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@display
PREHOOK: query: INSERT INTO display (skey, language_id, hierarchy_display) VALUES 
  (1090969, 3, 'f9e59bae9b131de1d8f02d887ee91e20-mergeupdated1-updated1'),
  (1090969, 3, 'f9e59bae9b131de1d8f02d887ee91e20-mergeupdated1-updated1-insertnew1')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@display
POSTHOOK: query: INSERT INTO display (skey, language_id, hierarchy_display) VALUES 
  (1090969, 3, 'f9e59bae9b131de1d8f02d887ee91e20-mergeupdated1-updated1'),
  (1090969, 3, 'f9e59bae9b131de1d8f02d887ee91e20-mergeupdated1-updated1-insertnew1')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@display
Warning: Shuffle Join MERGEJOIN[67][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 2' is a cross product
Warning: Shuffle Join MERGEJOIN[68][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 8' is a cross product
PREHOOK: query: explain vectorization only detail MERGE INTO display USING (
  SELECT distinct display_skey, display, display as orig_display 
  FROM (
    SELECT D.skey display_skey, D.hierarchy_display display
    FROM ( 
      SELECT s_key FROM calls WHERE s_key =  1090969
    ) R 
    INNER JOIN display D 
      ON R.s_key = D.skey AND D.language_id = 3 
    GROUP BY D.skey, 
      D.hierarchy_display
  ) sub1 

  UNION ALL 
  
  SELECT distinct display_skey, null as display, display as orig_display 
  FROM (
    SELECT D.skey display_skey, D.hierarchy_display display
    FROM ( 
      SELECT s_key FROM calls WHERE s_key =  1090969
    ) R 
    INNER JOIN display D 
      ON R.s_key = D.skey AND D.language_id = 3 
    GROUP BY D.skey,
      D.hierarchy_display
  ) sub2
) sub 
ON display.skey = sub.display_skey 
    and display.hierarchy_display = sub.display 

WHEN MATCHED THEN 
  UPDATE SET hierarchy_display = concat(sub.display, '-mergeupdated1') 
WHEN NOT MATCHED THEN 
  INSERT (skey, language_id, hierarchy_display) values (sub.display_skey, 3, concat(sub.orig_display, '-mergenew1'))
PREHOOK: type: QUERY
PREHOOK: Input: default@calls
PREHOOK: Input: default@display
PREHOOK: Output: default@display
PREHOOK: Output: default@display
PREHOOK: Output: default@merge_tmp_table
POSTHOOK: query: explain vectorization only detail MERGE INTO display USING (
  SELECT distinct display_skey, display, display as orig_display 
  FROM (
    SELECT D.skey display_skey, D.hierarchy_display display
    FROM ( 
      SELECT s_key FROM calls WHERE s_key =  1090969
    ) R 
    INNER JOIN display D 
      ON R.s_key = D.skey AND D.language_id = 3 
    GROUP BY D.skey, 
      D.hierarchy_display
  ) sub1 

  UNION ALL 
  
  SELECT distinct display_skey, null as display, display as orig_display 
  FROM (
    SELECT D.skey display_skey, D.hierarchy_display display
    FROM ( 
      SELECT s_key FROM calls WHERE s_key =  1090969
    ) R 
    INNER JOIN display D 
      ON R.s_key = D.skey AND D.language_id = 3 
    GROUP BY D.skey,
      D.hierarchy_display
  ) sub2
) sub 
ON display.skey = sub.display_skey 
    and display.hierarchy_display = sub.display 

WHEN MATCHED THEN 
  UPDATE SET hierarchy_display = concat(sub.display, '-mergeupdated1') 
WHEN NOT MATCHED THEN 
  INSERT (skey, language_id, hierarchy_display) values (sub.display_skey, 3, concat(sub.orig_display, '-mergenew1'))
POSTHOOK: type: QUERY
POSTHOOK: Input: default@calls
POSTHOOK: Input: default@display
POSTHOOK: Output: default@display
POSTHOOK: Output: default@display
POSTHOOK: Output: default@merge_tmp_table
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-5 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-5
  Stage-6 depends on stages: Stage-0
  Stage-3 depends on stages: Stage-5
  Stage-7 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-4
    Tez
      Edges:
        Reducer 2 <- Map 1 (XPROD_EDGE), Map 10 (XPROD_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE), Union 4 (CONTAINS)
        Reducer 5 <- Map 10 (SIMPLE_EDGE), Union 4 (SIMPLE_EDGE)
        Reducer 6 <- Reducer 5 (SIMPLE_EDGE)
        Reducer 7 <- Reducer 5 (SIMPLE_EDGE)
        Reducer 8 <- Map 1 (XPROD_EDGE), Map 10 (XPROD_EDGE)
        Reducer 9 <- Reducer 8 (SIMPLE_EDGE), Union 4 (CONTAINS)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:s_key:bigint, 1:year:int, 2:PARTITION__SPEC__ID:int, 3:PARTITION__HASH:bigint, 4:FILE__PATH:string, 5:ROW__POSITION:bigint, 6:PARTITION__PROJECTION:string]
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColEqualLongScalar(col 0:bigint, val 1090969)
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: []
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkEmptyKeyOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkEmptyKeyOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: s_key:bigint, year:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 10 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:skey:bigint, 1:hierarchy_number:string, 2:hierarchy_name:string, 3:language_id:int, 4:hierarchy_display:string, 5:orderby:string, 6:PARTITION__SPEC__ID:int, 7:PARTITION__HASH:bigint, 8:FILE__PATH:string, 9:ROW__POSITION:bigint, 10:PARTITION__PROJECTION:string]
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColEqualLongScalar(col 0:bigint, val 1090969), SelectColumnIsNotNull(col 4:string))
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5]
                          selectExpressions: ConstantVectorExpression(val 1090969) -> 11:bigint
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkStringOperator
                            keyColumns: 4:string
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumns: 6:int, 7:bigint, 8:string, 9:bigint, 10:string, 11:bigint, 1:string, 2:string, 3:int, 5:string
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColEqualLongScalar(col 3:int, val 3), FilterLongColEqualLongScalar(col 0:bigint, val 1090969))
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [4]
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkEmptyKeyOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumns: 4:string
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkEmptyKeyOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumns: 4:string
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.iceberg.mr.hive.HiveIcebergInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 6
                    includeColumns: [0, 1, 2, 3, 4, 5]
                    dataColumns: skey:bigint, hierarchy_number:string, hierarchy_name:string, language_id:int, hierarchy_display:string, orderby:string
                    neededVirtualColumns: #Masked#
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint]
        Reducer 2 
            MergeJoin Vectorization:
                enabled: false
                enableConditionsNotMet: Vectorizing MergeJoin Supported IS false
        Reducer 3 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY._col0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
                Group By Vectorization:
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    keyExpressions: col 0:string
                    native: false
                    vectorProcessingMode: MERGE_PARTIAL
                    projectedOutputColumnNums: []
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumnNums: [0, 0]
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkStringOperator
                        keyColumns: 0:string
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumns: 0:string
        Reducer 5 
            MergeJoin Vectorization:
                enabled: false
                enableConditionsNotMet: Vectorizing MergeJoin Supported IS false
        Reducer 6 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez] IS true
                reduceColumnNullOrder: zzzzz
                reduceColumnSortOrder: +++++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 10
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:bigint, KEY.reducesinkkey2:string, KEY.reducesinkkey3:bigint, KEY.reducesinkkey4:string, VALUE._col1:string, VALUE._col2:string, VALUE._col3:int, VALUE._col4:string, VALUE._col5:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint]
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3, 4, 10, 5, 6, 7, 8, 9]
                    selectExpressions: ConstantVectorExpression(val 1090969) -> 10:bigint
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
        Reducer 7 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez] IS true
                reduceColumnNullOrder: zzzzz
                reduceColumnSortOrder: +++++
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 6
                    dataColumns: KEY._col0:int, KEY._col1:bigint, KEY._col2:string, KEY._col3:bigint, KEY._col4:string, VALUE._col0:bigint
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
                Group By Vectorization:
                    aggregators: VectorUDAFCountMerge(col 5:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    keyExpressions: col 0:int, col 1:bigint, col 2:string, col 3:bigint, col 4:string
                    native: false
                    vectorProcessingMode: MERGE_PARTIAL
                    projectedOutputColumnNums: [0]
                  Filter Vectorization:
                      className: VectorFilterOperator
                      native: true
                      predicateExpression: FilterLongColGreaterLongScalar(col 5:bigint, val 1)
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [6]
                        selectExpressions: VectorUDFAdaptor(cardinality_violation(_col0,_col1,_col2,_col3,_col4)) -> 6:int
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
        Reducer 8 
            MergeJoin Vectorization:
                enabled: false
                enableConditionsNotMet: Vectorizing MergeJoin Supported IS false
        Reducer 9 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY._col0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
                Group By Vectorization:
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    keyExpressions: col 0:string
                    native: false
                    vectorProcessingMode: MERGE_PARTIAL
                    projectedOutputColumnNums: []
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumnNums: [1, 0]
                      selectExpressions: ConstantVectorExpression(val null) -> 1:string
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkStringOperator
                        keyColumns: 1:string
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumns: 0:string
        Union 4 

  Stage: Stage-5

  Stage: Stage-0

  Stage: Stage-6

  Stage: Stage-3

  Stage: Stage-7

Warning: Shuffle Join MERGEJOIN[67][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 2' is a cross product
Warning: Shuffle Join MERGEJOIN[68][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 8' is a cross product
PREHOOK: query: MERGE INTO display USING (
  SELECT distinct display_skey, display, display as orig_display 
  FROM (
    SELECT D.skey display_skey, D.hierarchy_display display
    FROM ( 
      SELECT s_key FROM calls WHERE s_key =  1090969
    ) R 
    INNER JOIN display D 
      ON R.s_key = D.skey AND D.language_id = 3 
    GROUP BY D.skey, 
      D.hierarchy_display
  ) sub1 

  UNION ALL 
  
  SELECT distinct display_skey, null as display, display as orig_display 
  FROM (
    SELECT D.skey display_skey, D.hierarchy_display display
    FROM ( 
      SELECT s_key FROM calls WHERE s_key =  1090969
    ) R 
    INNER JOIN display D 
      ON R.s_key = D.skey AND D.language_id = 3 
    GROUP BY D.skey,
      D.hierarchy_display
  ) sub2
) sub 
ON display.skey = sub.display_skey 
    and display.hierarchy_display = sub.display 

WHEN MATCHED THEN 
  UPDATE SET hierarchy_display = concat(sub.display, '-mergeupdated1') 
WHEN NOT MATCHED THEN 
  INSERT (skey, language_id, hierarchy_display) values (sub.display_skey, 3, concat(sub.orig_display, '-mergenew1'))
PREHOOK: type: QUERY
PREHOOK: Input: default@calls
PREHOOK: Input: default@display
PREHOOK: Output: default@display
PREHOOK: Output: default@display
PREHOOK: Output: default@merge_tmp_table
POSTHOOK: query: MERGE INTO display USING (
  SELECT distinct display_skey, display, display as orig_display 
  FROM (
    SELECT D.skey display_skey, D.hierarchy_display display
    FROM ( 
      SELECT s_key FROM calls WHERE s_key =  1090969
    ) R 
    INNER JOIN display D 
      ON R.s_key = D.skey AND D.language_id = 3 
    GROUP BY D.skey, 
      D.hierarchy_display
  ) sub1 

  UNION ALL 
  
  SELECT distinct display_skey, null as display, display as orig_display 
  FROM (
    SELECT D.skey display_skey, D.hierarchy_display display
    FROM ( 
      SELECT s_key FROM calls WHERE s_key =  1090969
    ) R 
    INNER JOIN display D 
      ON R.s_key = D.skey AND D.language_id = 3 
    GROUP BY D.skey,
      D.hierarchy_display
  ) sub2
) sub 
ON display.skey = sub.display_skey 
    and display.hierarchy_display = sub.display 

WHEN MATCHED THEN 
  UPDATE SET hierarchy_display = concat(sub.display, '-mergeupdated1') 
WHEN NOT MATCHED THEN 
  INSERT (skey, language_id, hierarchy_display) values (sub.display_skey, 3, concat(sub.orig_display, '-mergenew1'))
POSTHOOK: type: QUERY
POSTHOOK: Input: default@calls
POSTHOOK: Input: default@display
POSTHOOK: Output: default@display
POSTHOOK: Output: default@display
POSTHOOK: Output: default@merge_tmp_table
POSTHOOK: Lineage: merge_tmp_table.val EXPRESSION [(display)display.null, ]
PREHOOK: query: SELECT * FROM display
PREHOOK: type: QUERY
PREHOOK: Input: default@display
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: SELECT * FROM display
POSTHOOK: type: QUERY
POSTHOOK: Input: default@display
POSTHOOK: Output: hdfs://### HDFS PATH ###
1090969	NULL	NULL	3	f9e59bae9b131de1d8f02d887ee91e20-mergeupdated1-updated1-insertnew1-mergenew1	NULL
1090969	NULL	NULL	3	f9e59bae9b131de1d8f02d887ee91e20-mergeupdated1-updated1-insertnew1-mergeupdated1	NULL
1090969	NULL	NULL	3	f9e59bae9b131de1d8f02d887ee91e20-mergeupdated1-updated1-mergenew1	NULL
1090969	NULL	NULL	3	f9e59bae9b131de1d8f02d887ee91e20-mergeupdated1-updated1-mergeupdated1	NULL
PREHOOK: query: DROP TABLE calls
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@calls
PREHOOK: Output: database:default
PREHOOK: Output: default@calls
POSTHOOK: query: DROP TABLE calls
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@calls
POSTHOOK: Output: database:default
POSTHOOK: Output: default@calls
PREHOOK: query: DROP TABLE display
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@display
PREHOOK: Output: database:default
PREHOOK: Output: default@display
POSTHOOK: query: DROP TABLE display
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@display
POSTHOOK: Output: database:default
POSTHOOK: Output: default@display
