PREHOOK: query: create table nzhang_test1 stored as sequencefile as select 'key1' as key, 'value
1

http://asdf' value from src limit 1
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@nzhang_test1
POSTHOOK: query: create table nzhang_test1 stored as sequencefile as select 'key1' as key, 'value
1

http://asdf' value from src limit 1
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@nzhang_test1
POSTHOOK: Lineage: nzhang_test1.key SIMPLE []
POSTHOOK: Lineage: nzhang_test1.value SIMPLE []
PREHOOK: query: select * from nzhang_test1
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
POSTHOOK: query: select * from nzhang_test1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
key1	value
1

http://asdf
PREHOOK: query: select count(*) from nzhang_test1
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from nzhang_test1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
1
PREHOOK: query: explain vectorization detail
select * from nzhang_test1 where key='key1'
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from nzhang_test1 where key='key1'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: nzhang_test1
            filterExpr: (key = 'key1') (type: boolean)
            Statistics: Num rows: 1 Data size: 25 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                vectorizationSchemaColumns: [0:key:string, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
            Filter Operator
              Filter Vectorization:
                  className: VectorFilterOperator
                  native: true
                  predicateExpression: FilterStringGroupColEqualStringScalar(col 0:string, val key1)
              predicate: (key = 'key1') (type: boolean)
              Statistics: Num rows: 1 Data size: 25 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: 'key1' (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [3, 1]
                    selectExpressions: ConstantVectorExpression(val key1) -> 3:string
                Statistics: Num rows: 1 Data size: 25 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 1 Data size: 25 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.row.serde.deserialize IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.mapred.SequenceFileInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
          rowBatchContext:
              dataColumnCount: 2
              includeColumns: [0, 1]
              dataColumns: key:string, value:string
              partitionColumnCount: 0
              scratchColumnTypeNames: [string]

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from nzhang_test1 where key='key1'
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
POSTHOOK: query: select * from nzhang_test1 where key='key1'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
key1	value
1

http://asdf
PREHOOK: query: select * from nzhang_test1
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
POSTHOOK: query: select * from nzhang_test1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
key1	value
1

http://asdf
PREHOOK: query: select count(*) from nzhang_test1
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from nzhang_test1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
1
PREHOOK: query: explain vectorization detail
select * from nzhang_test1 where key='key1'
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from nzhang_test1 where key='key1'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: nzhang_test1
            filterExpr: (key = 'key1') (type: boolean)
            Statistics: Num rows: 1 Data size: 25 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                vectorizationSchemaColumns: [0:key:string, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
            Filter Operator
              Filter Vectorization:
                  className: VectorFilterOperator
                  native: true
                  predicateExpression: FilterStringGroupColEqualStringScalar(col 0:string, val key1)
              predicate: (key = 'key1') (type: boolean)
              Statistics: Num rows: 1 Data size: 25 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: 'key1' (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [3, 1]
                    selectExpressions: ConstantVectorExpression(val key1) -> 3:string
                Statistics: Num rows: 1 Data size: 25 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 1 Data size: 25 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.row.serde.deserialize IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.mapred.SequenceFileInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
          rowBatchContext:
              dataColumnCount: 2
              includeColumns: [0, 1]
              dataColumns: key:string, value:string
              partitionColumnCount: 0
              scratchColumnTypeNames: [string]

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from nzhang_test1 where key='key1'
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
POSTHOOK: query: select * from nzhang_test1 where key='key1'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_test1
#### A masked pattern was here ####
key1	value
1

http://asdf
