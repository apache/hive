PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_1_txt
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_1_txt
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_1
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_1
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_2_txt
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_2_txt
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_2
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_2
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_3_txt
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_3_txt
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_3
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_3
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE DECIMAL_6_1_txt(key decimal(10,5), value int)
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@DECIMAL_6_1_txt
POSTHOOK: query: CREATE TABLE DECIMAL_6_1_txt(key decimal(10,5), value int)
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@DECIMAL_6_1_txt
PREHOOK: query: CREATE TABLE DECIMAL_6_2_txt(key decimal(17,4), value int)
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@DECIMAL_6_2_txt
POSTHOOK: query: CREATE TABLE DECIMAL_6_2_txt(key decimal(17,4), value int)
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@DECIMAL_6_2_txt
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv9.txt' INTO TABLE DECIMAL_6_1_txt
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@decimal_6_1_txt
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv9.txt' INTO TABLE DECIMAL_6_1_txt
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@decimal_6_1_txt
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv9.txt' INTO TABLE DECIMAL_6_2_txt
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@decimal_6_2_txt
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv9.txt' INTO TABLE DECIMAL_6_2_txt
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@decimal_6_2_txt
PREHOOK: query: CREATE TABLE DECIMAL_6_1(key decimal(10,5), value int)
STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@DECIMAL_6_1
POSTHOOK: query: CREATE TABLE DECIMAL_6_1(key decimal(10,5), value int)
STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@DECIMAL_6_1
PREHOOK: query: CREATE TABLE DECIMAL_6_2(key decimal(17,4), value int)
STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@DECIMAL_6_2
POSTHOOK: query: CREATE TABLE DECIMAL_6_2(key decimal(17,4), value int)
STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@DECIMAL_6_2
PREHOOK: query: INSERT OVERWRITE TABLE DECIMAL_6_1 SELECT * FROM DECIMAL_6_1_txt
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_1_txt
PREHOOK: Output: default@decimal_6_1
POSTHOOK: query: INSERT OVERWRITE TABLE DECIMAL_6_1 SELECT * FROM DECIMAL_6_1_txt
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_1_txt
POSTHOOK: Output: default@decimal_6_1
POSTHOOK: Lineage: decimal_6_1.key SIMPLE [(decimal_6_1_txt)decimal_6_1_txt.FieldSchema(name:key, type:decimal(10,5), comment:null), ]
POSTHOOK: Lineage: decimal_6_1.value SIMPLE [(decimal_6_1_txt)decimal_6_1_txt.FieldSchema(name:value, type:int, comment:null), ]
PREHOOK: query: INSERT OVERWRITE TABLE DECIMAL_6_2 SELECT * FROM DECIMAL_6_2_txt
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_2_txt
PREHOOK: Output: default@decimal_6_2
POSTHOOK: query: INSERT OVERWRITE TABLE DECIMAL_6_2 SELECT * FROM DECIMAL_6_2_txt
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_2_txt
POSTHOOK: Output: default@decimal_6_2
POSTHOOK: Lineage: decimal_6_2.key SIMPLE [(decimal_6_2_txt)decimal_6_2_txt.FieldSchema(name:key, type:decimal(17,4), comment:null), ]
POSTHOOK: Lineage: decimal_6_2.value SIMPLE [(decimal_6_2_txt)decimal_6_2_txt.FieldSchema(name:value, type:int, comment:null), ]
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT * FROM DECIMAL_6_1 ORDER BY key, value
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT * FROM DECIMAL_6_1 ORDER BY key, value
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: decimal_6_1
            Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                vectorizationSchemaColumns: [0:key:decimal(10,5), 1:value:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
            Select Operator
              expressions: key (type: decimal(10,5)), value (type: int)
              outputColumnNames: _col0, _col1
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumnNums: [0, 1]
              Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: decimal(10,5)), _col1 (type: int)
                sort order: ++
                Reduce Sink Vectorization:
                    className: VectorReduceSinkOperator
                    native: false
                    nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
                Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
          rowBatchContext:
              dataColumnCount: 2
              includeColumns: [0, 1]
              dataColumns: key:decimal(10,5), value:int
              partitionColumnCount: 0
              scratchColumnTypeNames: []
      Reduce Vectorization:
          enabled: false
          enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true
          enableConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: decimal(10,5)), KEY.reducesinkkey1 (type: int)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT * FROM DECIMAL_6_1 ORDER BY key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM DECIMAL_6_1 ORDER BY key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_1
#### A masked pattern was here ####
NULL	-1234567890
NULL	0
NULL	3
NULL	4
NULL	1234567890
-4400.00000	4400
-1255.49000	-1255
-1.12200	-11
-1.12000	-1
-0.33300	0
-0.30000	0
0.00000	0
0.00000	0
0.33300	0
1.00000	1
1.00000	1
1.12000	1
1.12200	1
2.00000	2
3.14000	3
3.14000	3
3.14000	4
10.00000	10
10.73433	5
124.00000	124
125.20000	125
23232.23435	2
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT * FROM DECIMAL_6_2 ORDER BY key, value
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT * FROM DECIMAL_6_2 ORDER BY key, value
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: decimal_6_2
            Statistics: Num rows: 27 Data size: 3020 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                vectorizationSchemaColumns: [0:key:decimal(17,4), 1:value:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
            Select Operator
              expressions: key (type: decimal(17,4)), value (type: int)
              outputColumnNames: _col0, _col1
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumnNums: [0, 1]
              Statistics: Num rows: 27 Data size: 3020 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: decimal(17,4)), _col1 (type: int)
                sort order: ++
                Reduce Sink Vectorization:
                    className: VectorReduceSinkOperator
                    native: false
                    nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
                Statistics: Num rows: 27 Data size: 3020 Basic stats: COMPLETE Column stats: NONE
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
          rowBatchContext:
              dataColumnCount: 2
              includeColumns: [0, 1]
              dataColumns: key:decimal(17,4), value:int
              partitionColumnCount: 0
              scratchColumnTypeNames: []
      Reduce Vectorization:
          enabled: false
          enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true
          enableConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: decimal(17,4)), KEY.reducesinkkey1 (type: int)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 27 Data size: 3020 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 27 Data size: 3020 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT * FROM DECIMAL_6_2 ORDER BY key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_2
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM DECIMAL_6_2 ORDER BY key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_2
#### A masked pattern was here ####
NULL	0
-1234567890.1235	-1234567890
-4400.0000	4400
-1255.4900	-1255
-1.1220	-11
-1.1200	-1
-0.3330	0
-0.3000	0
0.0000	0
0.0000	0
0.3330	0
1.0000	1
1.0000	1
1.1200	1
1.1220	1
2.0000	2
3.1400	3
3.1400	3
3.1400	4
10.0000	10
10.7343	5
124.0000	124
125.2000	125
23232.2344	2
2389432.2375	3
2389432.2375	4
1234567890.1235	1234567890
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT T.key from (
  SELECT key, value from DECIMAL_6_1
  UNION ALL
  SELECT key, value from DECIMAL_6_2
) T order by T.key
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT T.key from (
  SELECT key, value from DECIMAL_6_1
  UNION ALL
  SELECT key, value from DECIMAL_6_2
) T order by T.key
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: decimal_6_1
            Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: CAST( key AS decimal(18,5)) (type: decimal(18,5))
              outputColumnNames: _col0
              Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
              Union
                Statistics: Num rows: 54 Data size: 5592 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: decimal(18,5))
                  sort order: +
                  Statistics: Num rows: 54 Data size: 5592 Basic stats: COMPLETE Column stats: NONE
          TableScan
            alias: decimal_6_2
            Statistics: Num rows: 27 Data size: 3020 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: CAST( key AS decimal(18,5)) (type: decimal(18,5))
              outputColumnNames: _col0
              Statistics: Num rows: 27 Data size: 3020 Basic stats: COMPLETE Column stats: NONE
              Union
                Statistics: Num rows: 54 Data size: 5592 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: decimal(18,5))
                  sort order: +
                  Statistics: Num rows: 54 Data size: 5592 Basic stats: COMPLETE Column stats: NONE
      Map Vectorization:
          enabled: false
          enabledConditionsNotMet: Vectorized map work only works with 1 TableScanOperator IS false
      Reduce Vectorization:
          enabled: false
          enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true
          enableConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: decimal(18,5))
          outputColumnNames: _col0
          Statistics: Num rows: 54 Data size: 5592 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 54 Data size: 5592 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT T.key from (
  SELECT key, value from DECIMAL_6_1
  UNION ALL
  SELECT key, value from DECIMAL_6_2
) T order by T.key
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_1
PREHOOK: Input: default@decimal_6_2
#### A masked pattern was here ####
POSTHOOK: query: SELECT T.key from (
  SELECT key, value from DECIMAL_6_1
  UNION ALL
  SELECT key, value from DECIMAL_6_2
) T order by T.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_1
POSTHOOK: Input: default@decimal_6_2
#### A masked pattern was here ####
NULL
NULL
NULL
NULL
NULL
NULL
-1234567890.12350
-4400.00000
-4400.00000
-1255.49000
-1255.49000
-1.12200
-1.12200
-1.12000
-1.12000
-0.33300
-0.33300
-0.30000
-0.30000
0.00000
0.00000
0.00000
0.00000
0.33300
0.33300
1.00000
1.00000
1.00000
1.00000
1.12000
1.12000
1.12200
1.12200
2.00000
2.00000
3.14000
3.14000
3.14000
3.14000
3.14000
3.14000
10.00000
10.00000
10.73430
10.73433
124.00000
124.00000
125.20000
125.20000
23232.23435
23232.23440
2389432.23750
2389432.23750
1234567890.12350
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
CREATE TABLE DECIMAL_6_3 STORED AS ORC AS SELECT key + 5.5 AS k, value * 11 AS v from DECIMAL_6_1 ORDER BY v
PREHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
CREATE TABLE DECIMAL_6_3 STORED AS ORC AS SELECT key + 5.5 AS k, value * 11 AS v from DECIMAL_6_1 ORDER BY v
POSTHOOK: type: CREATETABLE_AS_SELECT
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1
  Stage-3 depends on stages: Stage-0
  Stage-2 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: decimal_6_1
            Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                vectorizationSchemaColumns: [0:key:decimal(10,5), 1:value:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
            Select Operator
              expressions: (key + 5.5) (type: decimal(11,5)), (value * 11) (type: int)
              outputColumnNames: _col0, _col1
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumnNums: [3, 4]
                  selectExpressions: DecimalColAddDecimalScalar(col 0:decimal(10,5), val 5.5) -> 3:decimal(11,5), LongColMultiplyLongScalar(col 1:int, val 11) -> 4:int
              Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col1 (type: int)
                sort order: +
                Reduce Sink Vectorization:
                    className: VectorReduceSinkOperator
                    native: false
                    nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
                Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
                value expressions: _col0 (type: decimal(11,5))
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
          rowBatchContext:
              dataColumnCount: 2
              includeColumns: [0, 1]
              dataColumns: key:decimal(10,5), value:int
              partitionColumnCount: 0
              scratchColumnTypeNames: [decimal(11,5), bigint]
      Reduce Vectorization:
          enabled: false
          enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true
          enableConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
      Reduce Operator Tree:
        Select Operator
          expressions: VALUE._col0 (type: decimal(11,5)), KEY.reducesinkkey0 (type: int)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 27 Data size: 2572 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                name: default.DECIMAL_6_3

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-3
      Create Table Operator:
        Create Table
          columns: k decimal(11,5), v int
          input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
          serde name: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          name: default.DECIMAL_6_3

  Stage: Stage-2
    Stats Work
      Basic Stats Work:

PREHOOK: query: CREATE TABLE DECIMAL_6_3 STORED AS ORC AS SELECT key + 5.5 AS k, value * 11 AS v from DECIMAL_6_1 ORDER BY v
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@decimal_6_1
PREHOOK: Output: database:default
PREHOOK: Output: default@DECIMAL_6_3
POSTHOOK: query: CREATE TABLE DECIMAL_6_3 STORED AS ORC AS SELECT key + 5.5 AS k, value * 11 AS v from DECIMAL_6_1 ORDER BY v
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@decimal_6_1
POSTHOOK: Output: database:default
POSTHOOK: Output: default@DECIMAL_6_3
POSTHOOK: Lineage: decimal_6_3.k EXPRESSION [(decimal_6_1)decimal_6_1.FieldSchema(name:key, type:decimal(10,5), comment:null), ]
POSTHOOK: Lineage: decimal_6_3.v EXPRESSION [(decimal_6_1)decimal_6_1.FieldSchema(name:value, type:int, comment:null), ]
PREHOOK: query: desc DECIMAL_6_3
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@decimal_6_3
POSTHOOK: query: desc DECIMAL_6_3
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@decimal_6_3
k                   	decimal(11,5)       	                    
v                   	int                 	                    
PREHOOK: query: SELECT * FROM DECIMAL_6_3 ORDER BY k, v
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_3
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM DECIMAL_6_3 ORDER BY k, v
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_3
#### A masked pattern was here ####
NULL	-695344902
NULL	0
NULL	33
NULL	44
NULL	695344902
-4394.50000	48400
-1249.99000	-13805
4.37800	-121
4.38000	-11
5.16700	0
5.20000	0
5.50000	0
5.50000	0
5.83300	0
6.50000	11
6.50000	11
6.62000	11
6.62200	11
7.50000	22
8.64000	33
8.64000	33
8.64000	44
15.50000	110
16.23433	55
129.50000	1364
130.70000	1375
23237.73435	22
