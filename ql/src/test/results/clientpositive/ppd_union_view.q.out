PREHOOK: query: -- test predicate pushdown on a view with a union

drop view v
PREHOOK: type: DROPVIEW
POSTHOOK: query: -- test predicate pushdown on a view with a union

drop view v
POSTHOOK: type: DROPVIEW
PREHOOK: query: create table t1_new (key string, value string) partitioned by (ds string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@t1_new
POSTHOOK: query: create table t1_new (key string, value string) partitioned by (ds string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@t1_new
PREHOOK: query: insert overwrite table t1_new partition (ds = '2011-10-15')
select 'key1', 'value1' from src tablesample (1 rows)
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@t1_new@ds=2011-10-15
POSTHOOK: query: insert overwrite table t1_new partition (ds = '2011-10-15')
select 'key1', 'value1' from src tablesample (1 rows)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@t1_new@ds=2011-10-15
POSTHOOK: Lineage: t1_new PARTITION(ds=2011-10-15).key SIMPLE []
POSTHOOK: Lineage: t1_new PARTITION(ds=2011-10-15).value SIMPLE []
PREHOOK: query: insert overwrite table t1_new partition (ds = '2011-10-16')
select 'key2', 'value2' from src tablesample (1 rows)
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@t1_new@ds=2011-10-16
POSTHOOK: query: insert overwrite table t1_new partition (ds = '2011-10-16')
select 'key2', 'value2' from src tablesample (1 rows)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@t1_new@ds=2011-10-16
POSTHOOK: Lineage: t1_new PARTITION(ds=2011-10-16).key SIMPLE []
POSTHOOK: Lineage: t1_new PARTITION(ds=2011-10-16).value SIMPLE []
PREHOOK: query: create table t1_old (keymap string, value string) partitioned by (ds string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@t1_old
POSTHOOK: query: create table t1_old (keymap string, value string) partitioned by (ds string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@t1_old
PREHOOK: query: insert overwrite table t1_old partition (ds = '2011-10-13')
select 'keymap3', 'value3' from src tablesample (1 rows)
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@t1_old@ds=2011-10-13
POSTHOOK: query: insert overwrite table t1_old partition (ds = '2011-10-13')
select 'keymap3', 'value3' from src tablesample (1 rows)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@t1_old@ds=2011-10-13
POSTHOOK: Lineage: t1_old PARTITION(ds=2011-10-13).keymap SIMPLE []
POSTHOOK: Lineage: t1_old PARTITION(ds=2011-10-13).value SIMPLE []
PREHOOK: query: insert overwrite table t1_old partition (ds = '2011-10-14')
select 'keymap4', 'value4' from src tablesample (1 rows)
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@t1_old@ds=2011-10-14
POSTHOOK: query: insert overwrite table t1_old partition (ds = '2011-10-14')
select 'keymap4', 'value4' from src tablesample (1 rows)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@t1_old@ds=2011-10-14
POSTHOOK: Lineage: t1_old PARTITION(ds=2011-10-14).keymap SIMPLE []
POSTHOOK: Lineage: t1_old PARTITION(ds=2011-10-14).value SIMPLE []
PREHOOK: query: create table t1_mapping (key string, keymap string) partitioned by (ds string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@t1_mapping
POSTHOOK: query: create table t1_mapping (key string, keymap string) partitioned by (ds string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@t1_mapping
PREHOOK: query: insert overwrite table t1_mapping partition (ds = '2011-10-13')
select 'key3', 'keymap3' from src tablesample (1 rows)
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@t1_mapping@ds=2011-10-13
POSTHOOK: query: insert overwrite table t1_mapping partition (ds = '2011-10-13')
select 'key3', 'keymap3' from src tablesample (1 rows)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@t1_mapping@ds=2011-10-13
POSTHOOK: Lineage: t1_mapping PARTITION(ds=2011-10-13).key SIMPLE []
POSTHOOK: Lineage: t1_mapping PARTITION(ds=2011-10-13).keymap SIMPLE []
PREHOOK: query: insert overwrite table t1_mapping partition (ds = '2011-10-14')
select 'key4', 'keymap4' from src tablesample (1 rows)
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@t1_mapping@ds=2011-10-14
POSTHOOK: query: insert overwrite table t1_mapping partition (ds = '2011-10-14')
select 'key4', 'keymap4' from src tablesample (1 rows)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@t1_mapping@ds=2011-10-14
POSTHOOK: Lineage: t1_mapping PARTITION(ds=2011-10-14).key SIMPLE []
POSTHOOK: Lineage: t1_mapping PARTITION(ds=2011-10-14).keymap SIMPLE []
PREHOOK: query: create view t1 partitioned on (ds) as
select * from
(
select key, value, ds from t1_new
union all
select key, value, t1_old.ds from t1_old join t1_mapping
on t1_old.keymap = t1_mapping.keymap and
   t1_old.ds = t1_mapping.ds
) subq
PREHOOK: type: CREATEVIEW
PREHOOK: Input: default@t1_mapping
PREHOOK: Input: default@t1_new
PREHOOK: Input: default@t1_old
PREHOOK: Output: database:default
PREHOOK: Output: default@t1
POSTHOOK: query: create view t1 partitioned on (ds) as
select * from
(
select key, value, ds from t1_new
union all
select key, value, t1_old.ds from t1_old join t1_mapping
on t1_old.keymap = t1_mapping.keymap and
   t1_old.ds = t1_mapping.ds
) subq
POSTHOOK: type: CREATEVIEW
POSTHOOK: Input: default@t1_mapping
POSTHOOK: Input: default@t1_new
POSTHOOK: Input: default@t1_old
POSTHOOK: Output: database:default
POSTHOOK: Output: default@t1
PREHOOK: query: explain extended
select * from t1 where ds = '2011-10-13'
PREHOOK: type: QUERY
POSTHOOK: query: explain extended
select * from t1 where ds = '2011-10-13'
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF
      TOK_WHERE
         =
            TOK_TABLE_OR_COL
               ds
            '2011-10-13'


STAGE DEPENDENCIES:
  Stage-3 is a root stage
  Stage-2 depends on stages: Stage-3
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: t1_old
            Statistics: Num rows: 1 Data size: 14 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: keymap is not null (type: boolean)
              Statistics: Num rows: 1 Data size: 14 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: keymap (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 14 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string), '2011-10-13' (type: string)
                  sort order: ++
                  Map-reduce partition columns: _col0 (type: string), '2011-10-13' (type: string)
                  Statistics: Num rows: 1 Data size: 14 Basic stats: COMPLETE Column stats: NONE
                  tag: 0
                  value expressions: _col1 (type: string)
                  auto parallelism: false
          TableScan
            alias: t1_mapping
            Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: keymap is not null (type: boolean)
              Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), keymap (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: string), '2011-10-13' (type: string)
                  sort order: ++
                  Map-reduce partition columns: _col1 (type: string), '2011-10-13' (type: string)
                  Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: NONE
                  tag: 1
                  value expressions: _col0 (type: string)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: ds=2011-10-13
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2011-10-13
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,keymap
              columns.comments 
              columns.types string:string
#### A masked pattern was here ####
              name default.t1_mapping
              numFiles 1
              numRows 1
              partition_columns ds
              partition_columns.types string
              rawDataSize 12
              serialization.ddl struct t1_mapping { string key, string keymap}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 13
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,keymap
                columns.comments 
                columns.types string:string
#### A masked pattern was here ####
                name default.t1_mapping
                partition_columns ds
                partition_columns.types string
                serialization.ddl struct t1_mapping { string key, string keymap}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.t1_mapping
            name: default.t1_mapping
#### A masked pattern was here ####
          Partition
            base file name: ds=2011-10-13
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2011-10-13
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns keymap,value
              columns.comments 
              columns.types string:string
#### A masked pattern was here ####
              name default.t1_old
              numFiles 1
              numRows 1
              partition_columns ds
              partition_columns.types string
              rawDataSize 14
              serialization.ddl struct t1_old { string keymap, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 15
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns keymap,value
                columns.comments 
                columns.types string:string
#### A masked pattern was here ####
                name default.t1_old
                partition_columns ds
                partition_columns.types string
                serialization.ddl struct t1_old { string keymap, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.t1_old
            name: default.t1_old
      Truncated Path -> Alias:
        /t1_mapping/ds=2011-10-13 [null-subquery2:$hdt$_0-subquery2:$hdt$_1:t1_mapping]
        /t1_old/ds=2011-10-13 [null-subquery2:$hdt$_0-subquery2:$hdt$_0:t1_old]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 _col0 (type: string), _col2 (type: string)
            1 _col1 (type: string), _col2 (type: string)
          outputColumnNames: _col1, _col3
          Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: _col3 (type: string), _col1 (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string,string
                    escape.delim \
                    serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: t1_new
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (ds = '2011-10-13') (type: boolean)
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Union
                  Statistics: Num rows: 2 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string), '2011-10-13' (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 2 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      GlobalTableId: 0
#### A masked pattern was here ####
                      NumFilesPerFileSink: 1
                      Statistics: Num rows: 2 Data size: 15 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          properties:
                            columns _col0,_col1,_col2
                            columns.types string:string:string
                            escape.delim \
                            hive.serialization.extend.additional.nesting.levels true
                            serialization.escape.crlf true
                            serialization.format 1
                            serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      TotalFiles: 1
                      GatherStats: false
                      MultiFileSpray: false
          TableScan
            GatherStats: false
            Union
              Statistics: Num rows: 2 Data size: 15 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: _col0 (type: string), _col1 (type: string), '2011-10-13' (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 2 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 2 Data size: 15 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types string:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: -mr-10004
            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
            properties:
              columns _col0,_col1
              columns.types string,string
              escape.delim \
              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
          
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              properties:
                columns _col0,_col1
                columns.types string,string
                escape.delim \
                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
      Truncated Path -> Alias:
#### A masked pattern was here ####

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1 where ds = '2011-10-13'
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
PREHOOK: Input: default@t1_mapping
PREHOOK: Input: default@t1_mapping@ds=2011-10-13
PREHOOK: Input: default@t1_new
PREHOOK: Input: default@t1_old
PREHOOK: Input: default@t1_old@ds=2011-10-13
#### A masked pattern was here ####
POSTHOOK: query: select * from t1 where ds = '2011-10-13'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
POSTHOOK: Input: default@t1_mapping
POSTHOOK: Input: default@t1_mapping@ds=2011-10-13
POSTHOOK: Input: default@t1_new
POSTHOOK: Input: default@t1_old
POSTHOOK: Input: default@t1_old@ds=2011-10-13
#### A masked pattern was here ####
key3	value3	2011-10-13
PREHOOK: query: select * from t1 where ds = '2011-10-14'
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
PREHOOK: Input: default@t1_mapping
PREHOOK: Input: default@t1_mapping@ds=2011-10-14
PREHOOK: Input: default@t1_new
PREHOOK: Input: default@t1_old
PREHOOK: Input: default@t1_old@ds=2011-10-14
#### A masked pattern was here ####
POSTHOOK: query: select * from t1 where ds = '2011-10-14'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
POSTHOOK: Input: default@t1_mapping
POSTHOOK: Input: default@t1_mapping@ds=2011-10-14
POSTHOOK: Input: default@t1_new
POSTHOOK: Input: default@t1_old
POSTHOOK: Input: default@t1_old@ds=2011-10-14
#### A masked pattern was here ####
key4	value4	2011-10-14
PREHOOK: query: explain extended
select * from t1 where ds = '2011-10-15'
PREHOOK: type: QUERY
POSTHOOK: query: explain extended
select * from t1 where ds = '2011-10-15'
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF
      TOK_WHERE
         =
            TOK_TABLE_OR_COL
               ds
            '2011-10-15'


STAGE DEPENDENCIES:
  Stage-3 is a root stage
  Stage-2 depends on stages: Stage-3
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: t1_old
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: ((ds = '2011-10-15') and keymap is not null) (type: boolean)
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Select Operator
                expressions: keymap (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string), '2011-10-15' (type: string)
                  sort order: ++
                  Map-reduce partition columns: _col0 (type: string), '2011-10-15' (type: string)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  tag: 0
                  value expressions: _col1 (type: string)
                  auto parallelism: false
          TableScan
            alias: t1_mapping
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: ((ds = '2011-10-15') and keymap is not null) (type: boolean)
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Select Operator
                expressions: key (type: string), keymap (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: string), '2011-10-15' (type: string)
                  sort order: ++
                  Map-reduce partition columns: _col1 (type: string), '2011-10-15' (type: string)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  tag: 1
                  value expressions: _col0 (type: string)
                  auto parallelism: false
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 _col0 (type: string), _col2 (type: string)
            1 _col1 (type: string), _col2 (type: string)
          outputColumnNames: _col1, _col3
          Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
          Select Operator
            expressions: _col3 (type: string), _col1 (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string,string
                    escape.delim \
                    serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: t1_new
            Statistics: Num rows: 1 Data size: 11 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Select Operator
              expressions: key (type: string), value (type: string)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 1 Data size: 11 Basic stats: COMPLETE Column stats: NONE
              Union
                Statistics: Num rows: 2 Data size: 11 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: string), _col1 (type: string), '2011-10-15' (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 2 Data size: 11 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 2 Data size: 11 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          columns _col0,_col1,_col2
                          columns.types string:string:string
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false
          TableScan
            GatherStats: false
            Union
              Statistics: Num rows: 2 Data size: 11 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: _col0 (type: string), _col1 (type: string), '2011-10-15' (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 2 Data size: 11 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 2 Data size: 11 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types string:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: -mr-10004
            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
            properties:
              columns _col0,_col1
              columns.types string,string
              escape.delim \
              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
          
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              properties:
                columns _col0,_col1
                columns.types string,string
                escape.delim \
                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
#### A masked pattern was here ####
          Partition
            base file name: ds=2011-10-15
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2011-10-15
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 
              columns.types string:string
#### A masked pattern was here ####
              name default.t1_new
              numFiles 1
              numRows 1
              partition_columns ds
              partition_columns.types string
              rawDataSize 11
              serialization.ddl struct t1_new { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 12
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 
                columns.types string:string
#### A masked pattern was here ####
                name default.t1_new
                partition_columns ds
                partition_columns.types string
                serialization.ddl struct t1_new { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.t1_new
            name: default.t1_new
      Truncated Path -> Alias:
        /t1_new/ds=2011-10-15 [null-subquery1:$hdt$_0-subquery1:t1_new]
#### A masked pattern was here ####

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1 where ds = '2011-10-15'
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
PREHOOK: Input: default@t1_mapping
PREHOOK: Input: default@t1_new
PREHOOK: Input: default@t1_new@ds=2011-10-15
PREHOOK: Input: default@t1_old
#### A masked pattern was here ####
POSTHOOK: query: select * from t1 where ds = '2011-10-15'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
POSTHOOK: Input: default@t1_mapping
POSTHOOK: Input: default@t1_new
POSTHOOK: Input: default@t1_new@ds=2011-10-15
POSTHOOK: Input: default@t1_old
#### A masked pattern was here ####
key1	value1	2011-10-15
PREHOOK: query: select * from t1 where ds = '2011-10-16'
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
PREHOOK: Input: default@t1_mapping
PREHOOK: Input: default@t1_new
PREHOOK: Input: default@t1_new@ds=2011-10-16
PREHOOK: Input: default@t1_old
#### A masked pattern was here ####
POSTHOOK: query: select * from t1 where ds = '2011-10-16'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
POSTHOOK: Input: default@t1_mapping
POSTHOOK: Input: default@t1_new
POSTHOOK: Input: default@t1_new@ds=2011-10-16
POSTHOOK: Input: default@t1_old
#### A masked pattern was here ####
key2	value2	2011-10-16
