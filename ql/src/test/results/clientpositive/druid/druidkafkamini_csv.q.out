PREHOOK: query: CREATE EXTERNAL TABLE druid_kafka_test_csv(`__time` timestamp , `page` string, `user` string, `language` string,
                                            `country` string,`continent` string, `namespace` string, `newpage` boolean, `unpatrolled` boolean,
                                            `anonymous` boolean, `robot` boolean, added int, deleted int, delta bigint)
        STORED BY 'org.apache.hadoop.hive.druid.DruidStorageHandler'
        TBLPROPERTIES (
        "druid.segment.granularity" = "MONTH",
        "druid.query.granularity" = "MINUTE",
        "kafka.bootstrap.servers" = "localhost:9092",
        "kafka.topic" = "wiki_kafka_csv",
        "druid.kafka.ingestion.useEarliestOffset" = "true",
        "druid.kafka.ingestion.maxRowsInMemory" = "5",
        "druid.kafka.ingestion.startDelay" = "PT1S",
        "druid.kafka.ingestion.taskDuration" = "PT30S",
        "druid.kafka.ingestion.period" = "PT5S",
        "druid.kafka.ingestion.consumer.retries" = "2",
        "druid.kafka.ingestion.reportParseExceptions" = "true",
        "druid.parseSpec.format" = "csv",
        "druid.parseSpec.columns" = "__time,page,language,user,unpatrolled,newpage,robot,anonymous,namespace,continent,country,region,city,added,deleted,delta"
        )
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@druid_kafka_test_csv
POSTHOOK: query: CREATE EXTERNAL TABLE druid_kafka_test_csv(`__time` timestamp , `page` string, `user` string, `language` string,
                                            `country` string,`continent` string, `namespace` string, `newpage` boolean, `unpatrolled` boolean,
                                            `anonymous` boolean, `robot` boolean, added int, deleted int, delta bigint)
        STORED BY 'org.apache.hadoop.hive.druid.DruidStorageHandler'
        TBLPROPERTIES (
        "druid.segment.granularity" = "MONTH",
        "druid.query.granularity" = "MINUTE",
        "kafka.bootstrap.servers" = "localhost:9092",
        "kafka.topic" = "wiki_kafka_csv",
        "druid.kafka.ingestion.useEarliestOffset" = "true",
        "druid.kafka.ingestion.maxRowsInMemory" = "5",
        "druid.kafka.ingestion.startDelay" = "PT1S",
        "druid.kafka.ingestion.taskDuration" = "PT30S",
        "druid.kafka.ingestion.period" = "PT5S",
        "druid.kafka.ingestion.consumer.retries" = "2",
        "druid.kafka.ingestion.reportParseExceptions" = "true",
        "druid.parseSpec.format" = "csv",
        "druid.parseSpec.columns" = "__time,page,language,user,unpatrolled,newpage,robot,anonymous,namespace,continent,country,region,city,added,deleted,delta"
        )
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@druid_kafka_test_csv
PREHOOK: query: ALTER TABLE druid_kafka_test_csv SET TBLPROPERTIES('druid.kafka.ingestion' = 'START')
PREHOOK: type: ALTERTABLE_PROPERTIES
PREHOOK: Input: default@druid_kafka_test_csv
PREHOOK: Output: default@druid_kafka_test_csv
POSTHOOK: query: ALTER TABLE druid_kafka_test_csv SET TBLPROPERTIES('druid.kafka.ingestion' = 'START')
POSTHOOK: type: ALTERTABLE_PROPERTIES
POSTHOOK: Input: default@druid_kafka_test_csv
POSTHOOK: Output: default@druid_kafka_test_csv
["default.druid_kafka_test_csv"]
PREHOOK: query: DESCRIBE druid_kafka_test_csv
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@druid_kafka_test_csv
POSTHOOK: query: DESCRIBE druid_kafka_test_csv
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@druid_kafka_test_csv
__time              	timestamp           	from deserializer   
page                	string              	from deserializer   
user                	string              	from deserializer   
language            	string              	from deserializer   
country             	string              	from deserializer   
continent           	string              	from deserializer   
namespace           	string              	from deserializer   
newpage             	boolean             	from deserializer   
unpatrolled         	boolean             	from deserializer   
anonymous           	boolean             	from deserializer   
robot               	boolean             	from deserializer   
added               	int                 	from deserializer   
deleted             	int                 	from deserializer   
delta               	bigint              	from deserializer   
PREHOOK: query: DESCRIBE EXTENDED druid_kafka_test_csv
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@druid_kafka_test_csv
POSTHOOK: query: DESCRIBE EXTENDED druid_kafka_test_csv
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@druid_kafka_test_csv
__time              	timestamp           	from deserializer   
page                	string              	from deserializer   
user                	string              	from deserializer   
language            	string              	from deserializer   
country             	string              	from deserializer   
continent           	string              	from deserializer   
namespace           	string              	from deserializer   
newpage             	boolean             	from deserializer   
unpatrolled         	boolean             	from deserializer   
anonymous           	boolean             	from deserializer   
robot               	boolean             	from deserializer   
added               	int                 	from deserializer   
deleted             	int                 	from deserializer   
delta               	bigint              	from deserializer   
	 	 
#### A masked pattern was here ####
StorageHandlerInfo	 	 
Druid Storage Handler Runtime Status for default.druid_kafka_test_csv	 	 
kafkaPartitions=1	 	 
activeTasks=[]	 	 
publishingTasks=[]	 	 
#### A masked pattern was here ####
aggregateLag=0	 	 
#### A masked pattern was here ####
PREHOOK: query: Select count(*) FROM druid_kafka_test_csv
PREHOOK: type: QUERY
PREHOOK: Input: default@druid_kafka_test_csv
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: Select count(*) FROM druid_kafka_test_csv
POSTHOOK: type: QUERY
POSTHOOK: Input: default@druid_kafka_test_csv
POSTHOOK: Output: hdfs://### HDFS PATH ###
10
PREHOOK: query: Select page FROM druid_kafka_test_csv
PREHOOK: type: QUERY
PREHOOK: Input: default@druid_kafka_test_csv
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: Select page FROM druid_kafka_test_csv
POSTHOOK: type: QUERY
POSTHOOK: Input: default@druid_kafka_test_csv
POSTHOOK: Output: hdfs://### HDFS PATH ###
Gypsy Danger
Striker Eureka
Cherno Alpha
Crimson Typhoon
Coyote Tango
Gypsy Danger
Striker Eureka
Cherno Alpha
Crimson Typhoon
Coyote Tango
PREHOOK: query: DROP TABLE druid_kafka_test_csv
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@druid_kafka_test_csv
PREHOOK: Output: default@druid_kafka_test_csv
POSTHOOK: query: DROP TABLE druid_kafka_test_csv
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@druid_kafka_test_csv
POSTHOOK: Output: default@druid_kafka_test_csv
