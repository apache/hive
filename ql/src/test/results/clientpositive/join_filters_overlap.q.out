PREHOOK: query: -- HIVE-3411 Filter predicates on outer join overlapped on single alias is not handled properly

create table a as SELECT 100 as key, a.value as value FROM src LATERAL VIEW explode(array(40, 50, 60)) a as value limit 3
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
POSTHOOK: query: -- HIVE-3411 Filter predicates on outer join overlapped on single alias is not handled properly

create table a as SELECT 100 as key, a.value as value FROM src LATERAL VIEW explode(array(40, 50, 60)) a as value limit 3
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: default@a
PREHOOK: query: -- overlap on a
explain extended select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60)
PREHOOK: type: QUERY
POSTHOOK: query: -- overlap on a
explain extended select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_LEFTOUTERJOIN (TOK_LEFTOUTERJOIN (TOK_TABREF (TOK_TABNAME a)) (TOK_TABREF (TOK_TABNAME a) b) (AND (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) (= (. (TOK_TABLE_OR_COL a) value) 50)) (= (. (TOK_TABLE_OR_COL b) value) 50))) (TOK_TABREF (TOK_TABNAME a) c) (AND (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL c) key)) (= (. (TOK_TABLE_OR_COL a) value) 60)) (= (. (TOK_TABLE_OR_COL c) value) 60)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: int
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: int
              tag: 0
              value expressions:
                    expr: key
                    type: int
                    expr: value
                    type: int
        b 
          TableScan
            alias: b
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 50)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 1
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
        c 
          TableScan
            alias: c
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 60)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 2
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: a
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.types int:int
#### A masked pattern was here ####
              name default.a
              numFiles 1
              numRows 3
              rawDataSize 18
              serialization.ddl struct a { i32 key, i32 value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 21
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.types int:int
#### A masked pattern was here ####
                name default.a
                numFiles 1
                numRows 3
                rawDataSize 18
                serialization.ddl struct a { i32 key, i32 value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 21
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.a
            name: default.a
      Truncated Path -> Alias:
        /a [b, c, a]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Outer Join0 to 1
               Left Outer Join0 to 2
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 {VALUE._col0} {VALUE._col1}
            2 {VALUE._col0} {VALUE._col1}
          filter mappings:
            0 [1, 1, 2, 1]
          filter predicates:
            0 {(VALUE._col1 = 50)} {(VALUE._col1 = 60)}
            1 
            2 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col4, _col5, _col8, _col9
          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: int
                  expr: _col4
                  type: int
                  expr: _col5
                  type: int
                  expr: _col8
                  type: int
                  expr: _col9
                  type: int
            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1,_col2,_col3,_col4,_col5
                    columns.types int:int:int:int:int:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL
100	50	100	50	NULL	NULL
100	60	NULL	NULL	100	60
PREHOOK: query: select /*+ MAPJOIN(b,c)*/ * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) order by a.key ASC, a.value ASC
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(b,c)*/ * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) order by a.key ASC, a.value ASC
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL
100	50	100	50	NULL	NULL
100	60	NULL	NULL	100	60
PREHOOK: query: -- overlap on b
explain extended select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
POSTHOOK: query: -- overlap on b
explain extended select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_LEFTOUTERJOIN (TOK_RIGHTOUTERJOIN (TOK_TABREF (TOK_TABNAME a)) (TOK_TABREF (TOK_TABNAME a) b) (AND (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) (= (. (TOK_TABLE_OR_COL a) value) 50)) (= (. (TOK_TABLE_OR_COL b) value) 50))) (TOK_TABREF (TOK_TABNAME a) c) (AND (AND (= (. (TOK_TABLE_OR_COL b) key) (. (TOK_TABLE_OR_COL c) key)) (= (. (TOK_TABLE_OR_COL b) value) 60)) (= (. (TOK_TABLE_OR_COL c) value) 60)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 50)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 0
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
        b 
          TableScan
            alias: b
            GatherStats: false
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: int
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: int
              tag: 1
              value expressions:
                    expr: key
                    type: int
                    expr: value
                    type: int
        c 
          TableScan
            alias: c
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 60)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 2
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: a
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.types int:int
#### A masked pattern was here ####
              name default.a
              numFiles 1
              numRows 3
              rawDataSize 18
              serialization.ddl struct a { i32 key, i32 value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 21
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.types int:int
#### A masked pattern was here ####
                name default.a
                numFiles 1
                numRows 3
                rawDataSize 18
                serialization.ddl struct a { i32 key, i32 value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 21
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.a
            name: default.a
      Truncated Path -> Alias:
        /a [b, c, a]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Right Outer Join0 to 1
               Left Outer Join1 to 2
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 {VALUE._col0} {VALUE._col1}
            2 {VALUE._col0} {VALUE._col1}
          filter mappings:
            1 [0, 1, 2, 1]
          filter predicates:
            0 
            1 {(VALUE._col1 = 50)} {(VALUE._col1 = 60)}
            2 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col4, _col5, _col8, _col9
          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: int
                  expr: _col4
                  type: int
                  expr: _col5
                  type: int
                  expr: _col8
                  type: int
                  expr: _col9
                  type: int
            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1,_col2,_col3,_col4,_col5
                    columns.types int:int:int:int:int:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
NULL	NULL	100	40	NULL	NULL
100	50	100	50	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: select /*+ MAPJOIN(a,c)*/ * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60) order by b.key ASC, b.value ASC
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(a,c)*/ * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60) order by b.key ASC, b.value ASC
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
NULL	NULL	100	40	NULL	NULL
100	50	100	50	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: -- overlap on b with two filters for each
explain extended select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
POSTHOOK: query: -- overlap on b with two filters for each
explain extended select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_LEFTOUTERJOIN (TOK_RIGHTOUTERJOIN (TOK_TABREF (TOK_TABNAME a)) (TOK_TABREF (TOK_TABNAME a) b) (AND (AND (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) (= (. (TOK_TABLE_OR_COL a) value) 50)) (= (. (TOK_TABLE_OR_COL b) value) 50)) (> (. (TOK_TABLE_OR_COL b) value) 10))) (TOK_TABREF (TOK_TABNAME a) c) (AND (AND (AND (= (. (TOK_TABLE_OR_COL b) key) (. (TOK_TABLE_OR_COL c) key)) (= (. (TOK_TABLE_OR_COL b) value) 60)) (> (. (TOK_TABLE_OR_COL b) value) 20)) (= (. (TOK_TABLE_OR_COL c) value) 60)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 50)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 0
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
        b 
          TableScan
            alias: b
            GatherStats: false
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: int
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: int
              tag: 1
              value expressions:
                    expr: key
                    type: int
                    expr: value
                    type: int
        c 
          TableScan
            alias: c
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 60)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 2
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: a
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.types int:int
#### A masked pattern was here ####
              name default.a
              numFiles 1
              numRows 3
              rawDataSize 18
              serialization.ddl struct a { i32 key, i32 value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 21
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.types int:int
#### A masked pattern was here ####
                name default.a
                numFiles 1
                numRows 3
                rawDataSize 18
                serialization.ddl struct a { i32 key, i32 value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 21
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.a
            name: default.a
      Truncated Path -> Alias:
        /a [b, c, a]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Right Outer Join0 to 1
               Left Outer Join1 to 2
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 {VALUE._col0} {VALUE._col1}
            2 {VALUE._col0} {VALUE._col1}
          filter mappings:
            1 [0, 2, 2, 2]
          filter predicates:
            0 
            1 {(VALUE._col1 = 50)} {(VALUE._col1 > 10)} {(VALUE._col1 = 60)} {(VALUE._col1 > 20)}
            2 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col4, _col5, _col8, _col9
          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: int
                  expr: _col4
                  type: int
                  expr: _col5
                  type: int
                  expr: _col8
                  type: int
                  expr: _col9
                  type: int
            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1,_col2,_col3,_col4,_col5
                    columns.types int:int:int:int:int:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
NULL	NULL	100	40	NULL	NULL
100	50	100	50	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: select /*+ MAPJOIN(a,c)*/ * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60) order by b.key ASC, b.value ASC
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(a,c)*/ * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60) order by b.key ASC, b.value ASC
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
NULL	NULL	100	40	NULL	NULL
100	50	100	50	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: -- overlap on a, b
explain extended select * from a full outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
PREHOOK: type: QUERY
POSTHOOK: query: -- overlap on a, b
explain extended select * from a full outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_LEFTOUTERJOIN (TOK_LEFTOUTERJOIN (TOK_FULLOUTERJOIN (TOK_TABREF (TOK_TABNAME a)) (TOK_TABREF (TOK_TABNAME a) b) (AND (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) (= (. (TOK_TABLE_OR_COL a) value) 50)) (= (. (TOK_TABLE_OR_COL b) value) 50))) (TOK_TABREF (TOK_TABNAME a) c) (AND (AND (= (. (TOK_TABLE_OR_COL b) key) (. (TOK_TABLE_OR_COL c) key)) (= (. (TOK_TABLE_OR_COL b) value) 60)) (= (. (TOK_TABLE_OR_COL c) value) 60))) (TOK_TABREF (TOK_TABNAME a) d) (AND (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL d) key)) (= (. (TOK_TABLE_OR_COL a) value) 40)) (= (. (TOK_TABLE_OR_COL d) value) 40)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: int
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: int
              tag: 0
              value expressions:
                    expr: key
                    type: int
                    expr: value
                    type: int
        b 
          TableScan
            alias: b
            GatherStats: false
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: int
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: int
              tag: 1
              value expressions:
                    expr: key
                    type: int
                    expr: value
                    type: int
        c 
          TableScan
            alias: c
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 60)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 2
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
        d 
          TableScan
            alias: d
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 40)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 3
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: a
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.types int:int
#### A masked pattern was here ####
              name default.a
              numFiles 1
              numRows 3
              rawDataSize 18
              serialization.ddl struct a { i32 key, i32 value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 21
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.types int:int
#### A masked pattern was here ####
                name default.a
                numFiles 1
                numRows 3
                rawDataSize 18
                serialization.ddl struct a { i32 key, i32 value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 21
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.a
            name: default.a
      Truncated Path -> Alias:
        /a [d, b, c, a]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Outer Join 0 to 1
               Left Outer Join1 to 2
               Left Outer Join0 to 3
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 {VALUE._col0} {VALUE._col1}
            2 {VALUE._col0} {VALUE._col1}
            3 {VALUE._col0} {VALUE._col1}
          filter mappings:
            0 [1, 1, 3, 1]
            1 [0, 1, 2, 1]
          filter predicates:
            0 {(VALUE._col1 = 50)} {(VALUE._col1 = 40)}
            1 {(VALUE._col1 = 50)} {(VALUE._col1 = 60)}
            2 
            3 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col4, _col5, _col8, _col9, _col12, _col13
          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: int
                  expr: _col4
                  type: int
                  expr: _col5
                  type: int
                  expr: _col8
                  type: int
                  expr: _col9
                  type: int
                  expr: _col12
                  type: int
                  expr: _col13
                  type: int
            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
                    columns.types int:int:int:int:int:int:int:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: select * from a full outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select * from a full outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
NULL	NULL	100	40	NULL	NULL	NULL	NULL
NULL	NULL	100	60	100	60	NULL	NULL
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	NULL	NULL	NULL	NULL
PREHOOK: query: -- triple overlap on a
explain extended select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
PREHOOK: type: QUERY
POSTHOOK: query: -- triple overlap on a
explain extended select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_LEFTOUTERJOIN (TOK_LEFTOUTERJOIN (TOK_LEFTOUTERJOIN (TOK_TABREF (TOK_TABNAME a)) (TOK_TABREF (TOK_TABNAME a) b) (AND (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) (= (. (TOK_TABLE_OR_COL a) value) 50)) (= (. (TOK_TABLE_OR_COL b) value) 50))) (TOK_TABREF (TOK_TABNAME a) c) (AND (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL c) key)) (= (. (TOK_TABLE_OR_COL a) value) 60)) (= (. (TOK_TABLE_OR_COL c) value) 60))) (TOK_TABREF (TOK_TABNAME a) d) (AND (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL d) key)) (= (. (TOK_TABLE_OR_COL a) value) 40)) (= (. (TOK_TABLE_OR_COL d) value) 40)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: int
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: int
              tag: 0
              value expressions:
                    expr: key
                    type: int
                    expr: value
                    type: int
        b 
          TableScan
            alias: b
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 50)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 1
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
        c 
          TableScan
            alias: c
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 60)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 2
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
        d 
          TableScan
            alias: d
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (value = 40)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: int
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: int
                tag: 3
                value expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: a
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.types int:int
#### A masked pattern was here ####
              name default.a
              numFiles 1
              numRows 3
              rawDataSize 18
              serialization.ddl struct a { i32 key, i32 value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 21
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.types int:int
#### A masked pattern was here ####
                name default.a
                numFiles 1
                numRows 3
                rawDataSize 18
                serialization.ddl struct a { i32 key, i32 value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 21
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.a
            name: default.a
      Truncated Path -> Alias:
        /a [d, b, c, a]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Outer Join0 to 1
               Left Outer Join0 to 2
               Left Outer Join0 to 3
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 {VALUE._col0} {VALUE._col1}
            2 {VALUE._col0} {VALUE._col1}
            3 {VALUE._col0} {VALUE._col1}
          filter mappings:
            0 [1, 1, 2, 1, 3, 1]
          filter predicates:
            0 {(VALUE._col1 = 50)} {(VALUE._col1 = 60)} {(VALUE._col1 = 40)}
            1 
            2 
            3 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col4, _col5, _col8, _col9, _col12, _col13
          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: int
                  expr: _col4
                  type: int
                  expr: _col5
                  type: int
                  expr: _col8
                  type: int
                  expr: _col9
                  type: int
                  expr: _col12
                  type: int
                  expr: _col13
                  type: int
            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
                    columns.types int:int:int:int:int:int:int:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	100	60	NULL	NULL
PREHOOK: query: select /*+ MAPJOIN(b,c, d)*/ * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40) order by a.key ASC, a.value ASC
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(b,c, d)*/ * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40) order by a.key ASC, a.value ASC
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	100	60	NULL	NULL
