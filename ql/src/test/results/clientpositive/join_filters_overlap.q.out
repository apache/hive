PREHOOK: query: create table a_n4 as SELECT 100 as key, a_n4.value as value FROM src LATERAL VIEW explode(array(40, 50, 60)) a_n4 as value limit 3
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@a_n4
POSTHOOK: query: create table a_n4 as SELECT 100 as key, a_n4.value as value FROM src LATERAL VIEW explode(array(40, 50, 60)) a_n4 as value limit 3
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@a_n4
POSTHOOK: Lineage: a_n4.key SIMPLE []
POSTHOOK: Lineage: a_n4.value SCRIPT []
PREHOOK: query: explain extended select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: a_n4
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Select Operator
              expressions: key (type: int), value (type: int)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: int)
                null sort order: a
                sort order: +
                Map-reduce partition columns: _col0 (type: int)
                Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                tag: 0
                value expressions: _col1 (type: int)
                auto parallelism: false
          TableScan
            alias: b
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 50) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 50 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 1
                  value expressions: _col1 (type: int)
                  auto parallelism: false
          TableScan
            alias: c
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 60) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 60 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 2
                  value expressions: _col1 (type: int)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: a_n4
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count -1
              bucketing_version 2
              column.name.delimiter ,
              columns key,value
              columns.comments 
              columns.types int:int
#### A masked pattern was here ####
              name default.a_n4
              numFiles 1
              numRows 3
              rawDataSize 18
              serialization.ddl struct a_n4 { i32 key, i32 value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 21
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                bucket_count -1
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 
                columns.types int:int
#### A masked pattern was here ####
                name default.a_n4
                numFiles 1
                numRows 3
                rawDataSize 18
                serialization.ddl struct a_n4 { i32 key, i32 value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 21
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.a_n4
            name: default.a_n4
      Truncated Path -> Alias:
        /a_n4 [$hdt$_0:a_n4, $hdt$_1:b, $hdt$_2:c]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Outer Join 0 to 1
               Left Outer Join 0 to 2
          filter mappings:
            0 [1, 1, 2, 1]
          filter predicates:
            0 {(VALUE._col0 = 50)} {(VALUE._col0 = 60)}
            1 
            2 
          keys:
            0 _col0 (type: int)
            1 _col0 (type: int)
            2 _col0 (type: int)
          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
          Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            GlobalTableId: 0
#### A masked pattern was here ####
            NumFilesPerFileSink: 1
            Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                properties:
                  columns _col0,_col1,_col2,_col3,_col4,_col5
                  columns.types int:int:int:int:int:int
                  escape.delim \
                  hive.serialization.extend.additional.nesting.levels true
                  serialization.escape.crlf true
                  serialization.format 1
                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            TotalFiles: 1
            GatherStats: false
            MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL
100	50	100	50	NULL	NULL
100	60	NULL	NULL	100	60
PREHOOK: query: select /*+ MAPJOIN(b,c)*/ * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(b,c)*/ * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL
100	50	100	50	NULL	NULL
100	60	NULL	NULL	100	60
PREHOOK: query: explain extended select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: a_n4
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 50) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 50 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 0
                  value expressions: _col1 (type: int)
                  auto parallelism: false
          TableScan
            alias: b
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Select Operator
              expressions: key (type: int), value (type: int)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: int)
                null sort order: a
                sort order: +
                Map-reduce partition columns: _col0 (type: int)
                Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                tag: 1
                value expressions: _col1 (type: int)
                auto parallelism: false
          TableScan
            alias: c
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 60) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 60 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 2
                  value expressions: _col1 (type: int)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: a_n4
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count -1
              bucketing_version 2
              column.name.delimiter ,
              columns key,value
              columns.comments 
              columns.types int:int
#### A masked pattern was here ####
              name default.a_n4
              numFiles 1
              numRows 3
              rawDataSize 18
              serialization.ddl struct a_n4 { i32 key, i32 value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 21
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                bucket_count -1
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 
                columns.types int:int
#### A masked pattern was here ####
                name default.a_n4
                numFiles 1
                numRows 3
                rawDataSize 18
                serialization.ddl struct a_n4 { i32 key, i32 value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 21
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.a_n4
            name: default.a_n4
      Truncated Path -> Alias:
        /a_n4 [$hdt$_0:a_n4, $hdt$_1:b, $hdt$_2:c]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Right Outer Join 0 to 1
               Left Outer Join 1 to 2
          filter mappings:
            1 [0, 1, 2, 1]
          filter predicates:
            0 
            1 {(VALUE._col0 = 50)} {(VALUE._col0 = 60)}
            2 
          keys:
            0 _col0 (type: int)
            1 _col0 (type: int)
            2 _col0 (type: int)
          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
          Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            GlobalTableId: 0
#### A masked pattern was here ####
            NumFilesPerFileSink: 1
            Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                properties:
                  columns _col0,_col1,_col2,_col3,_col4,_col5
                  columns.types int:int:int:int:int:int
                  escape.delim \
                  hive.serialization.extend.additional.nesting.levels true
                  serialization.escape.crlf true
                  serialization.format 1
                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            TotalFiles: 1
            GatherStats: false
            MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: select /*+ MAPJOIN(a_n4,c)*/ * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(a_n4,c)*/ * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: explain extended select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: a_n4
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 50) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 50 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 0
                  value expressions: _col1 (type: int)
                  auto parallelism: false
          TableScan
            alias: b
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Select Operator
              expressions: key (type: int), value (type: int)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: int)
                null sort order: a
                sort order: +
                Map-reduce partition columns: _col0 (type: int)
                Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                tag: 1
                value expressions: _col1 (type: int)
                auto parallelism: false
          TableScan
            alias: c
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 60) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 60 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 2
                  value expressions: _col1 (type: int)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: a_n4
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count -1
              bucketing_version 2
              column.name.delimiter ,
              columns key,value
              columns.comments 
              columns.types int:int
#### A masked pattern was here ####
              name default.a_n4
              numFiles 1
              numRows 3
              rawDataSize 18
              serialization.ddl struct a_n4 { i32 key, i32 value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 21
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                bucket_count -1
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 
                columns.types int:int
#### A masked pattern was here ####
                name default.a_n4
                numFiles 1
                numRows 3
                rawDataSize 18
                serialization.ddl struct a_n4 { i32 key, i32 value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 21
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.a_n4
            name: default.a_n4
      Truncated Path -> Alias:
        /a_n4 [$hdt$_0:a_n4, $hdt$_1:b, $hdt$_2:c]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Right Outer Join 0 to 1
               Left Outer Join 1 to 2
          filter mappings:
            1 [0, 1, 2, 1]
          filter predicates:
            0 
            1 {(VALUE._col0 = 50)} {(VALUE._col0 = 60)}
            2 
          keys:
            0 _col0 (type: int)
            1 _col0 (type: int)
            2 _col0 (type: int)
          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
          Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            GlobalTableId: 0
#### A masked pattern was here ####
            NumFilesPerFileSink: 1
            Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                properties:
                  columns _col0,_col1,_col2,_col3,_col4,_col5
                  columns.types int:int:int:int:int:int
                  escape.delim \
                  hive.serialization.extend.additional.nesting.levels true
                  serialization.escape.crlf true
                  serialization.format 1
                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            TotalFiles: 1
            GatherStats: false
            MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: select /*+ MAPJOIN(a_n4,c)*/ * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(a_n4,c)*/ * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: explain extended select * from a_n4 full outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select * from a_n4 full outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: a_n4
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Select Operator
              expressions: key (type: int), value (type: int)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: int)
                null sort order: a
                sort order: +
                Map-reduce partition columns: _col0 (type: int)
                Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                tag: 0
                value expressions: _col1 (type: int)
                auto parallelism: false
          TableScan
            alias: b
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Select Operator
              expressions: key (type: int), value (type: int)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: int)
                null sort order: a
                sort order: +
                Map-reduce partition columns: _col0 (type: int)
                Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                tag: 1
                value expressions: _col1 (type: int)
                auto parallelism: false
          TableScan
            alias: c
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 60) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 60 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 2
                  value expressions: _col1 (type: int)
                  auto parallelism: false
          TableScan
            alias: d
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 40) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 40 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 3
                  value expressions: _col1 (type: int)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: a_n4
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count -1
              bucketing_version 2
              column.name.delimiter ,
              columns key,value
              columns.comments 
              columns.types int:int
#### A masked pattern was here ####
              name default.a_n4
              numFiles 1
              numRows 3
              rawDataSize 18
              serialization.ddl struct a_n4 { i32 key, i32 value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 21
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                bucket_count -1
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 
                columns.types int:int
#### A masked pattern was here ####
                name default.a_n4
                numFiles 1
                numRows 3
                rawDataSize 18
                serialization.ddl struct a_n4 { i32 key, i32 value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 21
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.a_n4
            name: default.a_n4
      Truncated Path -> Alias:
        /a_n4 [$hdt$_0:a_n4, $hdt$_1:b, $hdt$_2:c, $hdt$_3:d]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Outer Join 0 to 1
               Left Outer Join 1 to 2
               Left Outer Join 0 to 3
          filter mappings:
            0 [1, 1, 3, 1]
            1 [0, 1, 2, 1]
          filter predicates:
            0 {(VALUE._col0 = 50)} {(VALUE._col0 = 40)}
            1 {(VALUE._col0 = 50)} {(VALUE._col0 = 60)}
            2 
            3 
          keys:
            0 _col0 (type: int)
            1 _col0 (type: int)
            2 _col0 (type: int)
            3 _col0 (type: int)
          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
          Statistics: Num rows: 9 Data size: 59 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            GlobalTableId: 0
#### A masked pattern was here ####
            NumFilesPerFileSink: 1
            Statistics: Num rows: 9 Data size: 59 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                properties:
                  columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
                  columns.types int:int:int:int:int:int:int:int
                  escape.delim \
                  hive.serialization.extend.additional.nesting.levels true
                  serialization.escape.crlf true
                  serialization.format 1
                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            TotalFiles: 1
            GatherStats: false
            MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a_n4 full outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from a_n4 full outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	NULL	NULL	NULL	NULL
NULL	NULL	100	40	NULL	NULL	NULL	NULL
NULL	NULL	100	60	100	60	NULL	NULL
PREHOOK: query: explain extended select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: a_n4
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Select Operator
              expressions: key (type: int), value (type: int)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: int)
                null sort order: a
                sort order: +
                Map-reduce partition columns: _col0 (type: int)
                Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                tag: 0
                value expressions: _col1 (type: int)
                auto parallelism: false
          TableScan
            alias: b
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 50) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 50 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 1
                  value expressions: _col1 (type: int)
                  auto parallelism: false
          TableScan
            alias: c
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 60) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 60 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 2
                  value expressions: _col1 (type: int)
                  auto parallelism: false
          TableScan
            alias: d
            Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (value = 40) (type: boolean)
              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int), 40 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  null sort order: a
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  tag: 3
                  value expressions: _col1 (type: int)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: a_n4
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count -1
              bucketing_version 2
              column.name.delimiter ,
              columns key,value
              columns.comments 
              columns.types int:int
#### A masked pattern was here ####
              name default.a_n4
              numFiles 1
              numRows 3
              rawDataSize 18
              serialization.ddl struct a_n4 { i32 key, i32 value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 21
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                bucket_count -1
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 
                columns.types int:int
#### A masked pattern was here ####
                name default.a_n4
                numFiles 1
                numRows 3
                rawDataSize 18
                serialization.ddl struct a_n4 { i32 key, i32 value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 21
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.a_n4
            name: default.a_n4
      Truncated Path -> Alias:
        /a_n4 [$hdt$_0:a_n4, $hdt$_1:b, $hdt$_2:c, $hdt$_3:d]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Outer Join 0 to 1
               Left Outer Join 0 to 2
               Left Outer Join 0 to 3
          filter mappings:
            0 [1, 1, 2, 1, 3, 1]
          filter predicates:
            0 {(VALUE._col0 = 50)} {(VALUE._col0 = 60)} {(VALUE._col0 = 40)}
            1 
            2 
            3 
          keys:
            0 _col0 (type: int)
            1 _col0 (type: int)
            2 _col0 (type: int)
            3 _col0 (type: int)
          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
          Statistics: Num rows: 9 Data size: 59 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            GlobalTableId: 0
#### A masked pattern was here ####
            NumFilesPerFileSink: 1
            Statistics: Num rows: 9 Data size: 59 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                properties:
                  columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
                  columns.types int:int:int:int:int:int:int:int
                  escape.delim \
                  hive.serialization.extend.additional.nesting.levels true
                  serialization.escape.crlf true
                  serialization.format 1
                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            TotalFiles: 1
            GatherStats: false
            MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	100	60	NULL	NULL
PREHOOK: query: select /*+ MAPJOIN(b,c, d)*/ * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(b,c, d)*/ * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	100	60	NULL	NULL
