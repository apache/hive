PREHOOK: query: CREATE DATABASE db1
PREHOOK: type: CREATEDATABASE
PREHOOK: Output: database:db1
POSTHOOK: query: CREATE DATABASE db1
POSTHOOK: type: CREATEDATABASE
POSTHOOK: Output: database:db1
PREHOOK: query: CREATE DATABASE db2
PREHOOK: type: CREATEDATABASE
PREHOOK: Output: database:db2
POSTHOOK: query: CREATE DATABASE db2
POSTHOOK: type: CREATEDATABASE
POSTHOOK: Output: database:db2
PREHOOK: query: CREATE TABLE db1.sourceTable (one string,two string) PARTITIONED BY (ds string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:db1
PREHOOK: Output: db1@sourceTable
POSTHOOK: query: CREATE TABLE db1.sourceTable (one string,two string) PARTITIONED BY (ds string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:db1
POSTHOOK: Output: db1@sourceTable
PREHOOK: query: load data local inpath '../../data/files/kv1.txt' INTO TABLE db1.sourceTable partition(ds='2011-11-11')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: db1@sourcetable
POSTHOOK: query: load data local inpath '../../data/files/kv1.txt' INTO TABLE db1.sourceTable partition(ds='2011-11-11')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: db1@sourcetable
POSTHOOK: Output: db1@sourcetable@ds=2011-11-11
PREHOOK: query: load data local inpath '../../data/files/kv3.txt' INTO TABLE db1.sourceTable partition(ds='2011-11-11')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: db1@sourcetable@ds=2011-11-11
POSTHOOK: query: load data local inpath '../../data/files/kv3.txt' INTO TABLE db1.sourceTable partition(ds='2011-11-11')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: db1@sourcetable@ds=2011-11-11
PREHOOK: query: CREATE TABLE db2.destinTable (one string,two string) PARTITIONED BY (ds string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:db2
PREHOOK: Output: db2@destinTable
POSTHOOK: query: CREATE TABLE db2.destinTable (one string,two string) PARTITIONED BY (ds string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:db2
POSTHOOK: Output: db2@destinTable
PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE db2.destinTable PARTITION (ds='2011-11-11')
SELECT one,two FROM db1.sourceTable WHERE ds='2011-11-11' order by one desc, two desc limit 5
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT OVERWRITE TABLE db2.destinTable PARTITION (ds='2011-11-11')
SELECT one,two FROM db1.sourceTable WHERE ds='2011-11-11' order by one desc, two desc limit 5
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1
  Stage-2 depends on stages: Stage-0, Stage-3
  Stage-3 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: sourcetable
            Statistics: Num rows: 124 Data size: 60280 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: one (type: string), two (type: string)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 124 Data size: 60280 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: string), _col1 (type: string)
                sort order: --
                Statistics: Num rows: 124 Data size: 60280 Basic stats: COMPLETE Column stats: NONE
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 124 Data size: 60280 Basic stats: COMPLETE Column stats: NONE
          Limit
            Number of rows: 5
            Statistics: Num rows: 5 Data size: 2430 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              Statistics: Num rows: 5 Data size: 2430 Basic stats: COMPLETE Column stats: NONE
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  name: db2.destintable
            Select Operator
              expressions: _col0 (type: string), _col1 (type: string), '2011-11-11' (type: string)
              outputColumnNames: one, two, ds
              Statistics: Num rows: 5 Data size: 2430 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: compute_stats(one, 'hll'), compute_stats(two, 'hll')
                keys: ds (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 2430 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds 2011-11-11
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: db2.destintable

  Stage: Stage-2
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: one, two
          Column Types: string, string
          Table: db2.destintable

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Map-reduce partition columns: _col0 (type: string)
              Statistics: Num rows: 5 Data size: 2430 Basic stats: COMPLETE Column stats: NONE
              value expressions: _col1 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
      Reduce Operator Tree:
        Group By Operator
          aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 2 Data size: 972 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: _col1 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string)
            outputColumnNames: _col0, _col1, _col2
            Statistics: Num rows: 2 Data size: 972 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              Statistics: Num rows: 2 Data size: 972 Basic stats: COMPLETE Column stats: NONE
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

PREHOOK: query: INSERT OVERWRITE TABLE db2.destinTable PARTITION (ds='2011-11-11')
SELECT one,two FROM db1.sourceTable WHERE ds='2011-11-11' order by one desc, two desc limit 5
PREHOOK: type: QUERY
PREHOOK: Input: db1@sourcetable
PREHOOK: Input: db1@sourcetable@ds=2011-11-11
PREHOOK: Output: db2@destintable@ds=2011-11-11
POSTHOOK: query: INSERT OVERWRITE TABLE db2.destinTable PARTITION (ds='2011-11-11')
SELECT one,two FROM db1.sourceTable WHERE ds='2011-11-11' order by one desc, two desc limit 5
POSTHOOK: type: QUERY
POSTHOOK: Input: db1@sourcetable
POSTHOOK: Input: db1@sourcetable@ds=2011-11-11
POSTHOOK: Output: db2@destintable@ds=2011-11-11
POSTHOOK: Lineage: destintable PARTITION(ds=2011-11-11).one SIMPLE [(sourcetable)sourcetable.FieldSchema(name:one, type:string, comment:null), ]
POSTHOOK: Lineage: destintable PARTITION(ds=2011-11-11).two SIMPLE [(sourcetable)sourcetable.FieldSchema(name:two, type:string, comment:null), ]
PREHOOK: query: select one,two from db2.destinTable order by one desc, two desc
PREHOOK: type: QUERY
PREHOOK: Input: db2@destintable
PREHOOK: Input: db2@destintable@ds=2011-11-11
#### A masked pattern was here ####
POSTHOOK: query: select one,two from db2.destinTable order by one desc, two desc
POSTHOOK: type: QUERY
POSTHOOK: Input: db2@destintable
POSTHOOK: Input: db2@destintable@ds=2011-11-11
#### A masked pattern was here ####
98	val_98
98	val_98
98	val_98
97	val_97
97	val_97
PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE db2.destinTable PARTITION (ds='2011-11-11')
SELECT one,two FROM db1.sourceTable WHERE ds='2011-11-11' order by one desc, two desc limit 5
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT OVERWRITE TABLE db2.destinTable PARTITION (ds='2011-11-11')
SELECT one,two FROM db1.sourceTable WHERE ds='2011-11-11' order by one desc, two desc limit 5
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1
  Stage-2 depends on stages: Stage-0, Stage-3
  Stage-3 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: sourcetable
            Statistics: Num rows: 124 Data size: 60280 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: one (type: string), two (type: string)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 124 Data size: 60280 Basic stats: COMPLETE Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: string), _col1 (type: string)
                sort order: --
                Statistics: Num rows: 124 Data size: 60280 Basic stats: COMPLETE Column stats: NONE
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 124 Data size: 60280 Basic stats: COMPLETE Column stats: NONE
          Limit
            Number of rows: 5
            Statistics: Num rows: 5 Data size: 2430 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              Statistics: Num rows: 5 Data size: 2430 Basic stats: COMPLETE Column stats: NONE
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  name: db2.destintable
            Select Operator
              expressions: _col0 (type: string), _col1 (type: string), '2011-11-11' (type: string)
              outputColumnNames: one, two, ds
              Statistics: Num rows: 5 Data size: 2430 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: compute_stats(one, 'hll'), compute_stats(two, 'hll')
                keys: ds (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 2430 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds 2011-11-11
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: db2.destintable

  Stage: Stage-2
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: one, two
          Column Types: string, string
          Table: db2.destintable

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Map-reduce partition columns: _col0 (type: string)
              Statistics: Num rows: 5 Data size: 2430 Basic stats: COMPLETE Column stats: NONE
              value expressions: _col1 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
      Reduce Operator Tree:
        Group By Operator
          aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 2 Data size: 972 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: _col1 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string)
            outputColumnNames: _col0, _col1, _col2
            Statistics: Num rows: 2 Data size: 972 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              Statistics: Num rows: 2 Data size: 972 Basic stats: COMPLETE Column stats: NONE
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

PREHOOK: query: INSERT OVERWRITE TABLE db2.destinTable PARTITION (ds='2011-11-11')
SELECT one,two FROM db1.sourceTable WHERE ds='2011-11-11' order by one desc, two desc limit 5
PREHOOK: type: QUERY
PREHOOK: Input: db1@sourcetable
PREHOOK: Input: db1@sourcetable@ds=2011-11-11
PREHOOK: Output: db2@destintable@ds=2011-11-11
POSTHOOK: query: INSERT OVERWRITE TABLE db2.destinTable PARTITION (ds='2011-11-11')
SELECT one,two FROM db1.sourceTable WHERE ds='2011-11-11' order by one desc, two desc limit 5
POSTHOOK: type: QUERY
POSTHOOK: Input: db1@sourcetable
POSTHOOK: Input: db1@sourcetable@ds=2011-11-11
POSTHOOK: Output: db2@destintable@ds=2011-11-11
POSTHOOK: Lineage: destintable PARTITION(ds=2011-11-11).one SIMPLE [(sourcetable)sourcetable.FieldSchema(name:one, type:string, comment:null), ]
POSTHOOK: Lineage: destintable PARTITION(ds=2011-11-11).two SIMPLE [(sourcetable)sourcetable.FieldSchema(name:two, type:string, comment:null), ]
PREHOOK: query: select one,two from db2.destinTable order by one desc, two desc
PREHOOK: type: QUERY
PREHOOK: Input: db2@destintable
PREHOOK: Input: db2@destintable@ds=2011-11-11
#### A masked pattern was here ####
POSTHOOK: query: select one,two from db2.destinTable order by one desc, two desc
POSTHOOK: type: QUERY
POSTHOOK: Input: db2@destintable
POSTHOOK: Input: db2@destintable@ds=2011-11-11
#### A masked pattern was here ####
98	val_98
98	val_98
98	val_98
97	val_97
97	val_97
PREHOOK: query: drop table db2.destinTable
PREHOOK: type: DROPTABLE
PREHOOK: Input: db2@destintable
PREHOOK: Output: db2@destintable
POSTHOOK: query: drop table db2.destinTable
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: db2@destintable
POSTHOOK: Output: db2@destintable
PREHOOK: query: drop table db1.sourceTable
PREHOOK: type: DROPTABLE
PREHOOK: Input: db1@sourcetable
PREHOOK: Output: db1@sourcetable
POSTHOOK: query: drop table db1.sourceTable
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: db1@sourcetable
POSTHOOK: Output: db1@sourcetable
PREHOOK: query: DROP DATABASE db1
PREHOOK: type: DROPDATABASE
PREHOOK: Input: database:db1
PREHOOK: Output: database:db1
POSTHOOK: query: DROP DATABASE db1
POSTHOOK: type: DROPDATABASE
POSTHOOK: Input: database:db1
POSTHOOK: Output: database:db1
PREHOOK: query: DROP DATABASE db2
PREHOOK: type: DROPDATABASE
PREHOOK: Input: database:db2
PREHOOK: Output: database:db2
POSTHOOK: query: DROP DATABASE db2
POSTHOOK: type: DROPDATABASE
POSTHOOK: Input: database:db2
POSTHOOK: Output: database:db2
