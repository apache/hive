PREHOOK: query: CREATE TABLE orc_table_1(v1 STRING, a INT) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@orc_table_1
POSTHOOK: query: CREATE TABLE orc_table_1(v1 STRING, a INT) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orc_table_1
PREHOOK: query: CREATE TABLE orc_table_2(c INT, v2 STRING) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@orc_table_2
POSTHOOK: query: CREATE TABLE orc_table_2(c INT, v2 STRING) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orc_table_2
PREHOOK: query: insert into table orc_table_1 values ("<null1>", null),("one", 1),("one", 1),("two", 2),("three", 3),("<null2>", null)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@orc_table_1
POSTHOOK: query: insert into table orc_table_1 values ("<null1>", null),("one", 1),("one", 1),("two", 2),("three", 3),("<null2>", null)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@orc_table_1
POSTHOOK: Lineage: orc_table_1.a SCRIPT []
POSTHOOK: Lineage: orc_table_1.v1 SCRIPT []
PREHOOK: query: insert into table orc_table_2 values (0, "ZERO"),(2, "TWO"), (3, "THREE"),(null, "<NULL1>"),(4, "FOUR"),(null, "<NULL2>")
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@orc_table_2
POSTHOOK: query: insert into table orc_table_2 values (0, "ZERO"),(2, "TWO"), (3, "THREE"),(null, "<NULL1>"),(4, "FOUR"),(null, "<NULL2>")
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@orc_table_2
POSTHOOK: Lineage: orc_table_2.c SCRIPT []
POSTHOOK: Lineage: orc_table_2.v2 SCRIPT []
PREHOOK: query: select * from orc_table_1
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1
#### A masked pattern was here ####
POSTHOOK: query: select * from orc_table_1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1
#### A masked pattern was here ####
<null1>	NULL
<null2>	NULL
one	1
one	1
three	3
two	2
PREHOOK: query: select * from orc_table_2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
POSTHOOK: query: select * from orc_table_2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
0	ZERO
2	TWO
3	THREE
4	FOUR
NULL	<NULL1>
NULL	<NULL2>
PREHOOK: query: explain vectorization detail
select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 left outer join orc_table_2 t2 on t1.a = t2.c
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 left outer join orc_table_2 t2 on t1.a = t2.c
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-3 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-4
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $hdt$_1:t2 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $hdt$_1:t2 
          TableScan
            alias: t2
            Statistics: Num rows: 6 Data size: 550 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: c (type: int), v2 (type: string)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 6 Data size: 550 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: t1
            Statistics: Num rows: 6 Data size: 544 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                vectorizationSchemaColumns: [0:v1:string, 1:a:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
            Select Operator
              expressions: v1 (type: string), a (type: int)
              outputColumnNames: _col0, _col1
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumnNums: [0, 1]
              Statistics: Num rows: 6 Data size: 544 Basic stats: COMPLETE Column stats: NONE
              Map Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                Map Join Vectorization:
                    bigTableKeyExpressions: col 1:int
                    bigTableValueExpressions: col 0:string, col 1:int
                    className: VectorMapJoinOperator
                    native: false
                    nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                    nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 6 Data size: 598 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 6 Data size: 598 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
          rowBatchContext:
              dataColumnCount: 2
              includeColumns: [0, 1]
              dataColumns: v1:string, a:int
              partitionColumnCount: 0
              scratchColumnTypeNames: [bigint, string]
      Local Work:
        Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 left outer join orc_table_2 t2 on t1.a = t2.c
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1
PREHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
POSTHOOK: query: select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 left outer join orc_table_2 t2 on t1.a = t2.c
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1
POSTHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
<null1>	NULL	NULL	NULL
<null2>	NULL	NULL	NULL
one	1	NULL	NULL
one	1	NULL	NULL
three	3	3	THREE
two	2	2	TWO
PREHOOK: query: explain vectorization detail
select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 right outer join orc_table_2 t2 on t1.a = t2.c
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 right outer join orc_table_2 t2 on t1.a = t2.c
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-3 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-4
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $hdt$_0:t1 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $hdt$_0:t1 
          TableScan
            alias: t1
            Statistics: Num rows: 6 Data size: 544 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: v1 (type: string), a (type: int)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 6 Data size: 544 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: t2
            Statistics: Num rows: 6 Data size: 550 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                vectorizationSchemaColumns: [0:c:int, 1:v2:string, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
            Select Operator
              expressions: c (type: int), v2 (type: string)
              outputColumnNames: _col0, _col1
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumnNums: [0, 1]
              Statistics: Num rows: 6 Data size: 550 Basic stats: COMPLETE Column stats: NONE
              Map Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                Map Join Vectorization:
                    bigTableKeyExpressions: col 0:int
                    bigTableValueExpressions: col 0:int, col 1:string
                    className: VectorMapJoinOperator
                    native: false
                    nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                    nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 6 Data size: 598 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 6 Data size: 598 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
          rowBatchContext:
              dataColumnCount: 2
              includeColumns: [0, 1]
              dataColumns: c:int, v2:string
              partitionColumnCount: 0
              scratchColumnTypeNames: [string, bigint]
      Local Work:
        Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 right outer join orc_table_2 t2 on t1.a = t2.c
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1
PREHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
POSTHOOK: query: select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 right outer join orc_table_2 t2 on t1.a = t2.c
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1
POSTHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
NULL	NULL	0	ZERO
NULL	NULL	4	FOUR
NULL	NULL	NULL	<NULL1>
NULL	NULL	NULL	<NULL2>
three	3	3	THREE
two	2	2	TWO
