PREHOOK: query: CREATE TABLE orc_table_1(v1 STRING, a INT) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@orc_table_1
POSTHOOK: query: CREATE TABLE orc_table_1(v1 STRING, a INT) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orc_table_1
PREHOOK: query: CREATE TABLE orc_table_2(c INT, v2 STRING) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@orc_table_2
POSTHOOK: query: CREATE TABLE orc_table_2(c INT, v2 STRING) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orc_table_2
PREHOOK: query: insert into table orc_table_1 values ("<null1>", null),("one", 1),("one", 1),("two", 2),("three", 3),("<null2>", null)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@orc_table_1
POSTHOOK: query: insert into table orc_table_1 values ("<null1>", null),("one", 1),("one", 1),("two", 2),("three", 3),("<null2>", null)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@orc_table_1
POSTHOOK: Lineage: orc_table_1.a SCRIPT []
POSTHOOK: Lineage: orc_table_1.v1 SCRIPT []
PREHOOK: query: insert into table orc_table_2 values (0, "ZERO"),(2, "TWO"), (3, "THREE"),(null, "<NULL1>"),(4, "FOUR"),(null, "<NULL2>")
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@orc_table_2
POSTHOOK: query: insert into table orc_table_2 values (0, "ZERO"),(2, "TWO"), (3, "THREE"),(null, "<NULL1>"),(4, "FOUR"),(null, "<NULL2>")
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@orc_table_2
POSTHOOK: Lineage: orc_table_2.c SCRIPT []
POSTHOOK: Lineage: orc_table_2.v2 SCRIPT []
PREHOOK: query: select * from orc_table_1
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1
#### A masked pattern was here ####
POSTHOOK: query: select * from orc_table_1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1
#### A masked pattern was here ####
<null1>	NULL
<null2>	NULL
one	1
one	1
three	3
two	2
PREHOOK: query: select * from orc_table_2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
POSTHOOK: query: select * from orc_table_2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
0	ZERO
2	TWO
3	THREE
4	FOUR
NULL	<NULL1>
NULL	<NULL2>
PREHOOK: query: explain vectorization detail
select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 left outer join orc_table_2 t2 on t1.a = t2.c
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 left outer join orc_table_2 t2 on t1.a = t2.c
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-3 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-4
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $hdt$_1:t2 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $hdt$_1:t2 
          TableScan
            alias: t2
            Statistics: Num rows: 6 Data size: 550 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: c (type: int), v2 (type: string)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 6 Data size: 550 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: t1
            Statistics: Num rows: 6 Data size: 544 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                vectorizationSchemaColumns: [0:v1:string, 1:a:int, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
            Select Operator
              expressions: v1 (type: string), a (type: int)
              outputColumnNames: _col0, _col1
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumnNums: [0, 1]
              Statistics: Num rows: 6 Data size: 544 Basic stats: COMPLETE Column stats: NONE
              Map Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                Map Join Vectorization:
                    bigTableKeyExpressions: col 1:int
                    bigTableValueExpressions: col 0:string, col 1:int
                    className: VectorMapJoinOperator
                    native: false
                    nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                    nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 6 Data size: 598 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 6 Data size: 598 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
          rowBatchContext:
              dataColumnCount: 2
              includeColumns: [0, 1]
              dataColumns: v1:string, a:int
              partitionColumnCount: 0
              scratchColumnTypeNames: [bigint, string]
      Local Work:
        Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 left outer join orc_table_2 t2 on t1.a = t2.c
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1
PREHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
POSTHOOK: query: select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 left outer join orc_table_2 t2 on t1.a = t2.c
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1
POSTHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
<null1>	NULL	NULL	NULL
<null2>	NULL	NULL	NULL
one	1	NULL	NULL
one	1	NULL	NULL
three	3	3	THREE
two	2	2	TWO
PREHOOK: query: explain vectorization detail
select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 right outer join orc_table_2 t2 on t1.a = t2.c
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 right outer join orc_table_2 t2 on t1.a = t2.c
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-3 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-4
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $hdt$_0:t1 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $hdt$_0:t1 
          TableScan
            alias: t1
            Statistics: Num rows: 6 Data size: 544 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: v1 (type: string), a (type: int)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 6 Data size: 544 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: t2
            Statistics: Num rows: 6 Data size: 550 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                vectorizationSchemaColumns: [0:c:int, 1:v2:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
            Select Operator
              expressions: c (type: int), v2 (type: string)
              outputColumnNames: _col0, _col1
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumnNums: [0, 1]
              Statistics: Num rows: 6 Data size: 550 Basic stats: COMPLETE Column stats: NONE
              Map Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                Map Join Vectorization:
                    bigTableKeyExpressions: col 0:int
                    bigTableValueExpressions: col 0:int, col 1:string
                    className: VectorMapJoinOperator
                    native: false
                    nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                    nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 6 Data size: 598 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 6 Data size: 598 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
          rowBatchContext:
              dataColumnCount: 2
              includeColumns: [0, 1]
              dataColumns: c:int, v2:string
              partitionColumnCount: 0
              scratchColumnTypeNames: [string, bigint]
      Local Work:
        Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 right outer join orc_table_2 t2 on t1.a = t2.c
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1
PREHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
POSTHOOK: query: select t1.v1, t1.a, t2.c, t2.v2 from orc_table_1 t1 right outer join orc_table_2 t2 on t1.a = t2.c
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1
POSTHOOK: Input: default@orc_table_2
#### A masked pattern was here ####
NULL	NULL	0	ZERO
NULL	NULL	4	FOUR
NULL	NULL	NULL	<NULL1>
NULL	NULL	NULL	<NULL2>
three	3	3	THREE
two	2	2	TWO
