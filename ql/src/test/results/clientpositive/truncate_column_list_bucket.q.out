PREHOOK: query: -- Tests truncating a column from a list bucketing table

-- INCLUDE_HADOOP_MAJOR_VERSIONS(0.23)

CREATE TABLE test_tab (key STRING, value STRING) PARTITIONED BY (part STRING) STORED AS RCFILE
PREHOOK: type: CREATETABLE
POSTHOOK: query: -- Tests truncating a column from a list bucketing table

-- INCLUDE_HADOOP_MAJOR_VERSIONS(0.23)

CREATE TABLE test_tab (key STRING, value STRING) PARTITIONED BY (part STRING) STORED AS RCFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@test_tab
PREHOOK: query: ALTER TABLE test_tab
SKEWED BY (key) ON ("484")
STORED AS DIRECTORIES
PREHOOK: type: ALTERTABLE_SKEWED
PREHOOK: Input: default@test_tab
PREHOOK: Output: default@test_tab
POSTHOOK: query: ALTER TABLE test_tab
SKEWED BY (key) ON ("484")
STORED AS DIRECTORIES
POSTHOOK: type: ALTERTABLE_SKEWED
POSTHOOK: Input: default@test_tab
POSTHOOK: Output: default@test_tab
PREHOOK: query: INSERT OVERWRITE TABLE test_tab PARTITION (part = '1') SELECT * FROM src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@test_tab@part=1
POSTHOOK: query: INSERT OVERWRITE TABLE test_tab PARTITION (part = '1') SELECT * FROM src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@test_tab@part=1
POSTHOOK: Lineage: test_tab PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test_tab PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '0'
PREHOOK: type: QUERY
PREHOOK: Input: default@test_tab
PREHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '0'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test_tab
POSTHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
POSTHOOK: Lineage: test_tab PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test_tab PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
0	val_0	1
0	val_0	1
0	val_0	1
PREHOOK: query: TRUNCATE TABLE test_tab PARTITION (part ='1') COLUMNS (value)
PREHOOK: type: TRUNCATETABLE
PREHOOK: Input: default@test_tab
PREHOOK: Output: default@test_tab@part=1
POSTHOOK: query: TRUNCATE TABLE test_tab PARTITION (part ='1') COLUMNS (value)
POSTHOOK: type: TRUNCATETABLE
POSTHOOK: Input: default@test_tab
POSTHOOK: Output: default@test_tab@part=1
POSTHOOK: Lineage: test_tab PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test_tab PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: -- In the following select statements the list bucketing optimization should still be used
-- In both cases value should be null

EXPLAIN EXTENDED SELECT * FROM test_tab WHERE part = '1' AND key = '484'
PREHOOK: type: QUERY
POSTHOOK: query: -- In the following select statements the list bucketing optimization should still be used
-- In both cases value should be null

EXPLAIN EXTENDED SELECT * FROM test_tab WHERE part = '1' AND key = '484'
POSTHOOK: type: QUERY
POSTHOOK: Lineage: test_tab PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test_tab PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            test_tab
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF
      TOK_WHERE
         AND
            =
               TOK_TABLE_OR_COL
                  part
               '1'
            =
               TOK_TABLE_OR_COL
                  key
               '484'


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: test_tab
            Statistics: Num rows: 8 Data size: 1761 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (key = '484') (type: boolean)
              Statistics: Num rows: 4 Data size: 880 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string), part (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 4 Data size: 880 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 4 Data size: 880 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types string:string:string
                        escape.delim \
                        hive.serialization.extend.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: key=484
            input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
            output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
            partition values:
              part 1
            properties:
              bucket_count -1
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              name default.test_tab
              numFiles 2
              numRows 500
              partition_columns part
              rawDataSize 4812
              serialization.ddl struct test_tab { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
              totalSize 1761
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
          
              input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.types string:string
#### A masked pattern was here ####
                name default.test_tab
                numFiles 2
                numPartitions 1
                numRows 500
                partition_columns part
                rawDataSize 4812
                serialization.ddl struct test_tab { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
                totalSize 1761
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
              name: default.test_tab
            name: default.test_tab
      Truncated Path -> Alias:
        /test_tab/part=1/key=484 [test_tab]

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '484'
PREHOOK: type: QUERY
PREHOOK: Input: default@test_tab
PREHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '484'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test_tab
POSTHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
POSTHOOK: Lineage: test_tab PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test_tab PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
484	NULL	1
PREHOOK: query: EXPLAIN EXTENDED SELECT * FROM test_tab WHERE part = '1' AND key = '0'
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN EXTENDED SELECT * FROM test_tab WHERE part = '1' AND key = '0'
POSTHOOK: type: QUERY
POSTHOOK: Lineage: test_tab PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test_tab PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            test_tab
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF
      TOK_WHERE
         AND
            =
               TOK_TABLE_OR_COL
                  part
               '1'
            =
               TOK_TABLE_OR_COL
                  key
               '0'


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: test_tab
            Statistics: Num rows: 8 Data size: 1761 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (key = '0') (type: boolean)
              Statistics: Num rows: 4 Data size: 880 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string), part (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 4 Data size: 880 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 4 Data size: 880 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types string:string:string
                        escape.delim \
                        hive.serialization.extend.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: HIVE_DEFAULT_LIST_BUCKETING_DIR_NAME
            input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
            output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
            partition values:
              part 1
            properties:
              bucket_count -1
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              name default.test_tab
              numFiles 2
              numRows 500
              partition_columns part
              rawDataSize 4812
              serialization.ddl struct test_tab { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
              totalSize 1761
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
          
              input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.types string:string
#### A masked pattern was here ####
                name default.test_tab
                numFiles 2
                numPartitions 1
                numRows 500
                partition_columns part
                rawDataSize 4812
                serialization.ddl struct test_tab { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
                totalSize 1761
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
              name: default.test_tab
            name: default.test_tab
      Truncated Path -> Alias:
        /test_tab/part=1/HIVE_DEFAULT_LIST_BUCKETING_DIR_NAME [test_tab]

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '0'
PREHOOK: type: QUERY
PREHOOK: Input: default@test_tab
PREHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '0'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test_tab
POSTHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
POSTHOOK: Lineage: test_tab PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test_tab PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
0	NULL	1
0	NULL	1
0	NULL	1
