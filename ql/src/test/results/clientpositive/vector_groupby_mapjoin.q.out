Warning: Map Join MAPJOIN[55][bigTable=?] in task 'Stage-7:MAPRED' is a cross product
Warning: Map Join MAPJOIN[45][bigTable=?] in task 'Stage-6:MAPRED' is a cross product
Warning: Shuffle Join JOIN[20][tables = [$hdt$_0, $hdt$_1, $hdt$_2]] in Stage 'Stage-2:MAPRED' is a cross product
PREHOOK: query: explain vectorization expression
select *
from src
where not key in
(select key from src)
order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression
select *
from src
where not key in
(select key from src)
order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-10 depends on stages: Stage-4 , consists of Stage-13, Stage-1
  Stage-13 has a backup stage: Stage-1
  Stage-9 depends on stages: Stage-13
  Stage-8 depends on stages: Stage-1, Stage-5, Stage-9 , consists of Stage-11, Stage-12, Stage-2
  Stage-11 has a backup stage: Stage-2
  Stage-6 depends on stages: Stage-11
  Stage-3 depends on stages: Stage-2, Stage-6, Stage-7
  Stage-12 has a backup stage: Stage-2
  Stage-7 depends on stages: Stage-12
  Stage-2
  Stage-1
  Stage-5 is a root stage
  Stage-0 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-4
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            filterExpr: key is not null (type: boolean)
            Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
            TableScan Vectorization:
                native: true
            Filter Operator
              Filter Vectorization:
                  className: VectorFilterOperator
                  native: true
                  predicateExpression: SelectColumnIsNotNull(col 0:string)
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                Group By Vectorization:
                    className: VectorGroupByOperator
                    groupByMode: HASH
                    keyExpressions: col 0:string
                    native: false
                    vectorProcessingMode: HASH
                    projectedOutputColumnNums: []
                keys: key (type: string)
                minReductionHashAggr: 0.99
                mode: hash
                outputColumnNames: _col0
                Statistics: Num rows: 250 Data size: 21750 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkOperator
                      native: false
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
                  Statistics: Num rows: 250 Data size: 21750 Basic stats: COMPLETE Column stats: COMPLETE
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
          inputFormatFeatureSupport: [DECIMAL_64]
          featureSupportInUse: [DECIMAL_64]
          inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
      Reduce Vectorization:
          enabled: false
          enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true
          enableConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0
          Statistics: Num rows: 250 Data size: 21750 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), true (type: boolean)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 250 Data size: 22750 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-10
    Conditional Operator

  Stage: Stage-13
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $hdt$_0:$INTNAME 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $hdt$_0:$INTNAME 
          TableScan
            HashTable Sink Operator
              keys:
                0 _col0 (type: string)
                1 _col0 (type: string)

  Stage: Stage-9
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
            TableScan Vectorization:
                native: true
            Select Operator
              expressions: key (type: string), value (type: string)
              outputColumnNames: _col0, _col1
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumnNums: [0, 1]
              Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
              Map Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col0 (type: string)
                  1 _col0 (type: string)
                Map Join Vectorization:
                    bigTableKeyExpressions: col 0:string
                    bigTableValueExpressions: col 0:string, col 1:string
                    className: VectorMapJoinOperator
                    native: false
                    nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                    nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
                outputColumnNames: _col0, _col1, _col3
                Statistics: Num rows: 895 Data size: 160894 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
          inputFormatFeatureSupport: [DECIMAL_64]
          featureSupportInUse: [DECIMAL_64]
          inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
      Local Work:
        Map Reduce Local Work

  Stage: Stage-8
    Conditional Operator

  Stage: Stage-11
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $hdt$_0:$INTNAME1 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $hdt$_0:$INTNAME1 
          TableScan
            HashTable Sink Operator
              keys:
                0 
                1 

  Stage: Stage-6
    Map Reduce
      Map Operator Tree:
          TableScan
            TableScan Vectorization:
                native: true
            Map Join Operator
              condition map:
                   Inner Join 0 to 1
              keys:
                0 
                1 
              Map Join Vectorization:
                  bigTableValueExpressions: col 0:string, col 1:string, col 2:boolean
                  className: VectorMapJoinOperator
                  native: false
                  nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                  nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
              outputColumnNames: _col0, _col1, _col3, _col4, _col5
              Statistics: Num rows: 895 Data size: 175214 Basic stats: COMPLETE Column stats: COMPLETE
              Select Operator
                expressions: _col0 (type: string), _col1 (type: string), _col4 (type: bigint), _col5 (type: bigint), _col3 (type: boolean)
                outputColumnNames: _col0, _col1, _col2, _col3, _col5
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 3, 4, 2]
                Statistics: Num rows: 895 Data size: 175214 Basic stats: COMPLETE Column stats: COMPLETE
                Filter Operator
                  Filter Vectorization:
                      className: VectorFilterOperator
                      native: true
                      predicateExpression: FilterExprAndExpr(children: FilterExprOrExpr(children: SelectColumnIsNull(col 2:boolean), FilterLongColEqualLongScalar(col 3:bigint, val 0)), FilterExprOrExpr(children: FilterLongColGreaterEqualLongColumn(col 4:bigint, col 3:bigint), FilterLongColEqualLongScalar(col 3:bigint, val 0), SelectColumnIsNotNull(col 2:boolean), SelectColumnIsNull(col 0:string)), FilterExprOrExpr(children: SelectColumnIsNotNull(col 0:string), FilterLongColEqualLongScalar(col 3:bigint, val 0), SelectColumnIsNotNull(col 2:boolean)))
                  predicate: ((_col5 is null or (_col2 = 0L)) and ((_col3 >= _col2) or (_col2 = 0L) or _col5 is not null or _col0 is null) and (_col0 is not null or (_col2 = 0L) or _col5 is not null)) (type: boolean)
                  Statistics: Num rows: 895 Data size: 175214 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string)
                    outputColumnNames: _col0, _col1
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1]
                    Statistics: Num rows: 895 Data size: 159310 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.mapred.SequenceFileInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
      Local Work:
        Map Reduce Local Work

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            TableScan Vectorization:
                native: true
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Reduce Sink Vectorization:
                  className: VectorReduceSinkOperator
                  native: false
                  nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                  nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
              Statistics: Num rows: 895 Data size: 159310 Basic stats: COMPLETE Column stats: COMPLETE
              value expressions: _col1 (type: string)
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.mapred.SequenceFileInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
      Reduce Vectorization:
          enabled: false
          enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true
          enableConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 895 Data size: 159310 Basic stats: COMPLETE Column stats: COMPLETE
          File Output Operator
            compressed: false
            Statistics: Num rows: 895 Data size: 159310 Basic stats: COMPLETE Column stats: COMPLETE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-12
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $hdt$_0:$INTNAME 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $hdt$_0:$INTNAME 
          TableScan
            HashTable Sink Operator
              keys:
                0 
                1 

  Stage: Stage-7
    Map Reduce
      Map Operator Tree:
          TableScan
            TableScan Vectorization:
                native: true
            Map Join Operator
              condition map:
                   Inner Join 0 to 1
              keys:
                0 
                1 
              Map Join Vectorization:
                  bigTableValueExpressions: col 0:bigint, col 1:bigint
                  className: VectorMapJoinOperator
                  native: false
                  nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                  nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
              outputColumnNames: _col0, _col1, _col3, _col4, _col5
              Statistics: Num rows: 895 Data size: 175214 Basic stats: COMPLETE Column stats: COMPLETE
              Select Operator
                expressions: _col0 (type: string), _col1 (type: string), _col4 (type: bigint), _col5 (type: bigint), _col3 (type: boolean)
                outputColumnNames: _col0, _col1, _col2, _col3, _col5
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 3, 4, 2]
                Statistics: Num rows: 895 Data size: 175214 Basic stats: COMPLETE Column stats: COMPLETE
                Filter Operator
                  Filter Vectorization:
                      className: VectorFilterOperator
                      native: true
                      predicateExpression: FilterExprAndExpr(children: FilterExprOrExpr(children: SelectColumnIsNull(col 2:boolean), FilterLongColEqualLongScalar(col 3:bigint, val 0)), FilterExprOrExpr(children: FilterLongColGreaterEqualLongColumn(col 4:bigint, col 3:bigint), FilterLongColEqualLongScalar(col 3:bigint, val 0), SelectColumnIsNotNull(col 2:boolean), SelectColumnIsNull(col 0:string)), FilterExprOrExpr(children: SelectColumnIsNotNull(col 0:string), FilterLongColEqualLongScalar(col 3:bigint, val 0), SelectColumnIsNotNull(col 2:boolean)))
                  predicate: ((_col5 is null or (_col2 = 0L)) and ((_col3 >= _col2) or (_col2 = 0L) or _col5 is not null or _col0 is null) and (_col0 is not null or (_col2 = 0L) or _col5 is not null)) (type: boolean)
                  Statistics: Num rows: 895 Data size: 175214 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string)
                    outputColumnNames: _col0, _col1
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1]
                    Statistics: Num rows: 895 Data size: 159310 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
          inputFormatFeatureSupport: []
          featureSupportInUse: []
          inputFileFormats: org.apache.hadoop.mapred.SequenceFileInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
      Local Work:
        Map Reduce Local Work

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              sort order: 
              Statistics: Num rows: 895 Data size: 160894 Basic stats: COMPLETE Column stats: COMPLETE
              value expressions: _col0 (type: string), _col1 (type: string), _col3 (type: boolean)
          TableScan
            Reduce Output Operator
              sort order: 
              Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
              value expressions: _col0 (type: bigint), _col1 (type: bigint)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 
            1 
          outputColumnNames: _col0, _col1, _col3, _col4, _col5
          Statistics: Num rows: 895 Data size: 175214 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: string), _col4 (type: bigint), _col5 (type: bigint), _col3 (type: boolean)
            outputColumnNames: _col0, _col1, _col2, _col3, _col5
            Statistics: Num rows: 895 Data size: 175214 Basic stats: COMPLETE Column stats: COMPLETE
            Filter Operator
              predicate: ((_col5 is null or (_col2 = 0L)) and ((_col3 >= _col2) or (_col2 = 0L) or _col5 is not null or _col0 is null) and (_col0 is not null or (_col2 = 0L) or _col5 is not null)) (type: boolean)
              Statistics: Num rows: 895 Data size: 175214 Basic stats: COMPLETE Column stats: COMPLETE
              Select Operator
                expressions: _col0 (type: string), _col1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 895 Data size: 159310 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
            Select Operator
              expressions: key (type: string), value (type: string)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
              Reduce Output Operator
                key expressions: _col0 (type: string)
                sort order: +
                Map-reduce partition columns: _col0 (type: string)
                Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                value expressions: _col1 (type: string)
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Map-reduce partition columns: _col0 (type: string)
              Statistics: Num rows: 250 Data size: 22750 Basic stats: COMPLETE Column stats: COMPLETE
              value expressions: _col1 (type: boolean)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Outer Join 0 to 1
          keys:
            0 _col0 (type: string)
            1 _col0 (type: string)
          outputColumnNames: _col0, _col1, _col3
          Statistics: Num rows: 895 Data size: 160894 Basic stats: COMPLETE Column stats: COMPLETE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-5
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
            TableScan Vectorization:
                native: true
            Select Operator
              expressions: key (type: string)
              outputColumnNames: key
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumnNums: [0]
              Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                aggregations: count(), count(key)
                Group By Vectorization:
                    aggregators: VectorUDAFCountStar(*) -> bigint, VectorUDAFCount(col 0:string) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: HASH
                    native: false
                    vectorProcessingMode: HASH
                    projectedOutputColumnNums: [0, 1]
                minReductionHashAggr: 0.99
                mode: hash
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  sort order: 
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkOperator
                      native: false
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: _col0 (type: bigint), _col1 (type: bigint)
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
          inputFormatFeatureSupport: [DECIMAL_64]
          featureSupportInUse: [DECIMAL_64]
          inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true
      Reduce Vectorization:
          enabled: false
          enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true
          enableConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), count(VALUE._col1)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

Warning: Map Join MAPJOIN[55][bigTable=?] in task 'Stage-7:MAPRED' is a cross product
Warning: Map Join MAPJOIN[45][bigTable=?] in task 'Stage-6:MAPRED' is a cross product
Warning: Shuffle Join JOIN[20][tables = [$hdt$_0, $hdt$_1, $hdt$_2]] in Stage 'Stage-2:MAPRED' is a cross product
PREHOOK: query: select *
from src
where not key in
(select key from src)
order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select *
from src
where not key in
(select key from src)
order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
PREHOOK: query: CREATE TABLE orcsrc STORED AS ORC AS SELECT * FROM src
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@orcsrc
POSTHOOK: query: CREATE TABLE orcsrc STORED AS ORC AS SELECT * FROM src
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orcsrc
POSTHOOK: Lineage: orcsrc.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: orcsrc.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
Warning: Map Join MAPJOIN[55][bigTable=?] in task 'Stage-7:MAPRED' is a cross product
Warning: Map Join MAPJOIN[45][bigTable=?] in task 'Stage-6:MAPRED' is a cross product
Warning: Shuffle Join JOIN[20][tables = [$hdt$_0, $hdt$_1, $hdt$_2]] in Stage 'Stage-2:MAPRED' is a cross product
PREHOOK: query: select *
from orcsrc
where not key in
(select key from orcsrc)
order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@orcsrc
#### A masked pattern was here ####
POSTHOOK: query: select *
from orcsrc
where not key in
(select key from orcsrc)
order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orcsrc
#### A masked pattern was here ####
Warning: Map Join MAPJOIN[55][bigTable=?] in task 'Stage-7:MAPRED' is a cross product
Warning: Map Join MAPJOIN[45][bigTable=?] in task 'Stage-6:MAPRED' is a cross product
Warning: Shuffle Join JOIN[20][tables = [$hdt$_0, $hdt$_1, $hdt$_2]] in Stage 'Stage-2:MAPRED' is a cross product
PREHOOK: query: select *
from orcsrc
where not key in
(select key from orcsrc)
order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@orcsrc
#### A masked pattern was here ####
POSTHOOK: query: select *
from orcsrc
where not key in
(select key from orcsrc)
order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orcsrc
#### A masked pattern was here ####
