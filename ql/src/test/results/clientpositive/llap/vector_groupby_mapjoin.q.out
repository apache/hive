Warning: Map Join MAPJOIN[27][bigTable=?] in task 'Map 1' is a cross product
PREHOOK: query: explain vectorization expression
select *
from src
where not key in
(select key from src)
order by key
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
select *
from src
where not key in
(select key from src)
order by key
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Reducer 4 (BROADCAST_EDGE), Reducer 6 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 4 <- Map 3 (CUSTOM_SIMPLE_EDGE)
        Reducer 6 <- Map 5 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                      keys:
                        0 
                        1 
                      outputColumnNames: _col0, _col1, _col2, _col3
                      input vertices:
                        1 Reducer 4
                      Statistics: Num rows: 500 Data size: 97000 Basic stats: COMPLETE Column stats: COMPLETE
                      Map Join Operator
                        condition map:
                             Left Outer Join0 to 1
                        keys:
                          0 _col0 (type: string)
                          1 _col0 (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3, _col5
                        input vertices:
                          1 Reducer 6
                        Statistics: Num rows: 500 Data size: 99000 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: ((_col2 = 0) or (_col5 is null and _col0 is not null and (_col3 >= _col2))) (type: boolean)
                          Statistics: Num rows: 500 Data size: 99000 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: string)
                            outputColumnNames: _col0, _col1
                            Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              key expressions: _col0 (type: string)
                              sort order: +
                              Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col1 (type: string)
            Execution mode: llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: false
                enabledConditionsNotMet: hive.vectorized.use.vector.serde.deserialize IS false
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: key
                    Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: count(), count(key)
                      Group By Vectorization:
                          vectorOutput: false
                          native: false
                          projectedOutputColumns: null
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        sort order: 
                        Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: bigint), _col1 (type: bigint)
            Execution mode: llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: false
                enabledConditionsNotMet: hive.vectorized.use.vector.serde.deserialize IS false
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    Group By Vectorization:
                        vectorOutput: false
                        native: false
                        projectedOutputColumns: null
                    keys: key (type: string)
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 205 Data size: 17835 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col0 (type: string)
                      Statistics: Num rows: 205 Data size: 17835 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: false
                enabledConditionsNotMet: hive.vectorized.use.vector.serde.deserialize IS false
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                groupByVectorOutput: true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumns: [0, 1]
                Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                groupByVectorOutput: true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0), count(VALUE._col1)
                Group By Vectorization:
                    aggregators: VectorUDAFCountMerge(col 0) -> bigint, VectorUDAFCountMerge(col 1) -> bigint
                    className: VectorGroupByOperator
                    vectorOutput: true
                    native: false
                    projectedOutputColumns: [0, 1]
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  sort order: 
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkObjectHashOperator
                      native: true
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: _col0 (type: bigint), _col1 (type: bigint)
        Reducer 6 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                groupByVectorOutput: true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                Group By Vectorization:
                    className: VectorGroupByOperator
                    vectorOutput: true
                    keyExpressions: col 0
                    native: false
                    projectedOutputColumns: []
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 205 Data size: 17835 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col0 (type: string), true (type: boolean)
                  outputColumnNames: _col0, _col1
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumns: [0, 1]
                      selectExpressions: ConstantVectorExpression(val 1) -> 1:long
                  Statistics: Num rows: 205 Data size: 18655 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: string)
                    sort order: +
                    Map-reduce partition columns: _col0 (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkStringOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 205 Data size: 18655 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: _col1 (type: boolean)

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

Warning: Map Join MAPJOIN[27][bigTable=?] in task 'Map 1' is a cross product
PREHOOK: query: select *
from src
where not key in
(select key from src)
order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select *
from src
where not key in
(select key from src)
order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
