PREHOOK: query: create table test1_n10(key int, val int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@test1_n10
POSTHOOK: query: create table test1_n10(key int, val int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@test1_n10
PREHOOK: query: explain
insert overwrite table test1_n10
select key, count(1) from src group by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@test1_n10
POSTHOOK: query: explain
insert overwrite table test1_n10
select key, count(1) from src group by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@test1_n10
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: key
                    Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: count()
                      keys: key (type: string)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: bigint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: UDFToInteger(_col0) (type: int), UDFToInteger(_col1) (type: int)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 316 Data size: 2528 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 316 Data size: 2528 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: default.test1_n10
                  Select Operator
                    expressions: _col0 (type: int), _col1 (type: int)
                    outputColumnNames: key, val
                    Statistics: Num rows: 316 Data size: 2528 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(key), max(key), count(1), count(key), compute_bit_vector_hll(key), min(val), max(val), count(val), compute_bit_vector_hll(val)
                      minReductionHashAggr: 0.99
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                      Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        null sort order: 
                        sort order: 
                        Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col0) (type: bigint), UDFToLong(_col1) (type: bigint), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11
                  Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.test1_n10

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: key, val
          Column Types: int, int
          Table: default.test1_n10

PREHOOK: query: insert overwrite table test1_n10
select key, count(1) from src group by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@test1_n10
POSTHOOK: query: insert overwrite table test1_n10
select key, count(1) from src group by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@test1_n10
POSTHOOK: Lineage: test1_n10.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test1_n10.val EXPRESSION [(src)src.null, ]
PREHOOK: query: select * from test1_n10
PREHOOK: type: QUERY
PREHOOK: Input: default@test1_n10
#### A masked pattern was here ####
POSTHOOK: query: select * from test1_n10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test1_n10
#### A masked pattern was here ####
0	3
10	1
100	2
103	2
104	2
105	1
11	1
111	1
113	2
114	1
116	1
118	2
119	3
12	2
120	2
125	2
126	1
128	3
129	2
131	1
133	1
134	2
136	1
137	2
138	4
143	1
145	1
146	2
149	2
15	2
150	1
152	2
153	1
155	1
156	1
157	1
158	1
160	1
162	1
163	1
164	2
165	2
166	1
167	3
168	1
169	4
17	1
170	1
172	2
174	2
175	2
176	2
177	1
178	1
179	2
18	2
180	1
181	1
183	1
186	1
187	3
189	1
19	1
190	1
191	2
192	1
193	3
194	1
195	2
196	1
197	2
199	3
2	1
20	1
200	2
201	1
202	1
203	2
205	2
207	2
208	3
209	2
213	2
214	1
216	2
217	2
218	1
219	2
221	2
222	1
223	2
224	2
226	1
228	1
229	2
230	5
233	2
235	1
237	2
238	2
239	2
24	2
241	1
242	2
244	1
247	1
248	1
249	1
252	1
255	2
256	2
257	1
258	1
26	2
260	1
262	1
263	1
265	2
266	1
27	1
272	2
273	3
274	1
275	1
277	4
278	2
28	1
280	2
281	2
282	2
283	1
284	1
285	1
286	1
287	1
288	2
289	1
291	1
292	1
296	1
298	3
30	1
302	1
305	1
306	1
307	2
308	1
309	2
310	1
311	3
315	1
316	3
317	2
318	3
321	2
322	2
323	1
325	2
327	3
33	1
331	2
332	1
333	2
335	1
336	1
338	1
339	1
34	1
341	1
342	2
344	2
345	1
348	5
35	3
351	1
353	2
356	1
360	1
362	1
364	1
365	1
366	1
367	2
368	1
369	3
37	2
373	1
374	1
375	1
377	1
378	1
379	1
382	2
384	3
386	1
389	1
392	1
393	1
394	1
395	2
396	3
397	2
399	2
4	1
400	1
401	5
402	1
403	3
404	2
406	4
407	1
409	3
41	1
411	1
413	2
414	2
417	3
418	1
419	1
42	2
421	1
424	2
427	1
429	2
43	1
430	3
431	3
432	1
435	1
436	1
437	1
438	3
439	2
44	1
443	1
444	1
446	1
448	1
449	1
452	1
453	1
454	3
455	1
457	1
458	2
459	2
460	1
462	2
463	2
466	3
467	1
468	4
469	5
47	1
470	1
472	1
475	1
477	1
478	2
479	1
480	3
481	1
482	1
483	1
484	1
485	1
487	1
489	4
490	1
491	1
492	2
493	1
494	1
495	1
496	1
497	1
498	3
5	3
51	2
53	1
54	1
57	1
58	2
64	1
65	1
66	1
67	2
69	1
70	3
72	2
74	1
76	2
77	1
78	1
8	1
80	1
82	1
83	2
84	2
85	1
86	1
87	1
9	1
90	3
92	1
95	2
96	1
97	2
98	2
PREHOOK: query: drop table test1_n10
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@test1_n10
PREHOOK: Output: database:default
PREHOOK: Output: default@test1_n10
POSTHOOK: query: drop table test1_n10
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@test1_n10
POSTHOOK: Output: database:default
POSTHOOK: Output: default@test1_n10
PREHOOK: query: create table test_src_n0(key string, value string) partitioned by (ds string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@test_src_n0
POSTHOOK: query: create table test_src_n0(key string, value string) partitioned by (ds string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@test_src_n0
PREHOOK: query: create table test1_n10(key string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@test1_n10
POSTHOOK: query: create table test1_n10(key string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@test1_n10
PREHOOK: query: insert overwrite table test_src_n0 partition(ds='101') select * from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@test_src_n0@ds=101
POSTHOOK: query: insert overwrite table test_src_n0 partition(ds='101') select * from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@test_src_n0@ds=101
POSTHOOK: Lineage: test_src_n0 PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test_src_n0 PARTITION(ds=101).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: insert overwrite table test_src_n0 partition(ds='102') select * from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@test_src_n0@ds=102
POSTHOOK: query: insert overwrite table test_src_n0 partition(ds='102') select * from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@test_src_n0@ds=102
POSTHOOK: Lineage: test_src_n0 PARTITION(ds=102).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test_src_n0 PARTITION(ds=102).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain 
insert overwrite table test1_n10 select key from test_src_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@test_src_n0
PREHOOK: Input: default@test_src_n0@ds=101
PREHOOK: Input: default@test_src_n0@ds=102
PREHOOK: Output: default@test1_n10
POSTHOOK: query: explain 
insert overwrite table test1_n10 select key from test_src_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test_src_n0
POSTHOOK: Input: default@test_src_n0@ds=101
POSTHOOK: Input: default@test_src_n0@ds=102
POSTHOOK: Output: default@test1_n10
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: test_src_n0
                  Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.test1_n10
                    Select Operator
                      expressions: _col0 (type: string)
                      outputColumnNames: key
                      Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(key)), avg(COALESCE(length(key),0)), count(1), count(key), compute_bit_vector_hll(key)
                        minReductionHashAggr: 0.99
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4
                        Statistics: Num rows: 1 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 172 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 1 Data size: 266 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 266 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.test1_n10

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: key
          Column Types: string
          Table: default.test1_n10

PREHOOK: query: insert overwrite table test1_n10 select key from test_src_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@test_src_n0
PREHOOK: Input: default@test_src_n0@ds=101
PREHOOK: Input: default@test_src_n0@ds=102
PREHOOK: Output: default@test1_n10
POSTHOOK: query: insert overwrite table test1_n10 select key from test_src_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test_src_n0
POSTHOOK: Input: default@test_src_n0@ds=101
POSTHOOK: Input: default@test_src_n0@ds=102
POSTHOOK: Output: default@test1_n10
POSTHOOK: Lineage: test1_n10.key SIMPLE [(test_src_n0)test_src_n0.FieldSchema(name:key, type:string, comment:null), ]
PREHOOK: query: explain
insert overwrite table test1_n10 select key from test_src_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@test_src_n0
PREHOOK: Input: default@test_src_n0@ds=101
PREHOOK: Input: default@test_src_n0@ds=102
PREHOOK: Output: default@test1_n10
POSTHOOK: query: explain
insert overwrite table test1_n10 select key from test_src_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test_src_n0
POSTHOOK: Input: default@test_src_n0@ds=101
POSTHOOK: Input: default@test_src_n0@ds=102
POSTHOOK: Output: default@test1_n10
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: test_src_n0
                  Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.test1_n10
                    Select Operator
                      expressions: _col0 (type: string)
                      outputColumnNames: key
                      Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: max(length(key)), avg(COALESCE(length(key),0)), count(1), count(key), compute_bit_vector_hll(key)
                        minReductionHashAggr: 0.99
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4
                        Statistics: Num rows: 1 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: int), _col1 (type: struct<count:bigint,sum:double,input:int>), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), avg(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 172 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'STRING' (type: string), UDFToLong(COALESCE(_col0,0)) (type: bigint), COALESCE(_col1,0) (type: double), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 1 Data size: 266 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 266 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.test1_n10

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: key
          Column Types: string
          Table: default.test1_n10

PREHOOK: query: insert overwrite table test1_n10 select key from test_src_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@test_src_n0
PREHOOK: Input: default@test_src_n0@ds=101
PREHOOK: Input: default@test_src_n0@ds=102
PREHOOK: Output: default@test1_n10
POSTHOOK: query: insert overwrite table test1_n10 select key from test_src_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test_src_n0
POSTHOOK: Input: default@test_src_n0@ds=101
POSTHOOK: Input: default@test_src_n0@ds=102
POSTHOOK: Output: default@test1_n10
POSTHOOK: Lineage: test1_n10.key SIMPLE [(test_src_n0)test_src_n0.FieldSchema(name:key, type:string, comment:null), ]
