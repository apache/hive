PREHOOK: query: create table count_distinct_test(id int,key int,name int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@count_distinct_test
POSTHOOK: query: create table count_distinct_test(id int,key int,name int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@count_distinct_test
PREHOOK: query: insert into count_distinct_test values (1,1,2),(1,2,3),(1,3,2),(1,4,2),(1,5,3)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@count_distinct_test
POSTHOOK: query: insert into count_distinct_test values (1,1,2),(1,2,3),(1,3,2),(1,4,2),(1,5,3)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@count_distinct_test
POSTHOOK: Lineage: count_distinct_test.id SCRIPT []
POSTHOOK: Lineage: count_distinct_test.key SCRIPT []
POSTHOOK: Lineage: count_distinct_test.name SCRIPT []
PREHOOK: query: explain select id,count(distinct key),count(distinct name)
from count_distinct_test
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select id,count(distinct key),count(distinct name)
from count_distinct_test
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: count_distinct_test
                  Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: id (type: int), key (type: int), name (type: int)
                    outputColumnNames: id, key, name
                    Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: count(DISTINCT key), count(DISTINCT name)
                      keys: id (type: int), key (type: int), name (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 2 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 2 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col1:0._col0), count(DISTINCT KEY._col1:1._col0)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select id,count(distinct key),count(distinct name)
from count_distinct_test
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select id,count(distinct key),count(distinct name)
from count_distinct_test
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	5	2
PREHOOK: query: explain select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: count_distinct_test
                  Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: id (type: int), key (type: int), name (type: int)
                    outputColumnNames: id, key, name
                    Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: id (type: int), key (type: int), name (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                Group By Operator
                  aggregations: count(DISTINCT _col1), count(DISTINCT _col2)
                  keys: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                    sort order: +++
                    Map-reduce partition columns: _col0 (type: int)
                    Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col1:0._col0), count(DISTINCT KEY._col1:1._col0)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	5	2
PREHOOK: query: explain select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: count_distinct_test
                  Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: id (type: int), key (type: int), name (type: int)
                    outputColumnNames: id, key, name
                    Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: id (type: int), key (type: int), name (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                Group By Operator
                  aggregations: count(DISTINCT _col2), count(DISTINCT _col1)
                  keys: _col0 (type: int), _col2 (type: int), _col1 (type: int)
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                    sort order: +++
                    Map-reduce partition columns: _col0 (type: int)
                    Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col1:0._col0), count(DISTINCT KEY._col1:1._col0)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	2	5
PREHOOK: query: explain select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: count_distinct_test
                  Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: id (type: int), key (type: int), name (type: int)
                    outputColumnNames: id, key, name
                    Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: id (type: int), key (type: int), name (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                Group By Operator
                  aggregations: count(DISTINCT _col1), count(DISTINCT _col2)
                  keys: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                    sort order: +++
                    Map-reduce partition columns: _col0 (type: int)
                    Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col1:0._col0), count(DISTINCT KEY._col1:1._col0)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	5	2
PREHOOK: query: explain select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: count_distinct_test
                  Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: id (type: int), key (type: int), name (type: int)
                    outputColumnNames: id, key, name
                    Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: id (type: int), key (type: int), name (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                Group By Operator
                  aggregations: count(DISTINCT _col2), count(DISTINCT _col1)
                  keys: _col0 (type: int), _col2 (type: int), _col1 (type: int)
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                    sort order: +++
                    Map-reduce partition columns: _col0 (type: int)
                    Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col1:0._col0), count(DISTINCT KEY._col1:1._col0)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	2	5
