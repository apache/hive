PREHOOK: query: create table count_distinct_test(id int,key int,name int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@count_distinct_test
POSTHOOK: query: create table count_distinct_test(id int,key int,name int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@count_distinct_test
PREHOOK: query: insert into count_distinct_test values (1,1,2),(1,2,3),(1,3,2),(1,4,2),(1,5,3)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@count_distinct_test
POSTHOOK: query: insert into count_distinct_test values (1,1,2),(1,2,3),(1,3,2),(1,4,2),(1,5,3)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@count_distinct_test
POSTHOOK: Lineage: count_distinct_test.id SCRIPT []
POSTHOOK: Lineage: count_distinct_test.key SCRIPT []
POSTHOOK: Lineage: count_distinct_test.name SCRIPT []
PREHOOK: query: explain select id,count(distinct key),count(distinct name)
from count_distinct_test
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select id,count(distinct key),count(distinct name)
from count_distinct_test
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: count_distinct_test
                  Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: id (type: int), key (type: int), name (type: int)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: _col0 (type: int), _col1 (type: int), _col2 (type: int), 0L (type: bigint)
                      grouping sets: 1, 2
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: bigint)
                        null sort order: zzzz
                        sort order: ++++
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int), KEY._col3 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: if(((_col3 = 1L) and _col1 is not null), 1, null) (type: int), if(((_col3 = 2L) and _col2 is not null), 1, null) (type: int), _col0 (type: int)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: count(_col0), count(_col1)
                    keys: _col2 (type: int)
                    mode: complete
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select id,count(distinct key),count(distinct name)
from count_distinct_test
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select id,count(distinct key),count(distinct name)
from count_distinct_test
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	5	2
PREHOOK: query: explain select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: count_distinct_test
                  Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: id (type: int), key (type: int), name (type: int)
                    outputColumnNames: id, key, name
                    Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: id (type: int), key (type: int), name (type: int)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        null sort order: zzz
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                Group By Operator
                  keys: _col0 (type: int), _col1 (type: int), _col2 (type: int), 0L (type: bigint)
                  grouping sets: 1, 2
                  minReductionHashAggr: 0.4
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: bigint)
                    null sort order: zzzz
                    sort order: ++++
                    Map-reduce partition columns: _col0 (type: int)
                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int), KEY._col3 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: if(((_col3 = 1L) and _col1 is not null), 1, null) (type: int), if(((_col3 = 2L) and _col2 is not null), 1, null) (type: int), _col0 (type: int)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: count(_col0), count(_col1)
                    keys: _col2 (type: int)
                    mode: complete
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	5	2
PREHOOK: query: explain select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: count_distinct_test
                  Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: id (type: int), key (type: int), name (type: int)
                    outputColumnNames: id, key, name
                    Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: id (type: int), name (type: int), key (type: int)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        null sort order: zzz
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                Group By Operator
                  keys: _col0 (type: int), _col1 (type: int), _col2 (type: int), 0L (type: bigint)
                  grouping sets: 1, 2
                  minReductionHashAggr: 0.4
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: bigint)
                    null sort order: zzzz
                    sort order: ++++
                    Map-reduce partition columns: _col0 (type: int)
                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int), KEY._col3 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: if(((_col3 = 1L) and _col1 is not null), 1, null) (type: int), if(((_col3 = 2L) and _col2 is not null), 1, null) (type: int), _col0 (type: int)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: count(_col0), count(_col1)
                    keys: _col2 (type: int)
                    mode: complete
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	2	5
PREHOOK: query: explain select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: count_distinct_test
                  Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: id (type: int), key (type: int), name (type: int)
                    outputColumnNames: id, key, name
                    Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: id (type: int), key (type: int), name (type: int)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        null sort order: zzz
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                Group By Operator
                  keys: _col0 (type: int), _col1 (type: int), _col2 (type: int), 0L (type: bigint)
                  grouping sets: 1, 2
                  minReductionHashAggr: 0.4
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: bigint)
                    null sort order: zzzz
                    sort order: ++++
                    Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: bigint)
                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int), KEY._col3 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: if(((_col3 = 1L) and _col1 is not null), 1, null) (type: int), if(((_col3 = 2L) and _col2 is not null), 1, null) (type: int), _col0 (type: int)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: count(_col0), count(_col1)
                    keys: _col2 (type: int)
                    minReductionHashAggr: 0.8
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col1 (type: bigint), _col2 (type: bigint)
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0), count(VALUE._col1)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select id,count(Distinct key),count(Distinct name)
from (select id,key,name from count_distinct_test group by id,key,name)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	5	2
PREHOOK: query: explain select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: count_distinct_test
                  Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: id (type: int), key (type: int), name (type: int)
                    outputColumnNames: id, key, name
                    Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: id (type: int), name (type: int), key (type: int)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        null sort order: zzz
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                Group By Operator
                  keys: _col0 (type: int), _col1 (type: int), _col2 (type: int), 0L (type: bigint)
                  grouping sets: 1, 2
                  minReductionHashAggr: 0.4
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: bigint)
                    null sort order: zzzz
                    sort order: ++++
                    Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: bigint)
                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: int), KEY._col3 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: if(((_col3 = 1L) and _col1 is not null), 1, null) (type: int), if(((_col3 = 2L) and _col2 is not null), 1, null) (type: int), _col0 (type: int)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: count(_col0), count(_col1)
                    keys: _col2 (type: int)
                    minReductionHashAggr: 0.8
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col1 (type: bigint), _col2 (type: bigint)
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0), count(VALUE._col1)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
PREHOOK: type: QUERY
PREHOOK: Input: default@count_distinct_test
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select id,count(Distinct name),count(Distinct key)
from (select id,key,name from count_distinct_test group by id,name,key)m
group by id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@count_distinct_test
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	2	5
