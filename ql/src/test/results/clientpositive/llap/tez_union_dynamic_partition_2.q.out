PREHOOK: query: drop table if exists dummy_n7
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists dummy_n7
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table if exists partunion1_n0
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists partunion1_n0
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table dummy_n7(i int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@dummy_n7
POSTHOOK: query: create table dummy_n7(i int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@dummy_n7
PREHOOK: query: insert into table dummy_n7 values (1)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@dummy_n7
POSTHOOK: query: insert into table dummy_n7 values (1)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@dummy_n7
POSTHOOK: Lineage: dummy_n7.i SCRIPT []
PREHOOK: query: select * from dummy_n7
PREHOOK: type: QUERY
PREHOOK: Input: default@dummy_n7
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from dummy_n7
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dummy_n7
POSTHOOK: Output: hdfs://### HDFS PATH ###
1
PREHOOK: query: create table partunion1_n0(id1 int) partitioned by (part1 string) stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@partunion1_n0
POSTHOOK: query: create table partunion1_n0(id1 int) partitioned by (part1 string) stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@partunion1_n0
PREHOOK: query: explain insert into table partunion1_n0 partition(part1)
select temps.* from (
select 1 as id1, '2014' as part1 from dummy_n7 
union all 
select 2 as id1, '2014' as part1 from dummy_n7 ) temps
PREHOOK: type: QUERY
PREHOOK: Input: default@dummy_n7
PREHOOK: Output: default@partunion1_n0
POSTHOOK: query: explain insert into table partunion1_n0 partition(part1)
select temps.* from (
select 1 as id1, '2014' as part1 from dummy_n7 
union all 
select 2 as id1, '2014' as part1 from dummy_n7 ) temps
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dummy_n7
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
  Stage-5
  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0
  Stage-4
  Stage-6
  Stage-7 depends on stages: Stage-6

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Union 2 (CONTAINS)
        Map 4 <- Union 2 (CONTAINS)
        Reducer 3 <- Union 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: dummy_n7
                  Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: 1 (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: int), '2014' (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 2 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        Statistics: Num rows: 2 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                            name: default.partunion1_n0
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: string)
                        outputColumnNames: id1, part1
                        Statistics: Num rows: 2 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                        Group By Operator
                          aggregations: compute_stats(id1, 'hll')
                          keys: part1 (type: string)
                          mode: hash
                          outputColumnNames: _col0, _col1
                          Statistics: Num rows: 1 Data size: 512 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            key expressions: _col0 (type: string)
                            sort order: +
                            Map-reduce partition columns: _col0 (type: string)
                            Statistics: Num rows: 1 Data size: 512 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>)
            Execution mode: llap
            LLAP IO: no inputs
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: dummy_n7
                  Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: 2 (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: int), '2014' (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 2 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        Statistics: Num rows: 2 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                            name: default.partunion1_n0
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: string)
                        outputColumnNames: id1, part1
                        Statistics: Num rows: 2 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                        Group By Operator
                          aggregations: compute_stats(id1, 'hll')
                          keys: part1 (type: string)
                          mode: hash
                          outputColumnNames: _col0, _col1
                          Statistics: Num rows: 1 Data size: 512 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            key expressions: _col0 (type: string)
                            sort order: +
                            Map-reduce partition columns: _col0 (type: string)
                            Statistics: Num rows: 1 Data size: 512 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>)
            Execution mode: llap
            LLAP IO: no inputs
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Union 2 
            Vertex: Union 2

  Stage: Stage-8
    Conditional Operator

  Stage: Stage-5
    Move Operator
      files:
          hdfs directory: true
          destination: hdfs://### HDFS PATH ###

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            part1 
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.partunion1_n0

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: id1
          Column Types: int
          Table: default.partunion1_n0

  Stage: Stage-4
    Tez
#### A masked pattern was here ####
      Vertices:
        File Merge 
          Merge File Operator
            Map Operator Tree:
                ORC File Merge Operator
            merge level: stripe
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat

  Stage: Stage-6
    Tez
#### A masked pattern was here ####
      Vertices:
        File Merge 
          Merge File Operator
            Map Operator Tree:
                ORC File Merge Operator
            merge level: stripe
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat

  Stage: Stage-7
    Move Operator
      files:
          hdfs directory: true
          destination: hdfs://### HDFS PATH ###

PREHOOK: query: insert into table partunion1_n0 partition(part1)
select 1 as id1, '2014' as part1 from dummy_n7 
union all 
select 2 as id1, '2014' as part1 from dummy_n7
PREHOOK: type: QUERY
PREHOOK: Input: default@dummy_n7
PREHOOK: Output: default@partunion1_n0
POSTHOOK: query: insert into table partunion1_n0 partition(part1)
select 1 as id1, '2014' as part1 from dummy_n7 
union all 
select 2 as id1, '2014' as part1 from dummy_n7
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dummy_n7
POSTHOOK: Output: default@partunion1_n0@part1=2014
POSTHOOK: Lineage: partunion1_n0 PARTITION(part1=2014).id1 EXPRESSION []
PREHOOK: query: select * from partunion1_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@partunion1_n0
PREHOOK: Input: default@partunion1_n0@part1=2014
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select * from partunion1_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@partunion1_n0
POSTHOOK: Input: default@partunion1_n0@part1=2014
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	2014
2	2014
PREHOOK: query: drop table dummy_n7
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@dummy_n7
PREHOOK: Output: default@dummy_n7
POSTHOOK: query: drop table dummy_n7
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@dummy_n7
POSTHOOK: Output: default@dummy_n7
PREHOOK: query: drop table partunion1_n0
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@partunion1_n0
PREHOOK: Output: default@partunion1_n0
POSTHOOK: query: drop table partunion1_n0
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@partunion1_n0
POSTHOOK: Output: default@partunion1_n0
