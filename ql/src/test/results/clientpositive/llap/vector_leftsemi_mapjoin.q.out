PREHOOK: query: create table t1_n148 stored as orc as select cast(key as int) key, value from src where key <= 10
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@t1_n148
POSTHOOK: query: create table t1_n148 stored as orc as select cast(key as int) key, value from src where key <= 10
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@t1_n148
POSTHOOK: Lineage: t1_n148.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: t1_n148.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: select * from t1_n148 sort by key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 sort by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_10
2	val_2
4	val_4
5	val_5
5	val_5
5	val_5
8	val_8
9	val_9
PREHOOK: query: create table t2_n87 stored as orc as select cast(2*key as int) key, value from t1_n148
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@t1_n148
PREHOOK: Output: database:default
PREHOOK: Output: default@t2_n87
POSTHOOK: query: create table t2_n87 stored as orc as select cast(2*key as int) key, value from t1_n148
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@t1_n148
POSTHOOK: Output: database:default
POSTHOOK: Output: default@t2_n87
POSTHOOK: Lineage: t2_n87.key EXPRESSION [(t1_n148)t1_n148.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: t2_n87.value SIMPLE [(t1_n148)t1_n148.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: select * from t2_n87 sort by key
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 sort by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_5
10	val_5
10	val_5
16	val_8
18	val_9
20	val_10
4	val_2
8	val_4
PREHOOK: query: create table t3_n35 stored as orc as select * from (select * from t1_n148 union all select * from t2_n87) b
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Output: database:default
PREHOOK: Output: default@t3_n35
POSTHOOK: query: create table t3_n35 stored as orc as select * from (select * from t1_n148 union all select * from t2_n87) b
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Output: database:default
POSTHOOK: Output: default@t3_n35
POSTHOOK: Lineage: t3_n35.key EXPRESSION [(t1_n148)t1_n148.FieldSchema(name:key, type:int, comment:null), (t2_n87)t2_n87.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: t3_n35.value EXPRESSION [(t1_n148)t1_n148.FieldSchema(name:value, type:string, comment:null), (t2_n87)t2_n87.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: select * from t3_n35 sort by key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t3_n35 sort by key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
10	val_10
10	val_5
10	val_5
10	val_5
16	val_8
18	val_9
2	val_2
20	val_10
4	val_2
4	val_4
5	val_5
5	val_5
5	val_5
8	val_4
8	val_8
9	val_9
PREHOOK: query: analyze table t3_n35 compute statistics
PREHOOK: type: QUERY
PREHOOK: Input: default@t3_n35
PREHOOK: Output: default@t3_n35
POSTHOOK: query: analyze table t3_n35 compute statistics
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t3_n35
POSTHOOK: Output: default@t3_n35
PREHOOK: query: create table t4_n19 (key int, value string) stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@t4_n19
POSTHOOK: query: create table t4_n19 (key int, value string) stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@t4_n19
PREHOOK: query: select * from t4_n19
PREHOOK: type: QUERY
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: select * from t4_n19
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PREHOOK: query: explain vectorization only summary

select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary

select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_10
4	val_4
8	val_8
PREHOOK: query: explain vectorization only summary
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization only summary
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PREHOOK: query: explain vectorization only summary
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_0
val_0
val_0
val_10
val_2
val_4
val_5
val_5
val_5
val_8
val_9
PREHOOK: query: explain vectorization only summary
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
PREHOOK: query: explain vectorization only summary
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_10
val_8
val_9
PREHOOK: query: explain vectorization only summary
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PREHOOK: query: explain vectorization only summary
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization only summary
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
2
4
4
5
5
5
8
8
9
PREHOOK: query: explain vectorization only summary
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
8	val_8
PREHOOK: query: explain vectorization only summary
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
10	val_10	10	val_5
10	val_10	10	val_5
10	val_10	10	val_5
4	val_4	4	val_2
8	val_8	8	val_4
PREHOOK: query: explain vectorization only summary
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
10	val_10
2	val_2
4	val_4
5	val_5
5	val_5
5	val_5
8	val_8
9	val_9
PREHOOK: query: explain vectorization only summary
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization only summary
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
PREHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
NULL
NULL
PREHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
10
10
2
4
4
5
5
5
8
8
9
NULL
NULL
NULL
PREHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only summary
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PREHOOK: query: explain vectorization summary
select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_10
4	val_4
8	val_8
PREHOOK: query: explain vectorization summary
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization summary
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PREHOOK: query: explain vectorization summary
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col1 (type: int)
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (key < 15) (type: boolean)
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col1
                      Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col1 (type: int), _col1 (type: int)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col1 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col1 (type: int)
                          Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_0
val_0
val_0
val_10
val_2
val_4
val_5
val_5
val_5
val_8
val_9
PREHOOK: query: explain vectorization summary
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((value < 'val_10') and key is not null) (type: boolean)
                    Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
PREHOOK: query: explain vectorization summary
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t3_n35
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (key > 5) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_10
val_8
val_9
PREHOOK: query: explain vectorization summary
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t2_n87
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((key > 5) and (value <= 'val_20')) (type: boolean)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PREHOOK: query: explain vectorization summary
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1_n148
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (key > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization summary
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      outputColumnNames: _col0
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
2
4
4
5
5
5
8
8
9
PREHOOK: query: explain vectorization summary
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 (2 * _col0) (type: int)
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (2 * key) is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: (2 * _col0) (type: int)
                          sort order: +
                          Map-reduce partition columns: (2 * _col0) (type: int)
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
8	val_8
PREHOOK: query: explain vectorization summary
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                           Left Semi Join 1 to 2
                      keys:
                        0 key (type: int)
                        1 key (type: int)
                        2 _col0 (type: int)
                      outputColumnNames: _col0, _col1, _col5, _col6
                      input vertices:
                        1 Map 3
                        2 Map 4
                      Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: string), _col5 (type: int), _col6 (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: string)
                          sort order: ++
                          Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col2 (type: int), _col3 (type: string)
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                      value expressions: value (type: string)
            Execution mode: llap
            LLAP IO: all inputs
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: int), VALUE._col1 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
10	val_10	10	val_5
10	val_10	10	val_5
10	val_10	10	val_5
4	val_4	4	val_2
8	val_8	8	val_4
PREHOOK: query: explain vectorization summary
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (key is not null and value is not null) (type: boolean)
                    Statistics: Num rows: 20 Data size: 3760 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int), value (type: string)
                        1 _col0 (type: int), _col1 (type: string)
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (key is not null and value is not null) (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: string)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                          Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
10	val_10
2	val_2
4	val_4
5	val_5
5	val_5
5	val_5
8	val_8
9	val_9
PREHOOK: query: explain vectorization summary
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                           Left Semi Join 0 to 2
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                        2 _col0 (type: int)
                      outputColumnNames: _col0
                      input vertices:
                        1 Map 3
                        2 Map 4
                      Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization summary
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Map Join Operator
                    condition map:
                         Left Outer Join 0 to 1
                         Left Semi Join 1 to 2
                    keys:
                      0 key (type: int)
                      1 key (type: int)
                      2 _col0 (type: int)
                    outputColumnNames: _col0
                    input vertices:
                      1 Map 3
                      2 Map 4
                    Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      sort order: +
                      Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization summary
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Outer Join 0 to 1
                     Left Semi Join 1 to 2
                keys:
                  0 key (type: int)
                  1 key (type: int)
                  2 _col0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
PREHOOK: query: explain vectorization summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Left Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Right Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
NULL
NULL
PREHOOK: query: explain vectorization summary
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
10
10
2
4
4
5
5
5
8
8
9
NULL
NULL
NULL
PREHOOK: query: explain vectorization summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 3948 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 23 Data size: 4342 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Left Outer Join 0 to 1
                        keys:
                          0 _col1 (type: string)
                          1 value (type: string)
                        outputColumnNames: _col0
                        input vertices:
                          1 Map 4
                        Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: value (type: string)
                    sort order: +
                    Map-reduce partition columns: value (type: string)
                    Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization summary
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization summary
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((key > 100) and value is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Left Semi Join 0 to 1
                        keys:
                          0 _col1 (type: string)
                          1 _col0 (type: string)
                        outputColumnNames: _col0
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 12 Data size: 2226 Basic stats: COMPLETE Column stats: NONE
                        File Output Operator
                          compressed: false
                          Statistics: Num rows: 12 Data size: 2226 Basic stats: COMPLETE Column stats: NONE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: llap
            LLAP IO: all inputs
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: value (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: string)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: string)
                          Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
            Execution mode: llap
            LLAP IO: all inputs

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PREHOOK: query: explain vectorization only operator
select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_10
4	val_4
8	val_8
PREHOOK: query: explain vectorization only operator
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization only operator
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PREHOOK: query: explain vectorization only operator
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_0
val_0
val_0
val_10
val_2
val_4
val_5
val_5
val_5
val_8
val_9
PREHOOK: query: explain vectorization only operator
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
PREHOOK: query: explain vectorization only operator
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_10
val_8
val_9
PREHOOK: query: explain vectorization only operator
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PREHOOK: query: explain vectorization only operator
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization only operator
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
2
4
4
5
5
5
8
8
9
PREHOOK: query: explain vectorization only operator
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
8	val_8
PREHOOK: query: explain vectorization only operator
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, One MapJoin Condition IS false
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkLongOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 4 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
10	val_10	10	val_5
10	val_10	10	val_5
10	val_10	10	val_5
4	val_4	4	val_2
8	val_8	8	val_4
PREHOOK: query: explain vectorization only operator
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkMultiKeyOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
10	val_10
2	val_2
4	val_4
5	val_5
5	val_5
5	val_5
8	val_8
9	val_9
PREHOOK: query: explain vectorization only operator
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, One MapJoin Condition IS false
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 4 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Map Join Vectorization:
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, One MapJoin Condition IS false
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 4 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          native: false
                          vectorProcessingMode: HASH
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization only operator
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 4 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 5 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          native: false
                          vectorProcessingMode: HASH
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
PREHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 4 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          native: false
                          vectorProcessingMode: HASH
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 5 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 4 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          native: false
                          vectorProcessingMode: HASH
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 5 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
NULL
NULL
PREHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 4 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          native: false
                          vectorProcessingMode: HASH
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 5 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
10
10
2
4
4
5
5
5
8
8
9
NULL
NULL
NULL
PREHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Map Join Vectorization:
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        Map Join Vectorization:
                            className: VectorMapJoinOperator
                            native: false
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                            nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 3 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 4 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkStringOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization only operator
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE)
      Vertices:
        Map 1 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Map Join Vectorization:
                            className: VectorMapJoinOperator
                            native: false
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                  TableScan Vectorization:
                      native: true
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            native: false
                            vectorProcessingMode: HASH
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkStringOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true

  Stage: Stage-0
    Fetch Operator

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_10
4	val_4
8	val_8
PREHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PREHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col1 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [0]
                        Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColLessLongScalar(col 0:int, val 15)
                    predicate: (key < 15) (type: boolean)
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col1 (type: int), _col1 (type: int)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col1 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col1 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_0
val_0
val_0
val_10
val_2
val_4
val_5
val_5
val_5
val_8
val_9
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterStringGroupColLessStringScalar(col 1:string, val val_10), SelectColumnIsNotNull(col 0:int))
                    predicate: ((value < 'val_10') and key is not null) (type: boolean)
                    Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
PREHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t3_n35
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 5)
                    predicate: (key > 5) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [0]
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_10
val_8
val_9
PREHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t2_n87
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColGreaterLongScalar(col 0:int, val 5), FilterStringGroupColLessEqualStringScalar(col 1:string, val val_20))
                    predicate: ((key > 5) and (value <= 'val_20')) (type: boolean)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [0]
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PREHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1_n148
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (key > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization detail
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col0
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
2
4
4
5
5
5
8
8
9
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 (2 * _col0) (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 3:int)(children: LongScalarMultiplyLongColumn(val 2, col 0:int) -> 3:int)
                    predicate: (2 * key) is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: (2 * _col0) (type: int)
                          sort order: +
                          Map-reduce partition columns: (2 * _col0) (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [1]
                              keyExpressions: LongScalarMultiplyLongColumn(val 2, col 0:int) -> 1:int
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
8	val_8
PREHOOK: query: explain vectorization detail
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                           Left Semi Join 1 to 2
                      keys:
                        0 key (type: int)
                        1 key (type: int)
                        2 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, One MapJoin Condition IS false
                      outputColumnNames: _col0, _col1, _col5, _col6
                      input vertices:
                        1 Map 3
                        2 Map 4
                      Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: string), _col5 (type: int), _col6 (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [0, 1, 2, 3]
                        Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: string)
                          sort order: ++
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [0, 1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: [2, 3]
                          Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col2 (type: int), _col3 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string]
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkLongOperator
                          keyColumnNums: [0]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: [1]
                      Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                      value expressions: value (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 4
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string, VALUE._col0:int, VALUE._col1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: int), VALUE._col1 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3]
                Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
10	val_10	10	val_5
10	val_10	10	val_5
10	val_10	10	val_5
4	val_4	4	val_2
8	val_8	8	val_4
PREHOOK: query: explain vectorization detail
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: SelectColumnIsNotNull(col 0:int), SelectColumnIsNotNull(col 1:string))
                    predicate: (key is not null and value is not null) (type: boolean)
                    Statistics: Num rows: 20 Data size: 3760 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int), value (type: string)
                        1 _col0 (type: int), _col1 (type: string)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int, col 1:string
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: SelectColumnIsNotNull(col 0:int), SelectColumnIsNotNull(col 1:string))
                    predicate: (key is not null and value is not null) (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: string)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkMultiKeyOperator
                              keyColumnNums: [0, 1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
10	val_10
2	val_2
4	val_4
5	val_5
5	val_5
5	val_5
8	val_8
9	val_9
PREHOOK: query: explain vectorization detail
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                           Left Semi Join 0 to 2
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                        2 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, One MapJoin Condition IS false
                      outputColumnNames: _col0
                      input vertices:
                        1 Map 3
                        2 Map 4
                      Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Map Join Operator
                    condition map:
                         Left Outer Join 0 to 1
                         Left Semi Join 1 to 2
                    keys:
                      0 key (type: int)
                      1 key (type: int)
                      2 _col0 (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 0:int
                        bigTableValueExpressions: col 0:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, One MapJoin Condition IS false
                    outputColumnNames: _col0
                    input vertices:
                      1 Map 3
                      2 Map 4
                    Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: []
                      Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Outer Join 0 to 1
                     Left Semi Join 1 to 2
                keys:
                  0 key (type: int)
                  1 key (type: int)
                  2 _col0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Left Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Right Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
NULL
NULL
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
10
10
2
4
4
5
5
5
8
8
9
NULL
NULL
NULL
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 3948 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 23 Data size: 4342 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Left Outer Join 0 to 1
                        keys:
                          0 _col1 (type: string)
                          1 value (type: string)
                        Map Join Vectorization:
                            bigTableKeyExpressions: col 1:string
                            bigTableValueExpressions: col 0:int
                            className: VectorMapJoinOperator
                            native: false
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                            nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        outputColumnNames: _col0
                        input vertices:
                          1 Map 4
                        Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: value (type: string)
                    sort order: +
                    Map-reduce partition columns: value (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkStringOperator
                        keyColumnNums: [1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColGreaterLongScalar(col 0:int, val 100), SelectColumnIsNotNull(col 1:string))
                    predicate: ((key > 100) and value is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Left Semi Join 0 to 1
                        keys:
                          0 _col1 (type: string)
                          1 _col0 (type: string)
                        Map Join Vectorization:
                            bigTableKeyExpressions: col 1:string
                            bigTableValueExpressions: col 0:int
                            className: VectorMapJoinOperator
                            native: false
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        outputColumnNames: _col0
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 12 Data size: 2226 Basic stats: COMPLETE Column stats: NONE
                        File Output Operator
                          compressed: false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
                          Statistics: Num rows: 12 Data size: 2226 Basic stats: COMPLETE Column stats: NONE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 1:string)
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: value (type: string)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [1]
                      Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: string)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: string)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkStringOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_10
4	val_4
8	val_8
PREHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PREHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col1 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [1]
                          bigTableValueColumnNums: [1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [1]
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [1]
                        Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColLessLongScalar(col 0:int, val 15)
                    predicate: (key < 15) (type: boolean)
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col1 (type: int), _col1 (type: int)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col1 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col1 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_0
val_0
val_0
val_10
val_2
val_4
val_5
val_5
val_5
val_8
val_9
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterStringGroupColLessStringScalar(col 1:string, val val_10), SelectColumnIsNotNull(col 0:int))
                    predicate: ((value < 'val_10') and key is not null) (type: boolean)
                    Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
PREHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t3_n35
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 5)
                    predicate: (key > 5) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [1]
                          bigTableValueColumnNums: [1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [1]
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [1]
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_10
val_8
val_9
PREHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t2_n87
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColGreaterLongScalar(col 0:int, val 5), FilterStringGroupColLessEqualStringScalar(col 1:string, val val_20))
                    predicate: ((key > 5) and (value <= 'val_20')) (type: boolean)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [1]
                          bigTableValueColumnNums: [1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [1]
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [1]
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PREHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1_n148
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (key > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization detail
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0]
                          bigTableValueColumnNums: [0]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0]
                      outputColumnNames: _col0
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
2
4
4
5
5
5
8
8
9
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 (2 * _col0) (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 3:int)(children: LongScalarMultiplyLongColumn(val 2, col 0:int) -> 3:int)
                    predicate: (2 * key) is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: (2 * _col0) (type: int)
                          sort order: +
                          Map-reduce partition columns: (2 * _col0) (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [1]
                              keyExpressions: LongScalarMultiplyLongColumn(val 2, col 0:int) -> 1:int
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
8	val_8
PREHOOK: query: explain vectorization detail
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                           Left Semi Join 1 to 2
                      keys:
                        0 key (type: int)
                        1 key (type: int)
                        2 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: One MapJoin Condition IS false
                      outputColumnNames: _col0, _col1, _col5, _col6
                      input vertices:
                        1 Map 3
                        2 Map 4
                      Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: string), _col5 (type: int), _col6 (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [0, 1, 2, 3]
                        Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: string)
                          sort order: ++
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [0, 1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: [2, 3]
                          Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col2 (type: int), _col3 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string]
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkLongOperator
                          keyColumnNums: [0]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: [1]
                      Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                      value expressions: value (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 4
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string, VALUE._col0:int, VALUE._col1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: int), VALUE._col1 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3]
                Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
10	val_10	10	val_5
10	val_10	10	val_5
10	val_10	10	val_5
4	val_4	4	val_2
8	val_8	8	val_4
PREHOOK: query: explain vectorization detail
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: SelectColumnIsNotNull(col 0:int), SelectColumnIsNotNull(col 1:string))
                    predicate: (key is not null and value is not null) (type: boolean)
                    Statistics: Num rows: 20 Data size: 3760 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int), value (type: string)
                        1 _col0 (type: int), _col1 (type: string)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0, 1]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiMultiKeyOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: SelectColumnIsNotNull(col 0:int), SelectColumnIsNotNull(col 1:string))
                    predicate: (key is not null and value is not null) (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: string)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkMultiKeyOperator
                              keyColumnNums: [0, 1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
10	val_10
2	val_2
4	val_4
5	val_5
5	val_5
5	val_5
8	val_8
9	val_9
PREHOOK: query: explain vectorization detail
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                           Left Semi Join 0 to 2
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                        2 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: One MapJoin Condition IS false
                      outputColumnNames: _col0
                      input vertices:
                        1 Map 3
                        2 Map 4
                      Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Map Join Operator
                    condition map:
                         Left Outer Join 0 to 1
                         Left Semi Join 1 to 2
                    keys:
                      0 key (type: int)
                      1 key (type: int)
                      2 _col0 (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 0:int
                        bigTableValueExpressions: col 0:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: One MapJoin Condition IS false
                    outputColumnNames: _col0
                    input vertices:
                      1 Map 3
                      2 Map 4
                    Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: []
                      Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Outer Join 0 to 1
                     Left Semi Join 1 to 2
                keys:
                  0 key (type: int)
                  1 key (type: int)
                  2 _col0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Left Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Right Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
NULL
NULL
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
10
10
2
4
4
5
5
5
8
8
9
NULL
NULL
NULL
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 3948 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 23 Data size: 4342 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Left Outer Join 0 to 1
                        keys:
                          0 _col1 (type: string)
                          1 value (type: string)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [1]
                            bigTableRetainedColumnNums: [0]
                            bigTableValueColumnNums: [0]
                            className: VectorMapJoinOuterStringOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0]
                        outputColumnNames: _col0
                        input vertices:
                          1 Map 4
                        Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: value (type: string)
                    sort order: +
                    Map-reduce partition columns: value (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkStringOperator
                        keyColumnNums: [1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColGreaterLongScalar(col 0:int, val 100), SelectColumnIsNotNull(col 1:string))
                    predicate: ((key > 100) and value is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Left Semi Join 0 to 1
                        keys:
                          0 _col1 (type: string)
                          1 _col0 (type: string)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [1]
                            bigTableRetainedColumnNums: [0]
                            bigTableValueColumnNums: [0]
                            className: VectorMapJoinLeftSemiStringOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0]
                        outputColumnNames: _col0
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 12 Data size: 2226 Basic stats: COMPLETE Column stats: NONE
                        File Output Operator
                          compressed: false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
                          Statistics: Num rows: 12 Data size: 2226 Basic stats: COMPLETE Column stats: NONE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 1:string)
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: value (type: string)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [1]
                      Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: string)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: string)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkStringOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key=b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_10
4	val_4
8	val_8
PREHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join t1_n148 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t4_n19
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t4_n19 b on b.key=a.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t4_n19
#### A masked pattern was here ####
PREHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col1 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [1]
                          bigTableValueColumnNums: [1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [1]
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [1]
                        Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColLessLongScalar(col 0:int, val 15)
                    predicate: (key < 15) (type: boolean)
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col1 (type: int), _col1 (type: int)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col1 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col1 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 24 Data size: 96 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join t3_n35 b on (b.key = a.key and b.key < '15') sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_0
val_0
val_0
val_10
val_2
val_4
val_5
val_5
val_5
val_8
val_9
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterStringGroupColLessStringScalar(col 1:string, val val_10), SelectColumnIsNotNull(col 0:int))
                    predicate: ((value < 'val_10') and key is not null) (type: boolean)
                    Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 3 Data size: 564 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
PREHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t3_n35
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 5)
                    predicate: (key > 5) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [1]
                          bigTableValueColumnNums: [1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [1]
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [1]
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key from t3_n35 where key > 5) b on a.key = b.key sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
val_10
val_8
val_9
PREHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t2_n87
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColGreaterLongScalar(col 0:int, val 5), FilterStringGroupColLessEqualStringScalar(col 1:string, val val_20))
                    predicate: ((key > 5) and (value <= 'val_20')) (type: boolean)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [1]
                          bigTableValueColumnNums: [1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [1]
                      outputColumnNames: _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: string)
                        outputColumnNames: _col0
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [1]
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select a.value from t1_n148 a left semi join (select key , value from t2_n87 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PREHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1_n148
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (key > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 1
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t2_n87 a left semi join (select key , value from t1_n148 where key > 2) b on a.key = b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
10	val_5
10	val_5
10	val_5
4	val_2
8	val_4
PREHOOK: query: explain vectorization detail
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0]
                          bigTableValueColumnNums: [0]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0]
                      outputColumnNames: _col0
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 23 Data size: 92 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
2
4
4
5
5
5
8
8
9
PREHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 (2 * _col0) (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 3:int)(children: LongScalarMultiplyLongColumn(val 2, col 0:int) -> 3:int)
                    predicate: (2 * key) is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: (2 * _col0) (type: int)
                          sort order: +
                          Map-reduce partition columns: (2 * _col0) (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [1]
                              keyExpressions: LongScalarMultiplyLongColumn(val 2, col 0:int) -> 1:int
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 12 Data size: 2274 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a left semi join t2_n87 b on a.key = 2*b.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
8	val_8
PREHOOK: query: explain vectorization detail
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                           Left Semi Join 1 to 2
                      keys:
                        0 key (type: int)
                        1 key (type: int)
                        2 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:string
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: One MapJoin Condition IS false
                      outputColumnNames: _col0, _col1, _col5, _col6
                      input vertices:
                        1 Map 3
                        2 Map 4
                      Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: string), _col5 (type: int), _col6 (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [0, 1, 2, 3]
                        Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: string)
                          sort order: ++
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [0, 1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: [2, 3]
                          Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col2 (type: int), _col3 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string]
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkLongOperator
                          keyColumnNums: [0]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: [1]
                      Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                      value expressions: value (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 4
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string, VALUE._col0:int, VALUE._col1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: int), VALUE._col1 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3]
                Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t1_n148 a join t2_n87 b on a.key = b.key left semi join t3_n35 c on b.key = c.key sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
0	val_0	0	val_0
10	val_10	10	val_5
10	val_10	10	val_5
10	val_10	10	val_5
4	val_4	4	val_2
8	val_8	8	val_4
PREHOOK: query: explain vectorization detail
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: SelectColumnIsNotNull(col 0:int), SelectColumnIsNotNull(col 1:string))
                    predicate: (key is not null and value is not null) (type: boolean)
                    Statistics: Num rows: 20 Data size: 3760 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int), value (type: string)
                        1 _col0 (type: int), _col1 (type: string)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0, 1]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiMultiKeyOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: SelectColumnIsNotNull(col 0:int), SelectColumnIsNotNull(col 1:string))
                    predicate: (key is not null and value is not null) (type: boolean)
                    Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int, col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: string)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkMultiKeyOperator
                              keyColumnNums: [0, 1]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 2068 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: zz
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:int, KEY.reducesinkkey1:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select * from t3_n35 a left semi join t1_n148 b on a.key = b.key and a.value=b.value sort by a.key, a.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
10	val_10
2	val_2
4	val_4
5	val_5
5	val_5
5	val_5
8	val_8
9	val_9
PREHOOK: query: explain vectorization detail
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                           Left Semi Join 0 to 2
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                        2 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: One MapJoin Condition IS false
                      outputColumnNames: _col0
                      input vertices:
                        1 Map 3
                        2 Map 4
                      Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 46 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key left semi join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Map Join Operator
                    condition map:
                         Left Outer Join 0 to 1
                         Left Semi Join 1 to 2
                    keys:
                      0 key (type: int)
                      1 key (type: int)
                      2 _col0 (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 0:int
                        bigTableValueExpressions: col 0:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: One MapJoin Condition IS false
                    outputColumnNames: _col0
                    input vertices:
                      1 Map 3
                      2 Map 4
                    Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: []
                      Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left outer join t1_n148 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Outer Join 0 to 1
                     Left Semi Join 1 to 2
                keys:
                  0 key (type: int)
                  1 key (type: int)
                  2 _col0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t1_n148 a full outer join t3_n35 b on a.key = b.key left semi join t2_n87 c on b.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Left Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Right Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key right outer join t1_n148 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
4
4
8
8
NULL
NULL
NULL
NULL
NULL
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 22 Data size: 88 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: key (type: int)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0]
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      Group By Vectorization:
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 0:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: []
                      keys: _col0 (type: int)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumnNums: [0]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumnNums: [0]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Semi Join 0 to 1
                     Outer Join 0 to 2
                keys:
                  0 key (type: int)
                  1 _col0 (type: int)
                  2 key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 48 Data size: 193 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t1_n148 b on a.key = b.key full outer join t2_n87 c on a.key = c.key sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
10
10
2
4
4
5
5
5
8
8
9
NULL
NULL
NULL
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 3 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 21 Data size: 3948 Basic stats: COMPLETE Column stats: NONE
                    Map Join Operator
                      condition map:
                           Left Semi Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 _col0 (type: int)
                      Map Join Vectorization:
                          bigTableKeyColumnNums: [0]
                          bigTableRetainedColumnNums: [0, 1]
                          bigTableValueColumnNums: [0, 1]
                          className: VectorMapJoinLeftSemiLongOperator
                          native: true
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          projectedOutputColumnNums: [0, 1]
                      outputColumnNames: _col0, _col1
                      input vertices:
                        1 Map 3
                      Statistics: Num rows: 23 Data size: 4342 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Left Outer Join 0 to 1
                        keys:
                          0 _col1 (type: string)
                          1 value (type: string)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [1]
                            bigTableRetainedColumnNums: [0]
                            bigTableValueColumnNums: [0]
                            className: VectorMapJoinOuterStringOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0]
                        outputColumnNames: _col0
                        input vertices:
                          1 Map 4
                        Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkObjectHashOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkLongOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 44 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: value (type: string)
                    sort order: +
                    Map-reduce partition columns: value (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkStringOperator
                        keyColumnNums: [1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumnNums: []
                    Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: z
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    dataColumns: KEY.reducesinkkey0:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0]
                Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 25 Data size: 4776 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1_n148
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.key = b.key left outer join t1_n148 c on a.value = c.value sort by a.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1_n148
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10
10
10
10
10
10
10
10
10
10
16
18
20
4
4
8
8
PREHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 22 Data size: 4136 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColGreaterLongScalar(col 0:int, val 100), SelectColumnIsNotNull(col 1:string))
                    predicate: ((key > 100) and value is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Left Semi Join 0 to 1
                        keys:
                          0 _col1 (type: string)
                          1 _col0 (type: string)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [1]
                            bigTableRetainedColumnNums: [0]
                            bigTableValueColumnNums: [0]
                            className: VectorMapJoinLeftSemiStringOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0]
                        outputColumnNames: _col0
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 12 Data size: 2226 Basic stats: COMPLETE Column stats: NONE
                        File Output Operator
                          compressed: false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
                          Statistics: Num rows: 12 Data size: 2226 Basic stats: COMPLETE Column stats: NONE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 1:string)
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: value (type: string)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [1]
                      Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 1:string
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: string)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: string)
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkStringOperator
                              keyColumnNums: [0]
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                              valueColumnNums: []
                          Statistics: Num rows: 11 Data size: 2024 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [1]
                    dataColumns: key:int, value:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
PREHOOK: type: QUERY
PREHOOK: Input: default@t2_n87
PREHOOK: Input: default@t3_n35
#### A masked pattern was here ####
POSTHOOK: query: select a.key from t3_n35 a left semi join t2_n87 b on a.value = b.value where a.key > 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t2_n87
POSTHOOK: Input: default@t3_n35
#### A masked pattern was here ####
