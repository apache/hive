PREHOOK: query: drop table if exists vector_interval_1
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists vector_interval_1
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table vector_interval_1 (ts timestamp, dt date, str1 string, str2 string) stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@vector_interval_1
POSTHOOK: query: create table vector_interval_1 (ts timestamp, dt date, str1 string, str2 string) stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@vector_interval_1
PREHOOK: query: insert into vector_interval_1
  select timestamp '2001-01-01 01:02:03', date '2001-01-01', '1-2', '1 2:3:4' from src limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@vector_interval_1
POSTHOOK: query: insert into vector_interval_1
  select timestamp '2001-01-01 01:02:03', date '2001-01-01', '1-2', '1 2:3:4' from src limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@vector_interval_1
POSTHOOK: Lineage: vector_interval_1.dt SIMPLE []
POSTHOOK: Lineage: vector_interval_1.str1 SIMPLE []
POSTHOOK: Lineage: vector_interval_1.str2 SIMPLE []
POSTHOOK: Lineage: vector_interval_1.ts SIMPLE []
_c0	_c1	_c2	_c3
PREHOOK: query: insert into vector_interval_1
  select null, null, null, null from src limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@vector_interval_1
POSTHOOK: query: insert into vector_interval_1
  select null, null, null, null from src limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@vector_interval_1
POSTHOOK: Lineage: vector_interval_1.dt EXPRESSION []
POSTHOOK: Lineage: vector_interval_1.str1 EXPRESSION []
POSTHOOK: Lineage: vector_interval_1.str2 EXPRESSION []
POSTHOOK: Lineage: vector_interval_1.ts EXPRESSION []
_col0	_col1	_col2	_col3
PREHOOK: query: select * from vector_interval_1
PREHOOK: type: QUERY
PREHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
POSTHOOK: query: select * from vector_interval_1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
vector_interval_1.ts	vector_interval_1.dt	vector_interval_1.str1	vector_interval_1.str2
2001-01-01 01:02:03	2001-01-01	1-2	1 2:3:4
NULL	NULL	NULL	NULL
PREHOOK: query: explain vectorization expression
select
  str1,
  interval '1-2' year to month, interval_year_month(str1),
  interval '1 2:3:4' day to second, interval_day_time(str2)
from vector_interval_1 order by str1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
select
  str1,
  interval '1-2' year to month, interval_year_month(str1),
  interval '1 2:3:4' day to second, interval_day_time(str2)
from vector_interval_1 order by str1
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: vector_interval_1
                  Statistics: Num rows: 2 Data size: 736 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Select Operator
                    expressions: str1 (type: string), CAST( str1 AS INTERVAL YEAR TO MONTH) (type: interval_year_month), CAST( str2 AS INTERVAL DAY TO SECOND) (type: interval_day_time)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [2, 5, 6]
                        selectExpressions: CastStringToIntervalYearMonth(col 2:string) -> 5:interval_year_month, CastStringToIntervalDayTime(col 3:string) -> 6:interval_day_time
                    Statistics: Num rows: 2 Data size: 736 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 2 Data size: 736 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: interval_year_month), _col2 (type: interval_day_time)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), INTERVAL'1-2' (type: interval_year_month), VALUE._col0 (type: interval_year_month), INTERVAL'1 02:03:04.000000000' (type: interval_day_time), VALUE._col1 (type: interval_day_time)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 3, 1, 4, 2]
                    selectExpressions: ConstantVectorExpression(val 14) -> 3:interval_year_month, ConstantVectorExpression(val 1 02:03:04.000000000) -> 4:interval_day_time
                Statistics: Num rows: 2 Data size: 736 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 2 Data size: 736 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  str1,
  interval '1-2' year to month, interval_year_month(str1),
  interval '1 2:3:4' day to second, interval_day_time(str2)
from vector_interval_1 order by str1
PREHOOK: type: QUERY
PREHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
POSTHOOK: query: select
  str1,
  interval '1-2' year to month, interval_year_month(str1),
  interval '1 2:3:4' day to second, interval_day_time(str2)
from vector_interval_1 order by str1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
str1	_c1	_c2	_c3	_c4
NULL	1-2	NULL	1 02:03:04.000000000	NULL
1-2	1-2	1-2	1 02:03:04.000000000	1 02:03:04.000000000
PREHOOK: query: explain vectorization expression
select
  dt,
  interval '1-2' year to month + interval '1-2' year to month,
  interval_year_month(str1) + interval_year_month(str1),
  interval '1-2' year to month + interval_year_month(str1),
  interval '1-2' year to month - interval '1-2' year to month,
  interval_year_month(str1) - interval_year_month(str1),
  interval '1-2' year to month - interval_year_month(str1)
from vector_interval_1 order by dt
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
select
  dt,
  interval '1-2' year to month + interval '1-2' year to month,
  interval_year_month(str1) + interval_year_month(str1),
  interval '1-2' year to month + interval_year_month(str1),
  interval '1-2' year to month - interval '1-2' year to month,
  interval_year_month(str1) - interval_year_month(str1),
  interval '1-2' year to month - interval_year_month(str1)
from vector_interval_1 order by dt
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: vector_interval_1
                  Statistics: Num rows: 2 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Select Operator
                    expressions: dt (type: date), (CAST( str1 AS INTERVAL YEAR TO MONTH) + CAST( str1 AS INTERVAL YEAR TO MONTH)) (type: interval_year_month), (INTERVAL'1-2' + CAST( str1 AS INTERVAL YEAR TO MONTH)) (type: interval_year_month), (CAST( str1 AS INTERVAL YEAR TO MONTH) - CAST( str1 AS INTERVAL YEAR TO MONTH)) (type: interval_year_month), (INTERVAL'1-2' - CAST( str1 AS INTERVAL YEAR TO MONTH)) (type: interval_year_month)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [1, 7, 6, 9, 8]
                        selectExpressions: IntervalYearMonthColAddIntervalYearMonthColumn(col 5:interval_year_month, col 6:interval_year_month)(children: CastStringToIntervalYearMonth(col 2:string) -> 5:interval_year_month, CastStringToIntervalYearMonth(col 2:string) -> 6:interval_year_month) -> 7:interval_year_month, IntervalYearMonthScalarAddIntervalYearMonthColumn(val 14, col 5:interval_year_month)(children: CastStringToIntervalYearMonth(col 2:string) -> 5:interval_year_month) -> 6:interval_year_month, IntervalYearMonthColSubtractIntervalYearMonthColumn(col 5:interval_year_month, col 8:interval_year_month)(children: CastStringToIntervalYearMonth(col 2:string) -> 5:interval_year_month, CastStringToIntervalYearMonth(col 2:string) -> 8:interval_year_month) -> 9:interval_year_month, IntervalYearMonthScalarSubtractIntervalYearMonthColumn(val 14, col 5:interval_year_month)(children: CastStringToIntervalYearMonth(col 2:string) -> 5:interval_year_month) -> 8:interval_year_month
                    Statistics: Num rows: 2 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: date)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 2 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: interval_year_month), _col2 (type: interval_year_month), _col3 (type: interval_year_month), _col4 (type: interval_year_month)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: date), INTERVAL'2-4' (type: interval_year_month), VALUE._col0 (type: interval_year_month), VALUE._col1 (type: interval_year_month), INTERVAL'0-0' (type: interval_year_month), VALUE._col2 (type: interval_year_month), VALUE._col3 (type: interval_year_month)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 5, 1, 2, 6, 3, 4]
                    selectExpressions: ConstantVectorExpression(val 28) -> 5:interval_year_month, ConstantVectorExpression(val 0) -> 6:interval_year_month
                Statistics: Num rows: 2 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 2 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  dt,
  interval '1-2' year to month + interval '1-2' year to month,
  interval_year_month(str1) + interval_year_month(str1),
  interval '1-2' year to month + interval_year_month(str1),
  interval '1-2' year to month - interval '1-2' year to month,
  interval_year_month(str1) - interval_year_month(str1),
  interval '1-2' year to month - interval_year_month(str1)
from vector_interval_1 order by dt
PREHOOK: type: QUERY
PREHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
POSTHOOK: query: select
  dt,
  interval '1-2' year to month + interval '1-2' year to month,
  interval_year_month(str1) + interval_year_month(str1),
  interval '1-2' year to month + interval_year_month(str1),
  interval '1-2' year to month - interval '1-2' year to month,
  interval_year_month(str1) - interval_year_month(str1),
  interval '1-2' year to month - interval_year_month(str1)
from vector_interval_1 order by dt
POSTHOOK: type: QUERY
POSTHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
dt	_c1	_c2	_c3	_c4	_c5	_c6
NULL	2-4	NULL	NULL	0-0	NULL	NULL
2001-01-01	2-4	2-4	2-4	0-0	0-0	0-0
PREHOOK: query: explain vectorization expression
select
  dt,
  interval '1 2:3:4' day to second + interval '1 2:3:4' day to second,
  interval_day_time(str2) + interval_day_time(str2),
  interval '1 2:3:4' day to second + interval_day_time(str2),
  interval '1 2:3:4' day to second - interval '1 2:3:4' day to second,
  interval_day_time(str2) - interval_day_time(str2),
  interval '1 2:3:4' day to second - interval_day_time(str2)
from vector_interval_1 order by dt
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
select
  dt,
  interval '1 2:3:4' day to second + interval '1 2:3:4' day to second,
  interval_day_time(str2) + interval_day_time(str2),
  interval '1 2:3:4' day to second + interval_day_time(str2),
  interval '1 2:3:4' day to second - interval '1 2:3:4' day to second,
  interval_day_time(str2) - interval_day_time(str2),
  interval '1 2:3:4' day to second - interval_day_time(str2)
from vector_interval_1 order by dt
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: vector_interval_1
                  Statistics: Num rows: 2 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Select Operator
                    expressions: dt (type: date), (CAST( str2 AS INTERVAL DAY TO SECOND) + CAST( str2 AS INTERVAL DAY TO SECOND)) (type: interval_day_time), (INTERVAL'1 02:03:04.000000000' + CAST( str2 AS INTERVAL DAY TO SECOND)) (type: interval_day_time), (CAST( str2 AS INTERVAL DAY TO SECOND) - CAST( str2 AS INTERVAL DAY TO SECOND)) (type: interval_day_time), (INTERVAL'1 02:03:04.000000000' - CAST( str2 AS INTERVAL DAY TO SECOND)) (type: interval_day_time)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [1, 7, 6, 9, 8]
                        selectExpressions: IntervalDayTimeColAddIntervalDayTimeColumn(col 5:interval_day_time, col 6:interval_day_time)(children: CastStringToIntervalDayTime(col 3:string) -> 5:interval_day_time, CastStringToIntervalDayTime(col 3:string) -> 6:interval_day_time) -> 7:interval_day_time, IntervalDayTimeScalarAddIntervalDayTimeColumn(val 1 02:03:04.000000000, col 5:interval_day_time)(children: CastStringToIntervalDayTime(col 3:string) -> 5:interval_day_time) -> 6:interval_day_time, IntervalDayTimeColSubtractIntervalDayTimeColumn(col 5:interval_day_time, col 8:interval_day_time)(children: CastStringToIntervalDayTime(col 3:string) -> 5:interval_day_time, CastStringToIntervalDayTime(col 3:string) -> 8:interval_day_time) -> 9:interval_day_time, IntervalDayTimeScalarSubtractIntervalDayTimeColumn(val 1 02:03:04.000000000, col 5:interval_day_time)(children: CastStringToIntervalDayTime(col 3:string) -> 5:interval_day_time) -> 8:interval_day_time
                    Statistics: Num rows: 2 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: date)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 2 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: interval_day_time), _col2 (type: interval_day_time), _col3 (type: interval_day_time), _col4 (type: interval_day_time)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: date), INTERVAL'2 04:06:08.000000000' (type: interval_day_time), VALUE._col0 (type: interval_day_time), VALUE._col1 (type: interval_day_time), INTERVAL'0 00:00:00.000000000' (type: interval_day_time), VALUE._col2 (type: interval_day_time), VALUE._col3 (type: interval_day_time)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 5, 1, 2, 6, 3, 4]
                    selectExpressions: ConstantVectorExpression(val 2 04:06:08.000000000) -> 5:interval_day_time, ConstantVectorExpression(val 0 00:00:00.000000000) -> 6:interval_day_time
                Statistics: Num rows: 2 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 2 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  dt,
  interval '1 2:3:4' day to second + interval '1 2:3:4' day to second,
  interval_day_time(str2) + interval_day_time(str2),
  interval '1 2:3:4' day to second + interval_day_time(str2),
  interval '1 2:3:4' day to second - interval '1 2:3:4' day to second,
  interval_day_time(str2) - interval_day_time(str2),
  interval '1 2:3:4' day to second - interval_day_time(str2)
from vector_interval_1 order by dt
PREHOOK: type: QUERY
PREHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
POSTHOOK: query: select
  dt,
  interval '1 2:3:4' day to second + interval '1 2:3:4' day to second,
  interval_day_time(str2) + interval_day_time(str2),
  interval '1 2:3:4' day to second + interval_day_time(str2),
  interval '1 2:3:4' day to second - interval '1 2:3:4' day to second,
  interval_day_time(str2) - interval_day_time(str2),
  interval '1 2:3:4' day to second - interval_day_time(str2)
from vector_interval_1 order by dt
POSTHOOK: type: QUERY
POSTHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
dt	_c1	_c2	_c3	_c4	_c5	_c6
NULL	2 04:06:08.000000000	NULL	NULL	0 00:00:00.000000000	NULL	NULL
2001-01-01	2 04:06:08.000000000	2 04:06:08.000000000	2 04:06:08.000000000	0 00:00:00.000000000	0 00:00:00.000000000	0 00:00:00.000000000
PREHOOK: query: explain vectorization expression
select
  dt,
  dt + interval '1-2' year to month,
  dt + interval_year_month(str1),
  interval '1-2' year to month + dt,
  interval_year_month(str1) + dt,
  dt - interval '1-2' year to month,
  dt - interval_year_month(str1),
  dt + interval '1 2:3:4' day to second,
  dt + interval_day_time(str2),
  interval '1 2:3:4' day to second + dt,
  interval_day_time(str2) + dt,
  dt - interval '1 2:3:4' day to second,
  dt - interval_day_time(str2)
from vector_interval_1 order by dt
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
select
  dt,
  dt + interval '1-2' year to month,
  dt + interval_year_month(str1),
  interval '1-2' year to month + dt,
  interval_year_month(str1) + dt,
  dt - interval '1-2' year to month,
  dt - interval_year_month(str1),
  dt + interval '1 2:3:4' day to second,
  dt + interval_day_time(str2),
  interval '1 2:3:4' day to second + dt,
  interval_day_time(str2) + dt,
  dt - interval '1 2:3:4' day to second,
  dt - interval_day_time(str2)
from vector_interval_1 order by dt
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: vector_interval_1
                  Statistics: Num rows: 2 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Select Operator
                    expressions: dt (type: date), (dt + INTERVAL'1-2') (type: date), (dt + CAST( str1 AS INTERVAL YEAR TO MONTH)) (type: date), (INTERVAL'1-2' + dt) (type: date), (CAST( str1 AS INTERVAL YEAR TO MONTH) + dt) (type: date), (dt - INTERVAL'1-2') (type: date), (dt - CAST( str1 AS INTERVAL YEAR TO MONTH)) (type: date), (dt + INTERVAL'1 02:03:04.000000000') (type: timestamp), (dt + CAST( str2 AS INTERVAL DAY TO SECOND)) (type: timestamp), (INTERVAL'1 02:03:04.000000000' + dt) (type: timestamp), (CAST( str2 AS INTERVAL DAY TO SECOND) + dt) (type: timestamp), (dt - INTERVAL'1 02:03:04.000000000') (type: timestamp), (dt - CAST( str2 AS INTERVAL DAY TO SECOND)) (type: timestamp)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [1, 5, 7, 6, 9, 8, 11, 12, 14, 15, 16, 17, 18]
                        selectExpressions: DateColAddIntervalYearMonthScalar(col 1:date, val 1-2) -> 5:date, DateColAddIntervalYearMonthColumn(col 1:date, col 6:interval_year_month)(children: CastStringToIntervalYearMonth(col 2:string) -> 6:interval_year_month) -> 7:date, IntervalYearMonthScalarAddDateColumn(val 1-2, col 1:interval_year_month) -> 6:date, IntervalYearMonthColAddDateColumn(col 8:interval_year_month, col 1:date)(children: CastStringToIntervalYearMonth(col 2:string) -> 8:interval_year_month) -> 9:date, DateColSubtractIntervalYearMonthScalar(col 1:date, val 1-2) -> 8:date, DateColSubtractIntervalYearMonthColumn(col 1:date, col 10:interval_year_month)(children: CastStringToIntervalYearMonth(col 2:string) -> 10:interval_year_month) -> 11:date, DateColAddIntervalDayTimeScalar(col 1:date, val 1 02:03:04.000000000) -> 12:timestamp, DateColAddIntervalDayTimeColumn(col 1:date, col 13:interval_day_time)(children: CastStringToIntervalDayTime(col 3:string) -> 13:interval_day_time) -> 14:timestamp, IntervalDayTimeScalarAddDateColumn(val 1 02:03:04.000000000, col 1:date) -> 15:timestamp, IntervalDayTimeColAddDateColumn(col 13:interval_day_time, col 1:date)(children: CastStringToIntervalDayTime(col 3:string) -> 13:interval_day_time) -> 16:timestamp, DateColSubtractIntervalDayTimeScalar(col 1:date, val 1 02:03:04.000000000) -> 17:timestamp, DateColSubtractIntervalDayTimeColumn(col 1:date, col 13:interval_day_time)(children: CastStringToIntervalDayTime(col 3:string) -> 13:interval_day_time) -> 18:timestamp
                    Statistics: Num rows: 2 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: date)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 2 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: date), _col2 (type: date), _col3 (type: date), _col4 (type: date), _col5 (type: date), _col6 (type: date), _col7 (type: timestamp), _col8 (type: timestamp), _col9 (type: timestamp), _col10 (type: timestamp), _col11 (type: timestamp), _col12 (type: timestamp)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: date), VALUE._col0 (type: date), VALUE._col1 (type: date), VALUE._col2 (type: date), VALUE._col3 (type: date), VALUE._col4 (type: date), VALUE._col5 (type: date), VALUE._col6 (type: timestamp), VALUE._col7 (type: timestamp), VALUE._col8 (type: timestamp), VALUE._col9 (type: timestamp), VALUE._col10 (type: timestamp), VALUE._col11 (type: timestamp)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
                Statistics: Num rows: 2 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 2 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  dt,
  dt + interval '1-2' year to month,
  dt + interval_year_month(str1),
  interval '1-2' year to month + dt,
  interval_year_month(str1) + dt,
  dt - interval '1-2' year to month,
  dt - interval_year_month(str1),
  dt + interval '1 2:3:4' day to second,
  dt + interval_day_time(str2),
  interval '1 2:3:4' day to second + dt,
  interval_day_time(str2) + dt,
  dt - interval '1 2:3:4' day to second,
  dt - interval_day_time(str2)
from vector_interval_1 order by dt
PREHOOK: type: QUERY
PREHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
POSTHOOK: query: select
  dt,
  dt + interval '1-2' year to month,
  dt + interval_year_month(str1),
  interval '1-2' year to month + dt,
  interval_year_month(str1) + dt,
  dt - interval '1-2' year to month,
  dt - interval_year_month(str1),
  dt + interval '1 2:3:4' day to second,
  dt + interval_day_time(str2),
  interval '1 2:3:4' day to second + dt,
  interval_day_time(str2) + dt,
  dt - interval '1 2:3:4' day to second,
  dt - interval_day_time(str2)
from vector_interval_1 order by dt
POSTHOOK: type: QUERY
POSTHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
dt	_c1	_c2	_c3	_c4	_c5	_c6	_c7	_c8	_c9	_c10	_c11	_c12
NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL
2001-01-01	2002-03-01	2002-03-01	2002-03-01	2002-03-01	1999-11-01	1999-11-01	2001-01-02 02:03:04	2001-01-02 02:03:04	2001-01-02 02:03:04	2001-01-02 02:03:04	2000-12-30 21:56:56	2000-12-30 21:56:56
PREHOOK: query: explain vectorization expression
select
  ts,
  ts + interval '1-2' year to month,
  ts + interval_year_month(str1),
  interval '1-2' year to month + ts,
  interval_year_month(str1) + ts,
  ts - interval '1-2' year to month,
  ts - interval_year_month(str1),
  ts + interval '1 2:3:4' day to second,
  ts + interval_day_time(str2),
  interval '1 2:3:4' day to second + ts,
  interval_day_time(str2) + ts,
  ts - interval '1 2:3:4' day to second,
  ts - interval_day_time(str2)
from vector_interval_1 order by ts
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
select
  ts,
  ts + interval '1-2' year to month,
  ts + interval_year_month(str1),
  interval '1-2' year to month + ts,
  interval_year_month(str1) + ts,
  ts - interval '1-2' year to month,
  ts - interval_year_month(str1),
  ts + interval '1 2:3:4' day to second,
  ts + interval_day_time(str2),
  interval '1 2:3:4' day to second + ts,
  interval_day_time(str2) + ts,
  ts - interval '1 2:3:4' day to second,
  ts - interval_day_time(str2)
from vector_interval_1 order by ts
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: vector_interval_1
                  Statistics: Num rows: 2 Data size: 816 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Select Operator
                    expressions: ts (type: timestamp), (ts + INTERVAL'1-2') (type: timestamp), (ts + CAST( str1 AS INTERVAL YEAR TO MONTH)) (type: timestamp), (INTERVAL'1-2' + ts) (type: timestamp), (CAST( str1 AS INTERVAL YEAR TO MONTH) + ts) (type: timestamp), (ts - INTERVAL'1-2') (type: timestamp), (ts - CAST( str1 AS INTERVAL YEAR TO MONTH)) (type: timestamp), (ts + INTERVAL'1 02:03:04.000000000') (type: timestamp), (ts + CAST( str2 AS INTERVAL DAY TO SECOND)) (type: timestamp), (INTERVAL'1 02:03:04.000000000' + ts) (type: timestamp), (CAST( str2 AS INTERVAL DAY TO SECOND) + ts) (type: timestamp), (ts - INTERVAL'1 02:03:04.000000000') (type: timestamp), (ts - CAST( str2 AS INTERVAL DAY TO SECOND)) (type: timestamp)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18]
                        selectExpressions: TimestampColAddIntervalYearMonthScalar(col 0:timestamp, val 1-2) -> 5:timestamp, TimestampColAddIntervalYearMonthColumn(col 0:timestamp, col 6:interval_year_month)(children: CastStringToIntervalYearMonth(col 2:string) -> 6:interval_year_month) -> 7:timestamp, IntervalYearMonthScalarAddTimestampColumn(val 1-2, col 0:interval_year_month) -> 8:timestamp, IntervalYearMonthColAddTimestampColumn(col 6:interval_year_month, col 0:timestamp)(children: CastStringToIntervalYearMonth(col 2:string) -> 6:interval_year_month) -> 9:timestamp, TimestampColSubtractIntervalYearMonthScalar(col 0:timestamp, val 1-2) -> 10:timestamp, TimestampColSubtractIntervalYearMonthColumn(col 0:timestamp, col 6:interval_year_month)(children: CastStringToIntervalYearMonth(col 2:string) -> 6:interval_year_month) -> 11:timestamp, TimestampColAddIntervalDayTimeScalar(col 0:timestamp, val 1 02:03:04.000000000) -> 12:timestamp, TimestampColAddIntervalDayTimeColumn(col 0:timestamp, col 13:interval_day_time)(children: CastStringToIntervalDayTime(col 3:string) -> 13:interval_day_time) -> 14:timestamp, IntervalDayTimeScalarAddTimestampColumn(val 1 02:03:04.000000000, col 0:timestamp) -> 15:timestamp, IntervalDayTimeColAddTimestampColumn(col 13:interval_day_time, col 0:timestamp)(children: CastStringToIntervalDayTime(col 3:string) -> 13:interval_day_time) -> 16:timestamp, TimestampColSubtractIntervalDayTimeScalar(col 0:timestamp, val 1 02:03:04.000000000) -> 17:timestamp, TimestampColSubtractIntervalDayTimeColumn(col 0:timestamp, col 13:interval_day_time)(children: CastStringToIntervalDayTime(col 3:string) -> 13:interval_day_time) -> 18:timestamp
                    Statistics: Num rows: 2 Data size: 816 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: timestamp)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 2 Data size: 816 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: timestamp), _col2 (type: timestamp), _col3 (type: timestamp), _col4 (type: timestamp), _col5 (type: timestamp), _col6 (type: timestamp), _col7 (type: timestamp), _col8 (type: timestamp), _col9 (type: timestamp), _col10 (type: timestamp), _col11 (type: timestamp), _col12 (type: timestamp)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: timestamp), VALUE._col0 (type: timestamp), VALUE._col1 (type: timestamp), VALUE._col2 (type: timestamp), VALUE._col3 (type: timestamp), VALUE._col4 (type: timestamp), VALUE._col5 (type: timestamp), VALUE._col6 (type: timestamp), VALUE._col7 (type: timestamp), VALUE._col8 (type: timestamp), VALUE._col9 (type: timestamp), VALUE._col10 (type: timestamp), VALUE._col11 (type: timestamp)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
                Statistics: Num rows: 2 Data size: 816 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 2 Data size: 816 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  ts,
  ts + interval '1-2' year to month,
  ts + interval_year_month(str1),
  interval '1-2' year to month + ts,
  interval_year_month(str1) + ts,
  ts - interval '1-2' year to month,
  ts - interval_year_month(str1),
  ts + interval '1 2:3:4' day to second,
  ts + interval_day_time(str2),
  interval '1 2:3:4' day to second + ts,
  interval_day_time(str2) + ts,
  ts - interval '1 2:3:4' day to second,
  ts - interval_day_time(str2)
from vector_interval_1 order by ts
PREHOOK: type: QUERY
PREHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
POSTHOOK: query: select
  ts,
  ts + interval '1-2' year to month,
  ts + interval_year_month(str1),
  interval '1-2' year to month + ts,
  interval_year_month(str1) + ts,
  ts - interval '1-2' year to month,
  ts - interval_year_month(str1),
  ts + interval '1 2:3:4' day to second,
  ts + interval_day_time(str2),
  interval '1 2:3:4' day to second + ts,
  interval_day_time(str2) + ts,
  ts - interval '1 2:3:4' day to second,
  ts - interval_day_time(str2)
from vector_interval_1 order by ts
POSTHOOK: type: QUERY
POSTHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
ts	_c1	_c2	_c3	_c4	_c5	_c6	_c7	_c8	_c9	_c10	_c11	_c12
NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL
2001-01-01 01:02:03	2002-03-01 01:02:03	2002-03-01 01:02:03	2002-03-01 01:02:03	2002-03-01 01:02:03	1999-11-01 01:02:03	1999-11-01 01:02:03	2001-01-02 03:05:07	2001-01-02 03:05:07	2001-01-02 03:05:07	2001-01-02 03:05:07	2000-12-30 22:58:59	2000-12-30 22:58:59
PREHOOK: query: explain vectorization expression
select
  ts,
  ts - ts,
  timestamp '2001-01-01 01:02:03' - ts,
  ts - timestamp '2001-01-01 01:02:03'
from vector_interval_1 order by ts
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
select
  ts,
  ts - ts,
  timestamp '2001-01-01 01:02:03' - ts,
  ts - timestamp '2001-01-01 01:02:03'
from vector_interval_1 order by ts
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: vector_interval_1
                  Statistics: Num rows: 2 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Select Operator
                    expressions: ts (type: timestamp), (ts - ts) (type: interval_day_time), (TIMESTAMP'2001-01-01 01:02:03' - ts) (type: interval_day_time), (ts - TIMESTAMP'2001-01-01 01:02:03') (type: interval_day_time)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 5, 6, 7]
                        selectExpressions: TimestampColSubtractTimestampColumn(col 0:timestamp, col 0:timestamp) -> 5:interval_day_time, TimestampScalarSubtractTimestampColumn(val 2001-01-01 01:02:03, col 0:timestamp) -> 6:interval_day_time, TimestampColSubtractTimestampScalar(col 0:timestamp, val 2001-01-01 01:02:03) -> 7:interval_day_time
                    Statistics: Num rows: 2 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: timestamp)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 2 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: interval_day_time), _col2 (type: interval_day_time), _col3 (type: interval_day_time)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: timestamp), VALUE._col0 (type: interval_day_time), VALUE._col1 (type: interval_day_time), VALUE._col2 (type: interval_day_time)
                outputColumnNames: _col0, _col1, _col2, _col3
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3]
                Statistics: Num rows: 2 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 2 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  ts,
  ts - ts,
  timestamp '2001-01-01 01:02:03' - ts,
  ts - timestamp '2001-01-01 01:02:03'
from vector_interval_1 order by ts
PREHOOK: type: QUERY
PREHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
POSTHOOK: query: select
  ts,
  ts - ts,
  timestamp '2001-01-01 01:02:03' - ts,
  ts - timestamp '2001-01-01 01:02:03'
from vector_interval_1 order by ts
POSTHOOK: type: QUERY
POSTHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
ts	_c1	_c2	_c3
NULL	NULL	NULL	NULL
2001-01-01 01:02:03	0 00:00:00.000000000	0 00:00:00.000000000	0 00:00:00.000000000
PREHOOK: query: explain vectorization expression
select
  dt,
  dt - dt,
  date '2001-01-01' - dt,
  dt - date '2001-01-01'
from vector_interval_1 order by dt
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
select
  dt,
  dt - dt,
  date '2001-01-01' - dt,
  dt - date '2001-01-01'
from vector_interval_1 order by dt
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: vector_interval_1
                  Statistics: Num rows: 2 Data size: 112 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Select Operator
                    expressions: dt (type: date), (dt - dt) (type: interval_day_time), (DATE'2001-01-01' - dt) (type: interval_day_time), (dt - DATE'2001-01-01') (type: interval_day_time)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [1, 5, 6, 7]
                        selectExpressions: DateColSubtractDateColumn(col 1:date, col 1:date) -> 5:interval_day_time, DateScalarSubtractDateColumn(val 2001-01-01, col 1:date) -> 6:interval_day_time, DateColSubtractDateScalar(col 1:date, val 2001-01-01) -> 7:interval_day_time
                    Statistics: Num rows: 2 Data size: 112 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: date)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 2 Data size: 112 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: interval_day_time), _col2 (type: interval_day_time), _col3 (type: interval_day_time)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: date), VALUE._col0 (type: interval_day_time), VALUE._col1 (type: interval_day_time), VALUE._col2 (type: interval_day_time)
                outputColumnNames: _col0, _col1, _col2, _col3
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3]
                Statistics: Num rows: 2 Data size: 112 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 2 Data size: 112 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  dt,
  dt - dt,
  date '2001-01-01' - dt,
  dt - date '2001-01-01'
from vector_interval_1 order by dt
PREHOOK: type: QUERY
PREHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
POSTHOOK: query: select
  dt,
  dt - dt,
  date '2001-01-01' - dt,
  dt - date '2001-01-01'
from vector_interval_1 order by dt
POSTHOOK: type: QUERY
POSTHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
dt	_c1	_c2	_c3
NULL	NULL	NULL	NULL
2001-01-01	0 00:00:00.000000000	0 00:00:00.000000000	0 00:00:00.000000000
PREHOOK: query: explain vectorization expression
select
  dt,
  ts - dt,
  timestamp '2001-01-01 01:02:03' - dt,
  ts - date '2001-01-01',
  dt - ts,
  dt - timestamp '2001-01-01 01:02:03',
  date '2001-01-01' - ts
from vector_interval_1 order by dt
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
select
  dt,
  ts - dt,
  timestamp '2001-01-01 01:02:03' - dt,
  ts - date '2001-01-01',
  dt - ts,
  dt - timestamp '2001-01-01 01:02:03',
  date '2001-01-01' - ts
from vector_interval_1 order by dt
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: vector_interval_1
                  Statistics: Num rows: 2 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Select Operator
                    expressions: dt (type: date), (ts - dt) (type: interval_day_time), (TIMESTAMP'2001-01-01 01:02:03' - dt) (type: interval_day_time), (ts - DATE'2001-01-01') (type: interval_day_time), (dt - ts) (type: interval_day_time), (dt - TIMESTAMP'2001-01-01 01:02:03') (type: interval_day_time), (DATE'2001-01-01' - ts) (type: interval_day_time)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [1, 5, 6, 7, 8, 9, 10]
                        selectExpressions: TimestampColSubtractDateColumn(col 0:timestamp, col 1:date) -> 5:interval_day_time, TimestampScalarSubtractDateColumn(val 2001-01-01 01:02:03, col 1:date) -> 6:interval_day_time, TimestampColSubtractDateScalar(col 0:timestamp, val 2001-01-01) -> 7:interval_day_time, DateColSubtractTimestampColumn(col 1:date, col 0:timestamp) -> 8:interval_day_time, DateColSubtractTimestampScalar(col 1:date, val 2001-01-01 01:02:03) -> 9:interval_day_time, DateScalarSubtractTimestampColumn(val 2001-01-01, col 0:timestamp) -> 10:interval_day_time
                    Statistics: Num rows: 2 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: date)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 2 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: interval_day_time), _col2 (type: interval_day_time), _col3 (type: interval_day_time), _col4 (type: interval_day_time), _col5 (type: interval_day_time), _col6 (type: interval_day_time)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: date), VALUE._col0 (type: interval_day_time), VALUE._col1 (type: interval_day_time), VALUE._col2 (type: interval_day_time), VALUE._col3 (type: interval_day_time), VALUE._col4 (type: interval_day_time), VALUE._col5 (type: interval_day_time)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3, 4, 5, 6]
                Statistics: Num rows: 2 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 2 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  dt,
  ts - dt,
  timestamp '2001-01-01 01:02:03' - dt,
  ts - date '2001-01-01',
  dt - ts,
  dt - timestamp '2001-01-01 01:02:03',
  date '2001-01-01' - ts
from vector_interval_1 order by dt
PREHOOK: type: QUERY
PREHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
POSTHOOK: query: select
  dt,
  ts - dt,
  timestamp '2001-01-01 01:02:03' - dt,
  ts - date '2001-01-01',
  dt - ts,
  dt - timestamp '2001-01-01 01:02:03',
  date '2001-01-01' - ts
from vector_interval_1 order by dt
POSTHOOK: type: QUERY
POSTHOOK: Input: default@vector_interval_1
#### A masked pattern was here ####
dt	_c1	_c2	_c3	_c4	_c5	_c6
NULL	NULL	NULL	NULL	NULL	NULL	NULL
2001-01-01	0 01:02:03.000000000	0 01:02:03.000000000	0 01:02:03.000000000	-0 01:02:03.000000000	-0 01:02:03.000000000	-0 01:02:03.000000000
