PREHOOK: query: CREATE TABLE myinput1_txt(key int, value int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@myinput1_txt
POSTHOOK: query: CREATE TABLE myinput1_txt(key int, value int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@myinput1_txt
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/in8.txt' INTO TABLE myinput1_txt
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@myinput1_txt
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/in8.txt' INTO TABLE myinput1_txt
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@myinput1_txt
PREHOOK: query: CREATE TABLE myinput1 STORED AS ORC AS SELECT * FROM myinput1_txt
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@myinput1_txt
PREHOOK: Output: database:default
PREHOOK: Output: default@myinput1
POSTHOOK: query: CREATE TABLE myinput1 STORED AS ORC AS SELECT * FROM myinput1_txt
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@myinput1_txt
POSTHOOK: Output: database:default
POSTHOOK: Output: default@myinput1
POSTHOOK: Lineage: myinput1.key SIMPLE [(myinput1_txt)myinput1_txt.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: myinput1.value SIMPLE [(myinput1_txt)myinput1_txt.FieldSchema(name:value, type:int, comment:null), ]
PREHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Map Join Operator
                    condition map:
                         Inner Join 0 to 1
                    keys:
                      0 key (type: int)
                      1 value (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 0:int
                        bigTableValueExpressions: col 0:int, col 1:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                    nullSafes: [true]
                    outputColumnNames: _col0, _col1, _col5, _col6
                    input vertices:
                      1 Map 2
                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1, 2, 3]
                      Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Reduce Output Operator
                    key expressions: value (type: int)
                    null sort order: z
                    sort order: +
                    Map-reduce partition columns: value (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: key (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10
100	100	100	100
NULL	10	10	NULL
NULL	10	48	NULL
NULL	10	NULL	NULL
NULL	35	10	NULL
NULL	35	48	NULL
NULL	35	NULL	NULL
NULL	NULL	10	NULL
NULL	NULL	48	NULL
NULL	NULL	NULL	NULL
PREHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key=c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key=c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE), Reducer 3 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  filterExpr: key is not null (type: boolean)
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 value (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                      nullSafes: [true]
                      outputColumnNames: _col0, _col1, _col5, _col6
                      input vertices:
                        1 Reducer 3
                      Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 key (type: int)
                        Map Join Vectorization:
                            bigTableKeyExpressions: col 0:int
                            bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
                            className: VectorMapJoinOperator
                            native: false
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
                        outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                        Select Operator
                          expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
                          Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  filterExpr: (value is not null or key is not null) (type: boolean)
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 1:int)
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: value (type: int)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: value (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkLongOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: key (type: int)
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkLongOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: value (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), KEY.reducesinkkey0 (type: int)
                outputColumnNames: key, value
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1, 0]
                Reduce Output Operator
                  key expressions: value (type: int)
                  null sort order: z
                  sort order: +
                  Map-reduce partition columns: value (type: int)
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkLongOperator
                      native: true
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                  Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: key (type: int)

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key=c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key=c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10	10	NULL
100	100	100	100	100	100
PREHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key<=>c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key<=>c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE), Reducer 3 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Map Join Operator
                    condition map:
                         Inner Join 0 to 1
                    keys:
                      0 key (type: int)
                      1 value (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 0:int
                        bigTableValueExpressions: col 0:int, col 1:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                    nullSafes: [true]
                    outputColumnNames: _col0, _col1, _col5, _col6
                    input vertices:
                      1 Reducer 3
                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                      keys:
                        0 _col0 (type: int)
                        1 key (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                      nullSafes: [true]
                      outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                      input vertices:
                        1 Map 2
                      Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
                        Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
                          Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Reduce Output Operator
                    key expressions: value (type: int)
                    null sort order: z
                    sort order: +
                    Map-reduce partition columns: value (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: key (type: int)
                  Reduce Output Operator
                    key expressions: key (type: int)
                    null sort order: z
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: value (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), KEY.reducesinkkey0 (type: int)
                outputColumnNames: key, value
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1, 0]
                Reduce Output Operator
                  key expressions: value (type: int)
                  null sort order: z
                  sort order: +
                  Map-reduce partition columns: value (type: int)
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkLongOperator
                      native: true
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: key (type: int)

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key<=>c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key<=>c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10	10	NULL
100	100	100	100	100	100
NULL	10	10	NULL	NULL	10
NULL	10	10	NULL	NULL	35
NULL	10	10	NULL	NULL	NULL
NULL	10	48	NULL	NULL	10
NULL	10	48	NULL	NULL	35
NULL	10	48	NULL	NULL	NULL
NULL	10	NULL	NULL	NULL	10
NULL	10	NULL	NULL	NULL	35
NULL	10	NULL	NULL	NULL	NULL
NULL	35	10	NULL	NULL	10
NULL	35	10	NULL	NULL	35
NULL	35	10	NULL	NULL	NULL
NULL	35	48	NULL	NULL	10
NULL	35	48	NULL	NULL	35
NULL	35	48	NULL	NULL	NULL
NULL	35	NULL	NULL	NULL	10
NULL	35	NULL	NULL	NULL	35
NULL	35	NULL	NULL	NULL	NULL
NULL	NULL	10	NULL	NULL	10
NULL	NULL	10	NULL	NULL	35
NULL	NULL	10	NULL	NULL	NULL
NULL	NULL	48	NULL	NULL	10
NULL	NULL	48	NULL	NULL	35
NULL	NULL	48	NULL	NULL	NULL
NULL	NULL	NULL	NULL	NULL	10
NULL	NULL	NULL	NULL	NULL	35
NULL	NULL	NULL	NULL	NULL	NULL
PREHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value=b.key join myinput1 c on a.key<=>c.key AND a.value=c.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value=b.key join myinput1 c on a.key<=>c.key AND a.value=c.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE), Reducer 3 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  filterExpr: value is not null (type: boolean)
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 1:int)
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                      keys:
                        0 key (type: int), value (type: int)
                        1 value (type: int), key (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int, col 1:int
                          bigTableValueExpressions: col 0:int, col 1:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                      nullSafes: [true, false]
                      outputColumnNames: _col0, _col1, _col5, _col6
                      input vertices:
                        1 Map 2
                      Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int), _col1 (type: int)
                          1 key (type: int), value (type: int)
                        Map Join Vectorization:
                            bigTableKeyExpressions: col 0:int, col 1:int
                            bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
                            className: VectorMapJoinOperator
                            native: false
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                        nullSafes: [true, false]
                        outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                        input vertices:
                          1 Reducer 3
                        Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                        Select Operator
                          expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
                          Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  filterExpr: (key is not null or value is not null) (type: boolean)
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: value (type: int), key (type: int)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: value (type: int), key (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkMultiKeyOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 1:int)
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: key (type: int), value (type: int)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: key (type: int), value (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkMultiKeyOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int)
                outputColumnNames: key, value
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Reduce Output Operator
                  key expressions: key (type: int), value (type: int)
                  null sort order: zz
                  sort order: ++
                  Map-reduce partition columns: key (type: int), value (type: int)
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkMultiKeyOperator
                      native: true
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                  Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value=b.key join myinput1 c on a.key<=>c.key AND a.value=c.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value=b.key join myinput1 c on a.key<=>c.key AND a.value=c.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
100	100	100	100	100	100
NULL	10	10	NULL	NULL	10
PREHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value<=>b.key join myinput1 c on a.key<=>c.key AND a.value<=>c.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value<=>b.key join myinput1 c on a.key<=>c.key AND a.value<=>c.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE), Reducer 3 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Map Join Operator
                    condition map:
                         Inner Join 0 to 1
                    keys:
                      0 key (type: int), value (type: int)
                      1 value (type: int), key (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 0:int, col 1:int
                        bigTableValueExpressions: col 0:int, col 1:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                    nullSafes: [true, true]
                    outputColumnNames: _col0, _col1, _col5, _col6
                    input vertices:
                      1 Reducer 3
                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                      keys:
                        0 _col0 (type: int), _col1 (type: int)
                        1 key (type: int), value (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int, col 1:int
                          bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                      nullSafes: [true, true]
                      outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                      input vertices:
                        1 Map 2
                      Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
                        Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
                          Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Reduce Output Operator
                    key expressions: value (type: int), key (type: int)
                    null sort order: zz
                    sort order: ++
                    Map-reduce partition columns: value (type: int), key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkMultiKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: key (type: int), value (type: int)
                    null sort order: zz
                    sort order: ++
                    Map-reduce partition columns: key (type: int), value (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkMultiKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int)
                outputColumnNames: value, key
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Reduce Output Operator
                  key expressions: value (type: int), key (type: int)
                  null sort order: zz
                  sort order: ++
                  Map-reduce partition columns: value (type: int), key (type: int)
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkMultiKeyOperator
                      native: true
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value<=>b.key join myinput1 c on a.key<=>c.key AND a.value<=>c.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value<=>b.key join myinput1 c on a.key<=>c.key AND a.value<=>c.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10	10	NULL
100	100	100	100	100	100
NULL	10	10	NULL	NULL	10
NULL	NULL	NULL	NULL	NULL	NULL
PREHOOK: query: SELECT * FROM myinput1 a LEFT OUTER JOIN myinput1 b ON a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM myinput1 a LEFT OUTER JOIN myinput1 b ON a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10
100	100	100	100
48	NULL	NULL	NULL
NULL	10	10	NULL
NULL	10	48	NULL
NULL	10	NULL	NULL
NULL	35	10	NULL
NULL	35	48	NULL
NULL	35	NULL	NULL
NULL	NULL	10	NULL
NULL	NULL	48	NULL
NULL	NULL	NULL	NULL
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL DEBUG
SELECT * FROM myinput1 a RIGHT OUTER JOIN myinput1 b ON a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL DEBUG
SELECT * FROM myinput1 a RIGHT OUTER JOIN myinput1 b ON a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:int, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    null sort order: z
                    sort order: +
                    output key column names: KEY.reducesinkkey0
                    output value column names: VALUE._col0
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumns: 0:int
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumns: 1:int
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: value (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:int, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Map Join Operator
                    condition map:
                         Right Outer Join 0 to 1
                    keyContext: [types [int], serde=org.apache.hadoop.hive.serde2.binarysortable.BinarySortableSerDe, hasFilter=false]
                    outer filter mappings: [null, [0, 0]]
                    valueContexts: [0:[types [int], serde=org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe, hasFilter=false]]
                    keyExpressions:
                      0 [Column[key]]
                      1 [Column[value]]
                    keys:
                      0 key (type: int)
                      1 value (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 1:int
                        bigTableValueExpressions: col 0:int, col 1:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                    nullSafes: [true]
                    outputColumnNames: _col0, _col1, _col5, _col6
                    input vertices:
                      0 Map 1
                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1, 2, 3]
                      Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT * FROM myinput1 a FULL OUTER JOIN myinput1 b ON a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM myinput1 a FULL OUTER JOIN myinput1 b ON a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10
100	100	100	100
48	NULL	NULL	NULL
NULL	10	10	NULL
NULL	10	48	NULL
NULL	10	NULL	NULL
NULL	35	10	NULL
NULL	35	48	NULL
NULL	35	NULL	NULL
NULL	NULL	10	NULL
NULL	NULL	48	NULL
NULL	NULL	NULL	35
NULL	NULL	NULL	NULL
PREHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM myinput1 a JOIN myinput1 b ON a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM myinput1 a JOIN myinput1 b ON a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10
100	100	100	100
NULL	10	10	NULL
NULL	10	48	NULL
NULL	10	NULL	NULL
NULL	35	10	NULL
NULL	35	48	NULL
NULL	35	NULL	NULL
NULL	NULL	10	NULL
NULL	NULL	48	NULL
NULL	NULL	NULL	NULL
PREHOOK: query: SELECT /*+ MAPJOIN(b) */ * FROM myinput1 a JOIN myinput1 b ON a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: SELECT /*+ MAPJOIN(b) */ * FROM myinput1 a JOIN myinput1 b ON a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10
100	100	100	100
NULL	10	10	NULL
NULL	10	48	NULL
NULL	10	NULL	NULL
NULL	35	10	NULL
NULL	35	48	NULL
NULL	35	NULL	NULL
NULL	NULL	10	NULL
NULL	NULL	48	NULL
NULL	NULL	NULL	NULL
PREHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Map Join Operator
                    condition map:
                         Inner Join 0 to 1
                    keys:
                      0 key (type: int)
                      1 value (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 0:int
                        bigTableValueExpressions: col 0:int, col 1:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: No nullsafe IS false
                    nullSafes: [true]
                    outputColumnNames: _col0, _col1, _col5, _col6
                    input vertices:
                      1 Map 2
                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1, 2, 3]
                      Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Reduce Output Operator
                    key expressions: value (type: int)
                    null sort order: z
                    sort order: +
                    Map-reduce partition columns: value (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: key (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10
100	100	100	100
NULL	10	10	NULL
NULL	10	48	NULL
NULL	10	NULL	NULL
NULL	35	10	NULL
NULL	35	48	NULL
NULL	35	NULL	NULL
NULL	NULL	10	NULL
NULL	NULL	48	NULL
NULL	NULL	NULL	NULL
PREHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key=c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key=c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE), Reducer 3 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  filterExpr: key is not null (type: boolean)
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                      keys:
                        0 key (type: int)
                        1 value (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: No nullsafe IS false
                      nullSafes: [true]
                      outputColumnNames: _col0, _col1, _col5, _col6
                      input vertices:
                        1 Reducer 3
                      Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 key (type: int)
                        Map Join Vectorization:
                            className: VectorMapJoinInnerLongOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            hashTableImplementationType: OPTIMIZED
                        outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                        Select Operator
                          expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [0, 1, 2, 3, 0, 4]
                          Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  filterExpr: (value is not null or key is not null) (type: boolean)
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 1:int)
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: value (type: int)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: value (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkLongOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: key (type: int)
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkLongOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: value (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), KEY.reducesinkkey0 (type: int)
                outputColumnNames: key, value
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1, 0]
                Reduce Output Operator
                  key expressions: value (type: int)
                  null sort order: z
                  sort order: +
                  Map-reduce partition columns: value (type: int)
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkLongOperator
                      native: true
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                  Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: key (type: int)

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key=c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key=c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10	10	NULL
100	100	100	100	100	100
PREHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key<=>c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key<=>c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE), Reducer 3 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Map Join Operator
                    condition map:
                         Inner Join 0 to 1
                    keys:
                      0 key (type: int)
                      1 value (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 0:int
                        bigTableValueExpressions: col 0:int, col 1:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: No nullsafe IS false
                    nullSafes: [true]
                    outputColumnNames: _col0, _col1, _col5, _col6
                    input vertices:
                      1 Reducer 3
                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                      keys:
                        0 _col0 (type: int)
                        1 key (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int
                          bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: No nullsafe IS false
                      nullSafes: [true]
                      outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                      input vertices:
                        1 Map 2
                      Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
                        Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
                          Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Reduce Output Operator
                    key expressions: value (type: int)
                    null sort order: z
                    sort order: +
                    Map-reduce partition columns: value (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: key (type: int)
                  Reduce Output Operator
                    key expressions: key (type: int)
                    null sort order: z
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: value (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), KEY.reducesinkkey0 (type: int)
                outputColumnNames: key, value
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1, 0]
                Reduce Output Operator
                  key expressions: value (type: int)
                  null sort order: z
                  sort order: +
                  Map-reduce partition columns: value (type: int)
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkLongOperator
                      native: true
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: key (type: int)

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key<=>c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value join myinput1 c on a.key<=>c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10	10	NULL
100	100	100	100	100	100
NULL	10	10	NULL	NULL	10
NULL	10	10	NULL	NULL	35
NULL	10	10	NULL	NULL	NULL
NULL	10	48	NULL	NULL	10
NULL	10	48	NULL	NULL	35
NULL	10	48	NULL	NULL	NULL
NULL	10	NULL	NULL	NULL	10
NULL	10	NULL	NULL	NULL	35
NULL	10	NULL	NULL	NULL	NULL
NULL	35	10	NULL	NULL	10
NULL	35	10	NULL	NULL	35
NULL	35	10	NULL	NULL	NULL
NULL	35	48	NULL	NULL	10
NULL	35	48	NULL	NULL	35
NULL	35	48	NULL	NULL	NULL
NULL	35	NULL	NULL	NULL	10
NULL	35	NULL	NULL	NULL	35
NULL	35	NULL	NULL	NULL	NULL
NULL	NULL	10	NULL	NULL	10
NULL	NULL	10	NULL	NULL	35
NULL	NULL	10	NULL	NULL	NULL
NULL	NULL	48	NULL	NULL	10
NULL	NULL	48	NULL	NULL	35
NULL	NULL	48	NULL	NULL	NULL
NULL	NULL	NULL	NULL	NULL	10
NULL	NULL	NULL	NULL	NULL	35
NULL	NULL	NULL	NULL	NULL	NULL
PREHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value=b.key join myinput1 c on a.key<=>c.key AND a.value=c.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value=b.key join myinput1 c on a.key<=>c.key AND a.value=c.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE), Reducer 3 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  filterExpr: value is not null (type: boolean)
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 1:int)
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                      keys:
                        0 key (type: int), value (type: int)
                        1 value (type: int), key (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int, col 1:int
                          bigTableValueExpressions: col 0:int, col 1:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: No nullsafe IS false
                      nullSafes: [true, false]
                      outputColumnNames: _col0, _col1, _col5, _col6
                      input vertices:
                        1 Map 2
                      Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int), _col1 (type: int)
                          1 key (type: int), value (type: int)
                        Map Join Vectorization:
                            bigTableKeyExpressions: col 0:int, col 1:int
                            bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
                            className: VectorMapJoinOperator
                            native: false
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            nativeConditionsNotMet: No nullsafe IS false
                        nullSafes: [true, false]
                        outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                        input vertices:
                          1 Reducer 3
                        Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                        Select Operator
                          expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
                          Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  filterExpr: (key is not null or value is not null) (type: boolean)
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: value (type: int), key (type: int)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: value (type: int), key (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkMultiKeyOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 1:int)
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: key (type: int), value (type: int)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: key (type: int), value (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkMultiKeyOperator
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int)
                outputColumnNames: key, value
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Reduce Output Operator
                  key expressions: key (type: int), value (type: int)
                  null sort order: zz
                  sort order: ++
                  Map-reduce partition columns: key (type: int), value (type: int)
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkMultiKeyOperator
                      native: true
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                  Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value=b.key join myinput1 c on a.key<=>c.key AND a.value=c.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value=b.key join myinput1 c on a.key<=>c.key AND a.value=c.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
100	100	100	100	100	100
NULL	10	10	NULL	NULL	10
PREHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value<=>b.key join myinput1 c on a.key<=>c.key AND a.value<=>c.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization expression select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value<=>b.key join myinput1 c on a.key<=>c.key AND a.value<=>c.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Map 2 (BROADCAST_EDGE), Reducer 3 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Map Join Operator
                    condition map:
                         Inner Join 0 to 1
                    keys:
                      0 key (type: int), value (type: int)
                      1 value (type: int), key (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 0:int, col 1:int
                        bigTableValueExpressions: col 0:int, col 1:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: No nullsafe IS false
                    nullSafes: [true, true]
                    outputColumnNames: _col0, _col1, _col5, _col6
                    input vertices:
                      1 Reducer 3
                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                    Map Join Operator
                      condition map:
                           Inner Join 0 to 1
                      keys:
                        0 _col0 (type: int), _col1 (type: int)
                        1 key (type: int), value (type: int)
                      Map Join Vectorization:
                          bigTableKeyExpressions: col 0:int, col 1:int
                          bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
                          className: VectorMapJoinOperator
                          native: false
                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                          nativeConditionsNotMet: No nullsafe IS false
                      nullSafes: [true, true]
                      outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                      input vertices:
                        1 Map 2
                      Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                        Select Vectorization:
                            className: VectorSelectOperator
                            native: true
                            projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
                        Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                        File Output Operator
                          compressed: false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
                          Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                  Reduce Output Operator
                    key expressions: value (type: int), key (type: int)
                    null sort order: zz
                    sort order: ++
                    Map-reduce partition columns: value (type: int), key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkMultiKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: key (type: int), value (type: int)
                    null sort order: zz
                    sort order: ++
                    Map-reduce partition columns: key (type: int), value (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkMultiKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int)
                outputColumnNames: value, key
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Reduce Output Operator
                  key expressions: value (type: int), key (type: int)
                  null sort order: zz
                  sort order: ++
                  Map-reduce partition columns: value (type: int), key (type: int)
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkMultiKeyOperator
                      native: true
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value<=>b.key join myinput1 c on a.key<=>c.key AND a.value<=>c.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: select * from myinput1 a join myinput1 b on a.key<=>b.value AND a.value<=>b.key join myinput1 c on a.key<=>c.key AND a.value<=>c.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10	10	NULL
100	100	100	100	100	100
NULL	10	10	NULL	NULL	10
NULL	NULL	NULL	NULL	NULL	NULL
PREHOOK: query: SELECT * FROM myinput1 a LEFT OUTER JOIN myinput1 b ON a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM myinput1 a LEFT OUTER JOIN myinput1 b ON a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10
100	100	100	100
48	NULL	NULL	NULL
NULL	10	10	NULL
NULL	10	48	NULL
NULL	10	NULL	NULL
NULL	35	10	NULL
NULL	35	48	NULL
NULL	35	NULL	NULL
NULL	NULL	10	NULL
NULL	NULL	48	NULL
NULL	NULL	NULL	NULL
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL DEBUG
SELECT * FROM myinput1 a RIGHT OUTER JOIN myinput1 b ON a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL DEBUG
SELECT * FROM myinput1 a RIGHT OUTER JOIN myinput1 b ON a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:int, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: key (type: int)
                    null sort order: z
                    sort order: +
                    output key column names: KEY.reducesinkkey0
                    output value column names: VALUE._col0
                    Map-reduce partition columns: key (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkLongOperator
                        keyColumns: 0:int
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        valueColumns: 1:int
                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: value (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:key:int, 1:value:int, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Map Join Operator
                    condition map:
                         Right Outer Join 0 to 1
                    keyContext: [types [int], serde=org.apache.hadoop.hive.serde2.binarysortable.BinarySortableSerDe, hasFilter=false]
                    outer filter mappings: [null, [0, 0]]
                    valueContexts: [0:[types [int], serde=org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe, hasFilter=false]]
                    keyExpressions:
                      0 [Column[key]]
                      1 [Column[value]]
                    keys:
                      0 key (type: int)
                      1 value (type: int)
                    Map Join Vectorization:
                        bigTableKeyExpressions: col 1:int
                        bigTableValueExpressions: col 0:int, col 1:int
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: No nullsafe IS false
                    nullSafes: [true]
                    outputColumnNames: _col0, _col1, _col5, _col6
                    input vertices:
                      0 Map 1
                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1, 2, 3]
                      Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:int, value:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT * FROM myinput1 a FULL OUTER JOIN myinput1 b ON a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM myinput1 a FULL OUTER JOIN myinput1 b ON a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10
100	100	100	100
48	NULL	NULL	NULL
NULL	10	10	NULL
NULL	10	48	NULL
NULL	10	NULL	NULL
NULL	35	10	NULL
NULL	35	48	NULL
NULL	35	NULL	NULL
NULL	NULL	10	NULL
NULL	NULL	48	NULL
NULL	NULL	NULL	35
NULL	NULL	NULL	NULL
PREHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM myinput1 a JOIN myinput1 b ON a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM myinput1 a JOIN myinput1 b ON a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10
100	100	100	100
NULL	10	10	NULL
NULL	10	48	NULL
NULL	10	NULL	NULL
NULL	35	10	NULL
NULL	35	48	NULL
NULL	35	NULL	NULL
NULL	NULL	10	NULL
NULL	NULL	48	NULL
NULL	NULL	NULL	NULL
PREHOOK: query: SELECT /*+ MAPJOIN(b) */ * FROM myinput1 a JOIN myinput1 b ON a.key<=>b.value
PREHOOK: type: QUERY
PREHOOK: Input: default@myinput1
#### A masked pattern was here ####
POSTHOOK: query: SELECT /*+ MAPJOIN(b) */ * FROM myinput1 a JOIN myinput1 b ON a.key<=>b.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@myinput1
#### A masked pattern was here ####
10	NULL	NULL	10
100	100	100	100
NULL	10	10	NULL
NULL	10	48	NULL
NULL	10	NULL	NULL
NULL	35	10	NULL
NULL	35	48	NULL
NULL	35	NULL	NULL
NULL	NULL	10	NULL
NULL	NULL	48	NULL
NULL	NULL	NULL	NULL
