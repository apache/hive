PREHOOK: query: create table MY_TABLE_0001 (
  col_1 string,
  col_3 timestamp,
  col_7 string,
  col_20 string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@MY_TABLE_0001
POSTHOOK: query: create table MY_TABLE_0001 (
  col_1 string,
  col_3 timestamp,
  col_7 string,
  col_20 string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@MY_TABLE_0001
PREHOOK: query: create table MY_TABLE_0001_00 (
  col_1 string,
  col_22 string,
  col_23 int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@MY_TABLE_0001_00
POSTHOOK: query: create table MY_TABLE_0001_00 (
  col_1 string,
  col_22 string,
  col_23 int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@MY_TABLE_0001_00
PREHOOK: query: create table MY_TABLE_0003 (
  col_24 string,
  col_21 string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@MY_TABLE_0003
POSTHOOK: query: create table MY_TABLE_0003 (
  col_24 string,
  col_21 string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@MY_TABLE_0003
PREHOOK: query: create table MY_TABLE_0001_01 (
  col_1 string,
  col_100 string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@MY_TABLE_0001_01
POSTHOOK: query: create table MY_TABLE_0001_01 (
  col_1 string,
  col_100 string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@MY_TABLE_0001_01
PREHOOK: query: explain extended SELECT
  Table__323.col_7,
  CAST(Table__323.col_3 AS DATE) col_3,
  Table__323.col_20,  
  Table__1232.col_21 col_21_1232,
  Table__323.col_1,
  Table__133.col_22,
  Table__879.col_21 col_21_879
  ,Table__133.col_23
FROM MY_TABLE_0001 Table__323
LEFT OUTER JOIN MY_TABLE_0003 Table__1232 ON (Table__323.col_20=Table__1232.col_24)
LEFT OUTER JOIN MY_TABLE_0001_00 Table__133 ON (Table__323.col_1=Table__133.col_1)
LEFT OUTER JOIN MY_TABLE_0003 Table__879 ON (Table__133.col_22=Table__879.col_24)
LEFT OUTER JOIN MY_TABLE_0001_01 Table__1215 ON (Table__323.col_1=Table__1215.col_1 and Table__1215.col_100 = 210)
WHERE 1=1
AND  (cast(Table__323.col_7 AS DOUBLE) IS NOT NULL OR Table__323.col_7 IS NULL)
AND CAST(Table__323.col_3 AS DATE)  BETWEEN  '2018-07-01'  AND  '2019-01-23'
AND Table__323.col_20  IN  ('part1','part2','part3')
PREHOOK: type: QUERY
PREHOOK: Input: default@my_table_0001
PREHOOK: Input: default@my_table_0001_00
PREHOOK: Input: default@my_table_0001_01
PREHOOK: Input: default@my_table_0003
#### A masked pattern was here ####
POSTHOOK: query: explain extended SELECT
  Table__323.col_7,
  CAST(Table__323.col_3 AS DATE) col_3,
  Table__323.col_20,  
  Table__1232.col_21 col_21_1232,
  Table__323.col_1,
  Table__133.col_22,
  Table__879.col_21 col_21_879
  ,Table__133.col_23
FROM MY_TABLE_0001 Table__323
LEFT OUTER JOIN MY_TABLE_0003 Table__1232 ON (Table__323.col_20=Table__1232.col_24)
LEFT OUTER JOIN MY_TABLE_0001_00 Table__133 ON (Table__323.col_1=Table__133.col_1)
LEFT OUTER JOIN MY_TABLE_0003 Table__879 ON (Table__133.col_22=Table__879.col_24)
LEFT OUTER JOIN MY_TABLE_0001_01 Table__1215 ON (Table__323.col_1=Table__1215.col_1 and Table__1215.col_100 = 210)
WHERE 1=1
AND  (cast(Table__323.col_7 AS DOUBLE) IS NOT NULL OR Table__323.col_7 IS NULL)
AND CAST(Table__323.col_3 AS DATE)  BETWEEN  '2018-07-01'  AND  '2019-01-23'
AND Table__323.col_20  IN  ('part1','part2','part3')
POSTHOOK: type: QUERY
POSTHOOK: Input: default@my_table_0001
POSTHOOK: Input: default@my_table_0001_00
POSTHOOK: Input: default@my_table_0001_01
POSTHOOK: Input: default@my_table_0003
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT `t0`.`col_7`, `t0`.`CAST` AS `col_3`, `t0`.`col_20`, `t2`.`col_21` AS `col_21_1232`, `t0`.`col_1`, `t4`.`col_22`, `t6`.`col_21` AS `col_21_879`, `t4`.`col_23`
FROM (SELECT `col_1`, `col_7`, `col_20`, CAST(`col_3` AS DATE) AS `CAST`
FROM `default`.`my_table_0001`
WHERE (CAST(`col_7` AS DOUBLE) IS NOT NULL OR `col_7` IS NULL) AND (`col_20` IN ('part1', 'part2', 'part3') AND CAST(`col_3` AS DATE) BETWEEN DATE '2018-07-01' AND DATE '2019-01-23')) AS `t0`
LEFT JOIN (SELECT `col_24`, `col_21`
FROM `default`.`my_table_0003`
WHERE `col_24` IN ('part1', 'part2', 'part3')) AS `t2` ON `t0`.`col_20` = `t2`.`col_24`
LEFT JOIN (SELECT `col_1`, `col_22`, `col_23`
FROM `default`.`my_table_0001_00`
WHERE `col_1` IS NOT NULL) AS `t4` ON `t0`.`col_1` = `t4`.`col_1`
LEFT JOIN (SELECT `col_24`, `col_21`
FROM `default`.`my_table_0003`
WHERE `col_24` IS NOT NULL) AS `t6` ON `t4`.`col_22` = `t6`.`col_24`
LEFT JOIN (SELECT `col_1`
FROM `default`.`my_table_0001_01`
WHERE `col_100` = 210 AND `col_1` IS NOT NULL) AS `t8` ON `t0`.`col_1` = `t8`.`col_1`
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 7 (SIMPLE_EDGE)
        Reducer 3 <- Map 6 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Map 7 (SIMPLE_EDGE), Reducer 3 (SIMPLE_EDGE)
        Reducer 5 <- Map 8 (SIMPLE_EDGE), Reducer 4 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: table__323
                  filterExpr: ((UDFToDouble(col_7) is not null or col_7 is null) and (col_20) IN ('part1', 'part2', 'part3') and CAST( col_3 AS DATE) BETWEEN DATE'2018-07-01' AND DATE'2019-01-23') (type: boolean)
                  Statistics: Num rows: 1 Data size: 592 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((UDFToDouble(col_7) is not null or col_7 is null) and (col_20) IN ('part1', 'part2', 'part3') and CAST( col_3 AS DATE) BETWEEN DATE'2018-07-01' AND DATE'2019-01-23') (type: boolean)
                    Statistics: Num rows: 1 Data size: 592 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: col_1 (type: string), col_7 (type: string), col_20 (type: string), CAST( col_3 AS DATE) (type: date)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 1 Data size: 592 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col2 (type: string)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col2 (type: string)
                        Statistics: Num rows: 1 Data size: 592 Basic stats: COMPLETE Column stats: NONE
                        tag: 0
                        value expressions: _col0 (type: string), _col1 (type: string), _col3 (type: date)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: my_table_0001
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns col_1,col_3,col_7,col_20
                    columns.types string:timestamp:string:string
#### A masked pattern was here ####
                    name default.my_table_0001
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns col_1,col_3,col_7,col_20
                      columns.comments 
                      columns.types string:timestamp:string:string
#### A masked pattern was here ####
                      name default.my_table_0001
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.my_table_0001
                  name: default.my_table_0001
            Truncated Path -> Alias:
              /my_table_0001 [table__323]
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: table__133
                  filterExpr: col_1 is not null (type: boolean)
                  Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: col_1 is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: col_1 (type: string), col_22 (type: string), col_23 (type: int)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: string)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                        tag: 1
                        value expressions: _col1 (type: string), _col2 (type: int)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: my_table_0001_00
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns col_1,col_22,col_23
                    columns.types string:string:int
#### A masked pattern was here ####
                    name default.my_table_0001_00
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns col_1,col_22,col_23
                      columns.comments 
                      columns.types string:string:int
#### A masked pattern was here ####
                      name default.my_table_0001_00
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.my_table_0001_00
                  name: default.my_table_0001_00
            Truncated Path -> Alias:
              /my_table_0001_00 [table__133]
        Map 7 
            Map Operator Tree:
                TableScan
                  alias: table__879
                  filterExpr: (col_24 is not null or (col_24) IN ('part1', 'part2', 'part3')) (type: boolean)
                  Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: col_24 is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: col_24 (type: string), col_21 (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: string)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                        tag: 1
                        value expressions: _col1 (type: string)
                        auto parallelism: true
                  Filter Operator
                    isSamplingPred: false
                    predicate: (col_24) IN ('part1', 'part2', 'part3') (type: boolean)
                    Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: col_24 (type: string), col_21 (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: string)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                        tag: 1
                        value expressions: _col1 (type: string)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: my_table_0003
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns col_24,col_21
                    columns.types string:string
#### A masked pattern was here ####
                    name default.my_table_0003
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns col_24,col_21
                      columns.comments 
                      columns.types string:string
#### A masked pattern was here ####
                      name default.my_table_0003
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.my_table_0003
                  name: default.my_table_0003
            Truncated Path -> Alias:
              /my_table_0003 [table__879]
        Map 8 
            Map Operator Tree:
                TableScan
                  alias: table__1215
                  filterExpr: ((UDFToDouble(col_100) = 210.0D) and col_1 is not null) (type: boolean)
                  Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((UDFToDouble(col_100) = 210.0D) and col_1 is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: col_1 (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: string)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                        tag: 1
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: my_table_0001_01
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns col_1,col_100
                    columns.types string:string
#### A masked pattern was here ####
                    name default.my_table_0001_01
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns col_1,col_100
                      columns.comments 
                      columns.types string:string
#### A masked pattern was here ####
                      name default.my_table_0001_01
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.my_table_0001_01
                  name: default.my_table_0001_01
            Truncated Path -> Alias:
              /my_table_0001_01 [table__1215]
        Reducer 2 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col2 (type: string)
                  1 _col0 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col5
                Position of Big Table: 0
                Statistics: Num rows: 1 Data size: 651 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col0 (type: string)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 1 Data size: 651 Basic stats: COMPLETE Column stats: NONE
                  tag: 0
                  value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: date), _col5 (type: string)
                  auto parallelism: true
        Reducer 3 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col0 (type: string)
                  1 _col0 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col5, _col7, _col8
                Position of Big Table: 0
                Statistics: Num rows: 1 Data size: 716 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col7 (type: string)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col7 (type: string)
                  Statistics: Num rows: 1 Data size: 716 Basic stats: COMPLETE Column stats: NONE
                  tag: 0
                  value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: date), _col5 (type: string), _col8 (type: int)
                  auto parallelism: true
        Reducer 4 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col7 (type: string)
                  1 _col0 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col5, _col7, _col8, _col10
                Position of Big Table: 0
                Statistics: Num rows: 1 Data size: 787 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col0 (type: string)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 1 Data size: 787 Basic stats: COMPLETE Column stats: NONE
                  tag: 0
                  value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: date), _col5 (type: string), _col7 (type: string), _col8 (type: int), _col10 (type: string)
                  auto parallelism: true
        Reducer 5 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col0 (type: string)
                  1 _col0 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col5, _col7, _col8, _col10
                Position of Big Table: 0
                Statistics: Num rows: 1 Data size: 865 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col1 (type: string), _col3 (type: date), _col2 (type: string), _col5 (type: string), _col0 (type: string), _col7 (type: string), _col10 (type: string), _col8 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                  Statistics: Num rows: 1 Data size: 865 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    bucketingVersion: 2
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 1 Data size: 865 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          bucketing_version -1
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
                          columns.types string:date:string:string:string:string:string:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: explain extended
SELECT `t`.`p_name`
FROM (SELECT `p_name`, `p_type`, `p_size` + 1 AS `size`
FROM `part`) AS `t`
LEFT JOIN (SELECT `t5`.`size`, `t2`.`c`, `t2`.`ck`
FROM (SELECT `p_size` + 1 AS `+`, COUNT(*) AS `c`, COUNT(`p_type`) AS `ck`
FROM `part`
WHERE `p_size` IS NOT NULL
GROUP BY `p_size` + 1) AS `t2`
INNER JOIN (SELECT `p_size` + 1 AS `size`
FROM `part`
WHERE `p_size` IS NOT NULL
GROUP BY `p_size` + 1) AS `t5` ON `t2`.`+` = `t5`.`size`) AS `t6` ON `t`.`size` = `t6`.`size`
LEFT JOIN (SELECT `t9`.`p_type`, `t12`.`size`, TRUE AS `$f2`
FROM (SELECT `p_type`, `p_size` + 1 AS `+`
FROM `part`
WHERE `p_size` IS NOT NULL AND `p_type` IS NOT NULL
GROUP BY `p_type`, `p_size` + 1) AS `t9`
INNER JOIN (SELECT `p_size` + 1 AS `size`
FROM `part`
WHERE `p_size` IS NOT NULL
GROUP BY `p_size` + 1) AS `t12` ON `t9`.`+` = `t12`.`size`) AS `t14` ON `t`.`p_type` = `t14`.`p_type` AND `t`.`size` = `t14`.`size`
WHERE (`t14`.`$f2` IS NULL OR `t6`.`c` = 0 OR `t6`.`c` IS NULL)
    AND (`t`.`p_type` IS NOT NULL OR `t6`.`c` = 0 OR `t6`.`c` IS NULL OR `t14`.`$f2` IS NOT NULL)
    AND (`t6`.`ck` < `t6`.`c` IS NOT TRUE OR `t6`.`c` = 0 OR `t6`.`c` IS NULL OR `t14`.`$f2` IS NOT NULL
    OR `t`.`p_type` IS NULL)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: explain extended
SELECT `t`.`p_name`
FROM (SELECT `p_name`, `p_type`, `p_size` + 1 AS `size`
FROM `part`) AS `t`
LEFT JOIN (SELECT `t5`.`size`, `t2`.`c`, `t2`.`ck`
FROM (SELECT `p_size` + 1 AS `+`, COUNT(*) AS `c`, COUNT(`p_type`) AS `ck`
FROM `part`
WHERE `p_size` IS NOT NULL
GROUP BY `p_size` + 1) AS `t2`
INNER JOIN (SELECT `p_size` + 1 AS `size`
FROM `part`
WHERE `p_size` IS NOT NULL
GROUP BY `p_size` + 1) AS `t5` ON `t2`.`+` = `t5`.`size`) AS `t6` ON `t`.`size` = `t6`.`size`
LEFT JOIN (SELECT `t9`.`p_type`, `t12`.`size`, TRUE AS `$f2`
FROM (SELECT `p_type`, `p_size` + 1 AS `+`
FROM `part`
WHERE `p_size` IS NOT NULL AND `p_type` IS NOT NULL
GROUP BY `p_type`, `p_size` + 1) AS `t9`
INNER JOIN (SELECT `p_size` + 1 AS `size`
FROM `part`
WHERE `p_size` IS NOT NULL
GROUP BY `p_size` + 1) AS `t12` ON `t9`.`+` = `t12`.`size`) AS `t14` ON `t`.`p_type` = `t14`.`p_type` AND `t`.`size` = `t14`.`size`
WHERE (`t14`.`$f2` IS NULL OR `t6`.`c` = 0 OR `t6`.`c` IS NULL)
    AND (`t`.`p_type` IS NOT NULL OR `t6`.`c` = 0 OR `t6`.`c` IS NULL OR `t14`.`$f2` IS NOT NULL)
    AND (`t6`.`ck` < `t6`.`c` IS NOT TRUE OR `t6`.`c` = 0 OR `t6`.`c` IS NULL OR `t14`.`$f2` IS NOT NULL
    OR `t`.`p_type` IS NULL)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT `p_name`
FROM (SELECT `t`.`p_name`, `t`.`p_type`, `t`.`size`, `t7`.`$f0` AS `size0`, `t3`.`$f1` AS `c`, `t3`.`$f2` AS `ck`, `t16`.`p_type` AS `p_type0`, `t16`.`size` AS `size1`, `t16`.`$f2`
FROM (SELECT `p_name`, `p_type`, `p_size` + 1 AS `size`
FROM `default`.`part`) AS `t`
LEFT JOIN ((SELECT `p_size` + 1 AS `$f0`, COUNT(*) AS `$f1`, COUNT(`p_type`) AS `$f2`
FROM `default`.`part`
WHERE `p_size` IS NOT NULL
GROUP BY `p_size` + 1) AS `t3` INNER JOIN (SELECT `p_size` + 1 AS `$f0`
FROM `default`.`part`
WHERE `p_size` IS NOT NULL
GROUP BY `p_size` + 1) AS `t7` ON `t3`.`$f0` = `t7`.`$f0`) ON `t`.`size` = `t7`.`$f0`
LEFT JOIN (SELECT `t11`.`$f0` AS `p_type`, `t15`.`$f0` AS `size`, TRUE AS `$f2`
FROM (SELECT `p_type` AS `$f0`, `p_size` + 1 AS `$f1`
FROM `default`.`part`
WHERE `p_size` IS NOT NULL AND `p_type` IS NOT NULL
GROUP BY `p_type`, `p_size` + 1) AS `t11`
INNER JOIN (SELECT `p_size` + 1 AS `$f0`
FROM `default`.`part`
WHERE `p_size` IS NOT NULL
GROUP BY `p_size` + 1) AS `t15` ON `t11`.`$f1` = `t15`.`$f0`) AS `t16` ON `t`.`p_type` = `t16`.`p_type` AND `t`.`size` = `t16`.`size`) AS `t17`
WHERE (`t17`.`$f2` IS NULL OR (`t17`.`c` = 0 OR `t17`.`c` IS NULL)) AND ((`t17`.`ck` < `t17`.`c` IS NOT TRUE OR `t17`.`c` = 0 OR (`t17`.`c` IS NULL OR (`t17`.`$f2` IS NOT NULL OR `t17`.`p_type` IS NULL))) AND (`t17`.`p_type` IS NOT NULL OR `t17`.`c` = 0 OR (`t17`.`c` IS NULL OR `t17`.`$f2` IS NOT NULL)))
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE), Reducer 8 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 4 (SIMPLE_EDGE), Reducer 7 (SIMPLE_EDGE)
        Reducer 7 <- Map 6 (SIMPLE_EDGE), Reducer 9 (SIMPLE_EDGE)
        Reducer 8 <- Map 6 (SIMPLE_EDGE)
        Reducer 9 <- Map 1 (SIMPLE_EDGE), Map 6 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  filterExpr: p_size is not null (type: boolean)
                  Statistics: Num rows: 26 Data size: 104 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: p_size is not null (type: boolean)
                    Statistics: Num rows: 26 Data size: 104 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: (p_size + 1) (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 26 Data size: 104 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        keys: _col0 (type: int)
                        minReductionHashAggr: 0.4
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          bucketingVersion: 2
                          key expressions: _col0 (type: int)
                          null sort order: z
                          numBuckets: -1
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
                          tag: -1
                          auto parallelism: true
                        Reduce Output Operator
                          bucketingVersion: 2
                          key expressions: _col0 (type: int)
                          null sort order: z
                          numBuckets: -1
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
                          tag: -1
                          auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: part
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns p_partkey,p_name,p_mfgr,p_brand,p_type,p_size,p_container,p_retailprice,p_comment
                    columns.types int:string:string:string:string:int:string:double:string
#### A masked pattern was here ####
                    name default.part
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns p_partkey,p_name,p_mfgr,p_brand,p_type,p_size,p_container,p_retailprice,p_comment
                      columns.comments 
                      columns.types int:string:string:string:string:int:string:double:string
#### A masked pattern was here ####
                      name default.part
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.part
                  name: default.part
            Truncated Path -> Alias:
              /part [part]
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5954 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Select Operator
                    expressions: p_name (type: string), p_type (type: string), (p_size + 1) (type: int)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 26 Data size: 5954 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      bucketingVersion: 2
                      key expressions: _col2 (type: int)
                      null sort order: z
                      numBuckets: -1
                      sort order: +
                      Map-reduce partition columns: _col2 (type: int)
                      Statistics: Num rows: 26 Data size: 5954 Basic stats: COMPLETE Column stats: COMPLETE
                      tag: 1
                      value expressions: _col0 (type: string), _col1 (type: string)
                      auto parallelism: true
                  Filter Operator
                    isSamplingPred: false
                    predicate: (p_size is not null and p_type is not null) (type: boolean)
                    Statistics: Num rows: 26 Data size: 2808 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: p_type (type: string), (p_size + 1) (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 26 Data size: 2808 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        keys: _col1 (type: int), _col0 (type: string)
                        minReductionHashAggr: 0.4
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 24 Data size: 2592 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          bucketingVersion: 2
                          key expressions: _col0 (type: int), _col1 (type: string)
                          null sort order: zz
                          numBuckets: -1
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                          Statistics: Num rows: 24 Data size: 2592 Basic stats: COMPLETE Column stats: COMPLETE
                          tag: -1
                          auto parallelism: true
                  Filter Operator
                    isSamplingPred: false
                    predicate: p_size is not null (type: boolean)
                    Statistics: Num rows: 26 Data size: 2808 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: (p_size + 1) (type: int), p_type (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 26 Data size: 2808 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: count(), count(_col1)
                        keys: _col0 (type: int)
                        minReductionHashAggr: 0.4
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 21 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          bucketingVersion: 2
                          key expressions: _col0 (type: int)
                          null sort order: z
                          numBuckets: -1
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 21 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
                          tag: -1
                          value expressions: _col1 (type: bigint), _col2 (type: bigint)
                          auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: part
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns p_partkey,p_name,p_mfgr,p_brand,p_type,p_size,p_container,p_retailprice,p_comment
                    columns.types int:string:string:string:string:int:string:double:string
#### A masked pattern was here ####
                    name default.part
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns p_partkey,p_name,p_mfgr,p_brand,p_type,p_size,p_container,p_retailprice,p_comment
                      columns.comments 
                      columns.types int:string:string:string:string:int:string:double:string
#### A masked pattern was here ####
                      name default.part
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.part
                  name: default.part
            Truncated Path -> Alias:
              /part [part]
        Reducer 3 
            Execution mode: vectorized, llap
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col0 (type: int)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: 1
                  auto parallelism: true
        Reducer 4 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col2
                Position of Big Table: 0
                Statistics: Num rows: 24 Data size: 2592 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col0 (type: string), _col2 (type: int), true (type: boolean)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 24 Data size: 2688 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    bucketingVersion: 2
                    key expressions: _col0 (type: string), _col1 (type: int)
                    null sort order: zz
                    numBuckets: -1
                    sort order: ++
                    Map-reduce partition columns: _col0 (type: string), _col1 (type: int)
                    Statistics: Num rows: 24 Data size: 2688 Basic stats: COMPLETE Column stats: COMPLETE
                    tag: 1
                    value expressions: _col2 (type: boolean)
                    auto parallelism: true
        Reducer 5 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col5 (type: string), _col6 (type: int)
                  1 _col0 (type: string), _col1 (type: int)
                outputColumnNames: _col1, _col2, _col4, _col5, _col9
                Position of Big Table: 0
                Statistics: Num rows: 26 Data size: 6370 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col4 (type: string), _col5 (type: string), _col1 (type: bigint), _col2 (type: bigint), _col9 (type: boolean)
                  outputColumnNames: _col0, _col1, _col4, _col5, _col8
                  Statistics: Num rows: 26 Data size: 6370 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((_col8 is null or (_col4 = 0L) or _col4 is null) and ((_col5 < _col4) is not true or (_col4 = 0L) or _col4 is null or _col8 is not null or _col1 is null) and (_col1 is not null or (_col4 = 0L) or _col4 is null or _col8 is not null)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 245 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 121 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        bucketingVersion: 2
                        compressed: false
                        GlobalTableId: 0
#### A masked pattern was here ####
                        NumFilesPerFileSink: 1
                        Statistics: Num rows: 1 Data size: 121 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            properties:
                              bucketing_version -1
                              columns _col0
                              columns.types string
                              escape.delim \
                              hive.serialization.extend.additional.nesting.levels true
                              serialization.escape.crlf true
                              serialization.format 1
                              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        TotalFiles: 1
                        GatherStats: false
                        MultiFileSpray: false
        Reducer 7 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 _col3 (type: int)
                  1 _col2 (type: int)
                outputColumnNames: _col1, _col2, _col4, _col5, _col6
                Position of Big Table: 0
                Statistics: Num rows: 26 Data size: 6370 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col5 (type: string), _col6 (type: int)
                  null sort order: zz
                  numBuckets: -1
                  sort order: ++
                  Map-reduce partition columns: _col5 (type: string), _col6 (type: int)
                  Statistics: Num rows: 26 Data size: 6370 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: 0
                  value expressions: _col1 (type: bigint), _col2 (type: bigint), _col4 (type: string)
                  auto parallelism: true
        Reducer 8 
            Execution mode: vectorized, llap
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 24 Data size: 2592 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col1 (type: string), _col0 (type: int)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 24 Data size: 2592 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    bucketingVersion: 2
                    key expressions: _col1 (type: int)
                    null sort order: z
                    numBuckets: -1
                    sort order: +
                    Map-reduce partition columns: _col1 (type: int)
                    Statistics: Num rows: 24 Data size: 2592 Basic stats: COMPLETE Column stats: COMPLETE
                    tag: 0
                    value expressions: _col0 (type: string)
                    auto parallelism: true
        Reducer 9 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 21 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
                Dummy Store
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0), count(VALUE._col1)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 21 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
                Merge Join Operator
                  condition map:
                       Inner Join 0 to 1
                  keys:
                    0 _col0 (type: int)
                    1 _col0 (type: int)
                  outputColumnNames: _col1, _col2, _col3
                  Position of Big Table: 0
                  Statistics: Num rows: 21 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    bucketingVersion: 2
                    key expressions: _col3 (type: int)
                    null sort order: z
                    numBuckets: -1
                    sort order: +
                    Map-reduce partition columns: _col3 (type: int)
                    Statistics: Num rows: 21 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
                    tag: 0
                    value expressions: _col1 (type: bigint), _col2 (type: bigint)
                    auto parallelism: true

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

