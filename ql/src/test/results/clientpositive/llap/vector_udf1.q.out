PREHOOK: query: drop table varchar_udf_1_n2
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table varchar_udf_1_n2
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table varchar_udf_1_n2 (c1 string, c2 string, c3 varchar(10), c4 varchar(20),
     d1 string, d2 string, d3 varchar(10), d4 varchar(10)) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@varchar_udf_1_n2
POSTHOOK: query: create table varchar_udf_1_n2 (c1 string, c2 string, c3 varchar(10), c4 varchar(20),
     d1 string, d2 string, d3 varchar(10), d4 varchar(10)) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@varchar_udf_1_n2
PREHOOK: query: insert overwrite table varchar_udf_1_n2
  select key, value, key, value, '2015-01-14', '2015-01-14', '2017-01-11', '2017-01-11' from src where key = '238' limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@varchar_udf_1_n2
POSTHOOK: query: insert overwrite table varchar_udf_1_n2
  select key, value, key, value, '2015-01-14', '2015-01-14', '2017-01-11', '2017-01-11' from src where key = '238' limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@varchar_udf_1_n2
POSTHOOK: Lineage: varchar_udf_1_n2.c1 SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: varchar_udf_1_n2.c2 SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: varchar_udf_1_n2.c3 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: varchar_udf_1_n2.c4 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: varchar_udf_1_n2.d1 SIMPLE []
POSTHOOK: Lineage: varchar_udf_1_n2.d2 SIMPLE []
POSTHOOK: Lineage: varchar_udf_1_n2.d3 EXPRESSION []
POSTHOOK: Lineage: varchar_udf_1_n2.d4 EXPRESSION []
PREHOOK: query: explain vectorization detail
select
  concat(c1, c2),
  concat(c3, c4),
  concat(c1, c2) = concat(c3, c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  concat(c1, c2),
  concat(c3, c4),
  concat(c1, c2) = concat(c3, c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 356 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: concat(c1, c2) (type: string), concat(c3, c4) (type: varchar(30)), (concat(c1, c2) = CAST( concat(c3, c4) AS STRING)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 14]
                        selectExpressions: StringGroupConcatColCol(col 0:string, col 1:string) -> 9:string, StringGroupConcatColCol(col 2:varchar(10), col 3:varchar(20)) -> 10:varchar(30), StringGroupColEqualStringGroupColumn(col 11:string, col 13:string)(children: StringGroupConcatColCol(col 0:string, col 1:string) -> 11:string, CastStringGroupToString(col 12:varchar(30))(children: StringGroupConcatColCol(col 2:varchar(10), col 3:varchar(20)) -> 12:varchar(30)) -> 13:string) -> 14:boolean
                    Statistics: Num rows: 1 Data size: 302 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 302 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 302 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [0, 1, 2, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  concat(c1, c2),
  concat(c3, c4),
  concat(c1, c2) = concat(c3, c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  concat(c1, c2),
  concat(c3, c4),
  concat(c1, c2) = concat(c3, c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
238val_238	238val_238	true
PREHOOK: query: explain vectorization detail
select
  upper(c2),
  upper(c4),
  upper(c2) = upper(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  upper(c2),
  upper(c4),
  upper(c2) = upper(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: upper(c2) (type: string), upper(c4) (type: varchar(20)), (upper(c2) = CAST( upper(c4) AS STRING)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 14]
                        selectExpressions: StringUpper(col 1:string) -> 9:string, StringUpper(col 3:varchar(20)) -> 10:varchar(20), StringGroupColEqualStringGroupColumn(col 11:string, col 13:string)(children: StringUpper(col 1:string) -> 11:string, CastStringGroupToString(col 12:varchar(20))(children: StringUpper(col 3:varchar(20)) -> 12:varchar(20)) -> 13:string) -> 14:boolean
                    Statistics: Num rows: 1 Data size: 292 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 292 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 292 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  upper(c2),
  upper(c4),
  upper(c2) = upper(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  upper(c2),
  upper(c4),
  upper(c2) = upper(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
VAL_238	VAL_238	true
PREHOOK: query: explain vectorization detail
select
  lower(c2),
  lower(c4),
  lower(c2) = lower(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  lower(c2),
  lower(c4),
  lower(c2) = lower(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: lower(c2) (type: string), lower(c4) (type: varchar(20)), (lower(c2) = CAST( lower(c4) AS STRING)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 14]
                        selectExpressions: StringLower(col 1:string) -> 9:string, StringLower(col 3:varchar(20)) -> 10:varchar(20), StringGroupColEqualStringGroupColumn(col 11:string, col 13:string)(children: StringLower(col 1:string) -> 11:string, CastStringGroupToString(col 12:varchar(20))(children: StringLower(col 3:varchar(20)) -> 12:varchar(20)) -> 13:string) -> 14:boolean
                    Statistics: Num rows: 1 Data size: 292 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 292 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 292 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  lower(c2),
  lower(c4),
  lower(c2) = lower(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  lower(c2),
  lower(c4),
  lower(c2) = lower(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
val_238	val_238	true
PREHOOK: query: explain vectorization detail
select
  ascii(c2),
  ascii(c4),
  ascii(c2) = ascii(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  ascii(c2),
  ascii(c4),
  ascii(c2) = ascii(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: ascii(c2) (type: int), ascii(c4) (type: int), (ascii(c2) = ascii(c4)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(ascii(c2)) -> 9:int, VectorUDFAdaptor(ascii(c4)) -> 10:int, LongColEqualLongColumn(col 11:int, col 12:int)(children: VectorUDFAdaptor(ascii(c2)) -> 11:int, VectorUDFAdaptor(ascii(c4)) -> 12:int) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint, bigint, bigint, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  ascii(c2),
  ascii(c4),
  ascii(c2) = ascii(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  ascii(c2),
  ascii(c4),
  ascii(c2) = ascii(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
118	118	true
PREHOOK: query: explain vectorization detail
select
  concat_ws('|', c1, c2),
  concat_ws('|', c3, c4),
  concat_ws('|', c1, c2) = concat_ws('|', c3, c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  concat_ws('|', c1, c2),
  concat_ws('|', c3, c4),
  concat_ws('|', c1, c2) = concat_ws('|', c3, c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 356 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: concat_ws('|', c1, c2) (type: string), concat_ws('|', c3, c4) (type: string), (concat_ws('|', c1, c2) = concat_ws('|', c3, c4)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(concat_ws('|', c1, c2)) -> 9:string, VectorUDFAdaptor(concat_ws('|', c3, c4)) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: VectorUDFAdaptor(concat_ws('|', c1, c2)) -> 11:string, VectorUDFAdaptor(concat_ws('|', c3, c4)) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [0, 1, 2, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  concat_ws('|', c1, c2),
  concat_ws('|', c3, c4),
  concat_ws('|', c1, c2) = concat_ws('|', c3, c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  concat_ws('|', c1, c2),
  concat_ws('|', c3, c4),
  concat_ws('|', c1, c2) = concat_ws('|', c3, c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
238|val_238	238|val_238	true
PREHOOK: query: explain vectorization detail
select
  decode(encode(c2, 'US-ASCII'), 'US-ASCII'),
  decode(encode(c4, 'US-ASCII'), 'US-ASCII'),
  decode(encode(c2, 'US-ASCII'), 'US-ASCII') = decode(encode(c4, 'US-ASCII'), 'US-ASCII')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  decode(encode(c2, 'US-ASCII'), 'US-ASCII'),
  decode(encode(c4, 'US-ASCII'), 'US-ASCII'),
  decode(encode(c2, 'US-ASCII'), 'US-ASCII') = decode(encode(c4, 'US-ASCII'), 'US-ASCII')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: decode(encode(c2,'US-ASCII'),'US-ASCII') (type: string), decode(encode(c4,'US-ASCII'),'US-ASCII') (type: string), (decode(encode(c2,'US-ASCII'),'US-ASCII') = decode(encode(c4,'US-ASCII'),'US-ASCII')) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [10, 11, 14]
                        selectExpressions: VectorUDFAdaptor(decode(encode(c2,'US-ASCII'),'US-ASCII'))(children: VectorUDFAdaptor(encode(c2,'US-ASCII')) -> 9:binary) -> 10:string, VectorUDFAdaptor(decode(encode(c4,'US-ASCII'),'US-ASCII'))(children: VectorUDFAdaptor(encode(c4,'US-ASCII')) -> 9:binary) -> 11:string, StringGroupColEqualStringGroupColumn(col 12:string, col 13:string)(children: VectorUDFAdaptor(decode(encode(c2,'US-ASCII'),'US-ASCII'))(children: VectorUDFAdaptor(encode(c2,'US-ASCII')) -> 9:binary) -> 12:string, VectorUDFAdaptor(decode(encode(c4,'US-ASCII'),'US-ASCII'))(children: VectorUDFAdaptor(encode(c4,'US-ASCII')) -> 9:binary) -> 13:string) -> 14:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  decode(encode(c2, 'US-ASCII'), 'US-ASCII'),
  decode(encode(c4, 'US-ASCII'), 'US-ASCII'),
  decode(encode(c2, 'US-ASCII'), 'US-ASCII') = decode(encode(c4, 'US-ASCII'), 'US-ASCII')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  decode(encode(c2, 'US-ASCII'), 'US-ASCII'),
  decode(encode(c4, 'US-ASCII'), 'US-ASCII'),
  decode(encode(c2, 'US-ASCII'), 'US-ASCII') = decode(encode(c4, 'US-ASCII'), 'US-ASCII')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
val_238	val_238	true
PREHOOK: query: explain vectorization detail
select
  instr(c2, '_'),
  instr(c4, '_'),
  instr(c2, '_') = instr(c4, '_')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  instr(c2, '_'),
  instr(c4, '_'),
  instr(c2, '_') = instr(c4, '_')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: instr(c2, '_') (type: int), instr(c4, '_') (type: int), (instr(c2, '_') = instr(c4, '_')) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(instr(c2, '_')) -> 9:int, VectorUDFAdaptor(instr(c4, '_')) -> 10:int, LongColEqualLongColumn(col 11:int, col 12:int)(children: VectorUDFAdaptor(instr(c2, '_')) -> 11:int, VectorUDFAdaptor(instr(c4, '_')) -> 12:int) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint, bigint, bigint, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  instr(c2, '_'),
  instr(c4, '_'),
  instr(c2, '_') = instr(c4, '_')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  instr(c2, '_'),
  instr(c4, '_'),
  instr(c2, '_') = instr(c4, '_')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
4	4	true
PREHOOK: query: explain vectorization detail
select
  replace(c1, '_', c2),
  replace(c3, '_', c4),
  replace(c1, '_', c2) = replace(c3, '_', c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  replace(c1, '_', c2),
  replace(c3, '_', c4),
  replace(c1, '_', c2) = replace(c3, '_', c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 356 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: replace(c1, '_', c2) (type: string), replace(c3, '_', c4) (type: string), (replace(c1, '_', c2) = replace(c3, '_', c4)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(replace(c1, '_', c2)) -> 9:string, VectorUDFAdaptor(replace(c3, '_', c4)) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: VectorUDFAdaptor(replace(c1, '_', c2)) -> 11:string, VectorUDFAdaptor(replace(c3, '_', c4)) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [0, 1, 2, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  replace(c1, '_', c2),
  replace(c3, '_', c4),
  replace(c1, '_', c2) = replace(c3, '_', c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  replace(c1, '_', c2),
  replace(c3, '_', c4),
  replace(c1, '_', c2) = replace(c3, '_', c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
238	238	true
PREHOOK: query: explain vectorization detail
select
  reverse(c2),
  reverse(c4),
  reverse(c2) = reverse(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  reverse(c2),
  reverse(c4),
  reverse(c2) = reverse(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: reverse(c2) (type: string), reverse(c4) (type: string), (reverse(c2) = reverse(c4)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(reverse(c2)) -> 9:string, VectorUDFAdaptor(reverse(c4)) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: VectorUDFAdaptor(reverse(c2)) -> 11:string, VectorUDFAdaptor(reverse(c4)) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  reverse(c2),
  reverse(c4),
  reverse(c2) = reverse(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  reverse(c2),
  reverse(c4),
  reverse(c2) = reverse(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
832_lav	832_lav	true
PREHOOK: query: explain vectorization detail
select
  next_day(d1, 'TU'),
  next_day(d4, 'WE'),
  next_day(d1, 'TU') = next_day(d4, 'WE')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  next_day(d1, 'TU'),
  next_day(d4, 'WE'),
  next_day(d1, 'TU') = next_day(d4, 'WE')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: next_day(d1, 'TU') (type: string), next_day(d4, 'WE') (type: string), (next_day(d1, 'TU') = next_day(d4, 'WE')) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(next_day(d1, 'TU')) -> 9:string, VectorUDFAdaptor(next_day(d4, 'WE')) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: VectorUDFAdaptor(next_day(d1, 'TU')) -> 11:string, VectorUDFAdaptor(next_day(d4, 'WE')) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [4, 7]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  next_day(d1, 'TU'),
  next_day(d4, 'WE'),
  next_day(d1, 'TU') = next_day(d4, 'WE')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  next_day(d1, 'TU'),
  next_day(d4, 'WE'),
  next_day(d1, 'TU') = next_day(d4, 'WE')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
2015-01-20	2017-01-18	false
PREHOOK: query: explain vectorization detail
select
  months_between(d1, d3),
  months_between(d2, d4),
  months_between(d1, d3) = months_between(d2, d4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  months_between(d1, d3),
  months_between(d2, d4),
  months_between(d1, d3) = months_between(d2, d4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 376 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: months_between(d1, d3) (type: double), months_between(d2, d4) (type: double), (months_between(d1, d3) = months_between(d2, d4)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(months_between(d1, d3)) -> 9:double, VectorUDFAdaptor(months_between(d2, d4)) -> 10:double, DoubleColEqualDoubleColumn(col 11:double, col 12:double)(children: VectorUDFAdaptor(months_between(d1, d3)) -> 11:double, VectorUDFAdaptor(months_between(d2, d4)) -> 12:double) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [4, 5, 6, 7]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [double, double, double, double, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  months_between(d1, d3),
  months_between(d2, d4),
  months_between(d1, d3) = months_between(d2, d4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  months_between(d1, d3),
  months_between(d2, d4),
  months_between(d1, d3) = months_between(d2, d4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
-23.90322581	-23.90322581	true
PREHOOK: query: explain vectorization detail
select
  length(c2),
  length(c4),
  length(c2) = length(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  length(c2),
  length(c4),
  length(c2) = length(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: length(c2) (type: int), length(c4) (type: int), (length(c2) = length(c4)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: StringLength(col 1:string) -> 9:int, StringLength(col 3:varchar(20)) -> 10:int, LongColEqualLongColumn(col 11:int, col 12:int)(children: StringLength(col 1:string) -> 11:int, StringLength(col 3:varchar(20)) -> 12:int) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint, bigint, bigint, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  length(c2),
  length(c4),
  length(c2) = length(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  length(c2),
  length(c4),
  length(c2) = length(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
7	7	true
PREHOOK: query: explain vectorization detail
select
  locate('a', 'abcdabcd', 3),
  locate(cast('a' as varchar(1)), cast('abcdabcd' as varchar(10)), 3),
  locate('a', 'abcdabcd', 3) = locate(cast('a' as varchar(1)), cast('abcdabcd' as varchar(10)), 3)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  locate('a', 'abcdabcd', 3),
  locate(cast('a' as varchar(1)), cast('abcdabcd' as varchar(10)), 3),
  locate('a', 'abcdabcd', 3) = locate(cast('a' as varchar(1)), cast('abcdabcd' as varchar(10)), 3)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 732 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: 5 (type: int), 5 (type: int), true (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 11]
                        selectExpressions: ConstantVectorExpression(val 5) -> 9:int, ConstantVectorExpression(val 5) -> 10:int, ConstantVectorExpression(val 1) -> 11:boolean
                    Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: []
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  locate('a', 'abcdabcd', 3),
  locate(cast('a' as varchar(1)), cast('abcdabcd' as varchar(10)), 3),
  locate('a', 'abcdabcd', 3) = locate(cast('a' as varchar(1)), cast('abcdabcd' as varchar(10)), 3)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  locate('a', 'abcdabcd', 3),
  locate(cast('a' as varchar(1)), cast('abcdabcd' as varchar(10)), 3),
  locate('a', 'abcdabcd', 3) = locate(cast('a' as varchar(1)), cast('abcdabcd' as varchar(10)), 3)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
5	5	true
PREHOOK: query: explain vectorization detail
select
  lpad(c2, 15, ' '),
  lpad(c4, 15, ' '),
  lpad(c2, 15, ' ') = lpad(c4, 15, ' ')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  lpad(c2, 15, ' '),
  lpad(c4, 15, ' '),
  lpad(c2, 15, ' ') = lpad(c4, 15, ' ')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: lpad(c2, 15, ' ') (type: string), lpad(c4, 15, ' ') (type: string), (lpad(c2, 15, ' ') = lpad(c4, 15, ' ')) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(lpad(c2, 15, ' ')) -> 9:string, VectorUDFAdaptor(lpad(c4, 15, ' ')) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: VectorUDFAdaptor(lpad(c2, 15, ' ')) -> 11:string, VectorUDFAdaptor(lpad(c4, 15, ' ')) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  lpad(c2, 15, ' '),
  lpad(c4, 15, ' '),
  lpad(c2, 15, ' ') = lpad(c4, 15, ' ')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  lpad(c2, 15, ' '),
  lpad(c4, 15, ' '),
  lpad(c2, 15, ' ') = lpad(c4, 15, ' ')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
        val_238	        val_238	true
PREHOOK: query: explain vectorization detail
select
  ltrim(c2),
  ltrim(c4),
  ltrim(c2) = ltrim(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  ltrim(c2),
  ltrim(c4),
  ltrim(c2) = ltrim(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: ltrim(c2) (type: string), ltrim(c4) (type: string), (ltrim(c2) = ltrim(c4)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: StringLTrim(col 1:string) -> 9:string, StringLTrim(col 3:varchar(20)) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: StringLTrim(col 1:string) -> 11:string, StringLTrim(col 3:varchar(20)) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  ltrim(c2),
  ltrim(c4),
  ltrim(c2) = ltrim(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  ltrim(c2),
  ltrim(c4),
  ltrim(c2) = ltrim(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
val_238	val_238	true
PREHOOK: query: explain vectorization detail
select
  c2 regexp 'val',
  c4 regexp 'val',
  (c2 regexp 'val') = (c4 regexp 'val')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  c2 regexp 'val',
  c4 regexp 'val',
  (c2 regexp 'val') = (c4 regexp 'val')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: c2 regexp 'val' (type: boolean), c4 regexp 'val' (type: boolean), (c2 regexp 'val' = c4 regexp 'val') (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(c2 regexp 'val') -> 9:boolean, VectorUDFAdaptor(c4 regexp 'val') -> 10:boolean, LongColEqualLongColumn(col 11:boolean, col 12:boolean)(children: VectorUDFAdaptor(c2 regexp 'val') -> 11:boolean, VectorUDFAdaptor(c4 regexp 'val') -> 12:boolean) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint, bigint, bigint, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  c2 regexp 'val',
  c4 regexp 'val',
  (c2 regexp 'val') = (c4 regexp 'val')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  c2 regexp 'val',
  c4 regexp 'val',
  (c2 regexp 'val') = (c4 regexp 'val')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
true	true	true
PREHOOK: query: explain vectorization detail
select
  regexp_extract(c2, 'val_([0-9]+)', 1),
  regexp_extract(c4, 'val_([0-9]+)', 1),
  regexp_extract(c2, 'val_([0-9]+)', 1) = regexp_extract(c4, 'val_([0-9]+)', 1)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  regexp_extract(c2, 'val_([0-9]+)', 1),
  regexp_extract(c4, 'val_([0-9]+)', 1),
  regexp_extract(c2, 'val_([0-9]+)', 1) = regexp_extract(c4, 'val_([0-9]+)', 1)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: regexp_extract(c2, 'val_([0-9]+)', 1) (type: string), regexp_extract(c4, 'val_([0-9]+)', 1) (type: string), (regexp_extract(c2, 'val_([0-9]+)', 1) = regexp_extract(c4, 'val_([0-9]+)', 1)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(regexp_extract(c2, 'val_([0-9]+)', 1)) -> 9:string, VectorUDFAdaptor(regexp_extract(c4, 'val_([0-9]+)', 1)) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: VectorUDFAdaptor(regexp_extract(c2, 'val_([0-9]+)', 1)) -> 11:string, VectorUDFAdaptor(regexp_extract(c4, 'val_([0-9]+)', 1)) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  regexp_extract(c2, 'val_([0-9]+)', 1),
  regexp_extract(c4, 'val_([0-9]+)', 1),
  regexp_extract(c2, 'val_([0-9]+)', 1) = regexp_extract(c4, 'val_([0-9]+)', 1)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  regexp_extract(c2, 'val_([0-9]+)', 1),
  regexp_extract(c4, 'val_([0-9]+)', 1),
  regexp_extract(c2, 'val_([0-9]+)', 1) = regexp_extract(c4, 'val_([0-9]+)', 1)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
238	238	true
PREHOOK: query: explain vectorization detail
select
  regexp_replace(c2, 'val', 'replaced'),
  regexp_replace(c4, 'val', 'replaced'),
  regexp_replace(c2, 'val', 'replaced') = regexp_replace(c4, 'val', 'replaced')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  regexp_replace(c2, 'val', 'replaced'),
  regexp_replace(c4, 'val', 'replaced'),
  regexp_replace(c2, 'val', 'replaced') = regexp_replace(c4, 'val', 'replaced')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: regexp_replace(c2, 'val', 'replaced') (type: string), regexp_replace(c4, 'val', 'replaced') (type: string), (regexp_replace(c2, 'val', 'replaced') = regexp_replace(c4, 'val', 'replaced')) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(regexp_replace(c2, 'val', 'replaced')) -> 9:string, VectorUDFAdaptor(regexp_replace(c4, 'val', 'replaced')) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: VectorUDFAdaptor(regexp_replace(c2, 'val', 'replaced')) -> 11:string, VectorUDFAdaptor(regexp_replace(c4, 'val', 'replaced')) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  regexp_replace(c2, 'val', 'replaced'),
  regexp_replace(c4, 'val', 'replaced'),
  regexp_replace(c2, 'val', 'replaced') = regexp_replace(c4, 'val', 'replaced')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  regexp_replace(c2, 'val', 'replaced'),
  regexp_replace(c4, 'val', 'replaced'),
  regexp_replace(c2, 'val', 'replaced') = regexp_replace(c4, 'val', 'replaced')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
replaced_238	replaced_238	true
PREHOOK: query: explain vectorization detail
select
  reverse(c2),
  reverse(c4),
  reverse(c2) = reverse(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  reverse(c2),
  reverse(c4),
  reverse(c2) = reverse(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: reverse(c2) (type: string), reverse(c4) (type: string), (reverse(c2) = reverse(c4)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(reverse(c2)) -> 9:string, VectorUDFAdaptor(reverse(c4)) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: VectorUDFAdaptor(reverse(c2)) -> 11:string, VectorUDFAdaptor(reverse(c4)) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  reverse(c2),
  reverse(c4),
  reverse(c2) = reverse(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  reverse(c2),
  reverse(c4),
  reverse(c2) = reverse(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
832_lav	832_lav	true
PREHOOK: query: explain vectorization detail
select
  rpad(c2, 15, ' '),
  rpad(c4, 15, ' '),
  rpad(c2, 15, ' ') = rpad(c4, 15, ' ')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  rpad(c2, 15, ' '),
  rpad(c4, 15, ' '),
  rpad(c2, 15, ' ') = rpad(c4, 15, ' ')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: rpad(c2, 15, ' ') (type: string), rpad(c4, 15, ' ') (type: string), (rpad(c2, 15, ' ') = rpad(c4, 15, ' ')) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: VectorUDFAdaptor(rpad(c2, 15, ' ')) -> 9:string, VectorUDFAdaptor(rpad(c4, 15, ' ')) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: VectorUDFAdaptor(rpad(c2, 15, ' ')) -> 11:string, VectorUDFAdaptor(rpad(c4, 15, ' ')) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  rpad(c2, 15, ' '),
  rpad(c4, 15, ' '),
  rpad(c2, 15, ' ') = rpad(c4, 15, ' ')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  rpad(c2, 15, ' '),
  rpad(c4, 15, ' '),
  rpad(c2, 15, ' ') = rpad(c4, 15, ' ')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
val_238        	val_238        	true
PREHOOK: query: explain vectorization detail
select
  rtrim(c2),
  rtrim(c4),
  rtrim(c2) = rtrim(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  rtrim(c2),
  rtrim(c4),
  rtrim(c2) = rtrim(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: rtrim(c2) (type: string), rtrim(c4) (type: string), (rtrim(c2) = rtrim(c4)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: StringRTrim(col 1:string) -> 9:string, StringRTrim(col 3:varchar(20)) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: StringRTrim(col 1:string) -> 11:string, StringRTrim(col 3:varchar(20)) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  rtrim(c2),
  rtrim(c4),
  rtrim(c2) = rtrim(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  rtrim(c2),
  rtrim(c4),
  rtrim(c2) = rtrim(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
val_238	val_238	true
PREHOOK: query: explain vectorization detail
select
  sentences('See spot run.  See jane run.'),
  sentences(cast('See spot run.  See jane run.' as varchar(50)))
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  sentences('See spot run.  See jane run.'),
  sentences(cast('See spot run.  See jane run.' as varchar(50)))
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 732 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: sentences('See spot run.  See jane run.') (type: array<array<string>>), sentences('See spot run.  See jane run.') (type: array<array<string>>)
                    outputColumnNames: _col0, _col1
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10]
                        selectExpressions: VectorUDFAdaptor(sentences('See spot run.  See jane run.')) -> 9:array<array<string>>, VectorUDFAdaptor(sentences('See spot run.  See jane run.')) -> 10:array<array<string>>
                    Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: []
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [array<array<string>>, array<array<string>>]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  sentences('See spot run.  See jane run.'),
  sentences(cast('See spot run.  See jane run.' as varchar(50)))
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  sentences('See spot run.  See jane run.'),
  sentences(cast('See spot run.  See jane run.' as varchar(50)))
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
[["See","spot","run"],["See","jane","run"]]	[["See","spot","run"],["See","jane","run"]]
PREHOOK: query: explain vectorization detail
select
  split(c2, '_'),
  split(c4, '_')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  split(c2, '_'),
  split(c4, '_')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: split(c2, '_') (type: array<string>), split(c4, '_') (type: array<string>)
                    outputColumnNames: _col0, _col1
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10]
                        selectExpressions: VectorUDFAdaptor(split(c2, '_')) -> 9:array<string>, VectorUDFAdaptor(split(c4, '_')) -> 10:array<string>
                    Statistics: Num rows: 1 Data size: 3840 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 3840 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 3840 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [array<string>, array<string>]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  split(c2, '_'),
  split(c4, '_')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  split(c2, '_'),
  split(c4, '_')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
["val","238"]	["val","238"]
PREHOOK: query: explain vectorization detail
select
  str_to_map('a:1,b:2,c:3',',',':'),
  str_to_map(cast('a:1,b:2,c:3' as varchar(20)),',',':')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  str_to_map('a:1,b:2,c:3',',',':'),
  str_to_map(cast('a:1,b:2,c:3' as varchar(20)),',',':')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 732 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: str_to_map('a:1,b:2,c:3',',',':') (type: map<string,string>), str_to_map('a:1,b:2,c:3',',',':') (type: map<string,string>)
                    outputColumnNames: _col0, _col1
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10]
                        selectExpressions: VectorUDFAdaptor(str_to_map('a:1,b:2,c:3',',',':')) -> 9:map<string,string>, VectorUDFAdaptor(str_to_map('a:1,b:2,c:3',',',':')) -> 10:map<string,string>
                    Statistics: Num rows: 1 Data size: 1508 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 1508 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 1508 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: true
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: []
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [map<string,string>, map<string,string>]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  str_to_map('a:1,b:2,c:3',',',':'),
  str_to_map(cast('a:1,b:2,c:3' as varchar(20)),',',':')
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  str_to_map('a:1,b:2,c:3',',',':'),
  str_to_map(cast('a:1,b:2,c:3' as varchar(20)),',',':')
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
{"a":"1","b":"2","c":"3"}	{"a":"1","b":"2","c":"3"}
PREHOOK: query: explain vectorization detail
select
  substr(c2, 1, 3),
  substr(c4, 1, 3),
  substr(c2, 1, 3) = substr(c4, 1, 3)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  substr(c2, 1, 3),
  substr(c4, 1, 3),
  substr(c2, 1, 3) = substr(c4, 1, 3)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: substr(c2, 1, 3) (type: string), substr(c4, 1, 3) (type: string), (substr(c2, 1, 3) = substr(c4, 1, 3)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: StringSubstrColStartLen(col 1:string, start 0, length 3) -> 9:string, StringSubstrColStartLen(col 3:varchar(20), start 0, length 3) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: StringSubstrColStartLen(col 1:string, start 0, length 3) -> 11:string, StringSubstrColStartLen(col 3:varchar(20), start 0, length 3) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  substr(c2, 1, 3),
  substr(c4, 1, 3),
  substr(c2, 1, 3) = substr(c4, 1, 3)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  substr(c2, 1, 3),
  substr(c4, 1, 3),
  substr(c2, 1, 3) = substr(c4, 1, 3)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
val	val	true
PREHOOK: query: explain vectorization detail
select
  trim(c2),
  trim(c4),
  trim(c2) = trim(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  trim(c2),
  trim(c4),
  trim(c2) = trim(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: trim(c2) (type: string), trim(c4) (type: string), (trim(c2) = trim(c4)) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [9, 10, 13]
                        selectExpressions: StringTrim(col 1:string) -> 9:string, StringTrim(col 3:varchar(20)) -> 10:string, StringGroupColEqualStringGroupColumn(col 11:string, col 12:string)(children: StringTrim(col 1:string) -> 11:string, StringTrim(col 3:varchar(20)) -> 12:string) -> 13:boolean
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 1
                      Limit Vectorization:
                          className: VectorLimitOperator
                          native: true
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        File Sink Vectorization:
                            className: VectorFileSinkOperator
                            native: false
                        Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string, string, string, bigint]

  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select
  trim(c2),
  trim(c4),
  trim(c2) = trim(c4)
from varchar_udf_1_n2 limit 1
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  trim(c2),
  trim(c4),
  trim(c2) = trim(c4)
from varchar_udf_1_n2 limit 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
val_238	val_238	true
PREHOOK: query: explain vectorization detail
select
  compute_stats(c2, 16),
  compute_stats(c4, 16)
from varchar_udf_1_n2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  compute_stats(c2, 16),
  compute_stats(c4, 16)
from varchar_udf_1_n2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: c2 (type: string), c4 (type: varchar(20))
                    outputColumnNames: _col0, _col2
                    Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: compute_stats(_col0, 16), compute_stats(_col2, 16)
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        sort order: 
                        Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
            Execution mode: llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                notVectorizedReason: Aggregation Function expression for GROUPBY operator: UDF compute_stats not supported
                vectorized: false
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: Aggregation Function expression for GROUPBY operator: UDF compute_stats not supported
                vectorized: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  compute_stats(c2, 'fm', 16),
  compute_stats(c4, 'fm', 16)
from varchar_udf_1_n2
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  compute_stats(c2, 'fm', 16),
  compute_stats(c4, 'fm', 16)
from varchar_udf_1_n2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
{"columntype":"String","maxlength":7,"avglength":7.0,"countnulls":0,"numdistinctvalues":1,"ndvbitvector":FM                                                 }	{"columntype":"String","maxlength":7,"avglength":7.0,"countnulls":0,"numdistinctvalues":1,"ndvbitvector":FM                                                 }
PREHOOK: query: explain vectorization detail
select
  min(c2),
  min(c4)
from varchar_udf_1_n2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  min(c2),
  min(c4)
from varchar_udf_1_n2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: c2 (type: string), c4 (type: varchar(20))
                    outputColumnNames: c2, c4
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [1, 3]
                    Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(c2), min(c4)
                      Group By Vectorization:
                          aggregators: VectorUDAFMinString(col 1:string) -> string, VectorUDAFMinString(col 3:varchar(20)) -> varchar(20)
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: [0, 1]
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        sort order: 
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkEmptyKeyOperator
                            keyColumnNums: []
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: [0, 1]
                        Statistics: Num rows: 1 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: string), _col1 (type: varchar(20))
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: 
                reduceColumnSortOrder: 
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: VALUE._col0:string, VALUE._col1:varchar(20)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), min(VALUE._col1)
                Group By Vectorization:
                    aggregators: VectorUDAFMinString(col 0:string) -> string, VectorUDAFMinString(col 1:varchar(20)) -> varchar(20)
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    native: false
                    vectorProcessingMode: GLOBAL
                    projectedOutputColumnNums: [0, 1]
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 1 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  min(c2),
  min(c4)
from varchar_udf_1_n2
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  min(c2),
  min(c4)
from varchar_udf_1_n2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
val_238	val_238
PREHOOK: query: explain vectorization detail
select
  max(c2),
  max(c4)
from varchar_udf_1_n2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select
  max(c2),
  max(c4)
from varchar_udf_1_n2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: varchar_udf_1_n2
                  Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c1:string, 1:c2:string, 2:c3:varchar(10), 3:c4:varchar(20), 4:d1:string, 5:d2:string, 6:d3:varchar(10), 7:d4:varchar(10), 8:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: c2 (type: string), c4 (type: varchar(20))
                    outputColumnNames: c2, c4
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [1, 3]
                    Statistics: Num rows: 1 Data size: 182 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: max(c2), max(c4)
                      Group By Vectorization:
                          aggregators: VectorUDAFMaxString(col 1:string) -> string, VectorUDAFMaxString(col 3:varchar(20)) -> varchar(20)
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: [0, 1]
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        sort order: 
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkEmptyKeyOperator
                            keyColumnNums: []
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: [0, 1]
                        Statistics: Num rows: 1 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: string), _col1 (type: varchar(20))
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 8
                    includeColumns: [1, 3]
                    dataColumns: c1:string, c2:string, c3:varchar(10), c4:varchar(20), d1:string, d2:string, d3:varchar(10), d4:varchar(10)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: 
                reduceColumnSortOrder: 
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: VALUE._col0:string, VALUE._col1:varchar(20)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0), max(VALUE._col1)
                Group By Vectorization:
                    aggregators: VectorUDAFMaxString(col 0:string) -> string, VectorUDAFMaxString(col 1:varchar(20)) -> varchar(20)
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    native: false
                    vectorProcessingMode: GLOBAL
                    projectedOutputColumnNums: [0, 1]
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 1 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select
  max(c2),
  max(c4)
from varchar_udf_1_n2
PREHOOK: type: QUERY
PREHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
POSTHOOK: query: select
  max(c2),
  max(c4)
from varchar_udf_1_n2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@varchar_udf_1_n2
#### A masked pattern was here ####
val_238	val_238
PREHOOK: query: drop table varchar_udf_1_n2
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@varchar_udf_1_n2
PREHOOK: Output: default@varchar_udf_1_n2
POSTHOOK: query: drop table varchar_udf_1_n2
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@varchar_udf_1_n2
POSTHOOK: Output: default@varchar_udf_1_n2
