PREHOOK: query: CREATE TABLE tbl1_n2(key int, value string) CLUSTERED BY (key) SORTED BY (key) INTO 2 BUCKETS
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl1_n2
POSTHOOK: query: CREATE TABLE tbl1_n2(key int, value string) CLUSTERED BY (key) SORTED BY (key) INTO 2 BUCKETS
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl1_n2
PREHOOK: query: CREATE TABLE tbl2_n1(key int, value string) CLUSTERED BY (key) SORTED BY (key) INTO 2 BUCKETS
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl2_n1
POSTHOOK: query: CREATE TABLE tbl2_n1(key int, value string) CLUSTERED BY (key) SORTED BY (key) INTO 2 BUCKETS
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl2_n1
PREHOOK: query: insert overwrite table tbl1_n2 select * from src where key < 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@tbl1_n2
POSTHOOK: query: insert overwrite table tbl1_n2 select * from src where key < 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@tbl1_n2
POSTHOOK: Lineage: tbl1_n2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: tbl1_n2.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: insert overwrite table tbl2_n1 select * from src where key < 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@tbl2_n1
POSTHOOK: query: insert overwrite table tbl2_n1 select * from src where key < 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@tbl2_n1
POSTHOOK: Lineage: tbl2_n1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: tbl2_n1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: CREATE TABLE dest1_n20(k1 int, k2 int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@dest1_n20
POSTHOOK: query: CREATE TABLE dest1_n20(k1 int, k2 int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@dest1_n20
PREHOOK: query: CREATE TABLE dest2_n4(k1 string, k2 string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@dest2_n4
POSTHOOK: query: CREATE TABLE dest2_n4(k1 string, k2 string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@dest2_n4
PREHOOK: query: explain 
from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
PREHOOK: type: QUERY
POSTHOOK: query: explain 
from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-3
  Stage-4 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-3
  Stage-5 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
        Reducer 3 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                      Merge Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 16 Data size: 2976 Basic stats: COMPLETE Column stats: COMPLETE
                        Select Operator
                          expressions: _col0 (type: int), _col2 (type: int)
                          outputColumnNames: _col0, _col1
                          Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.dest1_n20
                          Select Operator
                            expressions: _col0 (type: int), _col1 (type: int)
                            outputColumnNames: k1, k2
                            Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: COMPLETE
                            Group By Operator
                              aggregations: compute_stats(k1, 'hll'), compute_stats(k2, 'hll')
                              mode: hash
                              outputColumnNames: _col0, _col1
                              Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: COMPLETE
                              Reduce Output Operator
                                sort order: 
                                Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: COMPLETE
                                value expressions: _col0 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>)
                        Select Operator
                          expressions: _col1 (type: string), _col3 (type: string)
                          outputColumnNames: _col0, _col1
                          Statistics: Num rows: 16 Data size: 2848 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 16 Data size: 2848 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.dest2_n4
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: string)
                            outputColumnNames: k1, k2
                            Statistics: Num rows: 16 Data size: 2848 Basic stats: COMPLETE Column stats: COMPLETE
                            Group By Operator
                              aggregations: compute_stats(k1, 'hll'), compute_stats(k2, 'hll')
                              mode: hash
                              outputColumnNames: _col0, _col1
                              Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                              Reduce Output Operator
                                sort order: 
                                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                                value expressions: _col0 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
            Execution mode: llap
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.dest1_n20

  Stage: Stage-4
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: k1, k2
          Column Types: int, int
          Table: default.dest1_n20

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.dest2_n4

  Stage: Stage-5
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: k1, k2
          Column Types: string, string
          Table: default.dest2_n4

PREHOOK: query: from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl1_n2
PREHOOK: Input: default@tbl2_n1
PREHOOK: Output: default@dest1_n20
PREHOOK: Output: default@dest2_n4
POSTHOOK: query: from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl1_n2
POSTHOOK: Input: default@tbl2_n1
POSTHOOK: Output: default@dest1_n20
POSTHOOK: Output: default@dest2_n4
POSTHOOK: Lineage: dest1_n20.k1 SIMPLE [(tbl1_n2)a.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: dest1_n20.k2 SIMPLE [(tbl2_n1)b.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: dest2_n4.k1 SIMPLE [(tbl1_n2)a.FieldSchema(name:value, type:string, comment:null), ]
POSTHOOK: Lineage: dest2_n4.k2 SIMPLE [(tbl2_n1)b.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: select * from dest1_n20
PREHOOK: type: QUERY
PREHOOK: Input: default@dest1_n20
#### A masked pattern was here ####
POSTHOOK: query: select * from dest1_n20
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest1_n20
#### A masked pattern was here ####
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
2	2
4	4
5	5
5	5
5	5
5	5
5	5
5	5
5	5
5	5
5	5
8	8
9	9
PREHOOK: query: select * from dest2_n4
PREHOOK: type: QUERY
PREHOOK: Input: default@dest2_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from dest2_n4
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest2_n4
#### A masked pattern was here ####
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_2	val_2
val_4	val_4
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_8	val_8
val_9	val_9
PREHOOK: query: explain 
from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
PREHOOK: type: QUERY
POSTHOOK: query: explain 
from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-3
  Stage-4 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-3
  Stage-5 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
        Reducer 3 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                      Merge Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 16 Data size: 2976 Basic stats: COMPLETE Column stats: COMPLETE
                        Select Operator
                          expressions: _col0 (type: int), _col2 (type: int)
                          outputColumnNames: _col0, _col1
                          Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.dest1_n20
                          Select Operator
                            expressions: _col0 (type: int), _col1 (type: int)
                            outputColumnNames: k1, k2
                            Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: COMPLETE
                            Group By Operator
                              aggregations: compute_stats(k1, 'hll'), compute_stats(k2, 'hll')
                              mode: hash
                              outputColumnNames: _col0, _col1
                              Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: COMPLETE
                              Reduce Output Operator
                                sort order: 
                                Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: COMPLETE
                                value expressions: _col0 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>)
                        Select Operator
                          expressions: _col1 (type: string), _col3 (type: string)
                          outputColumnNames: _col0, _col1
                          Statistics: Num rows: 16 Data size: 2848 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 16 Data size: 2848 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.dest2_n4
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: string)
                            outputColumnNames: k1, k2
                            Statistics: Num rows: 16 Data size: 2848 Basic stats: COMPLETE Column stats: COMPLETE
                            Group By Operator
                              aggregations: compute_stats(k1, 'hll'), compute_stats(k2, 'hll')
                              mode: hash
                              outputColumnNames: _col0, _col1
                              Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                              Reduce Output Operator
                                sort order: 
                                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                                value expressions: _col0 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
            Execution mode: llap
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.dest1_n20

  Stage: Stage-4
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: k1, k2
          Column Types: int, int
          Table: default.dest1_n20

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.dest2_n4

  Stage: Stage-5
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: k1, k2
          Column Types: string, string
          Table: default.dest2_n4

PREHOOK: query: from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl1_n2
PREHOOK: Input: default@tbl2_n1
PREHOOK: Output: default@dest1_n20
PREHOOK: Output: default@dest2_n4
POSTHOOK: query: from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl1_n2
POSTHOOK: Input: default@tbl2_n1
POSTHOOK: Output: default@dest1_n20
POSTHOOK: Output: default@dest2_n4
POSTHOOK: Lineage: dest1_n20.k1 SIMPLE [(tbl1_n2)a.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: dest1_n20.k2 SIMPLE [(tbl2_n1)b.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: dest2_n4.k1 SIMPLE [(tbl1_n2)a.FieldSchema(name:value, type:string, comment:null), ]
POSTHOOK: Lineage: dest2_n4.k2 SIMPLE [(tbl2_n1)b.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: select * from dest1_n20
PREHOOK: type: QUERY
PREHOOK: Input: default@dest1_n20
#### A masked pattern was here ####
POSTHOOK: query: select * from dest1_n20
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest1_n20
#### A masked pattern was here ####
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
2	2
4	4
5	5
5	5
5	5
5	5
5	5
5	5
5	5
5	5
5	5
8	8
9	9
PREHOOK: query: select * from dest2_n4
PREHOOK: type: QUERY
PREHOOK: Input: default@dest2_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from dest2_n4
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest2_n4
#### A masked pattern was here ####
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_2	val_2
val_4	val_4
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_8	val_8
val_9	val_9
PREHOOK: query: explain 
from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
PREHOOK: type: QUERY
POSTHOOK: query: explain 
from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-3
  Stage-4 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-3
  Stage-5 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
        Reducer 3 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 10 Data size: 930 Basic stats: COMPLETE Column stats: COMPLETE
                      Merge Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 16 Data size: 2976 Basic stats: COMPLETE Column stats: COMPLETE
                        Select Operator
                          expressions: _col0 (type: int), _col2 (type: int)
                          outputColumnNames: _col0, _col1
                          Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.dest1_n20
                          Select Operator
                            expressions: _col0 (type: int), _col1 (type: int)
                            outputColumnNames: k1, k2
                            Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: COMPLETE
                            Group By Operator
                              aggregations: compute_stats(k1, 'hll'), compute_stats(k2, 'hll')
                              mode: hash
                              outputColumnNames: _col0, _col1
                              Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: COMPLETE
                              Reduce Output Operator
                                sort order: 
                                Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: COMPLETE
                                value expressions: _col0 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>)
                        Select Operator
                          expressions: _col1 (type: string), _col3 (type: string)
                          outputColumnNames: _col0, _col1
                          Statistics: Num rows: 16 Data size: 2848 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 16 Data size: 2848 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.dest2_n4
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: string)
                            outputColumnNames: k1, k2
                            Statistics: Num rows: 16 Data size: 2848 Basic stats: COMPLETE Column stats: COMPLETE
                            Group By Operator
                              aggregations: compute_stats(k1, 'hll'), compute_stats(k2, 'hll')
                              mode: hash
                              outputColumnNames: _col0, _col1
                              Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                              Reduce Output Operator
                                sort order: 
                                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                                value expressions: _col0 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
            Execution mode: llap
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.dest1_n20

  Stage: Stage-4
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: k1, k2
          Column Types: int, int
          Table: default.dest1_n20

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.dest2_n4

  Stage: Stage-5
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: k1, k2
          Column Types: string, string
          Table: default.dest2_n4

PREHOOK: query: from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl1_n2
PREHOOK: Input: default@tbl2_n1
PREHOOK: Output: default@dest1_n20
PREHOOK: Output: default@dest2_n4
POSTHOOK: query: from (
  SELECT a.key key1, a.value value1, b.key key2, b.value value2 
  FROM tbl1_n2 a JOIN tbl2_n1 b 
  ON a.key = b.key ) subq
INSERT OVERWRITE TABLE dest1_n20 select key1, key2
INSERT OVERWRITE TABLE dest2_n4 select value1, value2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl1_n2
POSTHOOK: Input: default@tbl2_n1
POSTHOOK: Output: default@dest1_n20
POSTHOOK: Output: default@dest2_n4
POSTHOOK: Lineage: dest1_n20.k1 SIMPLE [(tbl1_n2)a.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: dest1_n20.k2 SIMPLE [(tbl2_n1)b.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: dest2_n4.k1 SIMPLE [(tbl1_n2)a.FieldSchema(name:value, type:string, comment:null), ]
POSTHOOK: Lineage: dest2_n4.k2 SIMPLE [(tbl2_n1)b.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: select * from dest1_n20
PREHOOK: type: QUERY
PREHOOK: Input: default@dest1_n20
#### A masked pattern was here ####
POSTHOOK: query: select * from dest1_n20
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest1_n20
#### A masked pattern was here ####
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
0	0
2	2
4	4
5	5
5	5
5	5
5	5
5	5
5	5
5	5
5	5
5	5
8	8
9	9
PREHOOK: query: select * from dest2_n4
PREHOOK: type: QUERY
PREHOOK: Input: default@dest2_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from dest2_n4
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest2_n4
#### A masked pattern was here ####
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_0	val_0
val_2	val_2
val_4	val_4
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_5	val_5
val_8	val_8
val_9	val_9
