PREHOOK: query: CREATE TABLE T1_text(key STRING, val STRING) STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@T1_text
POSTHOOK: query: CREATE TABLE T1_text(key STRING, val STRING) STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@T1_text
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/T1.txt' INTO TABLE T1_text
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@t1_text
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/T1.txt' INTO TABLE T1_text
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@t1_text
PREHOOK: query: CREATE TABLE T1 STORED AS ORC AS SELECT * FROM T1_text
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@t1_text
PREHOOK: Output: database:default
PREHOOK: Output: default@T1
POSTHOOK: query: CREATE TABLE T1 STORED AS ORC AS SELECT * FROM T1_text
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@t1_text
POSTHOOK: Output: database:default
POSTHOOK: Output: default@T1
POSTHOOK: Lineage: t1.key SIMPLE [(t1_text)t1_text.FieldSchema(name:key, type:string, comment:null), ]
POSTHOOK: Lineage: t1.val SIMPLE [(t1_text)t1_text.FieldSchema(name:val, type:string, comment:null), ]
PREHOOK: query: EXPLAIN
SELECT key, val, count(1) FROM T1 GROUP BY key, val with rollup
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN
SELECT key, val, count(1) FROM T1 GROUP BY key, val with rollup
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), val (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count(1)
                      keys: _col0 (type: string), _col1 (type: string), 0 (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                        Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col3 (type: bigint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col3
                Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                pruneGroupingSetId: true
                Select Operator
                  expressions: _col0 (type: string), _col1 (type: string), _col3 (type: bigint)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key, val, count(1) FROM T1 GROUP BY key, val with rollup
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, val, count(1) FROM T1 GROUP BY key, val with rollup
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
#### A masked pattern was here ####
1	11	1
1	NULL	1
2	12	1
2	NULL	1
3	13	1
3	NULL	1
7	17	1
7	NULL	1
8	18	1
8	28	1
8	NULL	2
NULL	NULL	6
PREHOOK: query: EXPLAIN
SELECT key, count(distinct val) FROM T1 GROUP BY key with rollup
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN
SELECT key, count(distinct val) FROM T1 GROUP BY key with rollup
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), val (type: string)
                    outputColumnNames: key, val
                    Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count(DISTINCT val)
                      keys: key (type: string), 0 (type: int), val (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 12 Data size: 2052 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: int)
                        Statistics: Num rows: 12 Data size: 2052 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col2:0._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col2
                Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                pruneGroupingSetId: true
                Select Operator
                  expressions: _col0 (type: string), _col2 (type: bigint)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key, count(distinct val) FROM T1 GROUP BY key with rollup
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, count(distinct val) FROM T1 GROUP BY key with rollup
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
#### A masked pattern was here ####
1	0
2	0
3	0
7	0
8	0
NULL	0
PREHOOK: query: EXPLAIN
SELECT key, val, count(1) FROM T1 GROUP BY key, val with rollup
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN
SELECT key, val, count(1) FROM T1 GROUP BY key, val with rollup
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), val (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count(1)
                      keys: _col0 (type: string), _col1 (type: string), 0 (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: rand() (type: double)
                        Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col3 (type: bigint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)
                mode: partials
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                  sort order: +++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                  Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col3 (type: bigint)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)
                mode: final
                outputColumnNames: _col0, _col1, _col3
                Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                pruneGroupingSetId: true
                Select Operator
                  expressions: _col0 (type: string), _col1 (type: string), _col3 (type: bigint)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key, val, count(1) FROM T1 GROUP BY key, val with rollup
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, val, count(1) FROM T1 GROUP BY key, val with rollup
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
#### A masked pattern was here ####
1	11	1
1	NULL	1
2	12	1
2	NULL	1
3	13	1
3	NULL	1
7	17	1
7	NULL	1
8	18	1
8	28	1
8	NULL	2
NULL	NULL	6
PREHOOK: query: EXPLAIN
SELECT key, count(distinct val) FROM T1 GROUP BY key with rollup
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN
SELECT key, count(distinct val) FROM T1 GROUP BY key with rollup
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), val (type: string)
                    outputColumnNames: key, val
                    Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count(DISTINCT val)
                      keys: key (type: string), 0 (type: int), val (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 12 Data size: 2052 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 12 Data size: 2052 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col2:0._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: int)
                mode: partials
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 12 Data size: 2052 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: int)
                  sort order: ++
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 12 Data size: 2052 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col2 (type: bigint)
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: int)
                mode: final
                outputColumnNames: _col0, _col2
                Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                pruneGroupingSetId: true
                Select Operator
                  expressions: _col0 (type: string), _col2 (type: bigint)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key, count(distinct val) FROM T1 GROUP BY key with rollup
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, count(distinct val) FROM T1 GROUP BY key with rollup
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
#### A masked pattern was here ####
1	0
2	0
3	0
7	0
8	0
NULL	0
PREHOOK: query: CREATE TABLE T2(key1 STRING, key2 STRING, val INT) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@T2
POSTHOOK: query: CREATE TABLE T2(key1 STRING, key2 STRING, val INT) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@T2
PREHOOK: query: CREATE TABLE T3(key1 STRING, key2 STRING, val INT) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@T3
POSTHOOK: query: CREATE TABLE T3(key1 STRING, key2 STRING, val INT) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@T3
PREHOOK: query: EXPLAIN
FROM T1
INSERT OVERWRITE TABLE T2 SELECT key, val, count(1) group by key, val with rollup
INSERT OVERWRITE TABLE T3 SELECT key, val, sum(1) group by rollup(key, val)
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN
FROM T1
INSERT OVERWRITE TABLE T2 SELECT key, val, count(1) group by key, val with rollup
INSERT OVERWRITE TABLE T3 SELECT key, val, sum(1) group by rollup(key, val)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-3
  Stage-4 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-3
  Stage-5 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Map 1 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 4 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), val (type: string)
                    outputColumnNames: key, val
                    Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count(1)
                      keys: key (type: string), val (type: string), 0 (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: rand() (type: double)
                        Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col3 (type: bigint)
                  Select Operator
                    expressions: key (type: string), val (type: string)
                    outputColumnNames: key, val
                    Statistics: Num rows: 6 Data size: 1026 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(1)
                      keys: key (type: string), val (type: string), 0 (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: rand() (type: double)
                        Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col3 (type: bigint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)
                mode: partials
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                  sort order: +++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                  Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col3 (type: bigint)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)
                mode: final
                outputColumnNames: _col0, _col1, _col3
                Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                pruneGroupingSetId: true
                Select Operator
                  expressions: _col0 (type: string), _col1 (type: string), UDFToInteger(_col3) (type: int)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                        output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                        serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                        name: default.t2
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)
                mode: partials
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                  sort order: +++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                  Statistics: Num rows: 18 Data size: 3078 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col3 (type: bigint)
        Reducer 5 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)
                mode: final
                outputColumnNames: _col0, _col1, _col3
                Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                pruneGroupingSetId: true
                Select Operator
                  expressions: _col0 (type: string), _col1 (type: string), UDFToInteger(_col3) (type: int)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 9 Data size: 1539 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                        output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                        serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                        name: default.t3

  Stage: Stage-3
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.t2

  Stage: Stage-4
    Stats-Aggr Operator

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.t3

  Stage: Stage-5
    Stats-Aggr Operator

PREHOOK: query: FROM T1
INSERT OVERWRITE TABLE T2 SELECT key, val, count(1) group by key, val with rollup
INSERT OVERWRITE TABLE T3 SELECT key, val, sum(1) group by key, val with rollup
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
PREHOOK: Output: default@t2
PREHOOK: Output: default@t3
POSTHOOK: query: FROM T1
INSERT OVERWRITE TABLE T2 SELECT key, val, count(1) group by key, val with rollup
INSERT OVERWRITE TABLE T3 SELECT key, val, sum(1) group by key, val with rollup
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
POSTHOOK: Output: default@t2
POSTHOOK: Output: default@t3
POSTHOOK: Lineage: t2.key1 SIMPLE [(t1)t1.FieldSchema(name:key, type:string, comment:null), ]
POSTHOOK: Lineage: t2.key2 SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comment:null), ]
POSTHOOK: Lineage: t2.val EXPRESSION [(t1)t1.null, ]
POSTHOOK: Lineage: t3.key1 SIMPLE [(t1)t1.FieldSchema(name:key, type:string, comment:null), ]
POSTHOOK: Lineage: t3.key2 SIMPLE [(t1)t1.FieldSchema(name:val, type:string, comment:null), ]
POSTHOOK: Lineage: t3.val EXPRESSION [(t1)t1.null, ]
