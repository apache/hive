PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum UNBOUNDED end frame is not supported for ROWS window type
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: sum_window_2
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), rank_window_0 (type: int), dense_rank_window_1 (type: int), round(sum_window_2, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size,
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size,
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	r	dr	s1
Manufacturer#1	almond antique burnished rose metallic	2	1	1	1173.15
Manufacturer#1	almond antique burnished rose metallic	2	1	1	2346.3
Manufacturer#1	almond antique chartreuse lavender yellow	34	3	2	4100.06
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4	3	5702.65
Manufacturer#1	almond aquamarine burnished black steel	28	5	4	7117.07
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6	5	8749.73
Manufacturer#2	almond antique violet chocolate turquoise	14	1	1	1690.68
Manufacturer#2	almond antique violet turquoise frosted	40	2	2	3491.38
Manufacturer#2	almond aquamarine midnight light salmon	2	3	3	5523.36
Manufacturer#2	almond aquamarine rose maroon antique	25	4	4	7222.02
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5	5	8923.62
Manufacturer#3	almond antique chartreuse khaki white	17	1	1	1671.68
Manufacturer#3	almond antique forest lavender goldenrod	14	2	2	2861.95
Manufacturer#3	almond antique metallic orange dim	19	3	3	4272.34
Manufacturer#3	almond antique misty red olive	1	4	4	6195.32
Manufacturer#3	almond antique olive coral navajo	45	5	5	7532.61
Manufacturer#4	almond antique gainsboro frosted violet	10	1	1	1620.67
Manufacturer#4	almond antique violet mint lemon	39	2	2	2996.09
Manufacturer#4	almond aquamarine floral ivory bisque	27	3	3	4202.35
Manufacturer#4	almond aquamarine yellow dodger mint	7	4	4	6047.27
Manufacturer#4	almond azure aquamarine papaya violet	12	5	5	7337.62
Manufacturer#5	almond antique blue firebrick mint	31	1	1	1789.69
Manufacturer#5	almond antique medium spring khaki	6	2	2	3401.35
Manufacturer#5	almond antique sky peru orange	2	3	3	5190.08
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4	4	6208.18
Manufacturer#5	almond azure blanched chiffon midnight	23	5	5	7672.66
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
min(p_retailprice),
rank() over(distribute by p_mfgr sort by p_name)as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
min(p_retailprice),
rank() over(distribute by p_mfgr sort by p_name)as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: p_name (type: string), p_mfgr (type: string), p_size (type: int), p_retailprice (type: double)
                    outputColumnNames: p_name, p_mfgr, p_size, p_retailprice
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [1, 2, 5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(p_retailprice)
                      Group By Vectorization:
                          aggregators: VectorUDAFMinDouble(col 7:double) -> double
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 2:string, col 1:string, col 5:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: [0]
                      keys: p_mfgr (type: string), p_name (type: string), p_size (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: string)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1, 2]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            partitionColumnNums: [0]
                            valueColumnNums: [3]
                        Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col3 (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: Only PTF directly under reduce-shuffle is supported
                vectorized: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: string, _col2: int, _col3: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: lag_window_2
                              arguments: _col2, 1, _col2
                              name: lag
                              window function: GenericUDAFLagEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: double), rank_window_0 (type: int), dense_rank_window_1 (type: int), _col2 (type: int), (_col2 - lag_window_2) (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                    Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, 
min(p_retailprice),
rank() over(distribute by p_mfgr sort by p_name)as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, 
min(p_retailprice),
rank() over(distribute by p_mfgr sort by p_name)as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	_c3	r	dr	p_size	deltasz
Manufacturer#1	almond antique burnished rose metallic	2	1173.15	1	1	2	0
Manufacturer#1	almond antique chartreuse lavender yellow	34	1753.76	2	2	34	32
Manufacturer#1	almond antique salmon chartreuse burlywood	6	1602.59	3	3	6	-28
Manufacturer#1	almond aquamarine burnished black steel	28	1414.42	4	4	28	22
Manufacturer#1	almond aquamarine pink moccasin thistle	42	1632.66	5	5	42	14
Manufacturer#2	almond antique violet chocolate turquoise	14	1690.68	1	1	14	0
Manufacturer#2	almond antique violet turquoise frosted	40	1800.7	2	2	40	26
Manufacturer#2	almond aquamarine midnight light salmon	2	2031.98	3	3	2	-38
Manufacturer#2	almond aquamarine rose maroon antique	25	1698.66	4	4	25	23
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	1701.6	5	5	18	-7
Manufacturer#3	almond antique chartreuse khaki white	17	1671.68	1	1	17	0
Manufacturer#3	almond antique forest lavender goldenrod	14	1190.27	2	2	14	-3
Manufacturer#3	almond antique metallic orange dim	19	1410.39	3	3	19	5
Manufacturer#3	almond antique misty red olive	1	1922.98	4	4	1	-18
Manufacturer#3	almond antique olive coral navajo	45	1337.29	5	5	45	44
Manufacturer#4	almond antique gainsboro frosted violet	10	1620.67	1	1	10	0
Manufacturer#4	almond antique violet mint lemon	39	1375.42	2	2	39	29
Manufacturer#4	almond aquamarine floral ivory bisque	27	1206.26	3	3	27	-12
Manufacturer#4	almond aquamarine yellow dodger mint	7	1844.92	4	4	7	-20
Manufacturer#4	almond azure aquamarine papaya violet	12	1290.35	5	5	12	5
Manufacturer#5	almond antique blue firebrick mint	31	1789.69	1	1	31	0
Manufacturer#5	almond antique medium spring khaki	6	1611.66	2	2	6	-25
Manufacturer#5	almond antique sky peru orange	2	1788.73	3	3	2	-4
Manufacturer#5	almond aquamarine dodger light gainsboro	46	1018.1	4	4	46	44
Manufacturer#5	almond azure blanched chiffon midnight	23	1464.48	5	5	23	-23
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, min(p_retailprice),
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
having p_size > 0
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, min(p_retailprice),
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
having p_size > 0
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 5:int, val 0)
                    predicate: (p_size > 0) (type: boolean)
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(p_retailprice)
                      Group By Vectorization:
                          aggregators: VectorUDAFMinDouble(col 7:double) -> double
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 2:string, col 1:string, col 5:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: [0]
                      keys: p_mfgr (type: string), p_name (type: string), p_size (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: string)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1, 2]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            partitionColumnNums: [0]
                            valueColumnNums: [3]
                        Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col3 (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: Only PTF directly under reduce-shuffle is supported
                vectorized: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: string, _col2: int, _col3: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: lag_window_2
                              arguments: _col2, 1, _col2
                              name: lag
                              window function: GenericUDAFLagEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: double), rank_window_0 (type: int), dense_rank_window_1 (type: int), _col2 (type: int), (_col2 - lag_window_2) (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                    Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, min(p_retailprice),
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
having p_size > 0
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, min(p_retailprice),
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
having p_size > 0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	_c3	r	dr	p_size	deltasz
Manufacturer#1	almond antique burnished rose metallic	2	1173.15	1	1	2	0
Manufacturer#1	almond antique chartreuse lavender yellow	34	1753.76	2	2	34	32
Manufacturer#1	almond antique salmon chartreuse burlywood	6	1602.59	3	3	6	-28
Manufacturer#1	almond aquamarine burnished black steel	28	1414.42	4	4	28	22
Manufacturer#1	almond aquamarine pink moccasin thistle	42	1632.66	5	5	42	14
Manufacturer#2	almond antique violet chocolate turquoise	14	1690.68	1	1	14	0
Manufacturer#2	almond antique violet turquoise frosted	40	1800.7	2	2	40	26
Manufacturer#2	almond aquamarine midnight light salmon	2	2031.98	3	3	2	-38
Manufacturer#2	almond aquamarine rose maroon antique	25	1698.66	4	4	25	23
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	1701.6	5	5	18	-7
Manufacturer#3	almond antique chartreuse khaki white	17	1671.68	1	1	17	0
Manufacturer#3	almond antique forest lavender goldenrod	14	1190.27	2	2	14	-3
Manufacturer#3	almond antique metallic orange dim	19	1410.39	3	3	19	5
Manufacturer#3	almond antique misty red olive	1	1922.98	4	4	1	-18
Manufacturer#3	almond antique olive coral navajo	45	1337.29	5	5	45	44
Manufacturer#4	almond antique gainsboro frosted violet	10	1620.67	1	1	10	0
Manufacturer#4	almond antique violet mint lemon	39	1375.42	2	2	39	29
Manufacturer#4	almond aquamarine floral ivory bisque	27	1206.26	3	3	27	-12
Manufacturer#4	almond aquamarine yellow dodger mint	7	1844.92	4	4	7	-20
Manufacturer#4	almond azure aquamarine papaya violet	12	1290.35	5	5	12	5
Manufacturer#5	almond antique blue firebrick mint	31	1789.69	1	1	31	0
Manufacturer#5	almond antique medium spring khaki	6	1611.66	2	2	6	-25
Manufacturer#5	almond antique sky peru orange	2	1788.73	3	3	2	-4
Manufacturer#5	almond aquamarine dodger light gainsboro	46	1018.1	4	4	46	44
Manufacturer#5	almond azure blanched chiffon midnight	23	1464.48	5	5	23	-23
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd 
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd 
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:string, KEY.reducesinkkey1:string, VALUE._col3:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint]
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1, 0, 2]
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: count_window_0
                              arguments: _col5
                              name: count
                              window function: GenericUDAFCountEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorCount]
                      functionInputExpressions: [col 2:int]
                      functionNames: [count]
                      keyInputColumns: [1, 0]
                      native: true
                      nonKeyInputColumns: [2]
                      orderExpressions: [col 1:string]
                      outputColumns: [3, 1, 0, 2]
                      outputTypes: [bigint, string, string, int]
                      partitionExpressions: [col 0:string]
                      streamingColumns: []
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), count_window_0 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1, 3]
                    Statistics: Num rows: 26 Data size: 5902 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
                      Statistics: Num rows: 26 Data size: 5902 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd 
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd 
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	cd
Manufacturer#1	almond antique burnished rose metallic	2
Manufacturer#1	almond antique burnished rose metallic	2
Manufacturer#1	almond antique chartreuse lavender yellow	3
Manufacturer#1	almond antique salmon chartreuse burlywood	4
Manufacturer#1	almond aquamarine burnished black steel	5
Manufacturer#1	almond aquamarine pink moccasin thistle	6
Manufacturer#2	almond antique violet chocolate turquoise	1
Manufacturer#2	almond antique violet turquoise frosted	2
Manufacturer#2	almond aquamarine midnight light salmon	3
Manufacturer#2	almond aquamarine rose maroon antique	4
Manufacturer#2	almond aquamarine sandy cyan gainsboro	5
Manufacturer#3	almond antique chartreuse khaki white	1
Manufacturer#3	almond antique forest lavender goldenrod	2
Manufacturer#3	almond antique metallic orange dim	3
Manufacturer#3	almond antique misty red olive	4
Manufacturer#3	almond antique olive coral navajo	5
Manufacturer#4	almond antique gainsboro frosted violet	1
Manufacturer#4	almond antique violet mint lemon	2
Manufacturer#4	almond aquamarine floral ivory bisque	3
Manufacturer#4	almond aquamarine yellow dodger mint	4
Manufacturer#4	almond azure aquamarine papaya violet	5
Manufacturer#5	almond antique blue firebrick mint	1
Manufacturer#5	almond antique medium spring khaki	2
Manufacturer#5	almond antique sky peru orange	3
Manufacturer#5	almond aquamarine dodger light gainsboro	4
Manufacturer#5	almond azure blanched chiffon midnight	5
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd, 
p_retailprice, round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz 
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd, 
p_retailprice, round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz 
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum UNBOUNDED end frame is not supported for ROWS window type
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: count_window_2
                              arguments: _col5
                              name: count
                              window function: GenericUDAFCountEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: sum_window_3
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: lag_window_4
                              arguments: _col5, 1, _col5
                              name: lag
                              window function: GenericUDAFLagEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), rank_window_0 (type: int), dense_rank_window_1 (type: int), count_window_2 (type: bigint), _col7 (type: double), round(sum_window_3, 2) (type: double), _col5 (type: int), (_col5 - lag_window_4) (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 26 Data size: 6734 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6734 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd, 
p_retailprice, round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz 
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd, 
p_retailprice, round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz 
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	r	dr	cd	p_retailprice	s1	p_size	deltasz
Manufacturer#1	almond antique burnished rose metallic	1	1	2	1173.15	1173.15	2	0
Manufacturer#1	almond antique burnished rose metallic	1	1	2	1173.15	2346.3	2	0
Manufacturer#1	almond antique chartreuse lavender yellow	3	2	3	1753.76	4100.06	34	32
Manufacturer#1	almond antique salmon chartreuse burlywood	4	3	4	1602.59	5702.65	6	-28
Manufacturer#1	almond aquamarine burnished black steel	5	4	5	1414.42	7117.07	28	22
Manufacturer#1	almond aquamarine pink moccasin thistle	6	5	6	1632.66	8749.73	42	14
Manufacturer#2	almond antique violet chocolate turquoise	1	1	1	1690.68	1690.68	14	0
Manufacturer#2	almond antique violet turquoise frosted	2	2	2	1800.7	3491.38	40	26
Manufacturer#2	almond aquamarine midnight light salmon	3	3	3	2031.98	5523.36	2	-38
Manufacturer#2	almond aquamarine rose maroon antique	4	4	4	1698.66	7222.02	25	23
Manufacturer#2	almond aquamarine sandy cyan gainsboro	5	5	5	1701.6	8923.62	18	-7
Manufacturer#3	almond antique chartreuse khaki white	1	1	1	1671.68	1671.68	17	0
Manufacturer#3	almond antique forest lavender goldenrod	2	2	2	1190.27	2861.95	14	-3
Manufacturer#3	almond antique metallic orange dim	3	3	3	1410.39	4272.34	19	5
Manufacturer#3	almond antique misty red olive	4	4	4	1922.98	6195.32	1	-18
Manufacturer#3	almond antique olive coral navajo	5	5	5	1337.29	7532.61	45	44
Manufacturer#4	almond antique gainsboro frosted violet	1	1	1	1620.67	1620.67	10	0
Manufacturer#4	almond antique violet mint lemon	2	2	2	1375.42	2996.09	39	29
Manufacturer#4	almond aquamarine floral ivory bisque	3	3	3	1206.26	4202.35	27	-12
Manufacturer#4	almond aquamarine yellow dodger mint	4	4	4	1844.92	6047.27	7	-20
Manufacturer#4	almond azure aquamarine papaya violet	5	5	5	1290.35	7337.62	12	5
Manufacturer#5	almond antique blue firebrick mint	1	1	1	1789.69	1789.69	31	0
Manufacturer#5	almond antique medium spring khaki	2	2	2	1611.66	3401.35	6	-25
Manufacturer#5	almond antique sky peru orange	3	3	3	1788.73	5190.08	2	-4
Manufacturer#5	almond aquamarine dodger light gainsboro	4	4	4	1018.1	6208.18	46	44
Manufacturer#5	almond azure blanched chiffon midnight	5	5	5	1464.48	7672.66	23	-23
PREHOOK: query: explain vectorization detail
select sub1.r, sub1.dr, sub1.cd, sub1.s1, sub1.deltaSz 
from (select p_mfgr, p_name, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd, 
p_retailprice, round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz 
from part 
) sub1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select sub1.r, sub1.dr, sub1.cd, sub1.s1, sub1.deltaSz 
from (select p_mfgr, p_name, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd, 
p_retailprice, round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz 
from part 
) sub1
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum UNBOUNDED end frame is not supported for ROWS window type
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: count_window_2
                              arguments: _col5
                              name: count
                              window function: GenericUDAFCountEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: sum_window_3
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: lag_window_4
                              arguments: _col5, 1, _col5
                              name: lag
                              window function: GenericUDAFLagEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: rank_window_0 (type: int), dense_rank_window_1 (type: int), count_window_2 (type: bigint), round(sum_window_3, 2) (type: double), (_col5 - lag_window_4) (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 26 Data size: 728 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 728 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select sub1.r, sub1.dr, sub1.cd, sub1.s1, sub1.deltaSz 
from (select p_mfgr, p_name, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd, 
p_retailprice, round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz 
from part 
) sub1
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select sub1.r, sub1.dr, sub1.cd, sub1.s1, sub1.deltaSz 
from (select p_mfgr, p_name, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
count(p_size) over(distribute by p_mfgr sort by p_name) as cd, 
p_retailprice, round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz 
from part 
) sub1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
sub1.r	sub1.dr	sub1.cd	sub1.s1	sub1.deltasz
1	1	1	1620.67	0
1	1	1	1671.68	0
1	1	1	1690.68	0
1	1	1	1789.69	0
1	1	2	1173.15	0
1	1	2	2346.3	0
2	2	2	2861.95	-3
2	2	2	2996.09	29
2	2	2	3401.35	-25
2	2	2	3491.38	26
3	2	3	4100.06	32
3	3	3	4202.35	-12
3	3	3	4272.34	5
3	3	3	5190.08	-4
3	3	3	5523.36	-38
4	3	4	5702.65	-28
4	4	4	6047.27	-20
4	4	4	6195.32	-18
4	4	4	6208.18	44
4	4	4	7222.02	23
5	4	5	7117.07	22
5	5	5	7337.62	5
5	5	5	7532.61	44
5	5	5	7672.66	-23
5	5	5	8923.62	-7
6	5	6	8749.73	14
PREHOOK: query: explain vectorization detail
select abc.p_mfgr, abc.p_name, 
rank() over(distribute by abc.p_mfgr sort by abc.p_name) as r, 
dense_rank() over(distribute by abc.p_mfgr sort by abc.p_name) as dr, 
abc.p_retailprice, round(sum(abc.p_retailprice) over (distribute by abc.p_mfgr sort by abc.p_name rows between unbounded preceding and current row),2) as s1,
abc.p_size, abc.p_size - lag(abc.p_size,1,abc.p_size) over(distribute by abc.p_mfgr sort by abc.p_name) as deltaSz 
from noop(on part 
partition by p_mfgr 
order by p_name 
) abc join part p1 on abc.p_partkey = p1.p_partkey
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select abc.p_mfgr, abc.p_name, 
rank() over(distribute by abc.p_mfgr sort by abc.p_name) as r, 
dense_rank() over(distribute by abc.p_mfgr sort by abc.p_name) as dr, 
abc.p_retailprice, round(sum(abc.p_retailprice) over (distribute by abc.p_mfgr sort by abc.p_name rows between unbounded preceding and current row),2) as s1,
abc.p_size, abc.p_size - lag(abc.p_size,1,abc.p_size) over(distribute by abc.p_mfgr sort by abc.p_name) as deltaSz 
from noop(on part 
partition by p_mfgr 
order by p_name 
) abc join part p1 on abc.p_partkey = p1.p_partkey
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 5 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6110 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [0, 5, 7]
                    Statistics: Num rows: 26 Data size: 6110 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_partkey (type: int), p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [0, 1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: p1
                  Statistics: Num rows: 26 Data size: 104 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: p_partkey is not null (type: boolean)
                    Statistics: Num rows: 26 Data size: 104 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: p_partkey (type: int)
                      sort order: +
                      Map-reduce partition columns: p_partkey (type: int)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          partitionColumnNums: [0]
                          valueColumnNums: []
                      Statistics: Num rows: 26 Data size: 104 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [0]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: NOOP not supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col0, _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 13078 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: part
                        output shape: _col0: int, _col1: string, _col2: string, _col5: int, _col7: double
                        type: TABLE
                      Partition table definition
                        input alias: abc
                        name: noop
                        order by: _col1 ASC NULLS FIRST
                        output shape: _col0: int, _col1: string, _col2: string, _col5: int, _col7: double
                        partition by: _col2
                        raw input shape:
                  Statistics: Num rows: 26 Data size: 13078 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: _col0 is not null (type: boolean)
                    Statistics: Num rows: 26 Data size: 13078 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 26 Data size: 13078 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col1 (type: string), _col2 (type: string), _col5 (type: int), _col7 (type: double)
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 p_partkey (type: int)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 27 Data size: 6237 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col2 (type: string), _col1 (type: string)
                  sort order: ++
                  Map-reduce partition columns: _col2 (type: string)
                  Statistics: Num rows: 27 Data size: 6237 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: _col5 (type: int), _col7 (type: double)
        Reducer 4 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum UNBOUNDED end frame is not supported for ROWS window type
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 27 Data size: 20709 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: sum_window_2
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: lag_window_3
                              arguments: _col5, 1, _col5
                              name: lag
                              window function: GenericUDAFLagEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 27 Data size: 20709 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), rank_window_0 (type: int), dense_rank_window_1 (type: int), _col7 (type: double), round(sum_window_2, 2) (type: double), _col5 (type: int), (_col5 - lag_window_3) (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                    Statistics: Num rows: 27 Data size: 6777 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 27 Data size: 6777 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select abc.p_mfgr, abc.p_name, 
rank() over(distribute by abc.p_mfgr sort by abc.p_name) as r, 
dense_rank() over(distribute by abc.p_mfgr sort by abc.p_name) as dr, 
abc.p_retailprice, round(sum(abc.p_retailprice) over (distribute by abc.p_mfgr sort by abc.p_name rows between unbounded preceding and current row),2) as s1,
abc.p_size, abc.p_size - lag(abc.p_size,1,abc.p_size) over(distribute by abc.p_mfgr sort by abc.p_name) as deltaSz 
from noop(on part 
partition by p_mfgr 
order by p_name 
) abc join part p1 on abc.p_partkey = p1.p_partkey
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select abc.p_mfgr, abc.p_name, 
rank() over(distribute by abc.p_mfgr sort by abc.p_name) as r, 
dense_rank() over(distribute by abc.p_mfgr sort by abc.p_name) as dr, 
abc.p_retailprice, round(sum(abc.p_retailprice) over (distribute by abc.p_mfgr sort by abc.p_name rows between unbounded preceding and current row),2) as s1,
abc.p_size, abc.p_size - lag(abc.p_size,1,abc.p_size) over(distribute by abc.p_mfgr sort by abc.p_name) as deltaSz 
from noop(on part 
partition by p_mfgr 
order by p_name 
) abc join part p1 on abc.p_partkey = p1.p_partkey
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
abc.p_mfgr	abc.p_name	r	dr	abc.p_retailprice	s1	abc.p_size	deltasz
Manufacturer#1	almond antique burnished rose metallic	1	1	1173.15	1173.15	2	0
Manufacturer#1	almond antique burnished rose metallic	1	1	1173.15	2346.3	2	0
Manufacturer#1	almond antique burnished rose metallic	1	1	1173.15	3519.45	2	0
Manufacturer#1	almond antique burnished rose metallic	1	1	1173.15	4692.6	2	0
Manufacturer#1	almond antique chartreuse lavender yellow	5	2	1753.76	6446.36	34	32
Manufacturer#1	almond antique salmon chartreuse burlywood	6	3	1602.59	8048.95	6	-28
Manufacturer#1	almond aquamarine burnished black steel	7	4	1414.42	9463.37	28	22
Manufacturer#1	almond aquamarine pink moccasin thistle	8	5	1632.66	11096.03	42	14
Manufacturer#2	almond antique violet chocolate turquoise	1	1	1690.68	1690.68	14	0
Manufacturer#2	almond antique violet turquoise frosted	2	2	1800.7	3491.38	40	26
Manufacturer#2	almond aquamarine midnight light salmon	3	3	2031.98	5523.36	2	-38
Manufacturer#2	almond aquamarine rose maroon antique	4	4	1698.66	7222.02	25	23
Manufacturer#2	almond aquamarine sandy cyan gainsboro	5	5	1701.6	8923.62	18	-7
Manufacturer#3	almond antique chartreuse khaki white	1	1	1671.68	1671.68	17	0
Manufacturer#3	almond antique forest lavender goldenrod	2	2	1190.27	2861.95	14	-3
Manufacturer#3	almond antique metallic orange dim	3	3	1410.39	4272.34	19	5
Manufacturer#3	almond antique misty red olive	4	4	1922.98	6195.32	1	-18
Manufacturer#3	almond antique olive coral navajo	5	5	1337.29	7532.61	45	44
Manufacturer#4	almond antique gainsboro frosted violet	1	1	1620.67	1620.67	10	0
Manufacturer#4	almond antique violet mint lemon	2	2	1375.42	2996.09	39	29
Manufacturer#4	almond aquamarine floral ivory bisque	3	3	1206.26	4202.35	27	-12
Manufacturer#4	almond aquamarine yellow dodger mint	4	4	1844.92	6047.27	7	-20
Manufacturer#4	almond azure aquamarine papaya violet	5	5	1290.35	7337.62	12	5
Manufacturer#5	almond antique blue firebrick mint	1	1	1789.69	1789.69	31	0
Manufacturer#5	almond antique medium spring khaki	2	2	1611.66	3401.35	6	-25
Manufacturer#5	almond antique sky peru orange	3	3	1788.73	5190.08	2	-4
Manufacturer#5	almond aquamarine dodger light gainsboro	4	4	1018.1	6208.18	46	44
Manufacturer#5	almond azure blanched chiffon midnight	5	5	1464.48	7672.66	23	-23
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name, p_size desc) as R
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name, p_size desc) as R
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string), p_size (type: int)
                    sort order: ++-
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1, 5]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: []
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: More than 1 argument expression of aggregation function rank
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), KEY.reducesinkkey2 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST, _col5 DESC NULLS LAST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1, _col5
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), rank_window_0 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 26 Data size: 5902 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 5902 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name, p_size desc) as R
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name, p_size desc) as R
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	r
Manufacturer#1	almond antique burnished rose metallic	2	1
Manufacturer#1	almond antique burnished rose metallic	2	1
Manufacturer#1	almond antique chartreuse lavender yellow	34	3
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4
Manufacturer#1	almond aquamarine burnished black steel	28	5
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6
Manufacturer#2	almond antique violet chocolate turquoise	14	1
Manufacturer#2	almond antique violet turquoise frosted	40	2
Manufacturer#2	almond aquamarine midnight light salmon	2	3
Manufacturer#2	almond aquamarine rose maroon antique	25	4
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5
Manufacturer#3	almond antique chartreuse khaki white	17	1
Manufacturer#3	almond antique forest lavender goldenrod	14	2
Manufacturer#3	almond antique metallic orange dim	19	3
Manufacturer#3	almond antique misty red olive	1	4
Manufacturer#3	almond antique olive coral navajo	45	5
Manufacturer#4	almond antique gainsboro frosted violet	10	1
Manufacturer#4	almond antique violet mint lemon	39	2
Manufacturer#4	almond aquamarine floral ivory bisque	27	3
Manufacturer#4	almond aquamarine yellow dodger mint	7	4
Manufacturer#4	almond azure aquamarine papaya violet	12	5
Manufacturer#5	almond antique blue firebrick mint	31	1
Manufacturer#5	almond antique medium spring khaki	6	2
Manufacturer#5	almond antique sky peru orange	2	3
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4
Manufacturer#5	almond azure blanched chiffon midnight	23	5
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2)  as s1
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2)  as s1
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum UNBOUNDED end frame is not supported for ROWS window type
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: sum_window_2
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), rank_window_0 (type: int), dense_rank_window_1 (type: int), round(sum_window_2, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2)  as s1
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2)  as s1
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	r	dr	s1
Manufacturer#1	almond antique burnished rose metallic	2	1	1	1173.15
Manufacturer#1	almond antique burnished rose metallic	2	1	1	2346.3
Manufacturer#1	almond antique chartreuse lavender yellow	34	3	2	4100.06
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4	3	5702.65
Manufacturer#1	almond aquamarine burnished black steel	28	5	4	7117.07
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6	5	8749.73
Manufacturer#2	almond antique violet chocolate turquoise	14	1	1	1690.68
Manufacturer#2	almond antique violet turquoise frosted	40	2	2	3491.38
Manufacturer#2	almond aquamarine midnight light salmon	2	3	3	5523.36
Manufacturer#2	almond aquamarine rose maroon antique	25	4	4	7222.02
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5	5	8923.62
Manufacturer#3	almond antique chartreuse khaki white	17	1	1	1671.68
Manufacturer#3	almond antique forest lavender goldenrod	14	2	2	2861.95
Manufacturer#3	almond antique metallic orange dim	19	3	3	4272.34
Manufacturer#3	almond antique misty red olive	1	4	4	6195.32
Manufacturer#3	almond antique olive coral navajo	45	5	5	7532.61
Manufacturer#4	almond antique gainsboro frosted violet	10	1	1	1620.67
Manufacturer#4	almond antique violet mint lemon	39	2	2	2996.09
Manufacturer#4	almond aquamarine floral ivory bisque	27	3	3	4202.35
Manufacturer#4	almond aquamarine yellow dodger mint	7	4	4	6047.27
Manufacturer#4	almond azure aquamarine papaya violet	12	5	5	7337.62
Manufacturer#5	almond antique blue firebrick mint	31	1	1	1789.69
Manufacturer#5	almond antique medium spring khaki	6	2	2	3401.35
Manufacturer#5	almond antique sky peru orange	2	3	3	5190.08
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4	4	6208.18
Manufacturer#5	almond azure blanched chiffon midnight	23	5	5	7672.66
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum UNBOUNDED end frame is not supported for ROWS window type
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: sum_window_2
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), rank_window_0 (type: int), dense_rank_window_1 (type: int), round(sum_window_2, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s1
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	r	dr	s1
Manufacturer#1	almond antique burnished rose metallic	2	1	1	1173.15
Manufacturer#1	almond antique burnished rose metallic	2	1	1	2346.3
Manufacturer#1	almond antique chartreuse lavender yellow	34	3	2	4100.06
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4	3	5702.65
Manufacturer#1	almond aquamarine burnished black steel	28	5	4	7117.07
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6	5	8749.73
Manufacturer#2	almond antique violet chocolate turquoise	14	1	1	1690.68
Manufacturer#2	almond antique violet turquoise frosted	40	2	2	3491.38
Manufacturer#2	almond aquamarine midnight light salmon	2	3	3	5523.36
Manufacturer#2	almond aquamarine rose maroon antique	25	4	4	7222.02
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5	5	8923.62
Manufacturer#3	almond antique chartreuse khaki white	17	1	1	1671.68
Manufacturer#3	almond antique forest lavender goldenrod	14	2	2	2861.95
Manufacturer#3	almond antique metallic orange dim	19	3	3	4272.34
Manufacturer#3	almond antique misty red olive	1	4	4	6195.32
Manufacturer#3	almond antique olive coral navajo	45	5	5	7532.61
Manufacturer#4	almond antique gainsboro frosted violet	10	1	1	1620.67
Manufacturer#4	almond antique violet mint lemon	39	2	2	2996.09
Manufacturer#4	almond aquamarine floral ivory bisque	27	3	3	4202.35
Manufacturer#4	almond aquamarine yellow dodger mint	7	4	4	6047.27
Manufacturer#4	almond azure aquamarine papaya violet	12	5	5	7337.62
Manufacturer#5	almond antique blue firebrick mint	31	1	1	1789.69
Manufacturer#5	almond antique medium spring khaki	6	2	2	3401.35
Manufacturer#5	almond antique sky peru orange	2	3	3	5190.08
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4	4	6208.18
Manufacturer#5	almond azure blanched chiffon midnight	23	5	5	7672.66
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
sum(p_size) over (distribute by p_mfgr sort by p_name rows between current row and current row) as s2, 
first_value(p_size) over w1  as f, 
last_value(p_size, false) over w1  as l 
from part 
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
sum(p_size) over (distribute by p_mfgr sort by p_name rows between current row and current row) as s2, 
first_value(p_size) over w1  as f, 
last_value(p_size, false) over w1  as l 
from part 
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS CURRENT~CURRENT
                            window function definition
                              alias: first_value_window_1
                              arguments: _col5
                              name: first_value
                              window function: GenericUDAFFirstValueEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: last_value_window_2
                              arguments: _col5, false
                              name: last_value
                              window function: GenericUDAFLastValueEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint), first_value_window_1 (type: int), last_value_window_2 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size, 
sum(p_size) over (distribute by p_mfgr sort by p_name rows between current row and current row) as s2, 
first_value(p_size) over w1  as f, 
last_value(p_size, false) over w1  as l 
from part 
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size, 
sum(p_size) over (distribute by p_mfgr sort by p_name rows between current row and current row) as s2, 
first_value(p_size) over w1  as f, 
last_value(p_size, false) over w1  as l 
from part 
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s2	f	l
Manufacturer#1	almond antique burnished rose metallic	2	2	2	34
Manufacturer#1	almond antique burnished rose metallic	2	2	2	6
Manufacturer#1	almond antique chartreuse lavender yellow	34	34	2	28
Manufacturer#1	almond antique salmon chartreuse burlywood	6	6	2	42
Manufacturer#1	almond aquamarine burnished black steel	28	28	34	42
Manufacturer#1	almond aquamarine pink moccasin thistle	42	42	6	42
Manufacturer#2	almond antique violet chocolate turquoise	14	14	14	2
Manufacturer#2	almond antique violet turquoise frosted	40	40	14	25
Manufacturer#2	almond aquamarine midnight light salmon	2	2	14	18
Manufacturer#2	almond aquamarine rose maroon antique	25	25	40	18
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	18	2	18
Manufacturer#3	almond antique chartreuse khaki white	17	17	17	19
Manufacturer#3	almond antique forest lavender goldenrod	14	14	17	1
Manufacturer#3	almond antique metallic orange dim	19	19	17	45
Manufacturer#3	almond antique misty red olive	1	1	14	45
Manufacturer#3	almond antique olive coral navajo	45	45	19	45
Manufacturer#4	almond antique gainsboro frosted violet	10	10	10	27
Manufacturer#4	almond antique violet mint lemon	39	39	10	7
Manufacturer#4	almond aquamarine floral ivory bisque	27	27	10	12
Manufacturer#4	almond aquamarine yellow dodger mint	7	7	39	12
Manufacturer#4	almond azure aquamarine papaya violet	12	12	27	12
Manufacturer#5	almond antique blue firebrick mint	31	31	31	2
Manufacturer#5	almond antique medium spring khaki	6	6	31	46
Manufacturer#5	almond antique sky peru orange	2	2	31	23
Manufacturer#5	almond aquamarine dodger light gainsboro	46	46	6	23
Manufacturer#5	almond azure blanched chiffon midnight	23	23	2	23
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
sum(p_size) over (distribute by p_mfgr sort by p_name rows between current row and current row) as s2, 
first_value(p_size) over w1 as f,  
last_value(p_size, false) over w1 as l 
from part 
where p_mfgr = 'Manufacturer#3'  
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
sum(p_size) over (distribute by p_mfgr sort by p_name rows between current row and current row) as s2, 
first_value(p_size) over w1 as f,  
last_value(p_size, false) over w1 as l 
from part 
where p_mfgr = 'Manufacturer#3'  
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterStringGroupColEqualStringScalar(col 2:string, val Manufacturer#3)
                    predicate: (p_mfgr = 'Manufacturer#3') (type: boolean)
                    Statistics: Num rows: 5 Data size: 1115 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: 'Manufacturer#3' (type: string), p_name (type: string)
                      sort order: ++
                      Map-reduce partition columns: 'Manufacturer#3' (type: string)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [10, 1]
                          keyExpressions: ConstantVectorExpression(val Manufacturer#3) -> 10:string
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          partitionColumnNums: [11]
                          valueColumnNums: [5]
                      Statistics: Num rows: 5 Data size: 1115 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string]
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), VALUE._col4 (type: int)
                outputColumnNames: _col1, _col5
                Statistics: Num rows: 5 Data size: 1965 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: 'Manufacturer#3'
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: sum_window_1
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS CURRENT~CURRENT
                            window function definition
                              alias: first_value_window_2
                              arguments: _col5
                              name: first_value
                              window function: GenericUDAFFirstValueEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: last_value_window_3
                              arguments: _col5, false
                              name: last_value
                              window function: GenericUDAFLastValueEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 5 Data size: 1965 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: 'Manufacturer#3' (type: string), _col1 (type: string), _col5 (type: int), rank_window_0 (type: int), sum_window_1 (type: bigint), first_value_window_2 (type: int), last_value_window_3 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                    Statistics: Num rows: 5 Data size: 1215 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 5 Data size: 1215 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
sum(p_size) over (distribute by p_mfgr sort by p_name rows between current row and current row) as s2, 
first_value(p_size) over w1 as f,  
last_value(p_size, false) over w1 as l 
from part 
where p_mfgr = 'Manufacturer#3'  
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, 
sum(p_size) over (distribute by p_mfgr sort by p_name rows between current row and current row) as s2, 
first_value(p_size) over w1 as f,  
last_value(p_size, false) over w1 as l 
from part 
where p_mfgr = 'Manufacturer#3'  
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	r	s2	f	l
Manufacturer#3	almond antique chartreuse khaki white	17	1	17	17	19
Manufacturer#3	almond antique forest lavender goldenrod	14	2	14	17	1
Manufacturer#3	almond antique metallic orange dim	19	3	19	17	45
Manufacturer#3	almond antique misty red olive	1	4	1	14	45
Manufacturer#3	almond antique olive coral navajo	45	5	45	19	45
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size,  
sum(p_size) over w1 as s1, 
sum(p_size) over (distribute by p_mfgr  sort by p_name rows between current row and current row)  as s2 
from part 
window w1 as (distribute by p_mfgr  sort by p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size,  
sum(p_size) over w1 as s1, 
sum(p_size) over (distribute by p_mfgr  sort by p_name rows between current row and current row)  as s2 
from part 
window w1 as (distribute by p_mfgr  sort by p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: sum_window_1
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS CURRENT~CURRENT
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint), sum_window_1 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size,  
sum(p_size) over w1 as s1, 
sum(p_size) over (distribute by p_mfgr  sort by p_name rows between current row and current row)  as s2 
from part 
window w1 as (distribute by p_mfgr  sort by p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size,  
sum(p_size) over w1 as s1, 
sum(p_size) over (distribute by p_mfgr  sort by p_name rows between current row and current row)  as s2 
from part 
window w1 as (distribute by p_mfgr  sort by p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s1	s2
Manufacturer#1	almond antique burnished rose metallic	2	38	2
Manufacturer#1	almond antique burnished rose metallic	2	44	2
Manufacturer#1	almond antique chartreuse lavender yellow	34	72	34
Manufacturer#1	almond antique salmon chartreuse burlywood	6	112	6
Manufacturer#1	almond aquamarine burnished black steel	28	110	28
Manufacturer#1	almond aquamarine pink moccasin thistle	42	76	42
Manufacturer#2	almond antique violet chocolate turquoise	14	56	14
Manufacturer#2	almond antique violet turquoise frosted	40	81	40
Manufacturer#2	almond aquamarine midnight light salmon	2	99	2
Manufacturer#2	almond aquamarine rose maroon antique	25	85	25
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	45	18
Manufacturer#3	almond antique chartreuse khaki white	17	50	17
Manufacturer#3	almond antique forest lavender goldenrod	14	51	14
Manufacturer#3	almond antique metallic orange dim	19	96	19
Manufacturer#3	almond antique misty red olive	1	79	1
Manufacturer#3	almond antique olive coral navajo	45	65	45
Manufacturer#4	almond antique gainsboro frosted violet	10	76	10
Manufacturer#4	almond antique violet mint lemon	39	83	39
Manufacturer#4	almond aquamarine floral ivory bisque	27	95	27
Manufacturer#4	almond aquamarine yellow dodger mint	7	85	7
Manufacturer#4	almond azure aquamarine papaya violet	12	46	12
Manufacturer#5	almond antique blue firebrick mint	31	39	31
Manufacturer#5	almond antique medium spring khaki	6	85	6
Manufacturer#5	almond antique sky peru orange	2	108	2
Manufacturer#5	almond aquamarine dodger light gainsboro	46	77	46
Manufacturer#5	almond azure blanched chiffon midnight	23	71	23
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, dense_rank() over(distribute by p_mfgr sort by p_name) as dr 
from part  
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, dense_rank() over(distribute by p_mfgr sort by p_name) as dr 
from part  
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:string, KEY.reducesinkkey1:string, VALUE._col3:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint]
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1, 0, 2]
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorRank, VectorPTFEvaluatorDenseRank]
                      functionInputExpressions: [col 1:string, col 1:string]
                      functionNames: [rank, dense_rank]
                      keyInputColumns: [1, 0]
                      native: true
                      nonKeyInputColumns: [2]
                      orderExpressions: [col 1:string]
                      outputColumns: [3, 4, 1, 0, 2]
                      outputTypes: [int, int, string, string, int]
                      partitionExpressions: [col 0:string]
                      streamingColumns: [3, 4]
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), rank_window_0 (type: int), dense_rank_window_1 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1, 2, 3, 4]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
                      Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, dense_rank() over(distribute by p_mfgr sort by p_name) as dr 
from part  
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name) as r, dense_rank() over(distribute by p_mfgr sort by p_name) as dr 
from part  
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	r	dr
Manufacturer#1	almond antique burnished rose metallic	2	1	1
Manufacturer#1	almond antique burnished rose metallic	2	1	1
Manufacturer#1	almond antique chartreuse lavender yellow	34	3	2
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4	3
Manufacturer#1	almond aquamarine burnished black steel	28	5	4
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6	5
Manufacturer#2	almond antique violet chocolate turquoise	14	1	1
Manufacturer#2	almond antique violet turquoise frosted	40	2	2
Manufacturer#2	almond aquamarine midnight light salmon	2	3	3
Manufacturer#2	almond aquamarine rose maroon antique	25	4	4
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5	5
Manufacturer#3	almond antique chartreuse khaki white	17	1	1
Manufacturer#3	almond antique forest lavender goldenrod	14	2	2
Manufacturer#3	almond antique metallic orange dim	19	3	3
Manufacturer#3	almond antique misty red olive	1	4	4
Manufacturer#3	almond antique olive coral navajo	45	5	5
Manufacturer#4	almond antique gainsboro frosted violet	10	1	1
Manufacturer#4	almond antique violet mint lemon	39	2	2
Manufacturer#4	almond aquamarine floral ivory bisque	27	3	3
Manufacturer#4	almond aquamarine yellow dodger mint	7	4	4
Manufacturer#4	almond azure aquamarine papaya violet	12	5	5
Manufacturer#5	almond antique blue firebrick mint	31	1	1
Manufacturer#5	almond antique medium spring khaki	6	2	2
Manufacturer#5	almond antique sky peru orange	2	3	3
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4	4
Manufacturer#5	almond azure blanched chiffon midnight	23	5	5
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size,  
rank() over(distribute by p_mfgr sort by p_name) as r,  
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
percent_rank() over(distribute by p_mfgr sort by p_name) as pr, 
ntile(3) over(distribute by p_mfgr sort by p_name) as nt, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
avg(p_size) over(distribute by p_mfgr sort by p_name) as avg, 
stddev(p_size) over(distribute by p_mfgr sort by p_name) as st, 
first_value(p_size % 5) over(distribute by p_mfgr sort by p_name) as fv, 
last_value(p_size) over(distribute by p_mfgr sort by p_name) as lv, 
first_value(p_size) over w1  as fvW1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size,  
rank() over(distribute by p_mfgr sort by p_name) as r,  
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
percent_rank() over(distribute by p_mfgr sort by p_name) as pr, 
ntile(3) over(distribute by p_mfgr sort by p_name) as nt, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
avg(p_size) over(distribute by p_mfgr sort by p_name) as avg, 
stddev(p_size) over(distribute by p_mfgr sort by p_name) as st, 
first_value(p_size % 5) over(distribute by p_mfgr sort by p_name) as fv, 
last_value(p_size) over(distribute by p_mfgr sort by p_name) as lv, 
first_value(p_size) over w1  as fvW1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: cume_dist not in supported functions [avg, count, dense_rank, first_value, last_value, max, min, rank, row_number, sum]
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: cume_dist_window_2
                              arguments: _col1
                              name: cume_dist
                              window function: GenericUDAFCumeDistEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: percent_rank_window_3
                              arguments: _col1
                              name: percent_rank
                              window function: GenericUDAFPercentRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: ntile_window_4
                              arguments: 3
                              name: ntile
                              window function: GenericUDAFNTileEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: count_window_5
                              arguments: _col5
                              name: count
                              window function: GenericUDAFCountEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: avg_window_6
                              arguments: _col5
                              name: avg
                              window function: GenericUDAFAverageEvaluatorDouble
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: stddev_pop_window_7
                              arguments: _col5
                              name: stddev_pop
                              window function: GenericUDAFStdEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: first_value_window_8
                              arguments: (_col5 % 5)
                              name: first_value
                              window function: GenericUDAFFirstValueEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: last_value_window_9
                              arguments: _col5
                              name: last_value
                              window function: GenericUDAFLastValueEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: rank_window_0 (type: int), dense_rank_window_1 (type: int), cume_dist_window_2 (type: double), percent_rank_window_3 (type: double), ntile_window_4 (type: int), count_window_5 (type: bigint), avg_window_6 (type: double), stddev_pop_window_7 (type: double), first_value_window_8 (type: int), last_value_window_9 (type: int), _col1 (type: string), _col2 (type: string), _col5 (type: int)
                    outputColumnNames: rank_window_0, dense_rank_window_1, cume_dist_window_2, percent_rank_window_3, ntile_window_4, count_window_5, avg_window_6, stddev_pop_window_7, first_value_window_8, last_value_window_9, _col1, _col2, _col5
                    Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col1 (type: string)
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string)
                      Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: rank_window_0 (type: int), dense_rank_window_1 (type: int), cume_dist_window_2 (type: double), percent_rank_window_3 (type: double), ntile_window_4 (type: int), count_window_5 (type: bigint), avg_window_6 (type: double), stddev_pop_window_7 (type: double), first_value_window_8 (type: int), last_value_window_9 (type: int), _col5 (type: int)
        Reducer 3 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: first_value only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: int), VALUE._col2 (type: double), VALUE._col3 (type: double), VALUE._col4 (type: int), VALUE._col5 (type: bigint), VALUE._col6 (type: double), VALUE._col7 (type: double), VALUE._col8 (type: int), VALUE._col9 (type: int), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col13 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col11, _col12, _col15
                Statistics: Num rows: 26 Data size: 14326 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: int, _col1: int, _col2: double, _col3: double, _col4: int, _col5: bigint, _col6: double, _col7: double, _col8: int, _col9: int, _col11: string, _col12: string, _col15: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col12 ASC NULLS FIRST, _col11 ASC NULLS FIRST
                        partition by: _col12
                        raw input shape:
                        window functions:
                            window function definition
                              alias: first_value_window_10
                              arguments: _col15
                              name: first_value
                              window function: GenericUDAFFirstValueEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 14326 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col12 (type: string), _col11 (type: string), _col15 (type: int), _col0 (type: int), _col1 (type: int), _col2 (type: double), _col3 (type: double), _col4 (type: int), _col5 (type: bigint), _col6 (type: double), _col7 (type: double), _col8 (type: int), _col9 (type: int), first_value_window_10 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13
                    Statistics: Num rows: 26 Data size: 7462 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 7462 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size,  
rank() over(distribute by p_mfgr sort by p_name) as r,  
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
percent_rank() over(distribute by p_mfgr sort by p_name) as pr, 
ntile(3) over(distribute by p_mfgr sort by p_name) as nt, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
avg(p_size) over(distribute by p_mfgr sort by p_name) as avg, 
stddev(p_size) over(distribute by p_mfgr sort by p_name) as st, 
first_value(p_size % 5) over(distribute by p_mfgr sort by p_name) as fv, 
last_value(p_size) over(distribute by p_mfgr sort by p_name) as lv, 
first_value(p_size) over w1  as fvW1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size,  
rank() over(distribute by p_mfgr sort by p_name) as r,  
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
percent_rank() over(distribute by p_mfgr sort by p_name) as pr, 
ntile(3) over(distribute by p_mfgr sort by p_name) as nt, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
avg(p_size) over(distribute by p_mfgr sort by p_name) as avg, 
stddev(p_size) over(distribute by p_mfgr sort by p_name) as st, 
first_value(p_size % 5) over(distribute by p_mfgr sort by p_name) as fv, 
last_value(p_size) over(distribute by p_mfgr sort by p_name) as lv, 
first_value(p_size) over w1  as fvW1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	r	dr	cud	pr	nt	ca	avg	st	fv	lv	fvw1
Manufacturer#1	almond antique burnished rose metallic	2	1	1	0.3333333333333333	0.0	1	2	2.0	0.0	2	2	2
Manufacturer#1	almond antique burnished rose metallic	2	1	1	0.3333333333333333	0.0	1	2	2.0	0.0	2	2	2
Manufacturer#1	almond antique chartreuse lavender yellow	34	3	2	0.5	0.4	2	3	12.666666666666666	15.084944665313014	2	34	2
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4	3	0.6666666666666666	0.6	2	4	11.0	13.379088160259652	2	6	2
Manufacturer#1	almond aquamarine burnished black steel	28	5	4	0.8333333333333334	0.8	3	5	14.4	13.763720427268202	2	28	34
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6	5	1.0	1.0	3	6	19.0	16.237815945091466	2	42	6
Manufacturer#2	almond antique violet chocolate turquoise	14	1	1	0.2	0.0	1	1	14.0	0.0	4	14	14
Manufacturer#2	almond antique violet turquoise frosted	40	2	2	0.4	0.25	1	2	27.0	13.0	4	40	14
Manufacturer#2	almond aquamarine midnight light salmon	2	3	3	0.6	0.5	2	3	18.666666666666668	15.86050300449376	4	2	14
Manufacturer#2	almond aquamarine rose maroon antique	25	4	4	0.8	0.75	2	4	20.25	14.00669482783144	4	25	40
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5	5	1.0	1.0	3	5	19.8	12.560254774486067	4	18	2
Manufacturer#3	almond antique chartreuse khaki white	17	1	1	0.2	0.0	1	1	17.0	0.0	2	17	17
Manufacturer#3	almond antique forest lavender goldenrod	14	2	2	0.4	0.25	1	2	15.5	1.5	2	14	17
Manufacturer#3	almond antique metallic orange dim	19	3	3	0.6	0.5	2	3	16.666666666666668	2.0548046676563256	2	19	17
Manufacturer#3	almond antique misty red olive	1	4	4	0.8	0.75	2	4	12.75	7.013380069552769	2	1	14
Manufacturer#3	almond antique olive coral navajo	45	5	5	1.0	1.0	3	5	19.2	14.344336861632886	2	45	19
Manufacturer#4	almond antique gainsboro frosted violet	10	1	1	0.2	0.0	1	1	10.0	0.0	0	10	10
Manufacturer#4	almond antique violet mint lemon	39	2	2	0.4	0.25	1	2	24.5	14.5	0	39	10
Manufacturer#4	almond aquamarine floral ivory bisque	27	3	3	0.6	0.5	2	3	25.333333333333332	11.897712198383164	0	27	10
Manufacturer#4	almond aquamarine yellow dodger mint	7	4	4	0.8	0.75	2	4	20.75	13.007209539328564	0	7	39
Manufacturer#4	almond azure aquamarine papaya violet	12	5	5	1.0	1.0	3	5	19.0	12.149074038789951	0	12	27
Manufacturer#5	almond antique blue firebrick mint	31	1	1	0.2	0.0	1	1	31.0	0.0	1	31	31
Manufacturer#5	almond antique medium spring khaki	6	2	2	0.4	0.25	1	2	18.5	12.5	1	6	31
Manufacturer#5	almond antique sky peru orange	2	3	3	0.6	0.5	2	3	13.0	12.832251036613439	1	2	31
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4	4	0.8	0.75	2	4	21.25	18.102140757380052	1	46	6
Manufacturer#5	almond azure blanched chiffon midnight	23	5	5	1.0	1.0	3	5	21.6	16.206171663906314	1	23	2
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size,  
  rank() over(distribute by p_mfgr sort by p_name) as r, 
  dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
sum(p_size) over (distribute by p_mfgr sort by p_name range between unbounded preceding and current row) as s1, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between 5 preceding and current row) as s2, 
first_value(p_size) over w1  as fv1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size,  
  rank() over(distribute by p_mfgr sort by p_name) as r, 
  dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
sum(p_size) over (distribute by p_mfgr sort by p_name range between unbounded preceding and current row) as s1, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between 5 preceding and current row) as s2, 
first_value(p_size) over w1  as fv1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: cume_dist not in supported functions [avg, count, dense_rank, first_value, last_value, max, min, rank, row_number, sum]
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: cume_dist_window_2
                              arguments: _col1
                              name: cume_dist
                              window function: GenericUDAFCumeDistEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: sum_window_3
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: rank_window_0 (type: int), dense_rank_window_1 (type: int), cume_dist_window_2 (type: double), sum_window_3 (type: bigint), _col1 (type: string), _col2 (type: string), _col5 (type: int)
                    outputColumnNames: rank_window_0, dense_rank_window_1, cume_dist_window_2, sum_window_3, _col1, _col2, _col5
                    Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col5 (type: int)
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string)
                      Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: rank_window_0 (type: int), dense_rank_window_1 (type: int), cume_dist_window_2 (type: double), sum_window_3 (type: bigint), _col1 (type: string)
        Reducer 3 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: int), VALUE._col2 (type: double), VALUE._col3 (type: bigint), VALUE._col5 (type: string), KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col5, _col6, _col9
                Statistics: Num rows: 26 Data size: 13390 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: int, _col1: int, _col2: double, _col3: bigint, _col5: string, _col6: string, _col9: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col9 ASC NULLS FIRST
                        partition by: _col6
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_4
                              arguments: _col9
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(5)~CURRENT
                  Statistics: Num rows: 26 Data size: 13390 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: sum_window_4 (type: bigint), _col0 (type: int), _col1 (type: int), _col2 (type: double), _col3 (type: bigint), _col5 (type: string), _col6 (type: string), _col9 (type: int)
                    outputColumnNames: sum_window_4, _col0, _col1, _col2, _col3, _col5, _col6, _col9
                    Statistics: Num rows: 26 Data size: 13390 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col6 (type: string), _col5 (type: string)
                      sort order: ++
                      Map-reduce partition columns: _col6 (type: string)
                      Statistics: Num rows: 26 Data size: 13390 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: sum_window_4 (type: bigint), _col0 (type: int), _col1 (type: int), _col2 (type: double), _col3 (type: bigint), _col9 (type: int)
        Reducer 4 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: first_value only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: bigint), VALUE._col1 (type: int), VALUE._col2 (type: int), VALUE._col3 (type: double), VALUE._col4 (type: bigint), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col8 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col6, _col7, _col10
                Statistics: Num rows: 26 Data size: 13598 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: bigint, _col1: int, _col2: int, _col3: double, _col4: bigint, _col6: string, _col7: string, _col10: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col7 ASC NULLS FIRST, _col6 ASC NULLS FIRST
                        partition by: _col7
                        raw input shape:
                        window functions:
                            window function definition
                              alias: first_value_window_5
                              arguments: _col10
                              name: first_value
                              window function: GenericUDAFFirstValueEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 13598 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col7 (type: string), _col6 (type: string), _col10 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: double), _col4 (type: bigint), _col0 (type: bigint), first_value_window_5 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 26 Data size: 6734 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6734 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size,  
  rank() over(distribute by p_mfgr sort by p_name) as r, 
  dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
sum(p_size) over (distribute by p_mfgr sort by p_name range between unbounded preceding and current row) as s1, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between 5 preceding and current row) as s2, 
first_value(p_size) over w1  as fv1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size,  
  rank() over(distribute by p_mfgr sort by p_name) as r, 
  dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
sum(p_size) over (distribute by p_mfgr sort by p_name range between unbounded preceding and current row) as s1, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between 5 preceding and current row) as s2, 
first_value(p_size) over w1  as fv1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	r	dr	cud	s1	s2	fv1
Manufacturer#1	almond antique burnished rose metallic	2	1	1	0.3333333333333333	4	4	2
Manufacturer#1	almond antique burnished rose metallic	2	1	1	0.3333333333333333	4	4	2
Manufacturer#1	almond antique chartreuse lavender yellow	34	3	2	0.5	38	34	2
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4	3	0.6666666666666666	44	10	2
Manufacturer#1	almond aquamarine burnished black steel	28	5	4	0.8333333333333334	72	28	34
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6	5	1.0	114	42	6
Manufacturer#2	almond antique violet chocolate turquoise	14	1	1	0.2	14	14	14
Manufacturer#2	almond antique violet turquoise frosted	40	2	2	0.4	54	40	14
Manufacturer#2	almond aquamarine midnight light salmon	2	3	3	0.6	56	2	14
Manufacturer#2	almond aquamarine rose maroon antique	25	4	4	0.8	81	25	40
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5	5	1.0	99	32	2
Manufacturer#3	almond antique chartreuse khaki white	17	1	1	0.2	17	31	17
Manufacturer#3	almond antique forest lavender goldenrod	14	2	2	0.4	31	14	17
Manufacturer#3	almond antique metallic orange dim	19	3	3	0.6	50	50	17
Manufacturer#3	almond antique misty red olive	1	4	4	0.8	51	1	14
Manufacturer#3	almond antique olive coral navajo	45	5	5	1.0	96	45	19
Manufacturer#4	almond antique gainsboro frosted violet	10	1	1	0.2	10	17	10
Manufacturer#4	almond antique violet mint lemon	39	2	2	0.4	49	39	10
Manufacturer#4	almond aquamarine floral ivory bisque	27	3	3	0.6	76	27	10
Manufacturer#4	almond aquamarine yellow dodger mint	7	4	4	0.8	83	7	39
Manufacturer#4	almond azure aquamarine papaya violet	12	5	5	1.0	95	29	27
Manufacturer#5	almond antique blue firebrick mint	31	1	1	0.2	31	31	31
Manufacturer#5	almond antique medium spring khaki	6	2	2	0.4	37	8	31
Manufacturer#5	almond antique sky peru orange	2	3	3	0.6	39	2	31
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4	4	0.8	85	46	6
Manufacturer#5	almond azure blanched chiffon midnight	23	5	5	1.0	108	23	2
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size,
count(*) over(distribute by p_mfgr sort by p_name ) as c, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
first_value(p_size) over w1  as fvW1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size,
count(*) over(distribute by p_mfgr sort by p_name ) as c, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
first_value(p_size) over w1  as fvW1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:string, KEY.reducesinkkey1:string, VALUE._col3:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint]
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1, 0, 2]
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: count_window_0
                              name: count
                              window function: GenericUDAFCountEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                              isStar: true
                            window function definition
                              alias: count_window_1
                              arguments: _col5
                              name: count
                              window function: GenericUDAFCountEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorCountStar, VectorPTFEvaluatorCount]
                      functionInputExpressions: [null, col 2:int]
                      functionNames: [count, count]
                      keyInputColumns: [1, 0]
                      native: true
                      nonKeyInputColumns: [2]
                      orderExpressions: [col 1:string]
                      outputColumns: [3, 4, 1, 0, 2]
                      outputTypes: [bigint, bigint, string, string, int]
                      partitionExpressions: [col 0:string]
                      streamingColumns: []
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: count_window_0 (type: bigint), count_window_1 (type: bigint), _col1 (type: string), _col2 (type: string), _col5 (type: int)
                    outputColumnNames: count_window_0, count_window_1, _col1, _col2, _col5
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [3, 4, 1, 0, 2]
                    Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col1 (type: string)
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0, 1]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          partitionColumnNums: [0]
                          valueColumnNums: [3, 4, 2]
                      Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: count_window_0 (type: bigint), count_window_1 (type: bigint), _col5 (type: int)
        Reducer 3 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: first_value only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: bigint), VALUE._col1 (type: bigint), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col5 (type: int)
                outputColumnNames: _col0, _col1, _col3, _col4, _col7
                Statistics: Num rows: 26 Data size: 13182 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: bigint, _col1: bigint, _col3: string, _col4: string, _col7: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col4 ASC NULLS FIRST, _col3 ASC NULLS FIRST
                        partition by: _col4
                        raw input shape:
                        window functions:
                            window function definition
                              alias: first_value_window_2
                              arguments: _col7
                              name: first_value
                              window function: GenericUDAFFirstValueEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 13182 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col4 (type: string), _col3 (type: string), _col7 (type: int), _col0 (type: bigint), _col1 (type: bigint), first_value_window_2 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 26 Data size: 6318 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6318 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size,
count(*) over(distribute by p_mfgr sort by p_name ) as c, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
first_value(p_size) over w1  as fvW1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size,
count(*) over(distribute by p_mfgr sort by p_name ) as c, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
first_value(p_size) over w1  as fvW1
from part 
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	c	ca	fvw1
Manufacturer#1	almond antique burnished rose metallic	2	2	2	2
Manufacturer#1	almond antique burnished rose metallic	2	2	2	2
Manufacturer#1	almond antique chartreuse lavender yellow	34	3	3	2
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4	4	2
Manufacturer#1	almond aquamarine burnished black steel	28	5	5	34
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6	6	6
Manufacturer#2	almond antique violet chocolate turquoise	14	1	1	14
Manufacturer#2	almond antique violet turquoise frosted	40	2	2	14
Manufacturer#2	almond aquamarine midnight light salmon	2	3	3	14
Manufacturer#2	almond aquamarine rose maroon antique	25	4	4	40
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5	5	2
Manufacturer#3	almond antique chartreuse khaki white	17	1	1	17
Manufacturer#3	almond antique forest lavender goldenrod	14	2	2	17
Manufacturer#3	almond antique metallic orange dim	19	3	3	17
Manufacturer#3	almond antique misty red olive	1	4	4	14
Manufacturer#3	almond antique olive coral navajo	45	5	5	19
Manufacturer#4	almond antique gainsboro frosted violet	10	1	1	10
Manufacturer#4	almond antique violet mint lemon	39	2	2	10
Manufacturer#4	almond aquamarine floral ivory bisque	27	3	3	10
Manufacturer#4	almond aquamarine yellow dodger mint	7	4	4	39
Manufacturer#4	almond azure aquamarine papaya violet	12	5	5	27
Manufacturer#5	almond antique blue firebrick mint	31	1	1	31
Manufacturer#5	almond antique medium spring khaki	6	2	2	31
Manufacturer#5	almond antique sky peru orange	2	3	3	31
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4	4	6
Manufacturer#5	almond azure blanched chiffon midnight	23	5	5	2
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
round(sum(p_retailprice) over w1,2) as s,
min(p_retailprice) over w1 as mi,
max(p_retailprice) over w1 as ma,
round(avg(p_retailprice) over w1,2) as ag
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
round(sum(p_retailprice) over w1,2) as s,
min(p_retailprice) over w1 as mi,
max(p_retailprice) over w1 as ma,
round(avg(p_retailprice) over w1,2) as ag
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col2 ASC NULLS FIRST, _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: min_window_1
                              arguments: _col7
                              name: min
                              window function: GenericUDAFMinEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: max_window_2
                              arguments: _col7
                              name: max
                              window function: GenericUDAFMaxEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: avg_window_3
                              arguments: _col7
                              name: avg
                              window function: GenericUDAFAverageEvaluatorDouble
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), round(sum_window_0, 2) (type: double), min_window_1 (type: double), max_window_2 (type: double), round(avg_window_3, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                    Statistics: Num rows: 26 Data size: 6630 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6630 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size, 
round(sum(p_retailprice) over w1,2) as s,
min(p_retailprice) over w1 as mi,
max(p_retailprice) over w1 as ma,
round(avg(p_retailprice) over w1,2) as ag
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size, 
round(sum(p_retailprice) over w1,2) as s,
min(p_retailprice) over w1 as mi,
max(p_retailprice) over w1 as ma,
round(avg(p_retailprice) over w1,2) as ag
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s	mi	ma	ag
Manufacturer#1	almond antique burnished rose metallic	2	4100.06	1173.15	1753.76	1366.69
Manufacturer#1	almond antique burnished rose metallic	2	5702.65	1173.15	1753.76	1425.66
Manufacturer#1	almond antique chartreuse lavender yellow	34	7117.07	1173.15	1753.76	1423.41
Manufacturer#1	almond antique salmon chartreuse burlywood	6	7576.58	1173.15	1753.76	1515.32
Manufacturer#1	almond aquamarine burnished black steel	28	6403.43	1414.42	1753.76	1600.86
Manufacturer#1	almond aquamarine pink moccasin thistle	42	4649.67	1414.42	1632.66	1549.89
Manufacturer#2	almond antique violet chocolate turquoise	14	5523.36	1690.68	2031.98	1841.12
Manufacturer#2	almond antique violet turquoise frosted	40	7222.02	1690.68	2031.98	1805.51
Manufacturer#2	almond aquamarine midnight light salmon	2	8923.62	1690.68	2031.98	1784.72
Manufacturer#2	almond aquamarine rose maroon antique	25	7232.94	1698.66	2031.98	1808.24
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5432.24	1698.66	2031.98	1810.75
Manufacturer#3	almond antique chartreuse khaki white	17	4272.34	1190.27	1671.68	1424.11
Manufacturer#3	almond antique forest lavender goldenrod	14	6195.32	1190.27	1922.98	1548.83
Manufacturer#3	almond antique metallic orange dim	19	7532.61	1190.27	1922.98	1506.52
Manufacturer#3	almond antique misty red olive	1	5860.93	1190.27	1922.98	1465.23
Manufacturer#3	almond antique olive coral navajo	45	4670.66	1337.29	1922.98	1556.89
Manufacturer#4	almond antique gainsboro frosted violet	10	4202.35	1206.26	1620.67	1400.78
Manufacturer#4	almond antique violet mint lemon	39	6047.27	1206.26	1844.92	1511.82
Manufacturer#4	almond aquamarine floral ivory bisque	27	7337.62	1206.26	1844.92	1467.52
Manufacturer#4	almond aquamarine yellow dodger mint	7	5716.95	1206.26	1844.92	1429.24
Manufacturer#4	almond azure aquamarine papaya violet	12	4341.53	1206.26	1844.92	1447.18
Manufacturer#5	almond antique blue firebrick mint	31	5190.08	1611.66	1789.69	1730.03
Manufacturer#5	almond antique medium spring khaki	6	6208.18	1018.1	1789.69	1552.05
Manufacturer#5	almond antique sky peru orange	2	7672.66	1018.1	1789.69	1534.53
Manufacturer#5	almond aquamarine dodger light gainsboro	46	5882.97	1018.1	1788.73	1470.74
Manufacturer#5	almond azure blanched chiffon midnight	23	4271.31	1018.1	1788.73	1423.77
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, p_retailprice, 
round(sum(p_retailprice) over w1,2) as s,
min(p_retailprice) as mi ,
max(p_retailprice) as ma ,
round(avg(p_retailprice) over w1,2) as ag
from part
group by p_mfgr,p_name, p_size, p_retailprice
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, p_retailprice, 
round(sum(p_retailprice) over w1,2) as s,
min(p_retailprice) as mi ,
max(p_retailprice) as ma ,
round(avg(p_retailprice) over w1,2) as ag
from part
group by p_mfgr,p_name, p_size, p_retailprice
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: p_name (type: string), p_mfgr (type: string), p_size (type: int), p_retailprice (type: double)
                    outputColumnNames: p_name, p_mfgr, p_size, p_retailprice
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [1, 2, 5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(p_retailprice), max(p_retailprice)
                      Group By Vectorization:
                          aggregators: VectorUDAFMinDouble(col 7:double) -> double, VectorUDAFMaxDouble(col 7:double) -> double
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 1:string, col 2:string, col 5:int, col 7:double
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: [0, 1]
                      keys: p_name (type: string), p_mfgr (type: string), p_size (type: int), p_retailprice (type: double)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                      Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: double)
                        sort order: ++++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: double)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1, 2, 3]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            partitionColumnNums: [0, 1, 2, 3]
                            valueColumnNums: [4, 5]
                        Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col4 (type: double), _col5 (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aaaa
                reduceColumnSortOrder: ++++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 6
                    dataColumns: KEY._col0:string, KEY._col1:string, KEY._col2:int, KEY._col3:double, VALUE._col0:double, VALUE._col1:double
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1)
                Group By Vectorization:
                    aggregators: VectorUDAFMinDouble(col 4:double) -> double, VectorUDAFMaxDouble(col 5:double) -> double
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    keyExpressions: col 0:string, col 1:string, col 2:int, col 3:double
                    native: false
                    vectorProcessingMode: MERGE_PARTIAL
                    projectedOutputColumnNums: [0, 1]
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int), KEY._col3 (type: double)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col1 (type: string), _col0 (type: string)
                  sort order: ++
                  Map-reduce partition columns: _col1 (type: string)
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkObjectHashOperator
                      keyColumnNums: [1, 0]
                      native: true
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      partitionColumnNums: [1]
                      valueColumnNums: [2, 3, 4, 5]
                  Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: _col2 (type: int), _col3 (type: double), _col4 (type: double), _col5 (type: double)
        Reducer 3 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col0 (type: int), VALUE._col1 (type: double), VALUE._col2 (type: double), VALUE._col3 (type: double)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: string, _col2: int, _col3: double, _col4: double, _col5: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST, _col0 ASC NULLS FIRST
                        partition by: _col1
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col3
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: avg_window_1
                              arguments: _col3
                              name: avg
                              window function: GenericUDAFAverageEvaluatorDouble
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col1 (type: string), _col0 (type: string), _col2 (type: int), _col3 (type: double), round(sum_window_0, 2) (type: double), _col4 (type: double), _col5 (type: double), round(avg_window_1, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                    Statistics: Num rows: 13 Data size: 3419 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 13 Data size: 3419 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size, p_retailprice, 
round(sum(p_retailprice) over w1,2) as s,
min(p_retailprice) as mi ,
max(p_retailprice) as ma ,
round(avg(p_retailprice) over w1,2) as ag
from part
group by p_mfgr,p_name, p_size, p_retailprice
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size, p_retailprice, 
round(sum(p_retailprice) over w1,2) as s,
min(p_retailprice) as mi ,
max(p_retailprice) as ma ,
round(avg(p_retailprice) over w1,2) as ag
from part
group by p_mfgr,p_name, p_size, p_retailprice
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	p_retailprice	s	mi	ma	ag
Manufacturer#1	almond antique burnished rose metallic	2	1173.15	4529.5	1173.15	1173.15	1509.83
Manufacturer#1	almond antique chartreuse lavender yellow	34	1753.76	5943.92	1753.76	1753.76	1485.98
Manufacturer#1	almond antique salmon chartreuse burlywood	6	1602.59	7576.58	1602.59	1602.59	1515.32
Manufacturer#1	almond aquamarine burnished black steel	28	1414.42	6403.43	1414.42	1414.42	1600.86
Manufacturer#1	almond aquamarine pink moccasin thistle	42	1632.66	4649.67	1632.66	1632.66	1549.89
Manufacturer#2	almond antique violet chocolate turquoise	14	1690.68	5523.36	1690.68	1690.68	1841.12
Manufacturer#2	almond antique violet turquoise frosted	40	1800.7	7222.02	1800.7	1800.7	1805.51
Manufacturer#2	almond aquamarine midnight light salmon	2	2031.98	8923.62	2031.98	2031.98	1784.72
Manufacturer#2	almond aquamarine rose maroon antique	25	1698.66	7232.94	1698.66	1698.66	1808.24
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	1701.6	5432.24	1701.6	1701.6	1810.75
Manufacturer#3	almond antique chartreuse khaki white	17	1671.68	4272.34	1671.68	1671.68	1424.11
Manufacturer#3	almond antique forest lavender goldenrod	14	1190.27	6195.32	1190.27	1190.27	1548.83
Manufacturer#3	almond antique metallic orange dim	19	1410.39	7532.61	1410.39	1410.39	1506.52
Manufacturer#3	almond antique misty red olive	1	1922.98	5860.93	1922.98	1922.98	1465.23
Manufacturer#3	almond antique olive coral navajo	45	1337.29	4670.66	1337.29	1337.29	1556.89
Manufacturer#4	almond antique gainsboro frosted violet	10	1620.67	4202.35	1620.67	1620.67	1400.78
Manufacturer#4	almond antique violet mint lemon	39	1375.42	6047.27	1375.42	1375.42	1511.82
Manufacturer#4	almond aquamarine floral ivory bisque	27	1206.26	7337.62	1206.26	1206.26	1467.52
Manufacturer#4	almond aquamarine yellow dodger mint	7	1844.92	5716.95	1844.92	1844.92	1429.24
Manufacturer#4	almond azure aquamarine papaya violet	12	1290.35	4341.53	1290.35	1290.35	1447.18
Manufacturer#5	almond antique blue firebrick mint	31	1789.69	5190.08	1789.69	1789.69	1730.03
Manufacturer#5	almond antique medium spring khaki	6	1611.66	6208.18	1611.66	1611.66	1552.05
Manufacturer#5	almond antique sky peru orange	2	1788.73	7672.66	1788.73	1788.73	1534.53
Manufacturer#5	almond aquamarine dodger light gainsboro	46	1018.1	5882.97	1018.1	1018.1	1470.74
Manufacturer#5	almond azure blanched chiffon midnight	23	1464.48	4271.31	1464.48	1464.48	1423.77
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
stddev(p_retailprice) over w1 as sdev, 
stddev_pop(p_retailprice) over w1 as sdev_pop, 
collect_set(p_size) over w1 as uniq_size, 
variance(p_retailprice) over w1 as var,
round(corr(p_size, p_retailprice) over w1,5) as cor,
covar_pop(p_size, p_retailprice) over w1 as covarp
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
stddev(p_retailprice) over w1 as sdev, 
stddev_pop(p_retailprice) over w1 as sdev_pop, 
collect_set(p_size) over w1 as uniq_size, 
variance(p_retailprice) over w1 as var,
round(corr(p_size, p_retailprice) over w1,5) as cor,
covar_pop(p_size, p_retailprice) over w1 as covarp
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF Output Columns expression for PTF operator: Data type array<int> of column collect_set_window_1 not supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col2 ASC NULLS FIRST, _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: stddev_pop_window_0
                              arguments: _col7
                              name: stddev_pop
                              window function: GenericUDAFStdEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: collect_set_window_1
                              arguments: _col5
                              name: collect_set
                              window function: GenericUDAFMkCollectionEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: var_pop_window_2
                              arguments: _col7
                              name: var_pop
                              window function: GenericUDAFVarianceEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: corr_window_3
                              arguments: _col5, _col7
                              name: corr
                              window function: GenericUDAFCorrelationEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: covar_pop_window_4
                              arguments: _col5, _col7
                              name: covar_pop
                              window function: GenericUDAFCovarianceEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), stddev_pop_window_0 (type: double), stddev_pop_window_0 (type: double), collect_set_window_1 (type: array<int>), var_pop_window_2 (type: double), round(corr_window_3, 5) (type: double), covar_pop_window_4 (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 26 Data size: 9958 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 9958 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size, 
stddev(p_retailprice) over w1 as sdev, 
stddev_pop(p_retailprice) over w1 as sdev_pop, 
collect_set(p_size) over w1 as uniq_size, 
variance(p_retailprice) over w1 as var,
round(corr(p_size, p_retailprice) over w1,5) as cor,
covar_pop(p_size, p_retailprice) over w1 as covarp
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size, 
stddev(p_retailprice) over w1 as sdev, 
stddev_pop(p_retailprice) over w1 as sdev_pop, 
collect_set(p_size) over w1 as uniq_size, 
variance(p_retailprice) over w1 as var,
round(corr(p_size, p_retailprice) over w1,5) as cor,
covar_pop(p_size, p_retailprice) over w1 as covarp
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	sdev	sdev_pop	uniq_size	var	cor	covarp
Manufacturer#1	almond antique burnished rose metallic	2	258.10677784349235	258.10677784349235	[2,34,6]	66619.10876874991	0.81133	2801.7074999999995
Manufacturer#1	almond antique burnished rose metallic	2	273.70217881648074	273.70217881648074	[2,34]	74912.8826888888	1.0	4128.782222222221
Manufacturer#1	almond antique chartreuse lavender yellow	34	230.90151585470358	230.90151585470358	[2,34,6,28]	53315.51002399992	0.69564	2210.7864
Manufacturer#1	almond antique salmon chartreuse burlywood	6	202.73109328368946	202.73109328368946	[2,34,6,28,42]	41099.896184	0.63079	2009.9536000000007
Manufacturer#1	almond aquamarine burnished black steel	28	121.6064517973862	121.6064517973862	[34,6,28,42]	14788.129118750014	0.20367	331.1337500000004
Manufacturer#1	almond aquamarine pink moccasin thistle	42	96.5751586416853	96.5751586416853	[6,28,42]	9326.761266666683	-1.4E-4	-0.20666666666708502
Manufacturer#2	almond antique violet chocolate turquoise	14	142.2363169751898	142.2363169751898	[14,40,2]	20231.169866666663	-0.4937	-1113.7466666666658
Manufacturer#2	almond antique violet turquoise frosted	40	137.76306498840682	137.76306498840682	[14,40,2,25]	18978.662075	-0.52056	-1004.4812499999995
Manufacturer#2	almond aquamarine midnight light salmon	2	130.03972279269132	130.03972279269132	[14,40,2,25,18]	16910.329504000005	-0.46909	-766.1791999999995
Manufacturer#2	almond aquamarine rose maroon antique	25	135.55100986344584	135.55100986344584	[40,2,25,18]	18374.07627499999	-0.60914	-1128.1787499999987
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	156.44019460768044	156.44019460768044	[2,25,18]	24473.534488888927	-0.95717	-1441.4466666666676
Manufacturer#3	almond antique chartreuse khaki white	17	196.7742266885805	196.7742266885805	[17,14,19]	38720.09628888887	0.55572	224.6944444444446
Manufacturer#3	almond antique forest lavender goldenrod	14	275.14144189852607	275.14144189852607	[17,14,19,1]	75702.81305	-0.67208	-1296.9000000000003
Manufacturer#3	almond antique metallic orange dim	19	260.23473614412046	260.23473614412046	[17,14,19,1,45]	67722.117896	-0.57035	-2129.0664
Manufacturer#3	almond antique misty red olive	1	275.9139962356932	275.9139962356932	[14,19,1,45]	76128.53331875012	-0.57748	-2547.7868749999993
Manufacturer#3	almond antique olive coral navajo	45	260.5815918713796	260.5815918713796	[19,1,45]	67902.76602222225	-0.87107	-4099.731111111111
Manufacturer#4	almond antique gainsboro frosted violet	10	170.13011889596618	170.13011889596618	[10,39,27]	28944.25735555559	-0.6657	-1347.4777777777779
Manufacturer#4	almond antique violet mint lemon	39	242.26834609323197	242.26834609323197	[10,39,27,7]	58693.95151875002	-0.80519	-2537.328125
Manufacturer#4	almond aquamarine floral ivory bisque	27	234.10001662537326	234.10001662537326	[10,39,27,7,12]	54802.817784000035	-0.60469	-1719.8079999999995
Manufacturer#4	almond aquamarine yellow dodger mint	7	247.3342714197732	247.3342714197732	[39,27,7,12]	61174.24181875003	-0.55087	-1719.0368749999975
Manufacturer#4	almond azure aquamarine papaya violet	12	283.3344330566893	283.3344330566893	[27,7,12]	80278.40095555557	-0.77557	-1867.4888888888881
Manufacturer#5	almond antique blue firebrick mint	31	83.69879024746363	83.69879024746363	[31,6,2]	7005.487488888913	0.39004	418.9233333333353
Manufacturer#5	almond antique medium spring khaki	6	316.68049612345885	316.68049612345885	[31,6,2,46]	100286.53662500004	-0.71361	-4090.853749999999
Manufacturer#5	almond antique sky peru orange	2	285.40506298242155	285.40506298242155	[31,6,2,46,23]	81456.04997600002	-0.71286	-3297.2011999999986
Manufacturer#5	almond aquamarine dodger light gainsboro	46	285.43749038756283	285.43749038756283	[6,2,46,23]	81474.56091875004	-0.98413	-4871.028125000002
Manufacturer#5	almond azure blanched chiffon midnight	23	315.9225931564038	315.9225931564038	[2,46,23]	99807.08486666664	-0.99789	-5664.856666666666
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
histogram_numeric(p_retailprice, 5) over w1 as hist, 
percentile(p_partkey, 0.5) over w1 as per,
row_number() over(distribute by p_mfgr sort by p_mfgr, p_name) as rn
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
histogram_numeric(p_retailprice, 5) over w1 as hist, 
percentile(p_partkey, 0.5) over w1 as per,
row_number() over(distribute by p_mfgr sort by p_mfgr, p_name) as rn
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6110 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [0, 5, 7]
                    Statistics: Num rows: 26 Data size: 6110 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_partkey (type: int), p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [0, 1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF Output Columns expression for PTF operator: Data type array<struct<x:double,y:double>> of column histogram_numeric_window_0 not supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col0, _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 13078 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: int, _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col2 ASC NULLS FIRST, _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: histogram_numeric_window_0
                              arguments: _col7, 5
                              name: histogram_numeric
                              window function: GenericUDAFHistogramNumericEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: percentile_window_1
                              arguments: _col0, 0.5
                              name: percentile
                              window function: GenericUDAFBridgeEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: row_number_window_2
                              name: row_number
                              window function: GenericUDAFRowNumberEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 26 Data size: 13078 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), histogram_numeric_window_0 (type: array<struct<x:double,y:double>>), percentile_window_1 (type: double), row_number_window_2 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 26 Data size: 24830 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 24830 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size, 
histogram_numeric(p_retailprice, 5) over w1 as hist, 
percentile(p_partkey, 0.5) over w1 as per,
row_number() over(distribute by p_mfgr sort by p_mfgr, p_name) as rn
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size, 
histogram_numeric(p_retailprice, 5) over w1 as hist, 
percentile(p_partkey, 0.5) over w1 as per,
row_number() over(distribute by p_mfgr sort by p_mfgr, p_name) as rn
from part
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	hist	per	rn
Manufacturer#1	almond antique burnished rose metallic	2	[{"x":1173.15,"y":2.0},{"x":1602.59,"y":1.0},{"x":1753.76,"y":1.0}]	115872.0	2
Manufacturer#1	almond antique burnished rose metallic	2	[{"x":1173.15,"y":2.0},{"x":1753.76,"y":1.0}]	121152.0	1
Manufacturer#1	almond antique chartreuse lavender yellow	34	[{"x":1173.15,"y":2.0},{"x":1414.42,"y":1.0},{"x":1602.59,"y":1.0},{"x":1753.76,"y":1.0}]	110592.0	3
Manufacturer#1	almond antique salmon chartreuse burlywood	6	[{"x":1173.15,"y":1.0},{"x":1414.42,"y":1.0},{"x":1602.59,"y":1.0},{"x":1632.66,"y":1.0},{"x":1753.76,"y":1.0}]	86428.0	4
Manufacturer#1	almond aquamarine burnished black steel	28	[{"x":1414.42,"y":1.0},{"x":1602.59,"y":1.0},{"x":1632.66,"y":1.0},{"x":1753.76,"y":1.0}]	86098.0	5
Manufacturer#1	almond aquamarine pink moccasin thistle	42	[{"x":1414.42,"y":1.0},{"x":1602.59,"y":1.0},{"x":1632.66,"y":1.0}]	86428.0	6
Manufacturer#2	almond antique violet chocolate turquoise	14	[{"x":1690.68,"y":1.0},{"x":1800.7,"y":1.0},{"x":2031.98,"y":1.0}]	146985.0	1
Manufacturer#2	almond antique violet turquoise frosted	40	[{"x":1690.68,"y":1.0},{"x":1698.66,"y":1.0},{"x":1800.7,"y":1.0},{"x":2031.98,"y":1.0}]	139825.5	2
Manufacturer#2	almond aquamarine midnight light salmon	2	[{"x":1690.68,"y":1.0},{"x":1698.66,"y":1.0},{"x":1701.6,"y":1.0},{"x":1800.7,"y":1.0},{"x":2031.98,"y":1.0}]	146985.0	3
Manufacturer#2	almond aquamarine rose maroon antique	25	[{"x":1698.66,"y":1.0},{"x":1701.6,"y":1.0},{"x":1800.7,"y":1.0},{"x":2031.98,"y":1.0}]	169347.0	4
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	[{"x":1698.66,"y":1.0},{"x":1701.6,"y":1.0},{"x":2031.98,"y":1.0}]	146985.0	5
Manufacturer#3	almond antique chartreuse khaki white	17	[{"x":1190.27,"y":1.0},{"x":1410.39,"y":1.0},{"x":1671.68,"y":1.0}]	90681.0	1
Manufacturer#3	almond antique forest lavender goldenrod	14	[{"x":1190.27,"y":1.0},{"x":1410.39,"y":1.0},{"x":1671.68,"y":1.0},{"x":1922.98,"y":1.0}]	65831.5	2
Manufacturer#3	almond antique metallic orange dim	19	[{"x":1190.27,"y":1.0},{"x":1337.29,"y":1.0},{"x":1410.39,"y":1.0},{"x":1671.68,"y":1.0},{"x":1922.98,"y":1.0}]	90681.0	3
Manufacturer#3	almond antique misty red olive	1	[{"x":1190.27,"y":1.0},{"x":1337.29,"y":1.0},{"x":1410.39,"y":1.0},{"x":1922.98,"y":1.0}]	76690.0	4
Manufacturer#3	almond antique olive coral navajo	45	[{"x":1337.29,"y":1.0},{"x":1410.39,"y":1.0},{"x":1922.98,"y":1.0}]	112398.0	5
Manufacturer#4	almond antique gainsboro frosted violet	10	[{"x":1206.26,"y":1.0},{"x":1375.42,"y":1.0},{"x":1620.67,"y":1.0}]	48427.0	1
Manufacturer#4	almond antique violet mint lemon	39	[{"x":1206.26,"y":1.0},{"x":1375.42,"y":1.0},{"x":1620.67,"y":1.0},{"x":1844.92,"y":1.0}]	46844.0	2
Manufacturer#4	almond aquamarine floral ivory bisque	27	[{"x":1206.26,"y":1.0},{"x":1290.35,"y":1.0},{"x":1375.42,"y":1.0},{"x":1620.67,"y":1.0},{"x":1844.92,"y":1.0}]	45261.0	3
Manufacturer#4	almond aquamarine yellow dodger mint	7	[{"x":1206.26,"y":1.0},{"x":1290.35,"y":1.0},{"x":1375.42,"y":1.0},{"x":1844.92,"y":1.0}]	39309.0	4
Manufacturer#4	almond azure aquamarine papaya violet	12	[{"x":1206.26,"y":1.0},{"x":1290.35,"y":1.0},{"x":1844.92,"y":1.0}]	33357.0	5
Manufacturer#5	almond antique blue firebrick mint	31	[{"x":1611.66,"y":1.0},{"x":1788.73,"y":1.0},{"x":1789.69,"y":1.0}]	155733.0	1
Manufacturer#5	almond antique medium spring khaki	6	[{"x":1018.1,"y":1.0},{"x":1611.66,"y":1.0},{"x":1788.73,"y":1.0},{"x":1789.69,"y":1.0}]	99201.0	2
Manufacturer#5	almond antique sky peru orange	2	[{"x":1018.1,"y":1.0},{"x":1464.48,"y":1.0},{"x":1611.66,"y":1.0},{"x":1788.73,"y":1.0},{"x":1789.69,"y":1.0}]	78486.0	3
Manufacturer#5	almond aquamarine dodger light gainsboro	46	[{"x":1018.1,"y":1.0},{"x":1464.48,"y":1.0},{"x":1611.66,"y":1.0},{"x":1788.73,"y":1.0}]	60577.5	4
Manufacturer#5	almond azure blanched chiffon midnight	23	[{"x":1018.1,"y":1.0},{"x":1464.48,"y":1.0},{"x":1788.73,"y":1.0}]	78486.0	5
PREHOOK: query: explain vectorization detail
create view IF NOT EXISTS mfgr_price_view_n2 as 
select p_mfgr, p_brand, 
round(sum(p_retailprice),2) as s 
from part 
group by p_mfgr, p_brand
PREHOOK: type: CREATEVIEW
POSTHOOK: query: explain vectorization detail
create view IF NOT EXISTS mfgr_price_view_n2 as 
select p_mfgr, p_brand, 
round(sum(p_retailprice),2) as s 
from part 
group by p_mfgr, p_brand
POSTHOOK: type: CREATEVIEW
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage

STAGE PLANS:
  Stage: Stage-1
      Create View Operator:
        Create View
          if not exists: true
          columns: p_mfgr string, p_brand string, s double
          expanded text: select `part`.`p_mfgr`, `part`.`p_brand`, 
round(sum(`part`.`p_retailprice`),2) as `s` 
from `default`.`part` 
group by `part`.`p_mfgr`, `part`.`p_brand`
          name: default.mfgr_price_view_n2
          original text: select p_mfgr, p_brand, 
round(sum(p_retailprice),2) as s 
from part 
group by p_mfgr, p_brand

PREHOOK: query: create view IF NOT EXISTS mfgr_price_view_n2 as 
select p_mfgr, p_brand, 
round(sum(p_retailprice),2) as s 
from part 
group by p_mfgr, p_brand
PREHOOK: type: CREATEVIEW
PREHOOK: Input: default@part
PREHOOK: Output: database:default
PREHOOK: Output: default@mfgr_price_view_n2
POSTHOOK: query: create view IF NOT EXISTS mfgr_price_view_n2 as 
select p_mfgr, p_brand, 
round(sum(p_retailprice),2) as s 
from part 
group by p_mfgr, p_brand
POSTHOOK: type: CREATEVIEW
POSTHOOK: Input: default@part
POSTHOOK: Output: database:default
POSTHOOK: Output: default@mfgr_price_view_n2
POSTHOOK: Lineage: mfgr_price_view_n2.p_brand SIMPLE [(part)part.FieldSchema(name:p_brand, type:string, comment:null), ]
POSTHOOK: Lineage: mfgr_price_view_n2.p_mfgr SIMPLE [(part)part.FieldSchema(name:p_mfgr, type:string, comment:null), ]
POSTHOOK: Lineage: mfgr_price_view_n2.s EXPRESSION [(part)part.FieldSchema(name:p_retailprice, type:double, comment:null), ]
p_mfgr	p_brand	s
PREHOOK: query: explain vectorization detail
select * 
from (
select p_mfgr, p_brand, s, 
round(sum(s) over w1 , 2)  as s1
from mfgr_price_view_n2 
window w1 as (distribute by p_mfgr sort by p_mfgr )
) sq
order by p_mfgr, p_brand
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select * 
from (
select p_mfgr, p_brand, s, 
round(sum(s) over w1 , 2)  as s1
from mfgr_price_view_n2 
window w1 as (distribute by p_mfgr sort by p_mfgr )
) sq
order by p_mfgr, p_brand
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  properties:
                    insideView TRUE
                  Statistics: Num rows: 26 Data size: 5148 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Select Operator
                    expressions: p_mfgr (type: string), p_brand (type: string), p_retailprice (type: double)
                    outputColumnNames: p_mfgr, p_brand, p_retailprice
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [2, 3, 7]
                    Statistics: Num rows: 26 Data size: 5148 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: sum(p_retailprice)
                      Group By Vectorization:
                          aggregators: VectorUDAFSumDouble(col 7:double) -> double
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 2:string, col 3:string
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: [0]
                      keys: p_mfgr (type: string), p_brand (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 13 Data size: 2574 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string)
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: string)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            partitionColumnNums: [0]
                            valueColumnNums: [2]
                        Statistics: Num rows: 13 Data size: 2574 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col2 (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [2, 3, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: Only PTF directly under reduce-shuffle is supported
                vectorized: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 13 Data size: 2574 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: string, _col2: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col0 ASC NULLS FIRST
                        partition by: _col0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: round(_col2, 2)
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 13 Data size: 2574 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string), round(_col2, 2) (type: double), round(sum_window_0, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 13 Data size: 2678 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: string), _col1 (type: string)
                      sort order: ++
                      Statistics: Num rows: 13 Data size: 2678 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col2 (type: double), _col3 (type: double)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 4
                    dataColumns: KEY.reducesinkkey0:string, KEY.reducesinkkey1:string, VALUE._col0:double, VALUE._col1:double
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: double), VALUE._col1 (type: double)
                outputColumnNames: _col0, _col1, _col2, _col3
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3]
                Statistics: Num rows: 13 Data size: 2678 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 13 Data size: 2678 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * 
from (
select p_mfgr, p_brand, s, 
round(sum(s) over w1 , 2)  as s1
from mfgr_price_view_n2 
window w1 as (distribute by p_mfgr sort by p_mfgr )
) sq
order by p_mfgr, p_brand
PREHOOK: type: QUERY
PREHOOK: Input: default@mfgr_price_view_n2
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select * 
from (
select p_mfgr, p_brand, s, 
round(sum(s) over w1 , 2)  as s1
from mfgr_price_view_n2 
window w1 as (distribute by p_mfgr sort by p_mfgr )
) sq
order by p_mfgr, p_brand
POSTHOOK: type: QUERY
POSTHOOK: Input: default@mfgr_price_view_n2
POSTHOOK: Input: default@part
#### A masked pattern was here ####
sq.p_mfgr	sq.p_brand	sq.s	sq.s1
Manufacturer#1	Brand#12	4800.84	8749.73
Manufacturer#1	Brand#14	2346.3	8749.73
Manufacturer#1	Brand#15	1602.59	8749.73
Manufacturer#2	Brand#22	3491.38	8923.62
Manufacturer#2	Brand#23	2031.98	8923.62
Manufacturer#2	Brand#24	1698.66	8923.62
Manufacturer#2	Brand#25	1701.6	8923.62
Manufacturer#3	Brand#31	1671.68	7532.61
Manufacturer#3	Brand#32	3333.37	7532.61
Manufacturer#3	Brand#34	1337.29	7532.61
Manufacturer#3	Brand#35	1190.27	7532.61
Manufacturer#4	Brand#41	4755.94	7337.62
Manufacturer#4	Brand#42	2581.68	7337.62
Manufacturer#5	Brand#51	1611.66	7672.66
Manufacturer#5	Brand#52	3254.17	7672.66
Manufacturer#5	Brand#53	2806.83	7672.66
PREHOOK: query: select p_mfgr, p_brand, s, 
round(sum(s) over w1 ,2)  as s1
from mfgr_price_view_n2 
window w1 as (distribute by p_mfgr sort by p_brand rows between 2 preceding and current row)
PREHOOK: type: QUERY
PREHOOK: Input: default@mfgr_price_view_n2
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_brand, s, 
round(sum(s) over w1 ,2)  as s1
from mfgr_price_view_n2 
window w1 as (distribute by p_mfgr sort by p_brand rows between 2 preceding and current row)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@mfgr_price_view_n2
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_brand	s	s1
Manufacturer#1	Brand#12	4800.84	4800.84
Manufacturer#1	Brand#14	2346.3	7147.14
Manufacturer#1	Brand#15	1602.59	8749.73
Manufacturer#2	Brand#22	3491.38	3491.38
Manufacturer#2	Brand#23	2031.98	5523.36
Manufacturer#2	Brand#24	1698.66	7222.02
Manufacturer#2	Brand#25	1701.6	5432.24
Manufacturer#3	Brand#31	1671.68	1671.68
Manufacturer#3	Brand#32	3333.37	5005.05
Manufacturer#3	Brand#34	1337.29	6342.34
Manufacturer#3	Brand#35	1190.27	5860.93
Manufacturer#4	Brand#41	4755.94	4755.94
Manufacturer#4	Brand#42	2581.68	7337.62
Manufacturer#5	Brand#51	1611.66	1611.66
Manufacturer#5	Brand#52	3254.17	4865.83
Manufacturer#5	Brand#53	2806.83	7672.66
PREHOOK: query: explain vectorization detail
create view IF NOT EXISTS mfgr_brand_price_view_n0 as 
select p_mfgr, p_brand, 
round(sum(p_retailprice) over w1,2) as s
from part 
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and current row)
PREHOOK: type: CREATEVIEW
POSTHOOK: query: explain vectorization detail
create view IF NOT EXISTS mfgr_brand_price_view_n0 as 
select p_mfgr, p_brand, 
round(sum(p_retailprice) over w1,2) as s
from part 
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and current row)
POSTHOOK: type: CREATEVIEW
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage

STAGE PLANS:
  Stage: Stage-1
      Create View Operator:
        Create View
          if not exists: true
          columns: p_mfgr string, p_brand string, s double
          expanded text: select `part`.`p_mfgr`, `part`.`p_brand`, 
round(sum(`part`.`p_retailprice`) over w1,2) as `s`
from `default`.`part` 
window w1 as (distribute by `part`.`p_mfgr` sort by `part`.`p_name` rows between 2 preceding and current row)
          name: default.mfgr_brand_price_view_n0
          original text: select p_mfgr, p_brand, 
round(sum(p_retailprice) over w1,2) as s
from part 
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and current row)

PREHOOK: query: create view IF NOT EXISTS mfgr_brand_price_view_n0 as 
select p_mfgr, p_brand, 
round(sum(p_retailprice) over w1,2) as s
from part 
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and current row)
PREHOOK: type: CREATEVIEW
PREHOOK: Input: default@part
PREHOOK: Output: database:default
PREHOOK: Output: default@mfgr_brand_price_view_n0
POSTHOOK: query: create view IF NOT EXISTS mfgr_brand_price_view_n0 as 
select p_mfgr, p_brand, 
round(sum(p_retailprice) over w1,2) as s
from part 
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and current row)
POSTHOOK: type: CREATEVIEW
POSTHOOK: Input: default@part
POSTHOOK: Output: database:default
POSTHOOK: Output: default@mfgr_brand_price_view_n0
POSTHOOK: Lineage: mfgr_brand_price_view_n0.p_brand SIMPLE [(part)part.FieldSchema(name:p_brand, type:string, comment:null), ]
POSTHOOK: Lineage: mfgr_brand_price_view_n0.p_mfgr SIMPLE [(part)part.FieldSchema(name:p_mfgr, type:string, comment:null), ]
POSTHOOK: Lineage: mfgr_brand_price_view_n0.s SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
p_mfgr	p_brand	s
PREHOOK: query: explain vectorization detail
select * from mfgr_brand_price_view_n0
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select * from mfgr_brand_price_view_n0
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  properties:
                    insideView TRUE
                  Statistics: Num rows: 26 Data size: 8294 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [3, 7]
                    Statistics: Num rows: 26 Data size: 8294 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_brand (type: string), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 3, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col1 (type: string), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col3, _col7
                Statistics: Num rows: 26 Data size: 15262 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col3: string, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(2)~CURRENT
                  Statistics: Num rows: 26 Data size: 15262 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col3 (type: string), round(sum_window_0, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 26 Data size: 5148 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 5148 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from mfgr_brand_price_view_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@mfgr_brand_price_view_n0
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select * from mfgr_brand_price_view_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@mfgr_brand_price_view_n0
POSTHOOK: Input: default@part
#### A masked pattern was here ####
mfgr_brand_price_view_n0.p_mfgr	mfgr_brand_price_view_n0.p_brand	mfgr_brand_price_view_n0.s
Manufacturer#1	Brand#12	4100.06
Manufacturer#1	Brand#12	4649.67
Manufacturer#1	Brand#12	4770.77
Manufacturer#1	Brand#14	1173.15
Manufacturer#1	Brand#14	2346.3
Manufacturer#1	Brand#15	4529.5
Manufacturer#2	Brand#22	1690.68
Manufacturer#2	Brand#22	3491.38
Manufacturer#2	Brand#23	5523.36
Manufacturer#2	Brand#24	5531.34
Manufacturer#2	Brand#25	5432.24
Manufacturer#3	Brand#31	1671.68
Manufacturer#3	Brand#32	4272.34
Manufacturer#3	Brand#32	4523.64
Manufacturer#3	Brand#34	4670.66
Manufacturer#3	Brand#35	2861.95
Manufacturer#4	Brand#41	1620.67
Manufacturer#4	Brand#41	4341.53
Manufacturer#4	Brand#41	4426.6
Manufacturer#4	Brand#42	2996.09
Manufacturer#4	Brand#42	4202.35
Manufacturer#5	Brand#51	3401.35
Manufacturer#5	Brand#52	1789.69
Manufacturer#5	Brand#52	4271.31
Manufacturer#5	Brand#53	4418.49
Manufacturer#5	Brand#53	5190.08
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, 
lv_col, p_size, sum(p_size) over w1   as s
from (select p_mfgr, p_name, p_size, array(1,2,3) arr from part) p 
lateral view explode(arr) part_lv as lv_col
window w1 as (distribute by p_mfgr sort by p_size, lv_col rows between 2 preceding and current row)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, 
lv_col, p_size, sum(p_size) over w1   as s
from (select p_mfgr, p_name, p_size, array(1,2,3) arr from part) p 
lateral view explode(arr) part_lv as lv_col
window w1 as (distribute by p_mfgr sort by p_size, lv_col rows between 2 preceding and current row)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: p_mfgr (type: string), p_name (type: string), p_size (type: int)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 26 Data size: 7254 Basic stats: COMPLETE Column stats: COMPLETE
                    Lateral View Forward
                      Statistics: Num rows: 26 Data size: 7254 Basic stats: COMPLETE Column stats: COMPLETE
                      Select Operator
                        expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 26 Data size: 8710 Basic stats: COMPLETE Column stats: COMPLETE
                        Lateral View Join Operator
                          outputColumnNames: _col0, _col1, _col2, _col4
                          Statistics: Num rows: 52 Data size: 10166 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            key expressions: _col0 (type: string), _col2 (type: int), _col4 (type: int)
                            sort order: +++
                            Map-reduce partition columns: _col0 (type: string)
                            Statistics: Num rows: 52 Data size: 10166 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col1 (type: string)
                      Select Operator
                        expressions: Const array<int> [1, 2, 3] (type: array<int>)
                        outputColumnNames: _col0
                        Statistics: Num rows: 26 Data size: 1456 Basic stats: COMPLETE Column stats: COMPLETE
                        UDTF Operator
                          Statistics: Num rows: 26 Data size: 1456 Basic stats: COMPLETE Column stats: COMPLETE
                          function name: explode
                          Lateral View Join Operator
                            outputColumnNames: _col0, _col1, _col2, _col4
                            Statistics: Num rows: 52 Data size: 10166 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              key expressions: _col0 (type: string), _col2 (type: int), _col4 (type: int)
                              sort order: +++
                              Map-reduce partition columns: _col0 (type: string)
                              Statistics: Num rows: 52 Data size: 10166 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col1 (type: string)
            Execution mode: llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                notVectorizedReason: Lateral View Forward (LATERALVIEWFORWARD) not supported
                vectorized: false
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), KEY.reducesinkkey1 (type: int), KEY.reducesinkkey2 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col4
                Statistics: Num rows: 52 Data size: 13780 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: string, _col2: int, _col4: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col2 ASC NULLS FIRST, _col4 ASC NULLS FIRST
                        partition by: _col0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col2
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS PRECEDING(2)~CURRENT
                  Statistics: Num rows: 52 Data size: 13780 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string), _col4 (type: int), _col2 (type: int), sum_window_0 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 52 Data size: 14196 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 52 Data size: 14196 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, 
lv_col, p_size, sum(p_size) over w1   as s
from (select p_mfgr, p_name, p_size, array(1,2,3) arr from part) p 
lateral view explode(arr) part_lv as lv_col
window w1 as (distribute by p_mfgr sort by p_size, lv_col rows between 2 preceding and current row)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, 
lv_col, p_size, sum(p_size) over w1   as s
from (select p_mfgr, p_name, p_size, array(1,2,3) arr from part) p 
lateral view explode(arr) part_lv as lv_col
window w1 as (distribute by p_mfgr sort by p_size, lv_col rows between 2 preceding and current row)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	lv_col	p_size	s
Manufacturer#1	almond antique burnished rose metallic	1	2	2
Manufacturer#1	almond antique burnished rose metallic	1	2	4
Manufacturer#1	almond antique burnished rose metallic	2	2	6
Manufacturer#1	almond antique burnished rose metallic	2	2	6
Manufacturer#1	almond antique burnished rose metallic	3	2	6
Manufacturer#1	almond antique burnished rose metallic	3	2	6
Manufacturer#1	almond antique chartreuse lavender yellow	1	34	90
Manufacturer#1	almond antique chartreuse lavender yellow	2	34	96
Manufacturer#1	almond antique chartreuse lavender yellow	3	34	102
Manufacturer#1	almond antique salmon chartreuse burlywood	1	6	10
Manufacturer#1	almond antique salmon chartreuse burlywood	2	6	14
Manufacturer#1	almond antique salmon chartreuse burlywood	3	6	18
Manufacturer#1	almond aquamarine burnished black steel	1	28	40
Manufacturer#1	almond aquamarine burnished black steel	2	28	62
Manufacturer#1	almond aquamarine burnished black steel	3	28	84
Manufacturer#1	almond aquamarine pink moccasin thistle	1	42	110
Manufacturer#1	almond aquamarine pink moccasin thistle	2	42	118
Manufacturer#1	almond aquamarine pink moccasin thistle	3	42	126
Manufacturer#2	almond antique violet chocolate turquoise	1	14	18
Manufacturer#2	almond antique violet chocolate turquoise	2	14	30
Manufacturer#2	almond antique violet chocolate turquoise	3	14	42
Manufacturer#2	almond antique violet turquoise frosted	1	40	90
Manufacturer#2	almond antique violet turquoise frosted	2	40	105
Manufacturer#2	almond antique violet turquoise frosted	3	40	120
Manufacturer#2	almond aquamarine midnight light salmon	1	2	2
Manufacturer#2	almond aquamarine midnight light salmon	2	2	4
Manufacturer#2	almond aquamarine midnight light salmon	3	2	6
Manufacturer#2	almond aquamarine rose maroon antique	1	25	61
Manufacturer#2	almond aquamarine rose maroon antique	2	25	68
Manufacturer#2	almond aquamarine rose maroon antique	3	25	75
Manufacturer#2	almond aquamarine sandy cyan gainsboro	1	18	46
Manufacturer#2	almond aquamarine sandy cyan gainsboro	2	18	50
Manufacturer#2	almond aquamarine sandy cyan gainsboro	3	18	54
Manufacturer#3	almond antique chartreuse khaki white	1	17	45
Manufacturer#3	almond antique chartreuse khaki white	2	17	48
Manufacturer#3	almond antique chartreuse khaki white	3	17	51
Manufacturer#3	almond antique forest lavender goldenrod	1	14	16
Manufacturer#3	almond antique forest lavender goldenrod	2	14	29
Manufacturer#3	almond antique forest lavender goldenrod	3	14	42
Manufacturer#3	almond antique metallic orange dim	1	19	53
Manufacturer#3	almond antique metallic orange dim	2	19	55
Manufacturer#3	almond antique metallic orange dim	3	19	57
Manufacturer#3	almond antique misty red olive	1	1	1
Manufacturer#3	almond antique misty red olive	2	1	2
Manufacturer#3	almond antique misty red olive	3	1	3
Manufacturer#3	almond antique olive coral navajo	1	45	83
Manufacturer#3	almond antique olive coral navajo	2	45	109
Manufacturer#3	almond antique olive coral navajo	3	45	135
Manufacturer#4	almond antique gainsboro frosted violet	1	10	24
Manufacturer#4	almond antique gainsboro frosted violet	2	10	27
Manufacturer#4	almond antique gainsboro frosted violet	3	10	30
Manufacturer#4	almond antique violet mint lemon	1	39	93
Manufacturer#4	almond antique violet mint lemon	2	39	105
Manufacturer#4	almond antique violet mint lemon	3	39	117
Manufacturer#4	almond aquamarine floral ivory bisque	1	27	51
Manufacturer#4	almond aquamarine floral ivory bisque	2	27	66
Manufacturer#4	almond aquamarine floral ivory bisque	3	27	81
Manufacturer#4	almond aquamarine yellow dodger mint	1	7	7
Manufacturer#4	almond aquamarine yellow dodger mint	2	7	14
Manufacturer#4	almond aquamarine yellow dodger mint	3	7	21
Manufacturer#4	almond azure aquamarine papaya violet	1	12	32
Manufacturer#4	almond azure aquamarine papaya violet	2	12	34
Manufacturer#4	almond azure aquamarine papaya violet	3	12	36
Manufacturer#5	almond antique blue firebrick mint	1	31	77
Manufacturer#5	almond antique blue firebrick mint	2	31	85
Manufacturer#5	almond antique blue firebrick mint	3	31	93
Manufacturer#5	almond antique medium spring khaki	1	6	10
Manufacturer#5	almond antique medium spring khaki	2	6	14
Manufacturer#5	almond antique medium spring khaki	3	6	18
Manufacturer#5	almond antique sky peru orange	1	2	2
Manufacturer#5	almond antique sky peru orange	2	2	4
Manufacturer#5	almond antique sky peru orange	3	2	6
Manufacturer#5	almond aquamarine dodger light gainsboro	1	46	108
Manufacturer#5	almond aquamarine dodger light gainsboro	2	46	123
Manufacturer#5	almond aquamarine dodger light gainsboro	3	46	138
Manufacturer#5	almond azure blanched chiffon midnight	1	23	35
Manufacturer#5	almond azure blanched chiffon midnight	2	23	52
Manufacturer#5	almond azure blanched chiffon midnight	3	23	69
PREHOOK: query: CREATE TABLE part_1_n0( 
p_mfgr STRING, 
p_name STRING, 
p_size INT, 
r INT, 
dr INT, 
s DOUBLE)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@part_1_n0
POSTHOOK: query: CREATE TABLE part_1_n0( 
p_mfgr STRING, 
p_name STRING, 
p_size INT, 
r INT, 
dr INT, 
s DOUBLE)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@part_1_n0
PREHOOK: query: CREATE TABLE part_2_n0( 
p_mfgr STRING, 
p_name STRING, 
p_size INT, 
r INT, 
dr INT, 
cud INT,  
s2 DOUBLE, 
fv1 INT)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@part_2_n0
POSTHOOK: query: CREATE TABLE part_2_n0( 
p_mfgr STRING, 
p_name STRING, 
p_size INT, 
r INT, 
dr INT, 
cud INT,  
s2 DOUBLE, 
fv1 INT)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@part_2_n0
PREHOOK: query: CREATE TABLE part_3_n0( 
p_mfgr STRING, 
p_name STRING, 
p_size INT, 
c INT, 
ca INT, 
fv INT)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@part_3_n0
POSTHOOK: query: CREATE TABLE part_3_n0( 
p_mfgr STRING, 
p_name STRING, 
p_size INT, 
c INT, 
ca INT, 
fv INT)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@part_3_n0
PREHOOK: query: explain vectorization detail
from part 
INSERT OVERWRITE TABLE part_1_n0 
select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name ) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name ) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s
INSERT OVERWRITE TABLE part_2_n0 
select  p_mfgr,p_name, p_size,  
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
round(sum(p_size) over (distribute by p_mfgr sort by p_size range between 5 preceding and current row),1) as s2, 
first_value(p_size) over w1  as fv1
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following) 
INSERT OVERWRITE TABLE part_3_n0 
select  p_mfgr,p_name, p_size,  
count(*) over(distribute by p_mfgr sort by p_name) as c, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
first_value(p_size) over w1  as fv
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
from part 
INSERT OVERWRITE TABLE part_1_n0 
select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name ) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name ) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s
INSERT OVERWRITE TABLE part_2_n0 
select  p_mfgr,p_name, p_size,  
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
round(sum(p_size) over (distribute by p_mfgr sort by p_size range between 5 preceding and current row),1) as s2, 
first_value(p_size) over w1  as fv1
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following) 
INSERT OVERWRITE TABLE part_3_n0 
select  p_mfgr,p_name, p_size,  
count(*) over(distribute by p_mfgr sort by p_name) as c, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
first_value(p_size) over w1  as fv
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-3 is a root stage
  Stage-4 depends on stages: Stage-3
  Stage-0 depends on stages: Stage-4
  Stage-5 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-4
  Stage-6 depends on stages: Stage-1
  Stage-2 depends on stages: Stage-4
  Stage-7 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-3
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 10 <- Reducer 9 (CUSTOM_SIMPLE_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
        Reducer 4 <- Map 1 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 4 (SIMPLE_EDGE)
        Reducer 6 <- Reducer 5 (SIMPLE_EDGE)
        Reducer 7 <- Reducer 6 (CUSTOM_SIMPLE_EDGE)
        Reducer 8 <- Map 1 (SIMPLE_EDGE)
        Reducer 9 <- Reducer 8 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 10 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: Aggregation Function expression for GROUPBY operator: UDF compute_stats not supported
                vectorized: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1), compute_stats(VALUE._col2), compute_stats(VALUE._col3), compute_stats(VALUE._col4), compute_stats(VALUE._col5)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 2640 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 2640 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum UNBOUNDED end frame is not supported for ROWS window type
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: sum_window_2
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), rank_window_0 (type: int), dense_rank_window_1 (type: int), round(sum_window_2, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.part_1_n0
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: int), _col4 (type: int), _col5 (type: double)
                      outputColumnNames: p_mfgr, p_name, p_size, r, dr, s
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: compute_stats(p_mfgr, 'hll'), compute_stats(p_name, 'hll'), compute_stats(p_size, 'hll'), compute_stats(r, 'hll'), compute_stats(dr, 'hll'), compute_stats(s, 'hll')
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                        Statistics: Num rows: 1 Data size: 2576 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          sort order: 
                          Statistics: Num rows: 1 Data size: 2576 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col2 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col4 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col5 (type: struct<columntype:string,min:double,max:double,countnulls:bigint,bitvector:binary>)
        Reducer 3 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: Aggregation Function expression for GROUPBY operator: UDF compute_stats not supported
                vectorized: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1), compute_stats(VALUE._col2), compute_stats(VALUE._col3), compute_stats(VALUE._col4), compute_stats(VALUE._col5)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 2640 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 2640 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 4 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: cume_dist not in supported functions [avg, count, dense_rank, first_value, last_value, max, min, rank, row_number, sum]
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: cume_dist_window_2
                              arguments: _col1
                              name: cume_dist
                              window function: GenericUDAFCumeDistEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: rank_window_0 (type: int), dense_rank_window_1 (type: int), cume_dist_window_2 (type: double), _col1 (type: string), _col2 (type: string), _col5 (type: int)
                    outputColumnNames: rank_window_0, dense_rank_window_1, cume_dist_window_2, _col1, _col2, _col5
                    Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col5 (type: int)
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string)
                      Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: rank_window_0 (type: int), dense_rank_window_1 (type: int), cume_dist_window_2 (type: double), _col1 (type: string)
        Reducer 5 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: int), VALUE._col2 (type: double), VALUE._col4 (type: string), KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col8
                Statistics: Num rows: 26 Data size: 13182 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: int, _col1: int, _col2: double, _col4: string, _col5: string, _col8: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col8 ASC NULLS FIRST
                        partition by: _col5
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_3
                              arguments: _col8
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(5)~CURRENT
                  Statistics: Num rows: 26 Data size: 13182 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: sum_window_3 (type: bigint), _col0 (type: int), _col1 (type: int), _col2 (type: double), _col4 (type: string), _col5 (type: string), _col8 (type: int)
                    outputColumnNames: sum_window_3, _col0, _col1, _col2, _col4, _col5, _col8
                    Statistics: Num rows: 26 Data size: 13182 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col5 (type: string), _col4 (type: string)
                      sort order: ++
                      Map-reduce partition columns: _col5 (type: string)
                      Statistics: Num rows: 26 Data size: 13182 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: sum_window_3 (type: bigint), _col0 (type: int), _col1 (type: int), _col2 (type: double), _col8 (type: int)
        Reducer 6 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: first_value only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: bigint), VALUE._col1 (type: int), VALUE._col2 (type: int), VALUE._col3 (type: double), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col7 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col5, _col6, _col9
                Statistics: Num rows: 26 Data size: 13390 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: bigint, _col1: int, _col2: int, _col3: double, _col5: string, _col6: string, _col9: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col6 ASC NULLS FIRST, _col5 ASC NULLS FIRST
                        partition by: _col6
                        raw input shape:
                        window functions:
                            window function definition
                              alias: first_value_window_4
                              arguments: _col9
                              name: first_value
                              window function: GenericUDAFFirstValueEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 13390 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col6 (type: string), _col5 (type: string), _col9 (type: int), _col1 (type: int), _col2 (type: int), UDFToInteger(_col3) (type: int), UDFToDouble(round(_col0, 1)) (type: double), first_value_window_4 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                    Statistics: Num rows: 26 Data size: 6422 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6422 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.part_2_n0
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: int), _col4 (type: int), _col5 (type: int), _col6 (type: double), _col7 (type: int)
                      outputColumnNames: p_mfgr, p_name, p_size, r, dr, cud, s2, fv1
                      Statistics: Num rows: 26 Data size: 6422 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: compute_stats(p_mfgr, 'hll'), compute_stats(p_name, 'hll'), compute_stats(p_size, 'hll'), compute_stats(r, 'hll'), compute_stats(dr, 'hll'), compute_stats(cud, 'hll'), compute_stats(s2, 'hll'), compute_stats(fv1, 'hll')
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                        Statistics: Num rows: 1 Data size: 3424 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          sort order: 
                          Statistics: Num rows: 1 Data size: 3424 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col2 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col4 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col5 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col6 (type: struct<columntype:string,min:double,max:double,countnulls:bigint,bitvector:binary>), _col7 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>)
        Reducer 7 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: Aggregation Function expression for GROUPBY operator: UDF compute_stats not supported
                vectorized: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1), compute_stats(VALUE._col2), compute_stats(VALUE._col3), compute_stats(VALUE._col4), compute_stats(VALUE._col5), compute_stats(VALUE._col6), compute_stats(VALUE._col7)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                Statistics: Num rows: 1 Data size: 3520 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 3520 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 8 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:string, KEY.reducesinkkey1:string, VALUE._col3:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint]
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1, 0, 2]
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: count_window_0
                              name: count
                              window function: GenericUDAFCountEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                              isStar: true
                            window function definition
                              alias: count_window_1
                              arguments: _col5
                              name: count
                              window function: GenericUDAFCountEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorCountStar, VectorPTFEvaluatorCount]
                      functionInputExpressions: [null, col 2:int]
                      functionNames: [count, count]
                      keyInputColumns: [1, 0]
                      native: true
                      nonKeyInputColumns: [2]
                      orderExpressions: [col 1:string]
                      outputColumns: [3, 4, 1, 0, 2]
                      outputTypes: [bigint, bigint, string, string, int]
                      partitionExpressions: [col 0:string]
                      streamingColumns: []
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: count_window_0 (type: bigint), count_window_1 (type: bigint), _col1 (type: string), _col2 (type: string), _col5 (type: int)
                    outputColumnNames: count_window_0, count_window_1, _col1, _col2, _col5
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [3, 4, 1, 0, 2]
                    Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col1 (type: string)
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0, 1]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          partitionColumnNums: [0]
                          valueColumnNums: [3, 4, 2]
                      Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: count_window_0 (type: bigint), count_window_1 (type: bigint), _col5 (type: int)
        Reducer 9 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: first_value only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: bigint), VALUE._col1 (type: bigint), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col5 (type: int)
                outputColumnNames: _col0, _col1, _col3, _col4, _col7
                Statistics: Num rows: 26 Data size: 13182 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: bigint, _col1: bigint, _col3: string, _col4: string, _col7: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col4 ASC NULLS FIRST, _col3 ASC NULLS FIRST
                        partition by: _col4
                        raw input shape:
                        window functions:
                            window function definition
                              alias: first_value_window_2
                              arguments: _col7
                              name: first_value
                              window function: GenericUDAFFirstValueEvaluator
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 13182 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col4 (type: string), _col3 (type: string), _col7 (type: int), UDFToInteger(_col0) (type: int), UDFToInteger(_col1) (type: int), first_value_window_2 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 26 Data size: 6110 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6110 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.part_3_n0
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: int), _col4 (type: int), _col5 (type: int)
                      outputColumnNames: p_mfgr, p_name, p_size, c, ca, fv
                      Statistics: Num rows: 26 Data size: 6110 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: compute_stats(p_mfgr, 'hll'), compute_stats(p_name, 'hll'), compute_stats(p_size, 'hll'), compute_stats(c, 'hll'), compute_stats(ca, 'hll'), compute_stats(fv, 'hll')
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                        Statistics: Num rows: 1 Data size: 2576 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          sort order: 
                          Statistics: Num rows: 1 Data size: 2576 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col2 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col4 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col5 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>)

  Stage: Stage-4
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.part_1_n0

  Stage: Stage-5
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: p_mfgr, p_name, p_size, r, dr, s
          Column Types: string, string, int, int, int, double
          Table: default.part_1_n0

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.part_2_n0

  Stage: Stage-6
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: p_mfgr, p_name, p_size, r, dr, cud, s2, fv1
          Column Types: string, string, int, int, int, int, double, int
          Table: default.part_2_n0

  Stage: Stage-2
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.part_3_n0

  Stage: Stage-7
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: p_mfgr, p_name, p_size, c, ca, fv
          Column Types: string, string, int, int, int, int
          Table: default.part_3_n0

PREHOOK: query: from part 
INSERT OVERWRITE TABLE part_1_n0 
select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name ) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name ) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s
INSERT OVERWRITE TABLE part_2_n0 
select  p_mfgr,p_name, p_size,  
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
round(sum(p_size) over (distribute by p_mfgr sort by p_size range between 5 preceding and current row),1) as s2, 
first_value(p_size) over w1  as fv1
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following) 
INSERT OVERWRITE TABLE part_3_n0 
select  p_mfgr,p_name, p_size,  
count(*) over(distribute by p_mfgr sort by p_name) as c, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
first_value(p_size) over w1  as fv
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
PREHOOK: Output: default@part_1_n0
PREHOOK: Output: default@part_2_n0
PREHOOK: Output: default@part_3_n0
POSTHOOK: query: from part 
INSERT OVERWRITE TABLE part_1_n0 
select p_mfgr, p_name, p_size, 
rank() over(distribute by p_mfgr sort by p_name ) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name ) as dr, 
round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between unbounded preceding and current row),2) as s
INSERT OVERWRITE TABLE part_2_n0 
select  p_mfgr,p_name, p_size,  
rank() over(distribute by p_mfgr sort by p_name) as r, 
dense_rank() over(distribute by p_mfgr sort by p_name) as dr, 
cume_dist() over(distribute by p_mfgr sort by p_name) as cud, 
round(sum(p_size) over (distribute by p_mfgr sort by p_size range between 5 preceding and current row),1) as s2, 
first_value(p_size) over w1  as fv1
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following) 
INSERT OVERWRITE TABLE part_3_n0 
select  p_mfgr,p_name, p_size,  
count(*) over(distribute by p_mfgr sort by p_name) as c, 
count(p_size) over(distribute by p_mfgr sort by p_name) as ca, 
first_value(p_size) over w1  as fv
window w1 as (distribute by p_mfgr sort by p_mfgr, p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
POSTHOOK: Output: default@part_1_n0
POSTHOOK: Output: default@part_2_n0
POSTHOOK: Output: default@part_3_n0
POSTHOOK: Lineage: part_1_n0.dr SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_1_n0.p_mfgr SIMPLE [(part)part.FieldSchema(name:p_mfgr, type:string, comment:null), ]
POSTHOOK: Lineage: part_1_n0.p_name SIMPLE [(part)part.FieldSchema(name:p_name, type:string, comment:null), ]
POSTHOOK: Lineage: part_1_n0.p_size SIMPLE [(part)part.FieldSchema(name:p_size, type:int, comment:null), ]
POSTHOOK: Lineage: part_1_n0.r SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_1_n0.s SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_2_n0.cud SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_2_n0.dr SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_2_n0.fv1 SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_2_n0.p_mfgr SIMPLE [(part)part.FieldSchema(name:p_mfgr, type:string, comment:null), ]
POSTHOOK: Lineage: part_2_n0.p_name SIMPLE [(part)part.FieldSchema(name:p_name, type:string, comment:null), ]
POSTHOOK: Lineage: part_2_n0.p_size SIMPLE [(part)part.FieldSchema(name:p_size, type:int, comment:null), ]
POSTHOOK: Lineage: part_2_n0.r SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_2_n0.s2 SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_3_n0.c SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_3_n0.ca SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_3_n0.fv SCRIPT [(part)part.FieldSchema(name:p_partkey, type:int, comment:null), (part)part.FieldSchema(name:p_name, type:string, comment:null), (part)part.FieldSchema(name:p_mfgr, type:string, comment:null), (part)part.FieldSchema(name:p_brand, type:string, comment:null), (part)part.FieldSchema(name:p_type, type:string, comment:null), (part)part.FieldSchema(name:p_size, type:int, comment:null), (part)part.FieldSchema(name:p_container, type:string, comment:null), (part)part.FieldSchema(name:p_retailprice, type:double, comment:null), (part)part.FieldSchema(name:p_comment, type:string, comment:null), ]
POSTHOOK: Lineage: part_3_n0.p_mfgr SIMPLE [(part)part.FieldSchema(name:p_mfgr, type:string, comment:null), ]
POSTHOOK: Lineage: part_3_n0.p_name SIMPLE [(part)part.FieldSchema(name:p_name, type:string, comment:null), ]
POSTHOOK: Lineage: part_3_n0.p_size SIMPLE [(part)part.FieldSchema(name:p_size, type:int, comment:null), ]
_col0	_col1	_col2	_col3	_col4	_col5
PREHOOK: query: select * from part_1_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@part_1_n0
#### A masked pattern was here ####
POSTHOOK: query: select * from part_1_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part_1_n0
#### A masked pattern was here ####
part_1_n0.p_mfgr	part_1_n0.p_name	part_1_n0.p_size	part_1_n0.r	part_1_n0.dr	part_1_n0.s
Manufacturer#1	almond antique burnished rose metallic	2	1	1	1173.15
Manufacturer#1	almond antique burnished rose metallic	2	1	1	2346.3
Manufacturer#1	almond antique chartreuse lavender yellow	34	3	2	4100.06
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4	3	5702.65
Manufacturer#1	almond aquamarine burnished black steel	28	5	4	7117.07
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6	5	8749.73
Manufacturer#2	almond antique violet chocolate turquoise	14	1	1	1690.68
Manufacturer#2	almond antique violet turquoise frosted	40	2	2	3491.38
Manufacturer#2	almond aquamarine midnight light salmon	2	3	3	5523.36
Manufacturer#2	almond aquamarine rose maroon antique	25	4	4	7222.02
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5	5	8923.62
Manufacturer#3	almond antique chartreuse khaki white	17	1	1	1671.68
Manufacturer#3	almond antique forest lavender goldenrod	14	2	2	2861.95
Manufacturer#3	almond antique metallic orange dim	19	3	3	4272.34
Manufacturer#3	almond antique misty red olive	1	4	4	6195.32
Manufacturer#3	almond antique olive coral navajo	45	5	5	7532.61
Manufacturer#4	almond antique gainsboro frosted violet	10	1	1	1620.67
Manufacturer#4	almond antique violet mint lemon	39	2	2	2996.09
Manufacturer#4	almond aquamarine floral ivory bisque	27	3	3	4202.35
Manufacturer#4	almond aquamarine yellow dodger mint	7	4	4	6047.27
Manufacturer#4	almond azure aquamarine papaya violet	12	5	5	7337.62
Manufacturer#5	almond antique blue firebrick mint	31	1	1	1789.69
Manufacturer#5	almond antique medium spring khaki	6	2	2	3401.35
Manufacturer#5	almond antique sky peru orange	2	3	3	5190.08
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4	4	6208.18
Manufacturer#5	almond azure blanched chiffon midnight	23	5	5	7672.66
PREHOOK: query: select * from part_2_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@part_2_n0
#### A masked pattern was here ####
POSTHOOK: query: select * from part_2_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part_2_n0
#### A masked pattern was here ####
part_2_n0.p_mfgr	part_2_n0.p_name	part_2_n0.p_size	part_2_n0.r	part_2_n0.dr	part_2_n0.cud	part_2_n0.s2	part_2_n0.fv1
Manufacturer#1	almond antique burnished rose metallic	2	1	1	0	4.0	2
Manufacturer#1	almond antique burnished rose metallic	2	1	1	0	4.0	2
Manufacturer#1	almond antique chartreuse lavender yellow	34	3	2	0	34.0	2
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4	3	0	10.0	2
Manufacturer#1	almond aquamarine burnished black steel	28	5	4	0	28.0	34
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6	5	1	42.0	6
Manufacturer#2	almond antique violet chocolate turquoise	14	1	1	0	14.0	14
Manufacturer#2	almond antique violet turquoise frosted	40	2	2	0	40.0	14
Manufacturer#2	almond aquamarine midnight light salmon	2	3	3	0	2.0	14
Manufacturer#2	almond aquamarine rose maroon antique	25	4	4	0	25.0	40
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5	5	1	32.0	2
Manufacturer#3	almond antique chartreuse khaki white	17	1	1	0	31.0	17
Manufacturer#3	almond antique forest lavender goldenrod	14	2	2	0	14.0	17
Manufacturer#3	almond antique metallic orange dim	19	3	3	0	50.0	17
Manufacturer#3	almond antique misty red olive	1	4	4	0	1.0	14
Manufacturer#3	almond antique olive coral navajo	45	5	5	1	45.0	19
Manufacturer#4	almond antique gainsboro frosted violet	10	1	1	0	17.0	10
Manufacturer#4	almond antique violet mint lemon	39	2	2	0	39.0	10
Manufacturer#4	almond aquamarine floral ivory bisque	27	3	3	0	27.0	10
Manufacturer#4	almond aquamarine yellow dodger mint	7	4	4	0	7.0	39
Manufacturer#4	almond azure aquamarine papaya violet	12	5	5	1	29.0	27
Manufacturer#5	almond antique blue firebrick mint	31	1	1	0	31.0	31
Manufacturer#5	almond antique medium spring khaki	6	2	2	0	8.0	31
Manufacturer#5	almond antique sky peru orange	2	3	3	0	2.0	31
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4	4	0	46.0	6
Manufacturer#5	almond azure blanched chiffon midnight	23	5	5	1	23.0	2
PREHOOK: query: select * from part_3_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@part_3_n0
#### A masked pattern was here ####
POSTHOOK: query: select * from part_3_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part_3_n0
#### A masked pattern was here ####
part_3_n0.p_mfgr	part_3_n0.p_name	part_3_n0.p_size	part_3_n0.c	part_3_n0.ca	part_3_n0.fv
Manufacturer#1	almond antique burnished rose metallic	2	2	2	2
Manufacturer#1	almond antique burnished rose metallic	2	2	2	2
Manufacturer#1	almond antique chartreuse lavender yellow	34	3	3	2
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4	4	2
Manufacturer#1	almond aquamarine burnished black steel	28	5	5	34
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6	6	6
Manufacturer#2	almond antique violet chocolate turquoise	14	1	1	14
Manufacturer#2	almond antique violet turquoise frosted	40	2	2	14
Manufacturer#2	almond aquamarine midnight light salmon	2	3	3	14
Manufacturer#2	almond aquamarine rose maroon antique	25	4	4	40
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5	5	2
Manufacturer#3	almond antique chartreuse khaki white	17	1	1	17
Manufacturer#3	almond antique forest lavender goldenrod	14	2	2	17
Manufacturer#3	almond antique metallic orange dim	19	3	3	17
Manufacturer#3	almond antique misty red olive	1	4	4	14
Manufacturer#3	almond antique olive coral navajo	45	5	5	19
Manufacturer#4	almond antique gainsboro frosted violet	10	1	1	10
Manufacturer#4	almond antique violet mint lemon	39	2	2	10
Manufacturer#4	almond aquamarine floral ivory bisque	27	3	3	10
Manufacturer#4	almond aquamarine yellow dodger mint	7	4	4	39
Manufacturer#4	almond azure aquamarine papaya violet	12	5	5	27
Manufacturer#5	almond antique blue firebrick mint	31	1	1	31
Manufacturer#5	almond antique medium spring khaki	6	2	2	31
Manufacturer#5	almond antique sky peru orange	2	3	3	31
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4	4	6
Manufacturer#5	almond azure blanched chiffon midnight	23	5	5	2
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, min(p_retailprice) as mi,
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
having p_size > 0
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, min(p_retailprice) as mi,
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
having p_size > 0
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 5:int, val 0)
                    predicate: (p_size > 0) (type: boolean)
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(p_retailprice)
                      Group By Vectorization:
                          aggregators: VectorUDAFMinDouble(col 7:double) -> double
                          className: VectorGroupByOperator
                          groupByMode: HASH
                          keyExpressions: col 2:string, col 1:string, col 5:int
                          native: false
                          vectorProcessingMode: HASH
                          projectedOutputColumnNums: [0]
                      keys: p_mfgr (type: string), p_name (type: string), p_size (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: string)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1, 2]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            partitionColumnNums: [0]
                            valueColumnNums: [3]
                        Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col3 (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: Only PTF directly under reduce-shuffle is supported
                vectorized: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: string, _col2: int, _col3: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: dense_rank_window_1
                              arguments: _col1
                              name: dense_rank
                              window function: GenericUDAFDenseRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                            window function definition
                              alias: lag_window_2
                              arguments: _col2, 1, _col2
                              name: lag
                              window function: GenericUDAFLagEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: double), rank_window_0 (type: int), dense_rank_window_1 (type: int), _col2 (type: int), (_col2 - lag_window_2) (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                    Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 13 Data size: 3211 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, min(p_retailprice) as mi,
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
having p_size > 0
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, min(p_retailprice) as mi,
rank() over(distribute by p_mfgr sort by p_name) as r,
dense_rank() over(distribute by p_mfgr sort by p_name) as dr,
p_size, p_size - lag(p_size,1,p_size) over(distribute by p_mfgr sort by p_name) as deltaSz
from part
group by p_mfgr, p_name, p_size
having p_size > 0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	mi	r	dr	p_size	deltasz
Manufacturer#1	almond antique burnished rose metallic	2	1173.15	1	1	2	0
Manufacturer#1	almond antique chartreuse lavender yellow	34	1753.76	2	2	34	32
Manufacturer#1	almond antique salmon chartreuse burlywood	6	1602.59	3	3	6	-28
Manufacturer#1	almond aquamarine burnished black steel	28	1414.42	4	4	28	22
Manufacturer#1	almond aquamarine pink moccasin thistle	42	1632.66	5	5	42	14
Manufacturer#2	almond antique violet chocolate turquoise	14	1690.68	1	1	14	0
Manufacturer#2	almond antique violet turquoise frosted	40	1800.7	2	2	40	26
Manufacturer#2	almond aquamarine midnight light salmon	2	2031.98	3	3	2	-38
Manufacturer#2	almond aquamarine rose maroon antique	25	1698.66	4	4	25	23
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	1701.6	5	5	18	-7
Manufacturer#3	almond antique chartreuse khaki white	17	1671.68	1	1	17	0
Manufacturer#3	almond antique forest lavender goldenrod	14	1190.27	2	2	14	-3
Manufacturer#3	almond antique metallic orange dim	19	1410.39	3	3	19	5
Manufacturer#3	almond antique misty red olive	1	1922.98	4	4	1	-18
Manufacturer#3	almond antique olive coral navajo	45	1337.29	5	5	45	44
Manufacturer#4	almond antique gainsboro frosted violet	10	1620.67	1	1	10	0
Manufacturer#4	almond antique violet mint lemon	39	1375.42	2	2	39	29
Manufacturer#4	almond aquamarine floral ivory bisque	27	1206.26	3	3	27	-12
Manufacturer#4	almond aquamarine yellow dodger mint	7	1844.92	4	4	7	-20
Manufacturer#4	almond azure aquamarine papaya violet	12	1290.35	5	5	12	5
Manufacturer#5	almond antique blue firebrick mint	31	1789.69	1	1	31	0
Manufacturer#5	almond antique medium spring khaki	6	1611.66	2	2	6	-25
Manufacturer#5	almond antique sky peru orange	2	1788.73	3	3	2	-4
Manufacturer#5	almond aquamarine dodger light gainsboro	46	1018.1	4	4	46	44
Manufacturer#5	almond azure blanched chiffon midnight	23	1464.48	5	5	23	-23
PREHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between 10 preceding and current row) as s2, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between current row and 10 following )  as s1
from part  
window w1 as (rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select  p_mfgr,p_name, p_size, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between 10 preceding and current row) as s2, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between current row and 10 following )  as s1
from part  
window w1 as (rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_size (type: int)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 5]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [1]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_name (type: string)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col1 (type: string), KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col5 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(10)~CURRENT
                            window function definition
                              alias: sum_window_1
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE CURRENT~FOLLOWING(10)
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint), sum_window_1 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select  p_mfgr,p_name, p_size, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between 10 preceding and current row) as s2, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between current row and 10 following )  as s1
from part  
window w1 as (rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select  p_mfgr,p_name, p_size, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between 10 preceding and current row) as s2, 
sum(p_size) over (distribute by p_mfgr sort by p_size range between current row and 10 following )  as s1
from part  
window w1 as (rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s2	s1
Manufacturer#1	almond antique burnished rose metallic	2	4	10
Manufacturer#1	almond antique burnished rose metallic	2	4	10
Manufacturer#1	almond antique chartreuse lavender yellow	34	62	76
Manufacturer#1	almond antique salmon chartreuse burlywood	6	10	6
Manufacturer#1	almond aquamarine burnished black steel	28	28	62
Manufacturer#1	almond aquamarine pink moccasin thistle	42	76	42
Manufacturer#2	almond antique violet chocolate turquoise	14	14	32
Manufacturer#2	almond antique violet turquoise frosted	40	40	40
Manufacturer#2	almond aquamarine midnight light salmon	2	2	2
Manufacturer#2	almond aquamarine rose maroon antique	25	43	25
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	32	43
Manufacturer#3	almond antique chartreuse khaki white	17	31	36
Manufacturer#3	almond antique forest lavender goldenrod	14	14	50
Manufacturer#3	almond antique metallic orange dim	19	50	19
Manufacturer#3	almond antique misty red olive	1	1	1
Manufacturer#3	almond antique olive coral navajo	45	45	45
Manufacturer#4	almond antique gainsboro frosted violet	10	17	22
Manufacturer#4	almond antique violet mint lemon	39	39	39
Manufacturer#4	almond aquamarine floral ivory bisque	27	27	27
Manufacturer#4	almond aquamarine yellow dodger mint	7	7	29
Manufacturer#4	almond azure aquamarine papaya violet	12	29	12
Manufacturer#5	almond antique blue firebrick mint	31	54	31
Manufacturer#5	almond antique medium spring khaki	6	8	6
Manufacturer#5	almond antique sky peru orange	2	2	8
Manufacturer#5	almond aquamarine dodger light gainsboro	46	46	46
Manufacturer#5	almond azure blanched chiffon midnight	23	23	54
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
sum(p_size) over (partition by p_mfgr  order by p_name  rows between 2 preceding and 2 following) as s
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
sum(p_size) over (partition by p_mfgr  order by p_name  rows between 2 preceding and 2 following) as s
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size,
sum(p_size) over (partition by p_mfgr  order by p_name  rows between 2 preceding and 2 following) as s
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size,
sum(p_size) over (partition by p_mfgr  order by p_name  rows between 2 preceding and 2 following) as s
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s
Manufacturer#1	almond antique burnished rose metallic	2	38
Manufacturer#1	almond antique burnished rose metallic	2	44
Manufacturer#1	almond antique chartreuse lavender yellow	34	72
Manufacturer#1	almond antique salmon chartreuse burlywood	6	112
Manufacturer#1	almond aquamarine burnished black steel	28	110
Manufacturer#1	almond aquamarine pink moccasin thistle	42	76
Manufacturer#2	almond antique violet chocolate turquoise	14	56
Manufacturer#2	almond antique violet turquoise frosted	40	81
Manufacturer#2	almond aquamarine midnight light salmon	2	99
Manufacturer#2	almond aquamarine rose maroon antique	25	85
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	45
Manufacturer#3	almond antique chartreuse khaki white	17	50
Manufacturer#3	almond antique forest lavender goldenrod	14	51
Manufacturer#3	almond antique metallic orange dim	19	96
Manufacturer#3	almond antique misty red olive	1	79
Manufacturer#3	almond antique olive coral navajo	45	65
Manufacturer#4	almond antique gainsboro frosted violet	10	76
Manufacturer#4	almond antique violet mint lemon	39	83
Manufacturer#4	almond aquamarine floral ivory bisque	27	95
Manufacturer#4	almond aquamarine yellow dodger mint	7	85
Manufacturer#4	almond azure aquamarine papaya violet	12	46
Manufacturer#5	almond antique blue firebrick mint	31	39
Manufacturer#5	almond antique medium spring khaki	6	85
Manufacturer#5	almond antique sky peru orange	2	108
Manufacturer#5	almond aquamarine dodger light gainsboro	46	77
Manufacturer#5	almond azure blanched chiffon midnight	23	71
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
sum(p_size) over w1 as s
from part
window w1 as (partition by p_mfgr  order by p_name  rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
sum(p_size) over w1 as s
from part
window w1 as (partition by p_mfgr  order by p_name  rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size,
sum(p_size) over w1 as s
from part
window w1 as (partition by p_mfgr  order by p_name  rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size,
sum(p_size) over w1 as s
from part
window w1 as (partition by p_mfgr  order by p_name  rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s
Manufacturer#1	almond antique burnished rose metallic	2	38
Manufacturer#1	almond antique burnished rose metallic	2	44
Manufacturer#1	almond antique chartreuse lavender yellow	34	72
Manufacturer#1	almond antique salmon chartreuse burlywood	6	112
Manufacturer#1	almond aquamarine burnished black steel	28	110
Manufacturer#1	almond aquamarine pink moccasin thistle	42	76
Manufacturer#2	almond antique violet chocolate turquoise	14	56
Manufacturer#2	almond antique violet turquoise frosted	40	81
Manufacturer#2	almond aquamarine midnight light salmon	2	99
Manufacturer#2	almond aquamarine rose maroon antique	25	85
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	45
Manufacturer#3	almond antique chartreuse khaki white	17	50
Manufacturer#3	almond antique forest lavender goldenrod	14	51
Manufacturer#3	almond antique metallic orange dim	19	96
Manufacturer#3	almond antique misty red olive	1	79
Manufacturer#3	almond antique olive coral navajo	45	65
Manufacturer#4	almond antique gainsboro frosted violet	10	76
Manufacturer#4	almond antique violet mint lemon	39	83
Manufacturer#4	almond aquamarine floral ivory bisque	27	95
Manufacturer#4	almond aquamarine yellow dodger mint	7	85
Manufacturer#4	almond azure aquamarine papaya violet	12	46
Manufacturer#5	almond antique blue firebrick mint	31	39
Manufacturer#5	almond antique medium spring khaki	6	85
Manufacturer#5	almond antique sky peru orange	2	108
Manufacturer#5	almond aquamarine dodger light gainsboro	46	77
Manufacturer#5	almond azure blanched chiffon midnight	23	71
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
sum(p_size) over w1 as s,
sum(p_size) over w2 as s2
from part
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following),
       w2 as (partition by p_mfgr order by p_name)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
sum(p_size) over w1 as s,
sum(p_size) over w2 as s2
from part
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following),
       w2 as (partition by p_mfgr order by p_name)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: sum_window_1
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint), sum_window_1 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size,
sum(p_size) over w1 as s,
sum(p_size) over w2 as s2
from part
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following),
       w2 as (partition by p_mfgr order by p_name)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size,
sum(p_size) over w1 as s,
sum(p_size) over w2 as s2
from part
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following),
       w2 as (partition by p_mfgr order by p_name)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s	s2
Manufacturer#1	almond antique burnished rose metallic	2	38	4
Manufacturer#1	almond antique burnished rose metallic	2	44	4
Manufacturer#1	almond antique chartreuse lavender yellow	34	72	38
Manufacturer#1	almond antique salmon chartreuse burlywood	6	112	44
Manufacturer#1	almond aquamarine burnished black steel	28	110	72
Manufacturer#1	almond aquamarine pink moccasin thistle	42	76	114
Manufacturer#2	almond antique violet chocolate turquoise	14	56	14
Manufacturer#2	almond antique violet turquoise frosted	40	81	54
Manufacturer#2	almond aquamarine midnight light salmon	2	99	56
Manufacturer#2	almond aquamarine rose maroon antique	25	85	81
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	45	99
Manufacturer#3	almond antique chartreuse khaki white	17	50	17
Manufacturer#3	almond antique forest lavender goldenrod	14	51	31
Manufacturer#3	almond antique metallic orange dim	19	96	50
Manufacturer#3	almond antique misty red olive	1	79	51
Manufacturer#3	almond antique olive coral navajo	45	65	96
Manufacturer#4	almond antique gainsboro frosted violet	10	76	10
Manufacturer#4	almond antique violet mint lemon	39	83	49
Manufacturer#4	almond aquamarine floral ivory bisque	27	95	76
Manufacturer#4	almond aquamarine yellow dodger mint	7	85	83
Manufacturer#4	almond azure aquamarine papaya violet	12	46	95
Manufacturer#5	almond antique blue firebrick mint	31	39	31
Manufacturer#5	almond antique medium spring khaki	6	85	37
Manufacturer#5	almond antique sky peru orange	2	108	39
Manufacturer#5	almond aquamarine dodger light gainsboro	46	77	85
Manufacturer#5	almond azure blanched chiffon midnight	23	71	108
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2
from part 
window w1 as (partition by p_mfgr order by p_name range between 2 preceding and 2 following), 
       w2 as w1
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2
from part 
window w1 as (partition by p_mfgr order by p_name range between 2 preceding and 2 following), 
       w2 as w1
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint), sum_window_0 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2
from part 
window w1 as (partition by p_mfgr order by p_name range between 2 preceding and 2 following), 
       w2 as w1
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2
from part 
window w1 as (partition by p_mfgr order by p_name range between 2 preceding and 2 following), 
       w2 as w1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s1	s2
Manufacturer#1	almond antique burnished rose metallic	2	4	4
Manufacturer#1	almond antique burnished rose metallic	2	4	4
Manufacturer#1	almond antique chartreuse lavender yellow	34	34	34
Manufacturer#1	almond antique salmon chartreuse burlywood	6	6	6
Manufacturer#1	almond aquamarine burnished black steel	28	28	28
Manufacturer#1	almond aquamarine pink moccasin thistle	42	42	42
Manufacturer#2	almond antique violet chocolate turquoise	14	14	14
Manufacturer#2	almond antique violet turquoise frosted	40	40	40
Manufacturer#2	almond aquamarine midnight light salmon	2	2	2
Manufacturer#2	almond aquamarine rose maroon antique	25	25	25
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	18	18
Manufacturer#3	almond antique chartreuse khaki white	17	17	17
Manufacturer#3	almond antique forest lavender goldenrod	14	14	14
Manufacturer#3	almond antique metallic orange dim	19	19	19
Manufacturer#3	almond antique misty red olive	1	1	1
Manufacturer#3	almond antique olive coral navajo	45	45	45
Manufacturer#4	almond antique gainsboro frosted violet	10	10	10
Manufacturer#4	almond antique violet mint lemon	39	39	39
Manufacturer#4	almond aquamarine floral ivory bisque	27	27	27
Manufacturer#4	almond aquamarine yellow dodger mint	7	7	7
Manufacturer#4	almond azure aquamarine papaya violet	12	12	12
Manufacturer#5	almond antique blue firebrick mint	31	31	31
Manufacturer#5	almond antique medium spring khaki	6	6	6
Manufacturer#5	almond antique sky peru orange	2	2	2
Manufacturer#5	almond aquamarine dodger light gainsboro	46	46	46
Manufacturer#5	almond azure blanched chiffon midnight	23	23	23
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2 
from part 
window w1 as (partition by p_mfgr order by p_name range between 2 preceding and 2 following), 
       w2 as (w1 rows between unbounded preceding and current row)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2 
from part 
window w1 as (partition by p_mfgr order by p_name range between 2 preceding and 2 following), 
       w2 as (w1 rows between unbounded preceding and current row)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: sum_window_1
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint), sum_window_1 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6214 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2 
from part 
window w1 as (partition by p_mfgr order by p_name range between 2 preceding and 2 following), 
       w2 as (w1 rows between unbounded preceding and current row)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2 
from part 
window w1 as (partition by p_mfgr order by p_name range between 2 preceding and 2 following), 
       w2 as (w1 rows between unbounded preceding and current row)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s1	s2
Manufacturer#1	almond antique burnished rose metallic	2	4	2
Manufacturer#1	almond antique burnished rose metallic	2	4	4
Manufacturer#1	almond antique chartreuse lavender yellow	34	34	38
Manufacturer#1	almond antique salmon chartreuse burlywood	6	6	44
Manufacturer#1	almond aquamarine burnished black steel	28	28	72
Manufacturer#1	almond aquamarine pink moccasin thistle	42	42	114
Manufacturer#2	almond antique violet chocolate turquoise	14	14	14
Manufacturer#2	almond antique violet turquoise frosted	40	40	54
Manufacturer#2	almond aquamarine midnight light salmon	2	2	56
Manufacturer#2	almond aquamarine rose maroon antique	25	25	81
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	18	99
Manufacturer#3	almond antique chartreuse khaki white	17	17	17
Manufacturer#3	almond antique forest lavender goldenrod	14	14	31
Manufacturer#3	almond antique metallic orange dim	19	19	50
Manufacturer#3	almond antique misty red olive	1	1	51
Manufacturer#3	almond antique olive coral navajo	45	45	96
Manufacturer#4	almond antique gainsboro frosted violet	10	10	10
Manufacturer#4	almond antique violet mint lemon	39	39	49
Manufacturer#4	almond aquamarine floral ivory bisque	27	27	76
Manufacturer#4	almond aquamarine yellow dodger mint	7	7	83
Manufacturer#4	almond azure aquamarine papaya violet	12	12	95
Manufacturer#5	almond antique blue firebrick mint	31	31	31
Manufacturer#5	almond antique medium spring khaki	6	6	37
Manufacturer#5	almond antique sky peru orange	2	2	39
Manufacturer#5	almond aquamarine dodger light gainsboro	46	46	85
Manufacturer#5	almond azure blanched chiffon midnight	23	23	108
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2,
sum(p_size) over w3 as s3
from part 
window w1 as (distribute by p_mfgr sort by p_name range between 2 preceding and 2 following), 
       w2 as w3,
       w3 as (distribute by p_mfgr sort by p_name range between unbounded preceding and current row)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2,
sum(p_size) over w3 as s3
from part 
window w1 as (distribute by p_mfgr sort by p_name range between 2 preceding and 2 following), 
       w2 as w3,
       w3 as (distribute by p_mfgr sort by p_name range between unbounded preceding and current row)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: sum_window_1
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint), sum_window_1 (type: bigint), sum_window_1 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 26 Data size: 6422 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6422 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2,
sum(p_size) over w3 as s3
from part 
window w1 as (distribute by p_mfgr sort by p_name range between 2 preceding and 2 following), 
       w2 as w3,
       w3 as (distribute by p_mfgr sort by p_name range between unbounded preceding and current row)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2,
sum(p_size) over w3 as s3
from part 
window w1 as (distribute by p_mfgr sort by p_name range between 2 preceding and 2 following), 
       w2 as w3,
       w3 as (distribute by p_mfgr sort by p_name range between unbounded preceding and current row)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s1	s2	s3
Manufacturer#1	almond antique burnished rose metallic	2	4	4	4
Manufacturer#1	almond antique burnished rose metallic	2	4	4	4
Manufacturer#1	almond antique chartreuse lavender yellow	34	34	38	38
Manufacturer#1	almond antique salmon chartreuse burlywood	6	6	44	44
Manufacturer#1	almond aquamarine burnished black steel	28	28	72	72
Manufacturer#1	almond aquamarine pink moccasin thistle	42	42	114	114
Manufacturer#2	almond antique violet chocolate turquoise	14	14	14	14
Manufacturer#2	almond antique violet turquoise frosted	40	40	54	54
Manufacturer#2	almond aquamarine midnight light salmon	2	2	56	56
Manufacturer#2	almond aquamarine rose maroon antique	25	25	81	81
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	18	99	99
Manufacturer#3	almond antique chartreuse khaki white	17	17	17	17
Manufacturer#3	almond antique forest lavender goldenrod	14	14	31	31
Manufacturer#3	almond antique metallic orange dim	19	19	50	50
Manufacturer#3	almond antique misty red olive	1	1	51	51
Manufacturer#3	almond antique olive coral navajo	45	45	96	96
Manufacturer#4	almond antique gainsboro frosted violet	10	10	10	10
Manufacturer#4	almond antique violet mint lemon	39	39	49	49
Manufacturer#4	almond aquamarine floral ivory bisque	27	27	76	76
Manufacturer#4	almond aquamarine yellow dodger mint	7	7	83	83
Manufacturer#4	almond azure aquamarine papaya violet	12	12	95	95
Manufacturer#5	almond antique blue firebrick mint	31	31	31	31
Manufacturer#5	almond antique medium spring khaki	6	6	37	37
Manufacturer#5	almond antique sky peru orange	2	2	39	39
Manufacturer#5	almond aquamarine dodger light gainsboro	46	46	85	85
Manufacturer#5	almond azure blanched chiffon midnight	23	23	108	108
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2,
sum(p_size) over (w3 rows between 2 preceding and 2 following)  as s3
from part 
window w1 as (distribute by p_mfgr sort by p_name range between 2 preceding and 2 following), 
       w2 as w3,
       w3 as (distribute by p_mfgr sort by p_name range between unbounded preceding and current row)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2,
sum(p_size) over (w3 rows between 2 preceding and 2 following)  as s3
from part 
window w1 as (distribute by p_mfgr sort by p_name range between 2 preceding and 2 following), 
       w2 as w3,
       w3 as (distribute by p_mfgr sort by p_name range between unbounded preceding and current row)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(2)~FOLLOWING(2)
                            window function definition
                              alias: sum_window_1
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: sum_window_2
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint), sum_window_1 (type: bigint), sum_window_2 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 26 Data size: 6422 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6422 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2,
sum(p_size) over (w3 rows between 2 preceding and 2 following)  as s3
from part 
window w1 as (distribute by p_mfgr sort by p_name range between 2 preceding and 2 following), 
       w2 as w3,
       w3 as (distribute by p_mfgr sort by p_name range between unbounded preceding and current row)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, 
sum(p_size) over w1 as s1, 
sum(p_size) over w2 as s2,
sum(p_size) over (w3 rows between 2 preceding and 2 following)  as s3
from part 
window w1 as (distribute by p_mfgr sort by p_name range between 2 preceding and 2 following), 
       w2 as w3,
       w3 as (distribute by p_mfgr sort by p_name range between unbounded preceding and current row)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s1	s2	s3
Manufacturer#1	almond antique burnished rose metallic	2	4	4	38
Manufacturer#1	almond antique burnished rose metallic	2	4	4	44
Manufacturer#1	almond antique chartreuse lavender yellow	34	34	38	72
Manufacturer#1	almond antique salmon chartreuse burlywood	6	6	44	112
Manufacturer#1	almond aquamarine burnished black steel	28	28	72	110
Manufacturer#1	almond aquamarine pink moccasin thistle	42	42	114	76
Manufacturer#2	almond antique violet chocolate turquoise	14	14	14	56
Manufacturer#2	almond antique violet turquoise frosted	40	40	54	81
Manufacturer#2	almond aquamarine midnight light salmon	2	2	56	99
Manufacturer#2	almond aquamarine rose maroon antique	25	25	81	85
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	18	99	45
Manufacturer#3	almond antique chartreuse khaki white	17	17	17	50
Manufacturer#3	almond antique forest lavender goldenrod	14	14	31	51
Manufacturer#3	almond antique metallic orange dim	19	19	50	96
Manufacturer#3	almond antique misty red olive	1	1	51	79
Manufacturer#3	almond antique olive coral navajo	45	45	96	65
Manufacturer#4	almond antique gainsboro frosted violet	10	10	10	76
Manufacturer#4	almond antique violet mint lemon	39	39	49	83
Manufacturer#4	almond aquamarine floral ivory bisque	27	27	76	95
Manufacturer#4	almond aquamarine yellow dodger mint	7	7	83	85
Manufacturer#4	almond azure aquamarine papaya violet	12	12	95	46
Manufacturer#5	almond antique blue firebrick mint	31	31	31	39
Manufacturer#5	almond antique medium spring khaki	6	6	37	85
Manufacturer#5	almond antique sky peru orange	2	2	39	108
Manufacturer#5	almond aquamarine dodger light gainsboro	46	46	85	77
Manufacturer#5	almond azure blanched chiffon midnight	23	23	108	71
PREHOOK: query: explain vectorization detail
select DISTINCT p_mfgr, p_name, p_size,
sum(p_size) over w1 as s
from part
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select DISTINCT p_mfgr, p_name, p_size,
sum(p_size) over w1 as s
from part
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS PRECEDING(2)~FOLLOWING(2)
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), sum_window_0 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: bigint)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: bigint)
                        sort order: ++++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: int), _col3 (type: bigint)
                        Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aaaa
                reduceColumnSortOrder: ++++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 4
                    dataColumns: KEY._col0:string, KEY._col1:string, KEY._col2:int, KEY._col3:bigint
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Group By Operator
                Group By Vectorization:
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    keyExpressions: col 0:string, col 1:string, col 2:int, col 3:bigint
                    native: false
                    vectorProcessingMode: MERGE_PARTIAL
                    projectedOutputColumnNums: []
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int), KEY._col3 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 13 Data size: 3003 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select DISTINCT p_mfgr, p_name, p_size,
sum(p_size) over w1 as s
from part
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select DISTINCT p_mfgr, p_name, p_size,
sum(p_size) over w1 as s
from part
window w1 as (distribute by p_mfgr sort by p_name rows between 2 preceding and 2 following)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s
Manufacturer#1	almond antique burnished rose metallic	2	38
Manufacturer#1	almond antique burnished rose metallic	2	44
Manufacturer#1	almond antique chartreuse lavender yellow	34	72
Manufacturer#1	almond antique salmon chartreuse burlywood	6	112
Manufacturer#1	almond aquamarine burnished black steel	28	110
Manufacturer#1	almond aquamarine pink moccasin thistle	42	76
Manufacturer#2	almond antique violet chocolate turquoise	14	56
Manufacturer#2	almond antique violet turquoise frosted	40	81
Manufacturer#2	almond aquamarine midnight light salmon	2	99
Manufacturer#2	almond aquamarine rose maroon antique	25	85
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	45
Manufacturer#3	almond antique chartreuse khaki white	17	50
Manufacturer#3	almond antique forest lavender goldenrod	14	51
Manufacturer#3	almond antique metallic orange dim	19	96
Manufacturer#3	almond antique misty red olive	1	79
Manufacturer#3	almond antique olive coral navajo	45	65
Manufacturer#4	almond antique gainsboro frosted violet	10	76
Manufacturer#4	almond antique violet mint lemon	39	83
Manufacturer#4	almond aquamarine floral ivory bisque	27	95
Manufacturer#4	almond aquamarine yellow dodger mint	7	85
Manufacturer#4	almond azure aquamarine papaya violet	12	46
Manufacturer#5	almond antique blue firebrick mint	31	39
Manufacturer#5	almond antique medium spring khaki	6	85
Manufacturer#5	almond antique sky peru orange	2	108
Manufacturer#5	almond aquamarine dodger light gainsboro	46	77
Manufacturer#5	almond azure blanched chiffon midnight	23	71
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
rank() over (partition by p_mfgr order by p_name )  as r
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size, 
rank() over (partition by p_mfgr order by p_name )  as r
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5]
                    Statistics: Num rows: 26 Data size: 5798 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:string, KEY.reducesinkkey1:string, VALUE._col3:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint]
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int)
                outputColumnNames: _col1, _col2, _col5
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1, 0, 2]
                Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorRank]
                      functionInputExpressions: [col 1:string]
                      functionNames: [rank]
                      keyInputColumns: [1, 0]
                      native: true
                      nonKeyInputColumns: [2]
                      orderExpressions: [col 1:string]
                      outputColumns: [3, 1, 0, 2]
                      outputTypes: [int, string, string, int]
                      partitionExpressions: [col 0:string]
                      streamingColumns: [3]
                  Statistics: Num rows: 26 Data size: 12766 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), rank_window_0 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1, 2, 3]
                    Statistics: Num rows: 26 Data size: 5902 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
                      Statistics: Num rows: 26 Data size: 5902 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size, 
rank() over (partition by p_mfgr order by p_name )  as r
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size, 
rank() over (partition by p_mfgr order by p_name )  as r
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	r
Manufacturer#1	almond antique burnished rose metallic	2	1
Manufacturer#1	almond antique burnished rose metallic	2	1
Manufacturer#1	almond antique chartreuse lavender yellow	34	3
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4
Manufacturer#1	almond aquamarine burnished black steel	28	5
Manufacturer#1	almond aquamarine pink moccasin thistle	42	6
Manufacturer#2	almond antique violet chocolate turquoise	14	1
Manufacturer#2	almond antique violet turquoise frosted	40	2
Manufacturer#2	almond aquamarine midnight light salmon	2	3
Manufacturer#2	almond aquamarine rose maroon antique	25	4
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5
Manufacturer#3	almond antique chartreuse khaki white	17	1
Manufacturer#3	almond antique forest lavender goldenrod	14	2
Manufacturer#3	almond antique metallic orange dim	19	3
Manufacturer#3	almond antique misty red olive	1	4
Manufacturer#3	almond antique olive coral navajo	45	5
Manufacturer#4	almond antique gainsboro frosted violet	10	1
Manufacturer#4	almond antique violet mint lemon	39	2
Manufacturer#4	almond aquamarine floral ivory bisque	27	3
Manufacturer#4	almond aquamarine yellow dodger mint	7	4
Manufacturer#4	almond azure aquamarine papaya violet	12	5
Manufacturer#5	almond antique blue firebrick mint	31	1
Manufacturer#5	almond antique medium spring khaki	6	2
Manufacturer#5	almond antique sky peru orange	2	3
Manufacturer#5	almond aquamarine dodger light gainsboro	46	4
Manufacturer#5	almond azure blanched chiffon midnight	23	5
PREHOOK: query: explain vectorization detail
select p_mfgr,
round(sum(p_retailprice) over (partition by p_mfgr order by p_mfgr),2) as s1,
min(p_retailprice) over (partition by p_mfgr) as s2,
max(p_retailprice) over (distribute by p_mfgr sort by p_mfgr) as s3,
round(avg(p_retailprice) over (distribute by p_mfgr),2) as s4,
count(p_retailprice) over (cluster by p_mfgr ) as s5
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr,
round(sum(p_retailprice) over (partition by p_mfgr order by p_mfgr),2) as s1,
min(p_retailprice) over (partition by p_mfgr) as s2,
max(p_retailprice) over (distribute by p_mfgr sort by p_mfgr) as s3,
round(avg(p_retailprice) over (distribute by p_mfgr),2) as s4,
count(p_retailprice) over (cluster by p_mfgr ) as s5
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 2756 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string)
                    sort order: +
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [7]
                    Statistics: Num rows: 26 Data size: 2756 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [2, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: a
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:string, VALUE._col6:double
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [double, double, double, double, bigint, double, double]
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col6 (type: double)
                outputColumnNames: _col2, _col7
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 26 Data size: 9724 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col2: string, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col2 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: min_window_1
                              arguments: _col7
                              name: min
                              window function: GenericUDAFMinEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                            window function definition
                              alias: max_window_2
                              arguments: _col7
                              name: max
                              window function: GenericUDAFMaxEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: avg_window_3
                              arguments: _col7
                              name: avg
                              window function: GenericUDAFAverageEvaluatorDouble
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                            window function definition
                              alias: count_window_4
                              arguments: _col7
                              name: count
                              window function: GenericUDAFCountEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorDoubleSum, VectorPTFEvaluatorDoubleMin, VectorPTFEvaluatorDoubleMax, VectorPTFEvaluatorDoubleAvg, VectorPTFEvaluatorCount]
                      functionInputExpressions: [col 1:double, col 1:double, col 1:double, col 1:double, col 1:double]
                      functionNames: [sum, min, max, avg, count]
                      keyInputColumns: [0]
                      native: true
                      nonKeyInputColumns: [1]
                      orderExpressions: [col 0:string]
                      outputColumns: [2, 3, 4, 5, 6, 0, 1]
                      outputTypes: [double, double, double, double, bigint, string, double]
                      streamingColumns: []
                  Statistics: Num rows: 26 Data size: 9724 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), round(sum_window_0, 2) (type: double), min_window_1 (type: double), max_window_2 (type: double), round(avg_window_3, 2) (type: double), count_window_4 (type: bigint)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 7, 3, 4, 8, 6]
                        selectExpressions: RoundWithNumDigitsDoubleToDouble(col 2, decimalPlaces 2) -> 7:double, RoundWithNumDigitsDoubleToDouble(col 5, decimalPlaces 2) -> 8:double
                    Statistics: Num rows: 26 Data size: 3588 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
                      Statistics: Num rows: 26 Data size: 3588 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr,
round(sum(p_retailprice) over (partition by p_mfgr order by p_mfgr),2) as s1,
min(p_retailprice) over (partition by p_mfgr) as s2,
max(p_retailprice) over (distribute by p_mfgr sort by p_mfgr) as s3,
round(avg(p_retailprice) over (distribute by p_mfgr),2) as s4,
count(p_retailprice) over (cluster by p_mfgr ) as s5
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr,
round(sum(p_retailprice) over (partition by p_mfgr order by p_mfgr),2) as s1,
min(p_retailprice) over (partition by p_mfgr) as s2,
max(p_retailprice) over (distribute by p_mfgr sort by p_mfgr) as s3,
round(avg(p_retailprice) over (distribute by p_mfgr),2) as s4,
count(p_retailprice) over (cluster by p_mfgr ) as s5
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	s1	s2	s3	s4	s5
Manufacturer#1	8749.73	1173.15	1753.76	1458.29	6
Manufacturer#1	8749.73	1173.15	1753.76	1458.29	6
Manufacturer#1	8749.73	1173.15	1753.76	1458.29	6
Manufacturer#1	8749.73	1173.15	1753.76	1458.29	6
Manufacturer#1	8749.73	1173.15	1753.76	1458.29	6
Manufacturer#1	8749.73	1173.15	1753.76	1458.29	6
Manufacturer#2	8923.62	1690.68	2031.98	1784.72	5
Manufacturer#2	8923.62	1690.68	2031.98	1784.72	5
Manufacturer#2	8923.62	1690.68	2031.98	1784.72	5
Manufacturer#2	8923.62	1690.68	2031.98	1784.72	5
Manufacturer#2	8923.62	1690.68	2031.98	1784.72	5
Manufacturer#3	7532.61	1190.27	1922.98	1506.52	5
Manufacturer#3	7532.61	1190.27	1922.98	1506.52	5
Manufacturer#3	7532.61	1190.27	1922.98	1506.52	5
Manufacturer#3	7532.61	1190.27	1922.98	1506.52	5
Manufacturer#3	7532.61	1190.27	1922.98	1506.52	5
Manufacturer#4	7337.62	1206.26	1844.92	1467.52	5
Manufacturer#4	7337.62	1206.26	1844.92	1467.52	5
Manufacturer#4	7337.62	1206.26	1844.92	1467.52	5
Manufacturer#4	7337.62	1206.26	1844.92	1467.52	5
Manufacturer#4	7337.62	1206.26	1844.92	1467.52	5
Manufacturer#5	7672.66	1018.1	1789.69	1534.53	5
Manufacturer#5	7672.66	1018.1	1789.69	1534.53	5
Manufacturer#5	7672.66	1018.1	1789.69	1534.53	5
Manufacturer#5	7672.66	1018.1	1789.69	1534.53	5
Manufacturer#5	7672.66	1018.1	1789.69	1534.53	5
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
round(sum(p_retailprice) over (partition by p_mfgr, p_name order by p_mfgr, p_name rows between unbounded preceding and current row),2) as s1,
min(p_retailprice) over (distribute by p_mfgr, p_name sort by p_mfgr, p_name rows between unbounded preceding and current row) as s2,
max(p_retailprice) over (partition by p_mfgr, p_name order by p_name) as s3
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
round(sum(p_retailprice) over (partition by p_mfgr, p_name order by p_mfgr, p_name rows between unbounded preceding and current row),2) as s1,
min(p_retailprice) over (distribute by p_mfgr, p_name sort by p_mfgr, p_name rows between unbounded preceding and current row) as s2,
max(p_retailprice) over (partition by p_mfgr, p_name order by p_name) as s3
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string), p_name (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2, 1]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum UNBOUNDED end frame is not supported for ROWS window type
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col2 ASC NULLS FIRST, _col1 ASC NULLS FIRST
                        partition by: _col2, _col1
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                            window function definition
                              alias: min_window_1
                              arguments: _col7
                              name: min
                              window function: GenericUDAFMinEvaluator
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: sum_window_0 (type: double), min_window_1 (type: double), _col1 (type: string), _col2 (type: string), _col5 (type: int), _col7 (type: double)
                    outputColumnNames: sum_window_0, min_window_1, _col1, _col2, _col5, _col7
                    Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col1 (type: string)
                      sort order: ++
                      Map-reduce partition columns: _col2 (type: string), _col1 (type: string)
                      Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: sum_window_0 (type: double), min_window_1 (type: double), _col5 (type: int), _col7 (type: double)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 6
                    dataColumns: KEY.reducesinkkey0:string, KEY.reducesinkkey1:string, VALUE._col0:double, VALUE._col1:double, VALUE._col5:int, VALUE._col7:double
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [double, double]
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: double), VALUE._col1 (type: double), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col5 (type: int), VALUE._col7 (type: double)
                outputColumnNames: _col0, _col1, _col3, _col4, _col7, _col9
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [2, 3, 1, 0, 4, 5]
                Statistics: Num rows: 26 Data size: 13390 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: double, _col1: double, _col3: string, _col4: string, _col7: int, _col9: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col3 ASC NULLS FIRST
                        partition by: _col4, _col3
                        raw input shape:
                        window functions:
                            window function definition
                              alias: max_window_2
                              arguments: _col9
                              name: max
                              window function: GenericUDAFMaxEvaluator
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorDoubleMax]
                      functionInputExpressions: [col 5:double]
                      functionNames: [max]
                      keyInputColumns: [1, 0]
                      native: true
                      nonKeyInputColumns: [2, 3, 4, 5]
                      orderExpressions: [col 1:string]
                      outputColumns: [6, 2, 3, 1, 0, 4, 5]
                      outputTypes: [double, double, double, string, string, int, double]
                      partitionExpressions: [col 0:string, col 1:string]
                      streamingColumns: []
                  Statistics: Num rows: 26 Data size: 13390 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col4 (type: string), _col3 (type: string), _col7 (type: int), round(_col0, 2) (type: double), _col1 (type: double), max_window_2 (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1, 4, 7, 3, 6]
                        selectExpressions: RoundWithNumDigitsDoubleToDouble(col 2, decimalPlaces 2) -> 7:double
                    Statistics: Num rows: 26 Data size: 6422 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
                      Statistics: Num rows: 26 Data size: 6422 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size,
round(sum(p_retailprice) over (partition by p_mfgr, p_name order by p_mfgr, p_name rows between unbounded preceding and current row),2) as s1,
min(p_retailprice) over (distribute by p_mfgr, p_name sort by p_mfgr, p_name rows between unbounded preceding and current row) as s2,
max(p_retailprice) over (partition by p_mfgr, p_name order by p_name) as s3
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size,
round(sum(p_retailprice) over (partition by p_mfgr, p_name order by p_mfgr, p_name rows between unbounded preceding and current row),2) as s1,
min(p_retailprice) over (distribute by p_mfgr, p_name sort by p_mfgr, p_name rows between unbounded preceding and current row) as s2,
max(p_retailprice) over (partition by p_mfgr, p_name order by p_name) as s3
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s1	s2	s3
Manufacturer#1	almond antique burnished rose metallic	2	1173.15	1173.15	1173.15
Manufacturer#1	almond antique burnished rose metallic	2	2346.3	1173.15	1173.15
Manufacturer#1	almond antique chartreuse lavender yellow	34	1753.76	1753.76	1753.76
Manufacturer#1	almond antique salmon chartreuse burlywood	6	1602.59	1602.59	1602.59
Manufacturer#1	almond aquamarine burnished black steel	28	1414.42	1414.42	1414.42
Manufacturer#1	almond aquamarine pink moccasin thistle	42	1632.66	1632.66	1632.66
Manufacturer#2	almond antique violet chocolate turquoise	14	1690.68	1690.68	1690.68
Manufacturer#2	almond antique violet turquoise frosted	40	1800.7	1800.7	1800.7
Manufacturer#2	almond aquamarine midnight light salmon	2	2031.98	2031.98	2031.98
Manufacturer#2	almond aquamarine rose maroon antique	25	1698.66	1698.66	1698.66
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	1701.6	1701.6	1701.6
Manufacturer#3	almond antique chartreuse khaki white	17	1671.68	1671.68	1671.68
Manufacturer#3	almond antique forest lavender goldenrod	14	1190.27	1190.27	1190.27
Manufacturer#3	almond antique metallic orange dim	19	1410.39	1410.39	1410.39
Manufacturer#3	almond antique misty red olive	1	1922.98	1922.98	1922.98
Manufacturer#3	almond antique olive coral navajo	45	1337.29	1337.29	1337.29
Manufacturer#4	almond antique gainsboro frosted violet	10	1620.67	1620.67	1620.67
Manufacturer#4	almond antique violet mint lemon	39	1375.42	1375.42	1375.42
Manufacturer#4	almond aquamarine floral ivory bisque	27	1206.26	1206.26	1206.26
Manufacturer#4	almond aquamarine yellow dodger mint	7	1844.92	1844.92	1844.92
Manufacturer#4	almond azure aquamarine papaya violet	12	1290.35	1290.35	1290.35
Manufacturer#5	almond antique blue firebrick mint	31	1789.69	1789.69	1789.69
Manufacturer#5	almond antique medium spring khaki	6	1611.66	1611.66	1611.66
Manufacturer#5	almond antique sky peru orange	2	1788.73	1788.73	1788.73
Manufacturer#5	almond aquamarine dodger light gainsboro	46	1018.1	1018.1	1018.1
Manufacturer#5	almond azure blanched chiffon midnight	23	1464.48	1464.48	1464.48
PREHOOK: query: explain vectorization detail
select p_mfgr, p_type, substr(p_type, 2) as short_ptype,
rank() over (partition by p_mfgr order by substr(p_type, 2))  as r
from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_type, substr(p_type, 2) as short_ptype,
rank() over (partition by p_mfgr order by substr(p_type, 2))  as r
from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5252 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), substr(p_type, 2) (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 10]
                        keyExpressions: StringSubstrColStart(col 4:string, start 1) -> 10:string
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [4]
                    Statistics: Num rows: 26 Data size: 5252 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_type (type: string)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [2, 4]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:string, KEY.reducesinkkey1:string, VALUE._col3:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, string, string, string]
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col3 (type: string)
                outputColumnNames: _col2, _col4
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 2]
                Statistics: Num rows: 26 Data size: 12220 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col2: string, _col4: string
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: substr(_col4, 2) ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: substr(_col4, 2)
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorRank]
                      functionInputExpressions: [StringSubstrColStart(col 2:string, start 1) -> 5:string]
                      functionNames: [rank]
                      keyInputColumns: [0]
                      native: true
                      nonKeyInputColumns: [2]
                      orderExpressions: [StringSubstrColStart(col 2:string, start 1) -> 4:string]
                      outputColumns: [3, 0, 2]
                      outputTypes: [int, string, string]
                      partitionExpressions: [col 0:string]
                      streamingColumns: [3]
                  Statistics: Num rows: 26 Data size: 12220 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col4 (type: string), substr(_col4, 2) (type: string), rank_window_0 (type: int)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 2, 6, 3]
                        selectExpressions: StringSubstrColStart(col 2:string, start 1) -> 6:string
                    Statistics: Num rows: 26 Data size: 10140 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
                      Statistics: Num rows: 26 Data size: 10140 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_type, substr(p_type, 2) as short_ptype,
rank() over (partition by p_mfgr order by substr(p_type, 2))  as r
from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_type, substr(p_type, 2) as short_ptype,
rank() over (partition by p_mfgr order by substr(p_type, 2))  as r
from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_type	short_ptype	r
Manufacturer#1	LARGE BRUSHED STEEL	ARGE BRUSHED STEEL	1
Manufacturer#1	LARGE BURNISHED STEEL	ARGE BURNISHED STEEL	2
Manufacturer#1	PROMO BURNISHED NICKEL	ROMO BURNISHED NICKEL	3
Manufacturer#1	PROMO PLATED TIN	ROMO PLATED TIN	4
Manufacturer#1	PROMO PLATED TIN	ROMO PLATED TIN	4
Manufacturer#1	STANDARD ANODIZED STEEL	TANDARD ANODIZED STEEL	6
Manufacturer#2	ECONOMY POLISHED STEEL	CONOMY POLISHED STEEL	1
Manufacturer#2	MEDIUM ANODIZED COPPER	EDIUM ANODIZED COPPER	2
Manufacturer#2	MEDIUM BURNISHED COPPER	EDIUM BURNISHED COPPER	3
Manufacturer#2	SMALL POLISHED NICKEL	MALL POLISHED NICKEL	4
Manufacturer#2	STANDARD PLATED TIN	TANDARD PLATED TIN	5
Manufacturer#3	ECONOMY PLATED COPPER	CONOMY PLATED COPPER	1
Manufacturer#3	MEDIUM BURNISHED BRASS	EDIUM BURNISHED BRASS	2
Manufacturer#3	MEDIUM BURNISHED TIN	EDIUM BURNISHED TIN	3
Manufacturer#3	PROMO ANODIZED TIN	ROMO ANODIZED TIN	4
Manufacturer#3	STANDARD POLISHED STEEL	TANDARD POLISHED STEEL	5
Manufacturer#4	ECONOMY BRUSHED COPPER	CONOMY BRUSHED COPPER	1
Manufacturer#4	PROMO POLISHED STEEL	ROMO POLISHED STEEL	4
Manufacturer#4	SMALL BRUSHED BRASS	MALL BRUSHED BRASS	2
Manufacturer#4	SMALL PLATED STEEL	MALL PLATED STEEL	3
Manufacturer#4	STANDARD ANODIZED TIN	TANDARD ANODIZED TIN	5
Manufacturer#5	ECONOMY BURNISHED STEEL	CONOMY BURNISHED STEEL	2
Manufacturer#5	LARGE BRUSHED BRASS	ARGE BRUSHED BRASS	1
Manufacturer#5	MEDIUM BURNISHED TIN	EDIUM BURNISHED TIN	3
Manufacturer#5	SMALL PLATED BRASS	MALL PLATED BRASS	4
Manufacturer#5	STANDARD BURNISHED TIN	TANDARD BURNISHED TIN	5
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows unbounded preceding),2) as s1
     from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows unbounded preceding),2) as s1
     from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum UNBOUNDED end frame is not supported for ROWS window type
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), round(sum_window_0, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows unbounded preceding),2) as s1
     from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows unbounded preceding),2) as s1
     from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s1
Manufacturer#1	almond antique burnished rose metallic	2	1173.15
Manufacturer#1	almond antique burnished rose metallic	2	2346.3
Manufacturer#1	almond antique chartreuse lavender yellow	34	4100.06
Manufacturer#1	almond antique salmon chartreuse burlywood	6	5702.65
Manufacturer#1	almond aquamarine burnished black steel	28	7117.07
Manufacturer#1	almond aquamarine pink moccasin thistle	42	8749.73
Manufacturer#2	almond antique violet chocolate turquoise	14	1690.68
Manufacturer#2	almond antique violet turquoise frosted	40	3491.38
Manufacturer#2	almond aquamarine midnight light salmon	2	5523.36
Manufacturer#2	almond aquamarine rose maroon antique	25	7222.02
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	8923.62
Manufacturer#3	almond antique chartreuse khaki white	17	1671.68
Manufacturer#3	almond antique forest lavender goldenrod	14	2861.95
Manufacturer#3	almond antique metallic orange dim	19	4272.34
Manufacturer#3	almond antique misty red olive	1	6195.32
Manufacturer#3	almond antique olive coral navajo	45	7532.61
Manufacturer#4	almond antique gainsboro frosted violet	10	1620.67
Manufacturer#4	almond antique violet mint lemon	39	2996.09
Manufacturer#4	almond aquamarine floral ivory bisque	27	4202.35
Manufacturer#4	almond aquamarine yellow dodger mint	7	6047.27
Manufacturer#4	almond azure aquamarine papaya violet	12	7337.62
Manufacturer#5	almond antique blue firebrick mint	31	1789.69
Manufacturer#5	almond antique medium spring khaki	6	3401.35
Manufacturer#5	almond antique sky peru orange	2	5190.08
Manufacturer#5	almond aquamarine dodger light gainsboro	46	6208.18
Manufacturer#5	almond azure blanched chiffon midnight	23	7672.66
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_size range unbounded preceding),2) as s1
     from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_size range unbounded preceding),2) as s1
     from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_size (type: int)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 5]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [1, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_name (type: string), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 4
                    dataColumns: KEY.reducesinkkey0:string, KEY.reducesinkkey1:int, VALUE._col1:string, VALUE._col5:double
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [double, double]
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col1 (type: string), KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [2, 0, 1, 3]
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col5 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: RANGE PRECEDING(MAX)~CURRENT
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorDoubleSum]
                      functionInputExpressions: [col 3:double]
                      functionNames: [sum]
                      keyInputColumns: [0, 1]
                      native: true
                      nonKeyInputColumns: [2, 3]
                      orderExpressions: [col 1:int]
                      outputColumns: [4, 2, 0, 1, 3]
                      outputTypes: [double, string, string, int, double]
                      partitionExpressions: [col 0:string]
                      streamingColumns: []
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), round(sum_window_0, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 2, 1, 5]
                        selectExpressions: RoundWithNumDigitsDoubleToDouble(col 4, decimalPlaces 2) -> 5:double
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
                      Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_size range unbounded preceding),2) as s1
     from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_size range unbounded preceding),2) as s1
     from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s1
Manufacturer#1	almond antique burnished rose metallic	2	2346.3
Manufacturer#1	almond antique burnished rose metallic	2	2346.3
Manufacturer#1	almond antique chartreuse lavender yellow	34	7117.07
Manufacturer#1	almond antique salmon chartreuse burlywood	6	3948.89
Manufacturer#1	almond aquamarine burnished black steel	28	5363.31
Manufacturer#1	almond aquamarine pink moccasin thistle	42	8749.73
Manufacturer#2	almond antique violet chocolate turquoise	14	3722.66
Manufacturer#2	almond antique violet turquoise frosted	40	8923.62
Manufacturer#2	almond aquamarine midnight light salmon	2	2031.98
Manufacturer#2	almond aquamarine rose maroon antique	25	7122.92
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5424.26
Manufacturer#3	almond antique chartreuse khaki white	17	4784.93
Manufacturer#3	almond antique forest lavender goldenrod	14	3113.25
Manufacturer#3	almond antique metallic orange dim	19	6195.32
Manufacturer#3	almond antique misty red olive	1	1922.98
Manufacturer#3	almond antique olive coral navajo	45	7532.61
Manufacturer#4	almond antique gainsboro frosted violet	10	3465.59
Manufacturer#4	almond antique violet mint lemon	39	7337.62
Manufacturer#4	almond aquamarine floral ivory bisque	27	5962.2
Manufacturer#4	almond aquamarine yellow dodger mint	7	1844.92
Manufacturer#4	almond azure aquamarine papaya violet	12	4755.94
Manufacturer#5	almond antique blue firebrick mint	31	6654.56
Manufacturer#5	almond antique medium spring khaki	6	3400.39
Manufacturer#5	almond antique sky peru orange	2	1788.73
Manufacturer#5	almond aquamarine dodger light gainsboro	46	7672.66
Manufacturer#5	almond azure blanched chiffon midnight	23	4864.87
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between current row and unbounded following),2) as s1
    from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between current row and unbounded following),2) as s1
    from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_name (type: string)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 1]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [5, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_size (type: int), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col3 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS CURRENT~FOLLOWING(MAX)
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), round(sum_window_0, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between current row and unbounded following),2) as s1
    from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_name rows between current row and unbounded following),2) as s1
    from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s1
Manufacturer#1	almond antique burnished rose metallic	2	7576.58
Manufacturer#1	almond antique burnished rose metallic	2	8749.73
Manufacturer#1	almond antique chartreuse lavender yellow	34	6403.43
Manufacturer#1	almond antique salmon chartreuse burlywood	6	4649.67
Manufacturer#1	almond aquamarine burnished black steel	28	3047.08
Manufacturer#1	almond aquamarine pink moccasin thistle	42	1632.66
Manufacturer#2	almond antique violet chocolate turquoise	14	8923.62
Manufacturer#2	almond antique violet turquoise frosted	40	7232.94
Manufacturer#2	almond aquamarine midnight light salmon	2	5432.24
Manufacturer#2	almond aquamarine rose maroon antique	25	3400.26
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	1701.6
Manufacturer#3	almond antique chartreuse khaki white	17	7532.61
Manufacturer#3	almond antique forest lavender goldenrod	14	5860.93
Manufacturer#3	almond antique metallic orange dim	19	4670.66
Manufacturer#3	almond antique misty red olive	1	3260.27
Manufacturer#3	almond antique olive coral navajo	45	1337.29
Manufacturer#4	almond antique gainsboro frosted violet	10	7337.62
Manufacturer#4	almond antique violet mint lemon	39	5716.95
Manufacturer#4	almond aquamarine floral ivory bisque	27	4341.53
Manufacturer#4	almond aquamarine yellow dodger mint	7	3135.27
Manufacturer#4	almond azure aquamarine papaya violet	12	1290.35
Manufacturer#5	almond antique blue firebrick mint	31	7672.66
Manufacturer#5	almond antique medium spring khaki	6	5882.97
Manufacturer#5	almond antique sky peru orange	2	4271.31
Manufacturer#5	almond aquamarine dodger light gainsboro	46	2482.58
Manufacturer#5	almond azure blanched chiffon midnight	23	1464.48
PREHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_size range between current row and unbounded following),2) as s1
    from part
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_size range between current row and unbounded following),2) as s1
    from part
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: p_mfgr (type: string), p_size (type: int)
                    sort order: ++
                    Map-reduce partition columns: p_mfgr (type: string)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [2, 5]
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [2]
                        valueColumnNums: [1, 7]
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_name (type: string), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 5, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col1 (type: string), KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: int), VALUE._col5 (type: double)
                outputColumnNames: _col1, _col2, _col5, _col7
                Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col2: string, _col5: int, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col5 ASC NULLS FIRST
                        partition by: _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: RANGE CURRENT~FOLLOWING(MAX)
                  Statistics: Num rows: 26 Data size: 12974 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col5 (type: int), round(sum_window_0, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 26 Data size: 6006 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_size range between current row and unbounded following),2) as s1
    from part
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, p_name, p_size,
    round(sum(p_retailprice) over (distribute by p_mfgr sort by p_size range between current row and unbounded following),2) as s1
    from part
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	p_name	p_size	s1
Manufacturer#1	almond antique burnished rose metallic	2	8749.73
Manufacturer#1	almond antique burnished rose metallic	2	8749.73
Manufacturer#1	almond antique chartreuse lavender yellow	34	3386.42
Manufacturer#1	almond antique salmon chartreuse burlywood	6	6403.43
Manufacturer#1	almond aquamarine burnished black steel	28	4800.84
Manufacturer#1	almond aquamarine pink moccasin thistle	42	1632.66
Manufacturer#2	almond antique violet chocolate turquoise	14	6891.64
Manufacturer#2	almond antique violet turquoise frosted	40	1800.7
Manufacturer#2	almond aquamarine midnight light salmon	2	8923.62
Manufacturer#2	almond aquamarine rose maroon antique	25	3499.36
Manufacturer#2	almond aquamarine sandy cyan gainsboro	18	5200.96
Manufacturer#3	almond antique chartreuse khaki white	17	4419.36
Manufacturer#3	almond antique forest lavender goldenrod	14	5609.63
Manufacturer#3	almond antique metallic orange dim	19	2747.68
Manufacturer#3	almond antique misty red olive	1	7532.61
Manufacturer#3	almond antique olive coral navajo	45	1337.29
Manufacturer#4	almond antique gainsboro frosted violet	10	5492.7
Manufacturer#4	almond antique violet mint lemon	39	1375.42
Manufacturer#4	almond aquamarine floral ivory bisque	27	2581.68
Manufacturer#4	almond aquamarine yellow dodger mint	7	7337.62
Manufacturer#4	almond azure aquamarine papaya violet	12	3872.03
Manufacturer#5	almond antique blue firebrick mint	31	2807.79
Manufacturer#5	almond antique medium spring khaki	6	5883.93
Manufacturer#5	almond antique sky peru orange	2	7672.66
Manufacturer#5	almond aquamarine dodger light gainsboro	46	1018.1
Manufacturer#5	almond azure blanched chiffon midnight	23	4272.27
PREHOOK: query: explain vectorization detail
select p_name, p_retailprice,
round(avg(p_retailprice) over(),2)
from part
order by p_name
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_name, p_retailprice,
round(avg(p_retailprice) over(),2)
from part
order by p_name
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 3354 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Reduce Output Operator
                    key expressions: 0 (type: int)
                    sort order: +
                    Map-reduce partition columns: 0 (type: int)
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkObjectHashOperator
                        keyColumnNums: [10]
                        keyExpressions: ConstantVectorExpression(val 0) -> 10:int
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        partitionColumnNums: [11]
                        valueColumnNums: [1, 7]
                    Statistics: Num rows: 26 Data size: 3354 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: p_name (type: string), p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, bigint]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: a
                reduceColumnSortOrder: +
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:int, VALUE._col1:string, VALUE._col7:double
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [double, bigint, double]
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col1 (type: string), VALUE._col7 (type: double)
                outputColumnNames: _col1, _col7
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1, 2]
                Statistics: Num rows: 26 Data size: 10322 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: 0 ASC NULLS FIRST
                        partition by: 0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: avg_window_0
                              arguments: _col7
                              name: avg
                              window function: GenericUDAFAverageEvaluatorDouble
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorDoubleAvg]
                      functionInputExpressions: [col 2:double]
                      functionNames: [avg]
                      keyInputColumns: []
                      native: true
                      nonKeyInputColumns: [1, 2]
                      orderExpressions: [ConstantVectorExpression(val 0) -> 4:int]
                      outputColumns: [3, 1, 2]
                      outputTypes: [double, string, double]
                      streamingColumns: []
                  Statistics: Num rows: 26 Data size: 10322 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col1 (type: string), _col7 (type: double), round(avg_window_0, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [1, 2, 5]
                        selectExpressions: RoundWithNumDigitsDoubleToDouble(col 3, decimalPlaces 2) -> 5:double
                    Statistics: Num rows: 26 Data size: 3562 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [1]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: [2, 5]
                      Statistics: Num rows: 26 Data size: 3562 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col1 (type: double), _col2 (type: double)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: a
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:string, VALUE._col0:double, VALUE._col1:double
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: double), VALUE._col1 (type: double)
                outputColumnNames: _col0, _col1, _col2
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2]
                Statistics: Num rows: 26 Data size: 3562 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 26 Data size: 3562 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_name, p_retailprice,
round(avg(p_retailprice) over(),2)
from part
order by p_name
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_name, p_retailprice,
round(avg(p_retailprice) over(),2)
from part
order by p_name
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_name	p_retailprice	_c2
almond antique blue firebrick mint	1789.69	1546.78
almond antique burnished rose metallic	1173.15	1546.78
almond antique burnished rose metallic	1173.15	1546.78
almond antique chartreuse khaki white	1671.68	1546.78
almond antique chartreuse lavender yellow	1753.76	1546.78
almond antique forest lavender goldenrod	1190.27	1546.78
almond antique gainsboro frosted violet	1620.67	1546.78
almond antique medium spring khaki	1611.66	1546.78
almond antique metallic orange dim	1410.39	1546.78
almond antique misty red olive	1922.98	1546.78
almond antique olive coral navajo	1337.29	1546.78
almond antique salmon chartreuse burlywood	1602.59	1546.78
almond antique sky peru orange	1788.73	1546.78
almond antique violet chocolate turquoise	1690.68	1546.78
almond antique violet mint lemon	1375.42	1546.78
almond antique violet turquoise frosted	1800.7	1546.78
almond aquamarine burnished black steel	1414.42	1546.78
almond aquamarine dodger light gainsboro	1018.1	1546.78
almond aquamarine floral ivory bisque	1206.26	1546.78
almond aquamarine midnight light salmon	2031.98	1546.78
almond aquamarine pink moccasin thistle	1632.66	1546.78
almond aquamarine rose maroon antique	1698.66	1546.78
almond aquamarine sandy cyan gainsboro	1701.6	1546.78
almond aquamarine yellow dodger mint	1844.92	1546.78
almond azure aquamarine papaya violet	1290.35	1546.78
almond azure blanched chiffon midnight	1464.48	1546.78
PREHOOK: query: explain vectorization detail
select p_mfgr, 
  sum(p_size) over (partition by p_mfgr order by p_size rows between unbounded preceding and current row) 
from part 
where p_mfgr = 'Manufacturer#6'
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_mfgr, 
  sum(p_size) over (partition by p_mfgr order by p_size rows between unbounded preceding and current row) 
from part 
where p_mfgr = 'Manufacturer#6'
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 2652 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterStringGroupColEqualStringScalar(col 2:string, val Manufacturer#6)
                    predicate: (p_mfgr = 'Manufacturer#6') (type: boolean)
                    Statistics: Num rows: 5 Data size: 510 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: 'Manufacturer#6' (type: string), p_size (type: int)
                      sort order: ++
                      Map-reduce partition columns: 'Manufacturer#6' (type: string)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [10, 5]
                          keyExpressions: ConstantVectorExpression(val Manufacturer#6) -> 10:string
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          partitionColumnNums: [11]
                          valueColumnNums: []
                      Statistics: Num rows: 5 Data size: 510 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string]
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: sum UNBOUNDED end frame is not supported for ROWS window type
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: int)
                outputColumnNames: _col5
                Statistics: Num rows: 5 Data size: 1360 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col5 ASC NULLS FIRST
                        partition by: 'Manufacturer#6'
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS PRECEDING(MAX)~CURRENT
                  Statistics: Num rows: 5 Data size: 1360 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: 'Manufacturer#6' (type: string), sum_window_0 (type: bigint)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 5 Data size: 530 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 5 Data size: 530 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_mfgr, 
  sum(p_size) over (partition by p_mfgr order by p_size rows between unbounded preceding and current row) 
from part 
where p_mfgr = 'Manufacturer#6'
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_mfgr, 
  sum(p_size) over (partition by p_mfgr order by p_size rows between unbounded preceding and current row) 
from part 
where p_mfgr = 'Manufacturer#6'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_mfgr	sum_window_0
PREHOOK: query: explain vectorization detail
select p_retailprice, round(avg(p_retailprice) over (partition by p_mfgr order by p_name rows between current row and 6 following),2),
round(sum(p_retailprice) over (partition by p_mfgr order by p_name rows between current row and 6 following),2)
from part 
where p_mfgr='Manufacturer#1'
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select p_retailprice, round(avg(p_retailprice) over (partition by p_mfgr order by p_name rows between current row and 6 following),2),
round(sum(p_retailprice) over (partition by p_mfgr order by p_name rows between current row and 6 following),2)
from part 
where p_mfgr='Manufacturer#1'
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 5902 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterStringGroupColEqualStringScalar(col 2:string, val Manufacturer#1)
                    predicate: (p_mfgr = 'Manufacturer#1') (type: boolean)
                    Statistics: Num rows: 5 Data size: 1135 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: 'Manufacturer#1' (type: string), p_name (type: string)
                      sort order: ++
                      Map-reduce partition columns: 'Manufacturer#1' (type: string)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [10, 1]
                          keyExpressions: ConstantVectorExpression(val Manufacturer#1) -> 10:string
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          partitionColumnNums: [11]
                          valueColumnNums: [7]
                      Statistics: Num rows: 5 Data size: 1135 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: p_retailprice (type: double)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [1, 2, 7]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string]
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                notVectorizedReason: PTF operator: avg only UNBOUNDED start frame is supported
                vectorized: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), VALUE._col6 (type: double)
                outputColumnNames: _col1, _col7
                Statistics: Num rows: 5 Data size: 1985 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col1: string, _col7: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS FIRST
                        partition by: 'Manufacturer#1'
                        raw input shape:
                        window functions:
                            window function definition
                              alias: avg_window_0
                              arguments: _col7
                              name: avg
                              window function: GenericUDAFAverageEvaluatorDouble
                              window frame: ROWS CURRENT~FOLLOWING(6)
                            window function definition
                              alias: sum_window_1
                              arguments: _col7
                              name: sum
                              window function: GenericUDAFSumDouble
                              window frame: ROWS CURRENT~FOLLOWING(6)
                  Statistics: Num rows: 5 Data size: 1985 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col7 (type: double), round(avg_window_0, 2) (type: double), round(sum_window_1, 2) (type: double)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 5 Data size: 120 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 5 Data size: 120 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select p_retailprice, round(avg(p_retailprice) over (partition by p_mfgr order by p_name rows between current row and 6 following),2),
round(sum(p_retailprice) over (partition by p_mfgr order by p_name rows between current row and 6 following),2)
from part 
where p_mfgr='Manufacturer#1'
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select p_retailprice, round(avg(p_retailprice) over (partition by p_mfgr order by p_name rows between current row and 6 following),2),
round(sum(p_retailprice) over (partition by p_mfgr order by p_name rows between current row and 6 following),2)
from part 
where p_mfgr='Manufacturer#1'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
p_retailprice	_c1	_c2
1173.15	1458.29	8749.73
1173.15	1515.32	7576.58
1414.42	1523.54	3047.08
1602.59	1549.89	4649.67
1632.66	1632.66	1632.66
1753.76	1600.86	6403.43
PREHOOK: query: explain vectorization detail
select sum(p_size) over (partition by p_mfgr )
from part where p_mfgr = 'm1'
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select sum(p_size) over (partition by p_mfgr )
from part where p_mfgr = 'm1'
POSTHOOK: type: QUERY
Explain
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part
                  Statistics: Num rows: 26 Data size: 2652 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:p_partkey:int, 1:p_name:string, 2:p_mfgr:string, 3:p_brand:string, 4:p_type:string, 5:p_size:int, 6:p_container:string, 7:p_retailprice:double, 8:p_comment:string, 9:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterStringGroupColEqualStringScalar(col 2:string, val m1)
                    predicate: (p_mfgr = 'm1') (type: boolean)
                    Statistics: Num rows: 5 Data size: 510 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: 'm1' (type: string)
                      sort order: +
                      Map-reduce partition columns: 'm1' (type: string)
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [10]
                          keyExpressions: ConstantVectorExpression(val m1) -> 10:string
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          partitionColumnNums: [11]
                          valueColumnNums: [5]
                      Statistics: Num rows: 5 Data size: 510 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: p_size (type: int)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 9
                    includeColumns: [2, 5]
                    dataColumns: p_partkey:int, p_name:string, p_mfgr:string, p_brand:string, p_type:string, p_size:int, p_container:string, p_retailprice:double, p_comment:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, string]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: a
                reduceColumnSortOrder: +
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:string, VALUE._col5:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, string]
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col5 (type: int)
                outputColumnNames: _col5
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [1]
                Statistics: Num rows: 5 Data size: 1360 Basic stats: COMPLETE Column stats: COMPLETE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col5: int
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: 'm1' ASC NULLS FIRST
                        partition by: 'm1'
                        raw input shape:
                        window functions:
                            window function definition
                              alias: sum_window_0
                              arguments: _col5
                              name: sum
                              window function: GenericUDAFSumLong
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                  PTF Vectorization:
                      className: VectorPTFOperator
                      evaluatorClasses: [VectorPTFEvaluatorLongSum]
                      functionInputExpressions: [col 1:int]
                      functionNames: [sum]
                      keyInputColumns: []
                      native: true
                      nonKeyInputColumns: [1]
                      orderExpressions: [ConstantVectorExpression(val m1) -> 3:string]
                      outputColumns: [2, 1]
                      outputTypes: [bigint, int]
                      streamingColumns: []
                  Statistics: Num rows: 5 Data size: 1360 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: sum_window_0 (type: bigint)
                    outputColumnNames: _col0
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [2]
                    Statistics: Num rows: 5 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      File Sink Vectorization:
                          className: VectorFileSinkOperator
                          native: false
                      Statistics: Num rows: 5 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select sum(p_size) over (partition by p_mfgr )
from part where p_mfgr = 'm1'
PREHOOK: type: QUERY
PREHOOK: Input: default@part
#### A masked pattern was here ####
POSTHOOK: query: select sum(p_size) over (partition by p_mfgr )
from part where p_mfgr = 'm1'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part
#### A masked pattern was here ####
sum_window_0
