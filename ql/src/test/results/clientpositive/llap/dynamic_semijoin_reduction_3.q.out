PREHOOK: query: create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@acidTbl
POSTHOOK: query: create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@acidTbl
PREHOOK: query: create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@nonAcidOrcTbl
POSTHOOK: query: create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@nonAcidOrcTbl
PREHOOK: query: explain merge into acidTbl as t using nonAcidOrcTbl s ON t.a = s.a 
WHEN MATCHED AND s.a > 8 THEN DELETE
WHEN MATCHED THEN UPDATE SET b = 7
WHEN NOT MATCHED THEN INSERT VALUES(s.a, s.b)
PREHOOK: type: QUERY
PREHOOK: Input: default@acidtbl
PREHOOK: Input: default@nonacidorctbl
PREHOOK: Output: default@acidtbl
PREHOOK: Output: default@acidtbl
PREHOOK: Output: default@acidtbl
PREHOOK: Output: default@merge_tmp_table
POSTHOOK: query: explain merge into acidTbl as t using nonAcidOrcTbl s ON t.a = s.a 
WHEN MATCHED AND s.a > 8 THEN DELETE
WHEN MATCHED THEN UPDATE SET b = 7
WHEN NOT MATCHED THEN INSERT VALUES(s.a, s.b)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acidtbl
POSTHOOK: Input: default@nonacidorctbl
POSTHOOK: Output: default@acidtbl
POSTHOOK: Output: default@acidtbl
POSTHOOK: Output: default@acidtbl
POSTHOOK: Output: default@merge_tmp_table
STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-5 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-5
  Stage-6 depends on stages: Stage-0
  Stage-2 depends on stages: Stage-5
  Stage-7 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-5
  Stage-8 depends on stages: Stage-3
  Stage-1 depends on stages: Stage-5
  Stage-9 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-4
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Reducer 9 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 6 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
        Reducer 7 <- Reducer 6 (CUSTOM_SIMPLE_EDGE)
        Reducer 9 <- Map 8 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (a BETWEEN DynamicValue(RS_3_s_a_min) AND DynamicValue(RS_3_s_a_max) and in_bloom_filter(a, DynamicValue(RS_3_s_a_bloom_filter))) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: a (type: int)
                      sort order: +
                      Map-reduce partition columns: a (type: int)
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      value expressions: ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Map 8 
            Map Operator Tree:
                TableScan
                  alias: s
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: a (type: int)
                    sort order: +
                    Map-reduce partition columns: a (type: int)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    value expressions: b (type: int)
                  Select Operator
                    expressions: a (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: min(_col0), max(_col0), bloom_filter(_col0, expectedEntries=1)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        sort order: 
                        Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: binary)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 a (type: int)
                  1 a (type: int)
                outputColumnNames: _col0, _col4, _col5, _col6
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: ((_col0 = _col5) and (_col5 > 8)) (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col4 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      sort order: +
                      Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: ((_col0 = _col5) and (_col5 <= 8)) (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col4 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col0 (type: int)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      sort order: +
                      Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: int)
                Filter Operator
                  predicate: (_col0 = _col5) (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col4 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                    outputColumnNames: _col4
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count()
                      keys: _col4 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: bigint)
                Filter Operator
                  predicate: _col0 is null (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col5 (type: int), _col6 (type: int)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: int), _col1 (type: int)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl
                  Write Type: DELETE
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), VALUE._col0 (type: int), 7 (type: int)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl
                  Write Type: UPDATE
        Reducer 5 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: (_col1 > 1L) (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: cardinality_violation(_col0) (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.merge_tmp_table
        Reducer 6 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl
                  Write Type: INSERT
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int)
                  outputColumnNames: a, b
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: compute_stats(a, 'hll'), compute_stats(b, 'hll')
                    mode: hash
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>)
        Reducer 7 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 9 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), bloom_filter(VALUE._col2, expectedEntries=1)
                mode: final
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: binary)

  Stage: Stage-5
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl
          Write Type: DELETE

  Stage: Stage-6
    Stats Work
      Basic Stats Work:

  Stage: Stage-2
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl
          Write Type: UPDATE

  Stage: Stage-7
    Stats Work
      Basic Stats Work:

  Stage: Stage-3
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.merge_tmp_table

  Stage: Stage-8
    Stats Work
      Basic Stats Work:

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl
          Write Type: INSERT

  Stage: Stage-9
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: a, b
          Column Types: int, int
          Table: default.acidtbl

PREHOOK: query: explain merge into acidTbl as t using nonAcidOrcTbl s ON t.a = s.a
WHEN NOT MATCHED THEN INSERT VALUES(s.a, s.b)
PREHOOK: type: QUERY
PREHOOK: Input: default@acidtbl
PREHOOK: Input: default@nonacidorctbl
PREHOOK: Output: default@acidtbl
POSTHOOK: query: explain merge into acidTbl as t using nonAcidOrcTbl s ON t.a = s.a
WHEN NOT MATCHED THEN INSERT VALUES(s.a, s.b)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acidtbl
POSTHOOK: Input: default@nonacidorctbl
POSTHOOK: Output: default@acidtbl
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Reducer 6 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (CUSTOM_SIMPLE_EDGE)
        Reducer 6 <- Map 5 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (a BETWEEN DynamicValue(RS_3_s_a_min) AND DynamicValue(RS_3_s_a_max) and in_bloom_filter(a, DynamicValue(RS_3_s_a_bloom_filter))) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: a (type: int)
                      sort order: +
                      Map-reduce partition columns: a (type: int)
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: s
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: a (type: int)
                    sort order: +
                    Map-reduce partition columns: a (type: int)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    value expressions: b (type: int)
                  Select Operator
                    expressions: a (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: min(_col0), max(_col0), bloom_filter(_col0, expectedEntries=1)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        sort order: 
                        Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: binary)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 a (type: int)
                  1 a (type: int)
                outputColumnNames: _col0, _col5, _col6
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: _col0 is null (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col5 (type: int), _col6 (type: int)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: int), _col1 (type: int)
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl
                  Write Type: INSERT
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int)
                  outputColumnNames: a, b
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: compute_stats(a, 'hll'), compute_stats(b, 'hll')
                    mode: hash
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>)
        Reducer 4 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 6 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), bloom_filter(VALUE._col2, expectedEntries=1)
                mode: final
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: binary)

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl
          Write Type: INSERT

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: a, b
          Column Types: int, int
          Table: default.acidtbl

PREHOOK: query: explain merge into acidTbl as t using (
  select * from nonAcidOrcTbl where a > 0
  union all
  select * from nonAcidOrcTbl where b > 0
) s ON t.a = s.a
WHEN MATCHED AND s.a > 8 THEN DELETE
WHEN MATCHED THEN UPDATE SET b = 7
WHEN NOT MATCHED THEN INSERT VALUES(s.a, s.b)
PREHOOK: type: QUERY
PREHOOK: Input: default@acidtbl
PREHOOK: Input: default@nonacidorctbl
PREHOOK: Output: default@acidtbl
PREHOOK: Output: default@acidtbl
PREHOOK: Output: default@acidtbl
PREHOOK: Output: default@merge_tmp_table
POSTHOOK: query: explain merge into acidTbl as t using (
  select * from nonAcidOrcTbl where a > 0
  union all
  select * from nonAcidOrcTbl where b > 0
) s ON t.a = s.a
WHEN MATCHED AND s.a > 8 THEN DELETE
WHEN MATCHED THEN UPDATE SET b = 7
WHEN NOT MATCHED THEN INSERT VALUES(s.a, s.b)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acidtbl
POSTHOOK: Input: default@nonacidorctbl
POSTHOOK: Output: default@acidtbl
POSTHOOK: Output: default@acidtbl
POSTHOOK: Output: default@acidtbl
POSTHOOK: Output: default@merge_tmp_table
STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-5 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-5
  Stage-6 depends on stages: Stage-0
  Stage-2 depends on stages: Stage-5
  Stage-7 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-5
  Stage-8 depends on stages: Stage-3
  Stage-1 depends on stages: Stage-5
  Stage-9 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-4
    Tez
#### A masked pattern was here ####
      Edges:
        Map 1 <- Union 2 (CONTAINS)
        Map 9 <- Union 2 (CONTAINS)
        Reducer 3 <- Map 10 (SIMPLE_EDGE), Union 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 3 (SIMPLE_EDGE)
        Reducer 6 <- Reducer 3 (SIMPLE_EDGE)
        Reducer 7 <- Reducer 3 (CUSTOM_SIMPLE_EDGE)
        Reducer 8 <- Reducer 7 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: nonacidorctbl
                  filterExpr: (a > 0) (type: boolean)
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (a > 0) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: a (type: int), b (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 2 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Map 10 
            Map Operator Tree:
                TableScan
                  alias: t
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: a (type: int)
                    sort order: +
                    Map-reduce partition columns: a (type: int)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    value expressions: ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Map 9 
            Map Operator Tree:
                TableScan
                  alias: nonacidorctbl
                  filterExpr: (b > 0) (type: boolean)
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (b > 0) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: a (type: int), b (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 2 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 a (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col4, _col5, _col6
                Statistics: Num rows: 2 Data size: 17 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: ((_col0 = _col5) and (_col5 > 8)) (type: boolean)
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col4 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      sort order: +
                      Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: ((_col0 = _col5) and (_col5 <= 8)) (type: boolean)
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col4 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col0 (type: int)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      sort order: +
                      Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: int)
                Filter Operator
                  predicate: (_col0 = _col5) (type: boolean)
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col4 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                    outputColumnNames: _col4
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count()
                      keys: _col4 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: bigint)
                Filter Operator
                  predicate: _col0 is null (type: boolean)
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col5 (type: int), _col6 (type: int)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: int), _col1 (type: int)
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl
                  Write Type: DELETE
        Reducer 5 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), VALUE._col0 (type: int), 7 (type: int)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl
                  Write Type: UPDATE
        Reducer 6 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: (_col1 > 1L) (type: boolean)
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: cardinality_violation(_col0) (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.merge_tmp_table
        Reducer 7 
            Execution mode: llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl
                  Write Type: INSERT
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int)
                  outputColumnNames: a, b
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: compute_stats(a, 'hll'), compute_stats(b, 'hll')
                    mode: hash
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 848 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>)
        Reducer 8 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 880 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Union 2 
            Vertex: Union 2

  Stage: Stage-5
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl
          Write Type: DELETE

  Stage: Stage-6
    Stats Work
      Basic Stats Work:

  Stage: Stage-2
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl
          Write Type: UPDATE

  Stage: Stage-7
    Stats Work
      Basic Stats Work:

  Stage: Stage-3
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.merge_tmp_table

  Stage: Stage-8
    Stats Work
      Basic Stats Work:

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl
          Write Type: INSERT

  Stage: Stage-9
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: a, b
          Column Types: int, int
          Table: default.acidtbl

PREHOOK: query: drop database if exists type2_scd_helper cascade
PREHOOK: type: DROPDATABASE
POSTHOOK: query: drop database if exists type2_scd_helper cascade
POSTHOOK: type: DROPDATABASE
PREHOOK: query: create database type2_scd_helper
PREHOOK: type: CREATEDATABASE
PREHOOK: Output: database:type2_scd_helper
POSTHOOK: query: create database type2_scd_helper
POSTHOOK: type: CREATEDATABASE
POSTHOOK: Output: database:type2_scd_helper
PREHOOK: query: use type2_scd_helper
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:type2_scd_helper
POSTHOOK: query: use type2_scd_helper
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:type2_scd_helper
PREHOOK: query: drop table if exists customer
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists customer
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table if exists customer_updates
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists customer_updates
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table if exists new_customer_stage
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists new_customer_stage
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table customer (
source_pk int,
sk string,
name string,
state string,
is_current boolean,
end_date date
)
CLUSTERED BY (sk) INTO 2 BUCKETS STORED AS ORC TBLPROPERTIES ("transactional"="true")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:type2_scd_helper
PREHOOK: Output: type2_scd_helper@customer
POSTHOOK: query: create table customer (
source_pk int,
sk string,
name string,
state string,
is_current boolean,
end_date date
)
CLUSTERED BY (sk) INTO 2 BUCKETS STORED AS ORC TBLPROPERTIES ("transactional"="true")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:type2_scd_helper
POSTHOOK: Output: type2_scd_helper@customer
PREHOOK: query: insert into customer values
                     ( 1, "ABC", "Abc Co.", "OH", true, null ),
                     ( 2, "DEF", "Def Co.", "PA", true, null ),
                     ( 3, "XYZ", "Xyz Co.", "CA", true, null )
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: type2_scd_helper@customer
POSTHOOK: query: insert into customer values
                     ( 1, "ABC", "Abc Co.", "OH", true, null ),
                     ( 2, "DEF", "Def Co.", "PA", true, null ),
                     ( 3, "XYZ", "Xyz Co.", "CA", true, null )
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: type2_scd_helper@customer
POSTHOOK: Lineage: customer.end_date EXPRESSION []
POSTHOOK: Lineage: customer.is_current SCRIPT []
POSTHOOK: Lineage: customer.name SCRIPT []
POSTHOOK: Lineage: customer.sk SCRIPT []
POSTHOOK: Lineage: customer.source_pk SCRIPT []
POSTHOOK: Lineage: customer.state SCRIPT []
PREHOOK: query: select * from customer order by source_pk
PREHOOK: type: QUERY
PREHOOK: Input: type2_scd_helper@customer
#### A masked pattern was here ####
POSTHOOK: query: select * from customer order by source_pk
POSTHOOK: type: QUERY
POSTHOOK: Input: type2_scd_helper@customer
#### A masked pattern was here ####
1	ABC	Abc Co.	OH	true	NULL
2	DEF	Def Co.	PA	true	NULL
3	XYZ	Xyz Co.	CA	true	NULL
PREHOOK: query: create table new_customer_stage (
source_pk int,
name string,
state string
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:type2_scd_helper
PREHOOK: Output: type2_scd_helper@new_customer_stage
POSTHOOK: query: create table new_customer_stage (
source_pk int,
name string,
state string
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:type2_scd_helper
POSTHOOK: Output: type2_scd_helper@new_customer_stage
PREHOOK: query: insert into new_customer_stage values
                               ( 1, "Abc Co.", "OH" ),
                               ( 2, "Def Co.", "PA" ),
                               ( 3, "Xyz Co.", "TX" ),
                               ( 4, "Pdq Co.", "WI" )
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: type2_scd_helper@new_customer_stage
POSTHOOK: query: insert into new_customer_stage values
                               ( 1, "Abc Co.", "OH" ),
                               ( 2, "Def Co.", "PA" ),
                               ( 3, "Xyz Co.", "TX" ),
                               ( 4, "Pdq Co.", "WI" )
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: type2_scd_helper@new_customer_stage
POSTHOOK: Lineage: new_customer_stage.name SCRIPT []
POSTHOOK: Lineage: new_customer_stage.source_pk SCRIPT []
POSTHOOK: Lineage: new_customer_stage.state SCRIPT []
PREHOOK: query: drop table if exists scd_types
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists scd_types
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table scd_types (
type int,
invalid_key int
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:type2_scd_helper
PREHOOK: Output: type2_scd_helper@scd_types
POSTHOOK: query: create table scd_types (
type int,
invalid_key int
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:type2_scd_helper
POSTHOOK: Output: type2_scd_helper@scd_types
PREHOOK: query: insert into scd_types values (1, null), (2, -1), (2, null)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: type2_scd_helper@scd_types
POSTHOOK: query: insert into scd_types values (1, null), (2, -1), (2, null)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: type2_scd_helper@scd_types
POSTHOOK: Lineage: scd_types.invalid_key SCRIPT []
POSTHOOK: Lineage: scd_types.type SCRIPT []
PREHOOK: query: merge into customer
using (
  select
    *,
    coalesce(invalid_key, source_pk) as join_key
  from (
    select
      stage.source_pk, stage.name, stage.state,
      case when customer.source_pk is null then 1
      when stage.name <> customer.name or stage.state <> customer.state then 2
      else 0 end as scd_row_type
    from
      new_customer_stage stage
    left join
      customer
    on (stage.source_pk = customer.source_pk and customer.is_current = true)
  ) updates
  join scd_types on scd_types.type = scd_row_type
) sub
on sub.join_key = customer.source_pk
when matched then update set
  is_current = false,
  end_date = date '2017-03-15' 
when not matched then insert values
  (sub.source_pk, upper(substr(sub.name, 0, 3)), sub.name, sub.state, true, null)
PREHOOK: type: QUERY
PREHOOK: Input: type2_scd_helper@customer
PREHOOK: Input: type2_scd_helper@new_customer_stage
PREHOOK: Input: type2_scd_helper@scd_types
PREHOOK: Output: type2_scd_helper@customer
PREHOOK: Output: type2_scd_helper@customer
PREHOOK: Output: type2_scd_helper@merge_tmp_table
POSTHOOK: query: merge into customer
using (
  select
    *,
    coalesce(invalid_key, source_pk) as join_key
  from (
    select
      stage.source_pk, stage.name, stage.state,
      case when customer.source_pk is null then 1
      when stage.name <> customer.name or stage.state <> customer.state then 2
      else 0 end as scd_row_type
    from
      new_customer_stage stage
    left join
      customer
    on (stage.source_pk = customer.source_pk and customer.is_current = true)
  ) updates
  join scd_types on scd_types.type = scd_row_type
) sub
on sub.join_key = customer.source_pk
when matched then update set
  is_current = false,
  end_date = date '2017-03-15' 
when not matched then insert values
  (sub.source_pk, upper(substr(sub.name, 0, 3)), sub.name, sub.state, true, null)
POSTHOOK: type: QUERY
POSTHOOK: Input: type2_scd_helper@customer
POSTHOOK: Input: type2_scd_helper@new_customer_stage
POSTHOOK: Input: type2_scd_helper@scd_types
POSTHOOK: Output: type2_scd_helper@customer
POSTHOOK: Output: type2_scd_helper@customer
POSTHOOK: Output: type2_scd_helper@merge_tmp_table
POSTHOOK: Lineage: customer.end_date EXPRESSION []
POSTHOOK: Lineage: customer.is_current SIMPLE []
POSTHOOK: Lineage: customer.name SIMPLE [(new_customer_stage)stage.FieldSchema(name:name, type:string, comment:null), ]
POSTHOOK: Lineage: customer.sk EXPRESSION [(new_customer_stage)stage.FieldSchema(name:name, type:string, comment:null), ]
POSTHOOK: Lineage: customer.source_pk SIMPLE [(new_customer_stage)stage.FieldSchema(name:source_pk, type:int, comment:null), ]
POSTHOOK: Lineage: customer.state SIMPLE [(new_customer_stage)stage.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: merge_tmp_table.val EXPRESSION [(customer)customer.FieldSchema(name:ROW__ID, type:struct<writeId:bigint,bucketId:int,rowId:bigint>, comment:), ]
PREHOOK: query: select * from customer order by source_pk, is_current
PREHOOK: type: QUERY
PREHOOK: Input: type2_scd_helper@customer
#### A masked pattern was here ####
POSTHOOK: query: select * from customer order by source_pk, is_current
POSTHOOK: type: QUERY
POSTHOOK: Input: type2_scd_helper@customer
#### A masked pattern was here ####
1	ABC	Abc Co.	OH	true	NULL
2	DEF	Def Co.	PA	true	NULL
3	XYZ	Xyz Co.	CA	false	2017-03-15
3	XYZ	Xyz Co.	TX	true	NULL
4	PDQ	Pdq Co.	WI	true	NULL
PREHOOK: query: drop table customer
PREHOOK: type: DROPTABLE
PREHOOK: Input: type2_scd_helper@customer
PREHOOK: Output: type2_scd_helper@customer
POSTHOOK: query: drop table customer
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: type2_scd_helper@customer
POSTHOOK: Output: type2_scd_helper@customer
PREHOOK: query: drop table customer_updates
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table customer_updates
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table new_customer_stage
PREHOOK: type: DROPTABLE
PREHOOK: Input: type2_scd_helper@new_customer_stage
PREHOOK: Output: type2_scd_helper@new_customer_stage
POSTHOOK: query: drop table new_customer_stage
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: type2_scd_helper@new_customer_stage
POSTHOOK: Output: type2_scd_helper@new_customer_stage
PREHOOK: query: drop table scd_types
PREHOOK: type: DROPTABLE
PREHOOK: Input: type2_scd_helper@scd_types
PREHOOK: Output: type2_scd_helper@scd_types
POSTHOOK: query: drop table scd_types
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: type2_scd_helper@scd_types
POSTHOOK: Output: type2_scd_helper@scd_types
