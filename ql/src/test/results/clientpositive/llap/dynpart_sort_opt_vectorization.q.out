PREHOOK: query: create table over1k_n1(
           t tinyint,
           si smallint,
           i int,
           b bigint,
           f float,
           d double,
           bo boolean,
           s string,
           ts timestamp,
           `dec` decimal(4,2),
           bin binary)
       row format delimited
       fields terminated by '|'
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@over1k_n1
POSTHOOK: query: create table over1k_n1(
           t tinyint,
           si smallint,
           i int,
           b bigint,
           f float,
           d double,
           bo boolean,
           s string,
           ts timestamp,
           `dec` decimal(4,2),
           bin binary)
       row format delimited
       fields terminated by '|'
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@over1k_n1
PREHOOK: query: load data local inpath '../../data/files/over1k' into table over1k_n1
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@over1k_n1
POSTHOOK: query: load data local inpath '../../data/files/over1k' into table over1k_n1
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@over1k_n1
PREHOOK: query: create table over1k_orc like over1k_n1
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@over1k_orc
POSTHOOK: query: create table over1k_orc like over1k_n1
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@over1k_orc
PREHOOK: query: alter table over1k_orc set fileformat orc
PREHOOK: type: ALTERTABLE_FILEFORMAT
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_orc
POSTHOOK: query: alter table over1k_orc set fileformat orc
POSTHOOK: type: ALTERTABLE_FILEFORMAT
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_orc
PREHOOK: query: insert overwrite table over1k_orc select * from over1k_n1
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_n1
PREHOOK: Output: default@over1k_orc
POSTHOOK: query: insert overwrite table over1k_orc select * from over1k_n1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_n1
POSTHOOK: Output: default@over1k_orc
POSTHOOK: Lineage: over1k_orc.b SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_orc.bin SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:bin, type:binary, comment:null), ]
POSTHOOK: Lineage: over1k_orc.bo SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:bo, type:boolean, comment:null), ]
POSTHOOK: Lineage: over1k_orc.d SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:d, type:double, comment:null), ]
POSTHOOK: Lineage: over1k_orc.dec SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
POSTHOOK: Lineage: over1k_orc.f SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_orc.i SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_orc.s SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:s, type:string, comment:null), ]
POSTHOOK: Lineage: over1k_orc.si SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_orc.t SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:t, type:tinyint, comment:null), ]
POSTHOOK: Lineage: over1k_orc.ts SIMPLE [(over1k_n1)over1k_n1.FieldSchema(name:ts, type:timestamp, comment:null), ]
PREHOOK: query: create table over1k_part_orc(
           si smallint,
           i int,
           b bigint,
           f float)
       partitioned by (ds string, t tinyint) stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@over1k_part_orc
POSTHOOK: query: create table over1k_part_orc(
           si smallint,
           i int,
           b bigint,
           f float)
       partitioned by (ds string, t tinyint) stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@over1k_part_orc
PREHOOK: query: create table over1k_part_limit_orc like over1k_part_orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@over1k_part_limit_orc
POSTHOOK: query: create table over1k_part_limit_orc like over1k_part_orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@over1k_part_limit_orc
PREHOOK: query: alter table over1k_part_limit_orc set fileformat orc
PREHOOK: type: ALTERTABLE_FILEFORMAT
PREHOOK: Input: default@over1k_part_limit_orc
PREHOOK: Output: default@over1k_part_limit_orc
POSTHOOK: query: alter table over1k_part_limit_orc set fileformat orc
POSTHOOK: type: ALTERTABLE_FILEFORMAT
POSTHOOK: Input: default@over1k_part_limit_orc
POSTHOOK: Output: default@over1k_part_limit_orc
PREHOOK: query: create table over1k_part_buck_orc(
           si smallint,
           i int,
           b bigint,
           f float)
       partitioned by (t tinyint)
       clustered by (si) into 4 buckets stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@over1k_part_buck_orc
POSTHOOK: query: create table over1k_part_buck_orc(
           si smallint,
           i int,
           b bigint,
           f float)
       partitioned by (t tinyint)
       clustered by (si) into 4 buckets stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@over1k_part_buck_orc
PREHOOK: query: create table over1k_part_buck_sort_orc(
           si smallint,
           i int,
           b bigint,
           f float)
       partitioned by (t tinyint)
       clustered by (si) 
       sorted by (f) into 4 buckets stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@over1k_part_buck_sort_orc
POSTHOOK: query: create table over1k_part_buck_sort_orc(
           si smallint,
           i int,
           b bigint,
           f float)
       partitioned by (t tinyint)
       clustered by (si) 
       sorted by (f) into 4 buckets stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@over1k_part_buck_sort_orc
PREHOOK: query: explain insert overwrite table over1k_part_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by si
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_orc@ds=foo
POSTHOOK: query: explain insert overwrite table over1k_part_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by si
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: smallint)
                        null sort order: z
                        sort order: +
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: smallint), VALUE._col0 (type: int), VALUE._col1 (type: bigint), VALUE._col2 (type: float), VALUE._col3 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col4 (type: tinyint), _col0 (type: smallint)
                  null sort order: aa
                  sort order: ++
                  Map-reduce partition columns: _col4 (type: tinyint)
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: _col1 (type: int), _col2 (type: bigint), _col3 (type: float)
                Select Operator
                  expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), 'foo' (type: string), _col4 (type: tinyint)
                  outputColumnNames: si, i, b, f, ds, t
                  Statistics: Num rows: 11 Data size: 1221 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                    keys: ds (type: string), t (type: tinyint)
                    minReductionHashAggr: 0.4
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                    Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: string), _col1 (type: tinyint)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: _col0 (type: string), _col1 (type: tinyint)
                      Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col2 (type: smallint), _col3 (type: smallint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: binary), _col15 (type: float), _col16 (type: float), _col17 (type: bigint), _col18 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float), KEY._col4 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.over1k_part_orc
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col2) (type: bigint), UDFToLong(_col3) (type: bigint), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'LONG' (type: string), _col11 (type: bigint), _col12 (type: bigint), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col15) (type: double), UDFToDouble(_col16) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), _col0 (type: string), _col1 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24, _col25
                  Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds foo
            t 
          replace: true
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.over1k_part_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part_orc

PREHOOK: query: explain insert overwrite table over1k_part_limit_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_limit_orc@ds=foo
POSTHOOK: query: explain insert overwrite table over1k_part_limit_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 10
                      Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                      Select Operator
                        expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4
                        Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                          TopN Hash Memory Usage: 0.1
                          value expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Limit
                Number of rows: 10
                Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: VALUE._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float), VALUE._col4 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col4 (type: tinyint)
                    null sort order: a
                    sort order: +
                    Map-reduce partition columns: _col4 (type: tinyint)
                    Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float)
                  Select Operator
                    expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), 'foo' (type: string), _col4 (type: tinyint)
                    outputColumnNames: si, i, b, f, ds, t
                    Statistics: Num rows: 10 Data size: 1110 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                      keys: ds (type: string), t (type: tinyint)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                      Statistics: Num rows: 10 Data size: 7470 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: tinyint)
                        null sort order: zz
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: tinyint)
                        Statistics: Num rows: 10 Data size: 7470 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col2 (type: smallint), _col3 (type: smallint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: binary), _col15 (type: float), _col16 (type: float), _col17 (type: bigint), _col18 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float), KEY._col4 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.over1k_part_limit_orc
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 10 Data size: 7470 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col2) (type: bigint), UDFToLong(_col3) (type: bigint), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'LONG' (type: string), _col11 (type: bigint), _col12 (type: bigint), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col15) (type: double), UDFToDouble(_col16) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), _col0 (type: string), _col1 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24, _col25
                  Statistics: Num rows: 10 Data size: 11490 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 10 Data size: 11490 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds foo
            t 
          replace: true
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.over1k_part_limit_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part_limit_orc

PREHOOK: query: explain insert overwrite table over1k_part_buck_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_orc
POSTHOOK: query: explain insert overwrite table over1k_part_buck_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col4 (type: tinyint), _bucket_number (type: string), _col0 (type: smallint)
                        null sort order: aaa
                        sort order: +++
                        Map-reduce partition columns: _col4 (type: tinyint)
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: int), _col2 (type: bigint), _col3 (type: float)
                      Select Operator
                        expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
                        outputColumnNames: si, i, b, f, t
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        Group By Operator
                          aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                          keys: t (type: tinyint)
                          minReductionHashAggr: 0.4
                          mode: hash
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                          Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            key expressions: _col0 (type: tinyint)
                            null sort order: z
                            sort order: +
                            Map-reduce partition columns: _col0 (type: tinyint)
                            Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col1 (type: smallint), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: binary), _col14 (type: float), _col15 (type: float), _col16 (type: bigint), _col17 (type: binary)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float), KEY._col4 (type: tinyint), KEY._bucket_number (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _bucket_number
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_BUCKET_SORTED
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.over1k_part_buck_orc
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col1) (type: bigint), UDFToLong(_col2) (type: bigint), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), _col10 (type: bigint), _col11 (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col14) (type: double), UDFToDouble(_col15) (type: double), (_col3 - _col16) (type: bigint), COALESCE(ndv_compute_bit_vector(_col17),0) (type: bigint), _col17 (type: binary), _col0 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            t 
          replace: true
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.over1k_part_buck_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part_buck_orc

PREHOOK: query: explain insert overwrite table over1k_part_buck_sort_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_sort_orc
POSTHOOK: query: explain insert overwrite table over1k_part_buck_sort_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_sort_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col4 (type: tinyint), _bucket_number (type: string), _col3 (type: float)
                        null sort order: aaa
                        sort order: +++
                        Map-reduce partition columns: _col4 (type: tinyint)
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint)
                      Select Operator
                        expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
                        outputColumnNames: si, i, b, f, t
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        Group By Operator
                          aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                          keys: t (type: tinyint)
                          minReductionHashAggr: 0.4
                          mode: hash
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                          Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            key expressions: _col0 (type: tinyint)
                            null sort order: z
                            sort order: +
                            Map-reduce partition columns: _col0 (type: tinyint)
                            Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col1 (type: smallint), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: binary), _col14 (type: float), _col15 (type: float), _col16 (type: bigint), _col17 (type: binary)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), KEY._col3 (type: float), KEY._col4 (type: tinyint), KEY._bucket_number (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _bucket_number
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_BUCKET_SORTED
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.over1k_part_buck_sort_orc
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col1) (type: bigint), UDFToLong(_col2) (type: bigint), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), _col10 (type: bigint), _col11 (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col14) (type: double), UDFToDouble(_col15) (type: double), (_col3 - _col16) (type: bigint), COALESCE(ndv_compute_bit_vector(_col17),0) (type: bigint), _col17 (type: binary), _col0 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            t 
          replace: true
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.over1k_part_buck_sort_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part_buck_sort_orc

PREHOOK: query: insert overwrite table over1k_part_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by si
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_orc@ds=foo
POSTHOOK: query: insert overwrite table over1k_part_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by si
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_orc@ds=foo/t=27
POSTHOOK: Output: default@over1k_part_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: insert overwrite table over1k_part_limit_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_limit_orc@ds=foo
POSTHOOK: query: insert overwrite table over1k_part_limit_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_limit_orc@ds=foo/t=27
POSTHOOK: Output: default@over1k_part_limit_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: insert overwrite table over1k_part_buck_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_orc
POSTHOOK: query: insert overwrite table over1k_part_buck_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_orc
POSTHOOK: Output: default@over1k_part_buck_orc@t=27
POSTHOOK: Output: default@over1k_part_buck_orc@t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: insert overwrite table over1k_part_buck_sort_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_sort_orc
POSTHOOK: query: insert overwrite table over1k_part_buck_sort_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_sort_orc
POSTHOOK: Output: default@over1k_part_buck_sort_orc@t=27
POSTHOOK: Output: default@over1k_part_buck_sort_orc@t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: explain insert into table over1k_part_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by si
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_orc@ds=foo
POSTHOOK: query: explain insert into table over1k_part_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by si
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: smallint)
                        null sort order: z
                        sort order: +
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: smallint), VALUE._col0 (type: int), VALUE._col1 (type: bigint), VALUE._col2 (type: float), VALUE._col3 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col4 (type: tinyint), _col0 (type: smallint)
                  null sort order: aa
                  sort order: ++
                  Map-reduce partition columns: _col4 (type: tinyint)
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: _col1 (type: int), _col2 (type: bigint), _col3 (type: float)
                Select Operator
                  expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), 'foo' (type: string), _col4 (type: tinyint)
                  outputColumnNames: si, i, b, f, ds, t
                  Statistics: Num rows: 11 Data size: 1221 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                    keys: ds (type: string), t (type: tinyint)
                    minReductionHashAggr: 0.4
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                    Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: string), _col1 (type: tinyint)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: _col0 (type: string), _col1 (type: tinyint)
                      Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col2 (type: smallint), _col3 (type: smallint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: binary), _col15 (type: float), _col16 (type: float), _col17 (type: bigint), _col18 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float), KEY._col4 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.over1k_part_orc
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col2) (type: bigint), UDFToLong(_col3) (type: bigint), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'LONG' (type: string), _col11 (type: bigint), _col12 (type: bigint), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col15) (type: double), UDFToDouble(_col16) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), _col0 (type: string), _col1 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24, _col25
                  Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds foo
            t 
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.over1k_part_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part_orc

PREHOOK: query: explain insert into table over1k_part_limit_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_limit_orc@ds=foo
POSTHOOK: query: explain insert into table over1k_part_limit_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 10
                      Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                      Select Operator
                        expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4
                        Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                          TopN Hash Memory Usage: 0.1
                          value expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Limit
                Number of rows: 10
                Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: VALUE._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float), VALUE._col4 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col4 (type: tinyint)
                    null sort order: a
                    sort order: +
                    Map-reduce partition columns: _col4 (type: tinyint)
                    Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float)
                  Select Operator
                    expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), 'foo' (type: string), _col4 (type: tinyint)
                    outputColumnNames: si, i, b, f, ds, t
                    Statistics: Num rows: 10 Data size: 1110 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                      keys: ds (type: string), t (type: tinyint)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                      Statistics: Num rows: 10 Data size: 7470 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: tinyint)
                        null sort order: zz
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: tinyint)
                        Statistics: Num rows: 10 Data size: 7470 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col2 (type: smallint), _col3 (type: smallint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: binary), _col15 (type: float), _col16 (type: float), _col17 (type: bigint), _col18 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float), KEY._col4 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.over1k_part_limit_orc
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 10 Data size: 7470 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col2) (type: bigint), UDFToLong(_col3) (type: bigint), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'LONG' (type: string), _col11 (type: bigint), _col12 (type: bigint), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col15) (type: double), UDFToDouble(_col16) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), _col0 (type: string), _col1 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24, _col25
                  Statistics: Num rows: 10 Data size: 11490 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 10 Data size: 11490 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds foo
            t 
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.over1k_part_limit_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part_limit_orc

PREHOOK: query: explain insert into table over1k_part_buck_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_orc
POSTHOOK: query: explain insert into table over1k_part_buck_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col4 (type: tinyint), _bucket_number (type: string), _col0 (type: smallint)
                        null sort order: aaa
                        sort order: +++
                        Map-reduce partition columns: _col4 (type: tinyint)
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: int), _col2 (type: bigint), _col3 (type: float)
                      Select Operator
                        expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
                        outputColumnNames: si, i, b, f, t
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        Group By Operator
                          aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                          keys: t (type: tinyint)
                          minReductionHashAggr: 0.4
                          mode: hash
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                          Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            key expressions: _col0 (type: tinyint)
                            null sort order: z
                            sort order: +
                            Map-reduce partition columns: _col0 (type: tinyint)
                            Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col1 (type: smallint), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: binary), _col14 (type: float), _col15 (type: float), _col16 (type: bigint), _col17 (type: binary)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float), KEY._col4 (type: tinyint), KEY._bucket_number (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _bucket_number
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_BUCKET_SORTED
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.over1k_part_buck_orc
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col1) (type: bigint), UDFToLong(_col2) (type: bigint), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), _col10 (type: bigint), _col11 (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col14) (type: double), UDFToDouble(_col15) (type: double), (_col3 - _col16) (type: bigint), COALESCE(ndv_compute_bit_vector(_col17),0) (type: bigint), _col17 (type: binary), _col0 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            t 
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.over1k_part_buck_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part_buck_orc

PREHOOK: query: explain insert into table over1k_part_buck_sort_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_sort_orc
POSTHOOK: query: explain insert into table over1k_part_buck_sort_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_sort_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col4 (type: tinyint), _bucket_number (type: string), _col3 (type: float)
                        null sort order: aaa
                        sort order: +++
                        Map-reduce partition columns: _col4 (type: tinyint)
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint)
                      Select Operator
                        expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
                        outputColumnNames: si, i, b, f, t
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        Group By Operator
                          aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                          keys: t (type: tinyint)
                          minReductionHashAggr: 0.4
                          mode: hash
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                          Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            key expressions: _col0 (type: tinyint)
                            null sort order: z
                            sort order: +
                            Map-reduce partition columns: _col0 (type: tinyint)
                            Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col1 (type: smallint), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: binary), _col14 (type: float), _col15 (type: float), _col16 (type: bigint), _col17 (type: binary)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), KEY._col3 (type: float), KEY._col4 (type: tinyint), KEY._bucket_number (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _bucket_number
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_BUCKET_SORTED
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.over1k_part_buck_sort_orc
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col1) (type: bigint), UDFToLong(_col2) (type: bigint), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), _col10 (type: bigint), _col11 (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col14) (type: double), UDFToDouble(_col15) (type: double), (_col3 - _col16) (type: bigint), COALESCE(ndv_compute_bit_vector(_col17),0) (type: bigint), _col17 (type: binary), _col0 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            t 
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.over1k_part_buck_sort_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part_buck_sort_orc

PREHOOK: query: insert into table over1k_part_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by si
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_orc@ds=foo
POSTHOOK: query: insert into table over1k_part_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by si
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_orc@ds=foo/t=27
POSTHOOK: Output: default@over1k_part_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: insert into table over1k_part_limit_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_limit_orc@ds=foo
POSTHOOK: query: insert into table over1k_part_limit_orc partition(ds="foo", t) select si,i,b,f,t from over1k_orc where t is null or t=27 limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_limit_orc@ds=foo/t=27
POSTHOOK: Output: default@over1k_part_limit_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_limit_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: insert into table over1k_part_buck_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_orc
POSTHOOK: query: insert into table over1k_part_buck_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_orc
POSTHOOK: Output: default@over1k_part_buck_orc@t=27
POSTHOOK: Output: default@over1k_part_buck_orc@t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: insert into table over1k_part_buck_sort_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_sort_orc
POSTHOOK: query: insert into table over1k_part_buck_sort_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_sort_orc
POSTHOOK: Output: default@over1k_part_buck_sort_orc@t=27
POSTHOOK: Output: default@over1k_part_buck_sort_orc@t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: desc formatted over1k_part_orc partition(ds="foo",t=27)
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_orc
POSTHOOK: query: desc formatted over1k_part_orc partition(ds="foo",t=27)
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[foo, 27]           	 
Database:           	default             	 
Table:              	over1k_part_orc     	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	2                   
	numRows             	32                  
	rawDataSize         	640                 
	totalSize           	1446                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part_orc partition(ds="foo",t="__HIVE_DEFAULT_PARTITION__")
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_orc
POSTHOOK: query: desc formatted over1k_part_orc partition(ds="foo",t="__HIVE_DEFAULT_PARTITION__")
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[foo, __HIVE_DEFAULT_PARTITION__]	 
Database:           	default             	 
Table:              	over1k_part_orc     	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	2                   
	numRows             	6                   
	rawDataSize         	120                 
	totalSize           	1150                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part_limit_orc partition(ds="foo",t=27)
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_limit_orc
POSTHOOK: query: desc formatted over1k_part_limit_orc partition(ds="foo",t=27)
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_limit_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[foo, 27]           	 
Database:           	default             	 
Table:              	over1k_part_limit_orc	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	2                   
	numRows             	14                  
	rawDataSize         	280                 
	totalSize           	1264                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part_limit_orc partition(ds="foo",t="__HIVE_DEFAULT_PARTITION__")
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_limit_orc
POSTHOOK: query: desc formatted over1k_part_limit_orc partition(ds="foo",t="__HIVE_DEFAULT_PARTITION__")
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_limit_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[foo, __HIVE_DEFAULT_PARTITION__]	 
Database:           	default             	 
Table:              	over1k_part_limit_orc	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	2                   
	numRows             	6                   
	rawDataSize         	120                 
	totalSize           	1150                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part_buck_orc partition(t=27)
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_buck_orc
POSTHOOK: query: desc formatted over1k_part_buck_orc partition(t=27)
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_buck_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[27]                	 
Database:           	default             	 
Table:              	over1k_part_buck_orc	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	8                   
	numRows             	32                  
	rawDataSize         	640                 
	totalSize           	4712                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	4                   	 
Bucket Columns:     	[si]                	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part_buck_orc partition(t="__HIVE_DEFAULT_PARTITION__")
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_buck_orc
POSTHOOK: query: desc formatted over1k_part_buck_orc partition(t="__HIVE_DEFAULT_PARTITION__")
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_buck_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[__HIVE_DEFAULT_PARTITION__]	 
Database:           	default             	 
Table:              	over1k_part_buck_orc	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	4                   
	numRows             	6                   
	rawDataSize         	120                 
	totalSize           	2110                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	4                   	 
Bucket Columns:     	[si]                	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part_buck_sort_orc partition(t=27)
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_buck_sort_orc
POSTHOOK: query: desc formatted over1k_part_buck_sort_orc partition(t=27)
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_buck_sort_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[27]                	 
Database:           	default             	 
Table:              	over1k_part_buck_sort_orc	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	8                   
	numRows             	32                  
	rawDataSize         	640                 
	totalSize           	4730                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	4                   	 
Bucket Columns:     	[si]                	 
Sort Columns:       	[Order(col:f, order:1)]	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part_buck_sort_orc partition(t="__HIVE_DEFAULT_PARTITION__")
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_buck_sort_orc
POSTHOOK: query: desc formatted over1k_part_buck_sort_orc partition(t="__HIVE_DEFAULT_PARTITION__")
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_buck_sort_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[__HIVE_DEFAULT_PARTITION__]	 
Database:           	default             	 
Table:              	over1k_part_buck_sort_orc	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	4                   
	numRows             	6                   
	rawDataSize         	120                 
	totalSize           	2110                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	4                   	 
Bucket Columns:     	[si]                	 
Sort Columns:       	[Order(col:f, order:1)]	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: select count(*) from over1k_part_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_orc
PREHOOK: Input: default@over1k_part_orc@ds=foo/t=27
PREHOOK: Input: default@over1k_part_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from over1k_part_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_orc
POSTHOOK: Input: default@over1k_part_orc@ds=foo/t=27
POSTHOOK: Input: default@over1k_part_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
38
PREHOOK: query: select count(*) from over1k_part_limit_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_limit_orc
PREHOOK: Input: default@over1k_part_limit_orc@ds=foo/t=27
PREHOOK: Input: default@over1k_part_limit_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from over1k_part_limit_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_limit_orc
POSTHOOK: Input: default@over1k_part_limit_orc@ds=foo/t=27
POSTHOOK: Input: default@over1k_part_limit_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
20
PREHOOK: query: select count(*) from over1k_part_buck_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_buck_orc
PREHOOK: Input: default@over1k_part_buck_orc@t=27
PREHOOK: Input: default@over1k_part_buck_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from over1k_part_buck_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_buck_orc
POSTHOOK: Input: default@over1k_part_buck_orc@t=27
POSTHOOK: Input: default@over1k_part_buck_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
38
PREHOOK: query: select count(*) from over1k_part_buck_sort_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_buck_sort_orc
PREHOOK: Input: default@over1k_part_buck_sort_orc@t=27
PREHOOK: Input: default@over1k_part_buck_sort_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from over1k_part_buck_sort_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_buck_sort_orc
POSTHOOK: Input: default@over1k_part_buck_sort_orc@t=27
POSTHOOK: Input: default@over1k_part_buck_sort_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
38
PREHOOK: query: create table over1k_part2_orc(
           si smallint,
           i int,
           b bigint,
           f float)
       partitioned by (ds string, t tinyint)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@over1k_part2_orc
POSTHOOK: query: create table over1k_part2_orc(
           si smallint,
           i int,
           b bigint,
           f float)
       partitioned by (ds string, t tinyint)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@over1k_part2_orc
PREHOOK: query: explain insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by i
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part2_orc@ds=foo
POSTHOOK: query: explain insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by i
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col1 (type: int)
                        null sort order: z
                        sort order: +
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: smallint), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: smallint), KEY.reducesinkkey0 (type: int), VALUE._col1 (type: bigint), VALUE._col2 (type: float), VALUE._col3 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: default.over1k_part2_orc
                Select Operator
                  expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), 'foo' (type: string), _col4 (type: tinyint)
                  outputColumnNames: si, i, b, f, ds, t
                  Statistics: Num rows: 11 Data size: 1221 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                    keys: ds (type: string), t (type: tinyint)
                    minReductionHashAggr: 0.4
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                    Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: string), _col1 (type: tinyint)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: _col0 (type: string), _col1 (type: tinyint)
                      Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col2 (type: smallint), _col3 (type: smallint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: binary), _col15 (type: float), _col16 (type: float), _col17 (type: bigint), _col18 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col2) (type: bigint), UDFToLong(_col3) (type: bigint), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'LONG' (type: string), _col11 (type: bigint), _col12 (type: bigint), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col15) (type: double), UDFToDouble(_col16) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), _col0 (type: string), _col1 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24, _col25
                  Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds foo
            t 
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.over1k_part2_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part2_orc

PREHOOK: query: explain insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by i
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part2_orc@ds=foo
POSTHOOK: query: explain insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by i
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col1 (type: int)
                        null sort order: z
                        sort order: +
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: smallint), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: smallint), KEY.reducesinkkey0 (type: int), VALUE._col1 (type: bigint), VALUE._col2 (type: float), VALUE._col3 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col4 (type: tinyint), _col1 (type: int)
                  null sort order: aa
                  sort order: ++
                  Map-reduce partition columns: _col4 (type: tinyint)
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: _col0 (type: smallint), _col2 (type: bigint), _col3 (type: float)
                Select Operator
                  expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), 'foo' (type: string), _col4 (type: tinyint)
                  outputColumnNames: si, i, b, f, ds, t
                  Statistics: Num rows: 11 Data size: 1221 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                    keys: ds (type: string), t (type: tinyint)
                    minReductionHashAggr: 0.4
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                    Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: string), _col1 (type: tinyint)
                      null sort order: zz
                      sort order: ++
                      Map-reduce partition columns: _col0 (type: string), _col1 (type: tinyint)
                      Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col2 (type: smallint), _col3 (type: smallint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: binary), _col15 (type: float), _col16 (type: float), _col17 (type: bigint), _col18 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: smallint), KEY._col1 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float), KEY._col4 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: default.over1k_part2_orc
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col2) (type: bigint), UDFToLong(_col3) (type: bigint), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'LONG' (type: string), _col11 (type: bigint), _col12 (type: bigint), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col15) (type: double), UDFToDouble(_col16) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), _col0 (type: string), _col1 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24, _col25
                  Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds foo
            t 
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.over1k_part2_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part2_orc

PREHOOK: query: explain insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from (select * from over1k_orc order by i limit 10) tmp where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part2_orc@ds=foo
POSTHOOK: query: explain insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from (select * from over1k_orc order by i limit 10) tmp where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Top N Key Operator
                    sort order: +
                    keys: i (type: int)
                    null sort order: z
                    Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                    top n: 10
                    Select Operator
                      expressions: t (type: tinyint), si (type: smallint), i (type: int), b (type: bigint), f (type: float)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 1049 Data size: 25136 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col2 (type: int)
                        null sort order: z
                        sort order: +
                        Statistics: Num rows: 1049 Data size: 25136 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: tinyint), _col1 (type: smallint), _col3 (type: bigint), _col4 (type: float)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: tinyint), VALUE._col1 (type: smallint), KEY.reducesinkkey0 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 1049 Data size: 25136 Basic stats: COMPLETE Column stats: COMPLETE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 240 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (_col0 is null or (_col0 = 27Y)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col1 (type: smallint), _col2 (type: int), _col3 (type: bigint), _col4 (type: float), _col0 (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col4 (type: tinyint)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col4 (type: tinyint)
                        Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float)
                      Select Operator
                        expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), 'foo' (type: string), _col4 (type: tinyint)
                        outputColumnNames: si, i, b, f, ds, t
                        Statistics: Num rows: 1 Data size: 111 Basic stats: COMPLETE Column stats: COMPLETE
                        Group By Operator
                          aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                          keys: ds (type: string), t (type: tinyint)
                          minReductionHashAggr: 0.4
                          mode: hash
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                          Statistics: Num rows: 1 Data size: 747 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            key expressions: _col0 (type: string), _col1 (type: tinyint)
                            null sort order: zz
                            sort order: ++
                            Map-reduce partition columns: _col0 (type: string), _col1 (type: tinyint)
                            Statistics: Num rows: 1 Data size: 747 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col2 (type: smallint), _col3 (type: smallint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: binary), _col15 (type: float), _col16 (type: float), _col17 (type: bigint), _col18 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), VALUE._col3 (type: float), KEY._col4 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_SORTED
                  Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: default.over1k_part2_orc
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 1 Data size: 747 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col2) (type: bigint), UDFToLong(_col3) (type: bigint), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'LONG' (type: string), _col11 (type: bigint), _col12 (type: bigint), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col15) (type: double), UDFToDouble(_col16) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), _col0 (type: string), _col1 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24, _col25
                  Statistics: Num rows: 1 Data size: 1149 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1149 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds foo
            t 
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.over1k_part2_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part2_orc

PREHOOK: query: explain insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 group by si,i,b,f,t
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part2_orc@ds=foo
POSTHOOK: query: explain insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 group by si,i,b,f,t
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: t (type: tinyint), si (type: smallint), i (type: int), b (type: bigint), f (type: float)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: tinyint), _col1 (type: smallint), _col2 (type: int), _col3 (type: bigint), _col4 (type: float)
                        null sort order: zzzzz
                        sort order: +++++
                        Map-reduce partition columns: _col0 (type: tinyint), _col1 (type: smallint), _col2 (type: int), _col3 (type: bigint), _col4 (type: float)
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: tinyint), KEY._col1 (type: smallint), KEY._col2 (type: int), KEY._col3 (type: bigint), KEY._col4 (type: float)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col1 (type: smallint), _col2 (type: int), _col3 (type: bigint), _col4 (type: float), _col0 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: default.over1k_part2_orc
                  Select Operator
                    expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), 'foo' (type: string), _col4 (type: tinyint)
                    outputColumnNames: si, i, b, f, ds, t
                    Statistics: Num rows: 11 Data size: 1221 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                      keys: ds (type: string), t (type: tinyint)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                      Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: tinyint)
                        null sort order: zz
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: tinyint)
                        Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col2 (type: smallint), _col3 (type: smallint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: binary), _col15 (type: float), _col16 (type: float), _col17 (type: bigint), _col18 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col2) (type: bigint), UDFToLong(_col3) (type: bigint), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'LONG' (type: string), _col11 (type: bigint), _col12 (type: bigint), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col15) (type: double), UDFToDouble(_col16) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), _col0 (type: string), _col1 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24, _col25
                  Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds foo
            t 
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.over1k_part2_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part2_orc

PREHOOK: query: explain insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 group by si,i,b,f,t
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part2_orc@ds=foo
POSTHOOK: query: explain insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 group by si,i,b,f,t
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      keys: t (type: tinyint), si (type: smallint), i (type: int), b (type: bigint), f (type: float)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: tinyint), _col1 (type: smallint), _col2 (type: int), _col3 (type: bigint), _col4 (type: float)
                        null sort order: azzzz
                        sort order: +++++
                        Map-reduce partition columns: _col0 (type: tinyint)
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: tinyint), KEY._col1 (type: smallint), KEY._col2 (type: int), KEY._col3 (type: bigint), KEY._col4 (type: float)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col1 (type: smallint), _col2 (type: int), _col3 (type: bigint), _col4 (type: float), _col0 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), 'foo' (type: string), _col4 (type: tinyint)
                    outputColumnNames: si, i, b, f, ds, t
                    Statistics: Num rows: 11 Data size: 1221 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                      keys: ds (type: string), t (type: tinyint)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                      Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: tinyint)
                        null sort order: zz
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: tinyint)
                        Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col2 (type: smallint), _col3 (type: smallint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: binary), _col7 (type: int), _col8 (type: int), _col9 (type: bigint), _col10 (type: binary), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: binary), _col15 (type: float), _col16 (type: float), _col17 (type: bigint), _col18 (type: binary)
                  Select Operator
                    expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    File Output Operator
                      compressed: false
                      Dp Sort State: PARTITION_SORTED
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.over1k_part2_orc
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: string), KEY._col1 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18
                Statistics: Num rows: 11 Data size: 8217 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col2) (type: bigint), UDFToLong(_col3) (type: bigint), (_col4 - _col5) (type: bigint), COALESCE(ndv_compute_bit_vector(_col6),0) (type: bigint), _col6 (type: binary), 'LONG' (type: string), UDFToLong(_col7) (type: bigint), UDFToLong(_col8) (type: bigint), (_col4 - _col9) (type: bigint), COALESCE(ndv_compute_bit_vector(_col10),0) (type: bigint), _col10 (type: binary), 'LONG' (type: string), _col11 (type: bigint), _col12 (type: bigint), (_col4 - _col13) (type: bigint), COALESCE(ndv_compute_bit_vector(_col14),0) (type: bigint), _col14 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col15) (type: double), UDFToDouble(_col16) (type: double), (_col4 - _col17) (type: bigint), COALESCE(ndv_compute_bit_vector(_col18),0) (type: bigint), _col18 (type: binary), _col0 (type: string), _col1 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24, _col25
                  Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 12639 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            ds foo
            t 
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.over1k_part2_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part2_orc

PREHOOK: query: insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by i
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part2_orc@ds=foo
POSTHOOK: query: insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by i
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part2_orc@ds=foo/t=27
POSTHOOK: Output: default@over1k_part2_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: desc formatted over1k_part2_orc partition(ds="foo",t=27)
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part2_orc
POSTHOOK: query: desc formatted over1k_part2_orc partition(ds="foo",t=27)
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part2_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[foo, 27]           	 
Database:           	default             	 
Table:              	over1k_part2_orc    	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	1                   
	numRows             	16                  
	rawDataSize         	415                 
	totalSize           	431                 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part2_orc partition(ds="foo",t="__HIVE_DEFAULT_PARTITION__")
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part2_orc
POSTHOOK: query: desc formatted over1k_part2_orc partition(ds="foo",t="__HIVE_DEFAULT_PARTITION__")
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part2_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[foo, __HIVE_DEFAULT_PARTITION__]	 
Database:           	default             	 
Table:              	over1k_part2_orc    	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	1                   
	numRows             	3                   
	rawDataSize         	78                  
	totalSize           	81                  
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: select * from over1k_part2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part2_orc
PREHOOK: Input: default@over1k_part2_orc@ds=foo/t=27
PREHOOK: Input: default@over1k_part2_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select * from over1k_part2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part2_orc
POSTHOOK: Input: default@over1k_part2_orc@ds=foo/t=27
POSTHOOK: Input: default@over1k_part2_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
405	65536	4294967508	82.24	foo	27
457	65570	4294967464	81.58	foo	27
256	65599	4294967383	89.55	foo	27
335	65617	4294967381	64.87	foo	27
261	65619	4294967401	88.78	foo	27
278	65622	4294967516	25.67	foo	27
482	65624	4294967313	78.98	foo	27
503	65628	4294967371	95.07	foo	27
335	65636	4294967505	37.14	foo	27
367	65675	4294967518	12.32	foo	27
340	65677	4294967461	98.96	foo	27
490	65680	4294967347	57.46	foo	27
287	65708	4294967542	83.33	foo	27
329	65778	4294967451	6.63	foo	27
401	65779	4294967402	97.39	foo	27
262	65787	4294967371	57.35	foo	27
409	65536	4294967490	46.97	foo	NULL
374	65560	4294967516	65.43	foo	NULL
473	65720	4294967324	80.74	foo	NULL
PREHOOK: query: select count(*) from over1k_part2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part2_orc
PREHOOK: Input: default@over1k_part2_orc@ds=foo/t=27
PREHOOK: Input: default@over1k_part2_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from over1k_part2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part2_orc
POSTHOOK: Input: default@over1k_part2_orc@ds=foo/t=27
POSTHOOK: Input: default@over1k_part2_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
19
PREHOOK: query: insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by i
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part2_orc@ds=foo
POSTHOOK: query: insert overwrite table over1k_part2_orc partition(ds="foo",t) select si,i,b,f,t from over1k_orc where t is null or t=27 order by i
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part2_orc@ds=foo/t=27
POSTHOOK: Output: default@over1k_part2_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part2_orc PARTITION(ds=foo,t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: desc formatted over1k_part2_orc partition(ds="foo",t=27)
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part2_orc
POSTHOOK: query: desc formatted over1k_part2_orc partition(ds="foo",t=27)
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part2_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[foo, 27]           	 
Database:           	default             	 
Table:              	over1k_part2_orc    	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	1                   
	numRows             	16                  
	rawDataSize         	415                 
	totalSize           	431                 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part2_orc partition(ds="foo",t="__HIVE_DEFAULT_PARTITION__")
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part2_orc
POSTHOOK: query: desc formatted over1k_part2_orc partition(ds="foo",t="__HIVE_DEFAULT_PARTITION__")
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part2_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[foo, __HIVE_DEFAULT_PARTITION__]	 
Database:           	default             	 
Table:              	over1k_part2_orc    	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	1                   
	numRows             	3                   
	rawDataSize         	78                  
	totalSize           	81                  
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: select * from over1k_part2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part2_orc
PREHOOK: Input: default@over1k_part2_orc@ds=foo/t=27
PREHOOK: Input: default@over1k_part2_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select * from over1k_part2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part2_orc
POSTHOOK: Input: default@over1k_part2_orc@ds=foo/t=27
POSTHOOK: Input: default@over1k_part2_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
405	65536	4294967508	82.24	foo	27
457	65570	4294967464	81.58	foo	27
256	65599	4294967383	89.55	foo	27
335	65617	4294967381	64.87	foo	27
261	65619	4294967401	88.78	foo	27
278	65622	4294967516	25.67	foo	27
482	65624	4294967313	78.98	foo	27
503	65628	4294967371	95.07	foo	27
335	65636	4294967505	37.14	foo	27
367	65675	4294967518	12.32	foo	27
340	65677	4294967461	98.96	foo	27
490	65680	4294967347	57.46	foo	27
287	65708	4294967542	83.33	foo	27
329	65778	4294967451	6.63	foo	27
401	65779	4294967402	97.39	foo	27
262	65787	4294967371	57.35	foo	27
409	65536	4294967490	46.97	foo	NULL
374	65560	4294967516	65.43	foo	NULL
473	65720	4294967324	80.74	foo	NULL
PREHOOK: query: select count(*) from over1k_part2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part2_orc
PREHOOK: Input: default@over1k_part2_orc@ds=foo/t=27
PREHOOK: Input: default@over1k_part2_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from over1k_part2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part2_orc
POSTHOOK: Input: default@over1k_part2_orc@ds=foo/t=27
POSTHOOK: Input: default@over1k_part2_orc@ds=foo/t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
19
PREHOOK: query: create table over1k_part_buck_sort2_orc(
           si smallint,
           i int,
           b bigint,
           f float)
       partitioned by (t tinyint)
       clustered by (si)
       sorted by (f) into 1 buckets
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@over1k_part_buck_sort2_orc
POSTHOOK: query: create table over1k_part_buck_sort2_orc(
           si smallint,
           i int,
           b bigint,
           f float)
       partitioned by (t tinyint)
       clustered by (si)
       sorted by (f) into 1 buckets
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@over1k_part_buck_sort2_orc
PREHOOK: query: explain insert overwrite table over1k_part_buck_sort2_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_sort2_orc
POSTHOOK: query: explain insert overwrite table over1k_part_buck_sort2_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_sort2_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col3 (type: float)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: smallint)
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col4 (type: tinyint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), KEY.reducesinkkey0 (type: float), VALUE._col3 (type: tinyint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: default.over1k_part_buck_sort2_orc
                Select Operator
                  expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
                  outputColumnNames: si, i, b, f, t
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                    keys: t (type: tinyint)
                    minReductionHashAggr: 0.4
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                    Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: tinyint)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: _col0 (type: tinyint)
                      Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col1 (type: smallint), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: binary), _col14 (type: float), _col15 (type: float), _col16 (type: bigint), _col17 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col1) (type: bigint), UDFToLong(_col2) (type: bigint), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), _col10 (type: bigint), _col11 (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col14) (type: double), UDFToDouble(_col15) (type: double), (_col3 - _col16) (type: bigint), COALESCE(ndv_compute_bit_vector(_col17),0) (type: bigint), _col17 (type: binary), _col0 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            t 
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.over1k_part_buck_sort2_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part_buck_sort2_orc

PREHOOK: query: explain insert overwrite table over1k_part_buck_sort2_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_sort2_orc
POSTHOOK: query: explain insert overwrite table over1k_part_buck_sort2_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_sort2_orc
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_orc
                  filterExpr: (t is null or (t = 27Y)) (type: boolean)
                  Statistics: Num rows: 1049 Data size: 25160 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (t is null or (t = 27Y)) (type: boolean)
                    Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col4 (type: tinyint), _bucket_number (type: string), _col3 (type: float)
                        null sort order: aaa
                        sort order: +++
                        Map-reduce partition columns: _col4 (type: tinyint)
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint)
                      Select Operator
                        expressions: _col0 (type: smallint), _col1 (type: int), _col2 (type: bigint), _col3 (type: float), _col4 (type: tinyint)
                        outputColumnNames: si, i, b, f, t
                        Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                        Group By Operator
                          aggregations: min(si), max(si), count(1), count(si), compute_bit_vector_hll(si), min(i), max(i), count(i), compute_bit_vector_hll(i), min(b), max(b), count(b), compute_bit_vector_hll(b), min(f), max(f), count(f), compute_bit_vector_hll(f)
                          keys: t (type: tinyint)
                          minReductionHashAggr: 0.4
                          mode: hash
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                          Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            key expressions: _col0 (type: tinyint)
                            null sort order: z
                            sort order: +
                            Map-reduce partition columns: _col0 (type: tinyint)
                            Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col1 (type: smallint), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: int), _col7 (type: int), _col8 (type: bigint), _col9 (type: binary), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: binary), _col14 (type: float), _col15 (type: float), _col16 (type: bigint), _col17 (type: binary)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: smallint), VALUE._col1 (type: int), VALUE._col2 (type: bigint), KEY._col3 (type: float), KEY._col4 (type: tinyint), KEY._bucket_number (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _bucket_number
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_BUCKET_SORTED
                  Statistics: Num rows: 11 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: default.over1k_part_buck_sort2_orc
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8), min(VALUE._col9), max(VALUE._col10), count(VALUE._col11), compute_bit_vector_hll(VALUE._col12), min(VALUE._col13), max(VALUE._col14), count(VALUE._col15), compute_bit_vector_hll(VALUE._col16)
                keys: KEY._col0 (type: tinyint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                Statistics: Num rows: 11 Data size: 7260 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col1) (type: bigint), UDFToLong(_col2) (type: bigint), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), 'LONG' (type: string), _col10 (type: bigint), _col11 (type: bigint), (_col3 - _col12) (type: bigint), COALESCE(ndv_compute_bit_vector(_col13),0) (type: bigint), _col13 (type: binary), 'DOUBLE' (type: string), UDFToDouble(_col14) (type: double), UDFToDouble(_col15) (type: double), (_col3 - _col16) (type: bigint), COALESCE(ndv_compute_bit_vector(_col17),0) (type: bigint), _col17 (type: binary), _col0 (type: tinyint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23, _col24
                  Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 11 Data size: 11682 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            t 
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.over1k_part_buck_sort2_orc

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: si, i, b, f
          Column Types: smallint, int, bigint, float
          Table: default.over1k_part_buck_sort2_orc

PREHOOK: query: insert overwrite table over1k_part_buck_sort2_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_sort2_orc
POSTHOOK: query: insert overwrite table over1k_part_buck_sort2_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_sort2_orc
POSTHOOK: Output: default@over1k_part_buck_sort2_orc@t=27
POSTHOOK: Output: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: desc formatted over1k_part_buck_sort2_orc partition(t=27)
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: query: desc formatted over1k_part_buck_sort2_orc partition(t=27)
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[27]                	 
Database:           	default             	 
Table:              	over1k_part_buck_sort2_orc	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	1                   
	numRows             	16                  
	rawDataSize         	415                 
	totalSize           	431                 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	1                   	 
Bucket Columns:     	[si]                	 
Sort Columns:       	[Order(col:f, order:1)]	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part_buck_sort2_orc partition(t="__HIVE_DEFAULT_PARTITION__")
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: query: desc formatted over1k_part_buck_sort2_orc partition(t="__HIVE_DEFAULT_PARTITION__")
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[__HIVE_DEFAULT_PARTITION__]	 
Database:           	default             	 
Table:              	over1k_part_buck_sort2_orc	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	1                   
	numRows             	3                   
	rawDataSize         	78                  
	totalSize           	81                  
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	1                   	 
Bucket Columns:     	[si]                	 
Sort Columns:       	[Order(col:f, order:1)]	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: explain select * from over1k_part_buck_sort2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_buck_sort2_orc
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: explain select * from over1k_part_buck_sort2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: over1k_part_buck_sort2_orc
          Select Operator
            expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
            outputColumnNames: _col0, _col1, _col2, _col3, _col4
            ListSink

PREHOOK: query: select * from over1k_part_buck_sort2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_buck_sort2_orc
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select * from over1k_part_buck_sort2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
329	65778	4294967451	6.63	27
367	65675	4294967518	12.32	27
278	65622	4294967516	25.67	27
335	65636	4294967505	37.14	27
262	65787	4294967371	57.35	27
490	65680	4294967347	57.46	27
335	65617	4294967381	64.87	27
482	65624	4294967313	78.98	27
457	65570	4294967464	81.58	27
405	65536	4294967508	82.24	27
287	65708	4294967542	83.33	27
261	65619	4294967401	88.78	27
256	65599	4294967383	89.55	27
503	65628	4294967371	95.07	27
401	65779	4294967402	97.39	27
340	65677	4294967461	98.96	27
409	65536	4294967490	46.97	NULL
374	65560	4294967516	65.43	NULL
473	65720	4294967324	80.74	NULL
PREHOOK: query: explain select count(*) from over1k_part_buck_sort2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_buck_sort2_orc
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: explain select count(*) from over1k_part_buck_sort2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_part_buck_sort2_orc
                  Statistics: Num rows: 19 Data size: 645 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    Statistics: Num rows: 19 Data size: 645 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: count()
                      minReductionHashAggr: 0.94736844
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        null sort order: 
                        sort order: 
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: bigint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(*) from over1k_part_buck_sort2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_buck_sort2_orc
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from over1k_part_buck_sort2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
19
PREHOOK: query: insert overwrite table over1k_part_buck_sort2_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_orc
PREHOOK: Output: default@over1k_part_buck_sort2_orc
POSTHOOK: query: insert overwrite table over1k_part_buck_sort2_orc partition(t) select si,i,b,f,t from over1k_orc where t is null or t=27
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_orc
POSTHOOK: Output: default@over1k_part_buck_sort2_orc
POSTHOOK: Output: default@over1k_part_buck_sort2_orc@t=27
POSTHOOK: Output: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=27).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=27).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=27).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=27).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).b SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).f SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).i SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: over1k_part_buck_sort2_orc PARTITION(t=__HIVE_DEFAULT_PARTITION__).si SIMPLE [(over1k_orc)over1k_orc.FieldSchema(name:si, type:smallint, comment:null), ]
PREHOOK: query: desc formatted over1k_part_buck_sort2_orc partition(t=27)
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: query: desc formatted over1k_part_buck_sort2_orc partition(t=27)
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[27]                	 
Database:           	default             	 
Table:              	over1k_part_buck_sort2_orc	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	1                   
	numRows             	16                  
	rawDataSize         	415                 
	totalSize           	431                 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	1                   	 
Bucket Columns:     	[si]                	 
Sort Columns:       	[Order(col:f, order:1)]	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: desc formatted over1k_part_buck_sort2_orc partition(t="__HIVE_DEFAULT_PARTITION__")
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: query: desc formatted over1k_part_buck_sort2_orc partition(t="__HIVE_DEFAULT_PARTITION__")
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
# col_name            	data_type           	comment             
si                  	smallint            	                    
i                   	int                 	                    
b                   	bigint              	                    
f                   	float               	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
t                   	tinyint             	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[__HIVE_DEFAULT_PARTITION__]	 
Database:           	default             	 
Table:              	over1k_part_buck_sort2_orc	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"b\":\"true\",\"f\":\"true\",\"i\":\"true\",\"si\":\"true\"}}
	numFiles            	1                   
	numRows             	3                   
	rawDataSize         	78                  
	totalSize           	81                  
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	1                   	 
Bucket Columns:     	[si]                	 
Sort Columns:       	[Order(col:f, order:1)]	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: explain select * from over1k_part_buck_sort2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_buck_sort2_orc
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: explain select * from over1k_part_buck_sort2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: over1k_part_buck_sort2_orc
          Select Operator
            expressions: si (type: smallint), i (type: int), b (type: bigint), f (type: float), t (type: tinyint)
            outputColumnNames: _col0, _col1, _col2, _col3, _col4
            ListSink

PREHOOK: query: select * from over1k_part_buck_sort2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_buck_sort2_orc
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select * from over1k_part_buck_sort2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
329	65778	4294967451	6.63	27
367	65675	4294967518	12.32	27
278	65622	4294967516	25.67	27
335	65636	4294967505	37.14	27
262	65787	4294967371	57.35	27
490	65680	4294967347	57.46	27
335	65617	4294967381	64.87	27
482	65624	4294967313	78.98	27
457	65570	4294967464	81.58	27
405	65536	4294967508	82.24	27
287	65708	4294967542	83.33	27
261	65619	4294967401	88.78	27
256	65599	4294967383	89.55	27
503	65628	4294967371	95.07	27
401	65779	4294967402	97.39	27
340	65677	4294967461	98.96	27
409	65536	4294967490	46.97	NULL
374	65560	4294967516	65.43	NULL
473	65720	4294967324	80.74	NULL
PREHOOK: query: explain select count(*) from over1k_part_buck_sort2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_buck_sort2_orc
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: explain select count(*) from over1k_part_buck_sort2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: over1k_part_buck_sort2_orc
                  Statistics: Num rows: 19 Data size: 645 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    Statistics: Num rows: 19 Data size: 645 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: count()
                      minReductionHashAggr: 0.94736844
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        null sort order: 
                        sort order: 
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: bigint)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(*) from over1k_part_buck_sort2_orc
PREHOOK: type: QUERY
PREHOOK: Input: default@over1k_part_buck_sort2_orc
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
PREHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from over1k_part_buck_sort2_orc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@over1k_part_buck_sort2_orc
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=27
POSTHOOK: Input: default@over1k_part_buck_sort2_orc@t=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
19
PREHOOK: query: create table addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
(i int,si smallint)
partitioned by (s string)
clustered by (si) into 2 buckets
stored as orc tblproperties ('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
POSTHOOK: query: create table addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
(i int,si smallint)
partitioned by (s string)
clustered by (si) into 2 buckets
stored as orc tblproperties ('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
PREHOOK: query: explain insert into table addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint partition (s)
  select cint,csmallint, cstring1 from alltypesorc limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@alltypesorc
PREHOOK: Output: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
POSTHOOK: query: explain insert into table addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint partition (s)
  select cint,csmallint, cstring1 from alltypesorc limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@alltypesorc
POSTHOOK: Output: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: alltypesorc
                  Statistics: Num rows: 12288 Data size: 935846 Basic stats: COMPLETE Column stats: COMPLETE
                  Limit
                    Number of rows: 10
                    Statistics: Num rows: 10 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: cint (type: int), csmallint (type: smallint), cstring1 (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 10 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        null sort order: 
                        sort order: 
                        Statistics: Num rows: 10 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                        TopN Hash Memory Usage: 0.1
                        value expressions: _col0 (type: int), _col1 (type: smallint), _col2 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Limit
                Number of rows: 10
                Statistics: Num rows: 10 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: VALUE._col0 (type: int), VALUE._col1 (type: smallint), VALUE._col2 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 10 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col2 (type: string), _bucket_number (type: string), _col1 (type: smallint)
                    null sort order: aaa
                    sort order: +++
                    Map-reduce partition columns: _col2 (type: string)
                    Statistics: Num rows: 10 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: _col0 (type: int)
                  Select Operator
                    expressions: _col0 (type: int), _col1 (type: smallint), _col2 (type: string)
                    outputColumnNames: i, si, s
                    Statistics: Num rows: 10 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(i), max(i), count(1), count(i), compute_bit_vector_hll(i), min(si), max(si), count(si), compute_bit_vector_hll(si)
                      keys: s (type: string)
                      minReductionHashAggr: 0.4
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                      Statistics: Num rows: 10 Data size: 4032 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 10 Data size: 4032 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: int), _col2 (type: int), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: binary), _col6 (type: smallint), _col7 (type: smallint), _col8 (type: bigint), _col9 (type: binary)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), KEY._col1 (type: smallint), KEY._col2 (type: string), KEY._bucket_number (type: string)
                outputColumnNames: _col0, _col1, _col2, _bucket_number
                File Output Operator
                  compressed: false
                  Dp Sort State: PARTITION_BUCKET_SORTED
                  Statistics: Num rows: 10 Data size: 816 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
                  Write Type: INSERT
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                Statistics: Num rows: 10 Data size: 4032 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col1) (type: bigint), UDFToLong(_col2) (type: bigint), (_col3 - _col4) (type: bigint), COALESCE(ndv_compute_bit_vector(_col5),0) (type: bigint), _col5 (type: binary), 'LONG' (type: string), UDFToLong(_col6) (type: bigint), UDFToLong(_col7) (type: bigint), (_col3 - _col8) (type: bigint), COALESCE(ndv_compute_bit_vector(_col9),0) (type: bigint), _col9 (type: binary), _col0 (type: string)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
                  Statistics: Num rows: 10 Data size: 6032 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 10 Data size: 6032 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            s 
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
          Write Type: INSERT

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: i, si
          Column Types: int, smallint
          Table: default.addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint

PREHOOK: query: insert into table addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint partition (s)
  select cint,csmallint, cstring1 from alltypesorc limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@alltypesorc
PREHOOK: Output: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
POSTHOOK: query: insert into table addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint partition (s)
  select cint,csmallint, cstring1 from alltypesorc limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@alltypesorc
POSTHOOK: Output: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
POSTHOOK: Output: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint@s=cvLH6Eat2yFsyy7p
POSTHOOK: Lineage: addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint PARTITION(s=cvLH6Eat2yFsyy7p).i SIMPLE [(alltypesorc)alltypesorc.FieldSchema(name:cint, type:int, comment:null), ]
POSTHOOK: Lineage: addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint PARTITION(s=cvLH6Eat2yFsyy7p).si SIMPLE [(alltypesorc)alltypesorc.FieldSchema(name:csmallint, type:smallint, comment:null), ]
PREHOOK: query: select cint, csmallint, cstring1 from alltypesorc limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@alltypesorc
#### A masked pattern was here ####
POSTHOOK: query: select cint, csmallint, cstring1 from alltypesorc limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@alltypesorc
#### A masked pattern was here ####
528534767	-13326	cvLH6Eat2yFsyy7p
528534767	-4213	cvLH6Eat2yFsyy7p
528534767	-15813	cvLH6Eat2yFsyy7p
528534767	-9566	cvLH6Eat2yFsyy7p
528534767	15007	cvLH6Eat2yFsyy7p
528534767	7021	cvLH6Eat2yFsyy7p
528534767	4963	cvLH6Eat2yFsyy7p
528534767	-7824	cvLH6Eat2yFsyy7p
528534767	-15431	cvLH6Eat2yFsyy7p
528534767	-15549	cvLH6Eat2yFsyy7p
PREHOOK: query: select * from addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
PREHOOK: type: QUERY
PREHOOK: Input: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
PREHOOK: Input: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint@s=cvLH6Eat2yFsyy7p
#### A masked pattern was here ####
POSTHOOK: query: select * from addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
POSTHOOK: type: QUERY
POSTHOOK: Input: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint
POSTHOOK: Input: default@addcolumns_vectorization_true_disallowincompatible_true_fileformat_orc_tinyint@s=cvLH6Eat2yFsyy7p
#### A masked pattern was here ####
528534767	-15549	cvLH6Eat2yFsyy7p
528534767	-13326	cvLH6Eat2yFsyy7p
528534767	-9566	cvLH6Eat2yFsyy7p
528534767	7021	cvLH6Eat2yFsyy7p
528534767	-15813	cvLH6Eat2yFsyy7p
528534767	-15431	cvLH6Eat2yFsyy7p
528534767	-7824	cvLH6Eat2yFsyy7p
528534767	-4213	cvLH6Eat2yFsyy7p
528534767	4963	cvLH6Eat2yFsyy7p
528534767	15007	cvLH6Eat2yFsyy7p
