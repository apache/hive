PREHOOK: query: create table a_n4 as SELECT 100 as key, a_n4.value as value FROM src LATERAL VIEW explode(array(40, 50, 60)) a_n4 as value limit 3
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@a_n4
POSTHOOK: query: create table a_n4 as SELECT 100 as key, a_n4.value as value FROM src LATERAL VIEW explode(array(40, 50, 60)) a_n4 as value limit 3
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@a_n4
POSTHOOK: Lineage: a_n4.key SIMPLE []
POSTHOOK: Lineage: a_n4.value SCRIPT []
PREHOOK: query: explain extended select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: explain extended select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT `t`.`key`, `t`.`value`, `t1`.`key` AS `key1`, `t1`.`value` AS `value1`, `t3`.`key` AS `key2`, `t3`.`value` AS `value2`
FROM (SELECT `key`, `value`, `value` = 60 AS `=`, `value` = 50 AS `=3`
FROM `default`.`a_n4`) AS `t`
LEFT JOIN (SELECT `key`, CAST(50 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 50 AND `key` IS NOT NULL) AS `t1` ON `t`.`=3` AND `t`.`key` = `t1`.`key`
LEFT JOIN (SELECT `key`, CAST(60 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 60 AND `key` IS NOT NULL) AS `t3` ON `t`.`=` AND `t`.`key` = `t3`.`key`
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a_n4
                  Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Select Operator
                    expressions: key (type: int), value (type: int), (value = 60) (type: boolean), (value = 50) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      bucketingVersion: 2
                      key expressions: _col0 (type: int)
                      null sort order: z
                      numBuckets: -1
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      tag: 0
                      value expressions: _col1 (type: int), _col2 (type: boolean), _col3 (type: boolean)
                      auto parallelism: true
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 60) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 60 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 1
                        value expressions: _col1 (type: int)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a_n4
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns key,value
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a_n4
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a_n4
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a_n4
                  name: default.a_n4
            Truncated Path -> Alias:
              /a_n4 [a_n4]
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  filterExpr: ((value = 50) and key is not null) (type: boolean)
                  Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 50) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 50 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 1
                        value expressions: _col1 (type: int)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a_n4
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns key,value
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a_n4
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a_n4
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a_n4
                  name: default.a_n4
            Truncated Path -> Alias:
              /a_n4 [b]
        Reducer 2 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                filter mappings:
                  0 [1, 1]
                filter predicates:
                  0 {VALUE._col2}
                  1 
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col4, _col5
                Position of Big Table: 0
                Statistics: Num rows: 3 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col0 (type: int)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 3 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: 0
                  value expressions: _col1 (type: int), _col2 (type: boolean), _col4 (type: int), _col5 (type: int)
                  auto parallelism: true
        Reducer 3 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                filter mappings:
                  0 [1, 1]
                filter predicates:
                  0 {VALUE._col1}
                  1 
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col4, _col5, _col6, _col7
                Position of Big Table: 0
                Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    bucketingVersion: 2
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          bucketing_version -1
                          columns _col0,_col1,_col2,_col3,_col4,_col5
                          columns.types int:int:int:int:int:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL
100	50	100	50	NULL	NULL
100	60	NULL	NULL	100	60
PREHOOK: query: select /*+ MAPJOIN(b,c)*/ * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(b,c)*/ * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL
100	50	100	50	NULL	NULL
100	60	NULL	NULL	100	60
PREHOOK: query: explain extended select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: explain extended select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT `t0`.`key`, `t0`.`value`, `t1`.`key` AS `key1`, `t1`.`value` AS `value1`, `t3`.`key` AS `key2`, `t3`.`value` AS `value2`
FROM (SELECT `key`, CAST(50 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 50 AND `key` IS NOT NULL) AS `t0`
RIGHT JOIN (SELECT `key`, `value`, `value` = 60 AS `=`, `value` = 50 AS `=3`
FROM `default`.`a_n4`) AS `t1` ON `t1`.`=3` AND `t0`.`key` = `t1`.`key`
LEFT JOIN (SELECT `key`, CAST(60 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 60 AND `key` IS NOT NULL) AS `t3` ON `t1`.`=` AND `t1`.`key` = `t3`.`key`
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
        Reducer 3 <- Map 4 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a_n4
                  filterExpr: ((value = 50) and key is not null) (type: boolean)
                  Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 50) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 50 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 0
                        value expressions: _col1 (type: int)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a_n4
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns key,value
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a_n4
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a_n4
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a_n4
                  name: default.a_n4
            Truncated Path -> Alias:
              /a_n4 [a_n4]
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Select Operator
                    expressions: key (type: int), value (type: int), (value = 60) (type: boolean), (value = 50) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      bucketingVersion: 2
                      key expressions: _col0 (type: int)
                      null sort order: z
                      numBuckets: -1
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      tag: 1
                      value expressions: _col1 (type: int), _col2 (type: boolean), _col3 (type: boolean)
                      auto parallelism: true
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 60) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 60 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 1
                        value expressions: _col1 (type: int)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a_n4
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns key,value
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a_n4
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a_n4
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a_n4
                  name: default.a_n4
            Truncated Path -> Alias:
              /a_n4 [b]
        Reducer 2 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Right Outer Join 0 to 1
                filter mappings:
                  1 [0, 1]
                filter predicates:
                  0 
                  1 {VALUE._col2}
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Position of Big Table: 1
                Statistics: Num rows: 3 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col2 (type: int)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col2 (type: int)
                  Statistics: Num rows: 3 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: 0
                  value expressions: _col0 (type: int), _col1 (type: int), _col3 (type: int), _col4 (type: boolean)
                  auto parallelism: true
        Reducer 3 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                filter mappings:
                  0 [1, 1]
                filter predicates:
                  0 {VALUE._col3}
                  1 
                keys:
                  0 _col2 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col6, _col7
                Position of Big Table: 0
                Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: int), _col6 (type: int), _col7 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    bucketingVersion: 2
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          bucketing_version -1
                          columns _col0,_col1,_col2,_col3,_col4,_col5
                          columns.types int:int:int:int:int:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: select /*+ MAPJOIN(a_n4,c)*/ * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(a_n4,c)*/ * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: explain extended select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: explain extended select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT `t0`.`key`, `t0`.`value`, `t1`.`key` AS `key1`, `t1`.`value` AS `value1`, `t3`.`key` AS `key2`, `t3`.`value` AS `value2`
FROM (SELECT `key`, CAST(50 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 50 AND `key` IS NOT NULL) AS `t0`
RIGHT JOIN (SELECT `key`, `value`, `value` = 60 AS `=`, `value` = 50 AS `=3`
FROM `default`.`a_n4`) AS `t1` ON `t1`.`=3` AND `t0`.`key` = `t1`.`key`
LEFT JOIN (SELECT `key`, CAST(60 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 60 AND `key` IS NOT NULL) AS `t3` ON `t1`.`=` AND `t1`.`key` = `t3`.`key`
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
        Reducer 3 <- Map 4 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a_n4
                  filterExpr: ((value = 50) and key is not null) (type: boolean)
                  Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 50) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 50 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 0
                        value expressions: _col1 (type: int)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a_n4
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns key,value
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a_n4
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a_n4
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a_n4
                  name: default.a_n4
            Truncated Path -> Alias:
              /a_n4 [a_n4]
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Select Operator
                    expressions: key (type: int), value (type: int), (value = 60) (type: boolean), (value = 50) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      bucketingVersion: 2
                      key expressions: _col0 (type: int)
                      null sort order: z
                      numBuckets: -1
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      tag: 1
                      value expressions: _col1 (type: int), _col2 (type: boolean), _col3 (type: boolean)
                      auto parallelism: true
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 60) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 60 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 1
                        value expressions: _col1 (type: int)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a_n4
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns key,value
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a_n4
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a_n4
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a_n4
                  name: default.a_n4
            Truncated Path -> Alias:
              /a_n4 [b]
        Reducer 2 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Right Outer Join 0 to 1
                filter mappings:
                  1 [0, 1]
                filter predicates:
                  0 
                  1 {VALUE._col2}
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Position of Big Table: 1
                Statistics: Num rows: 3 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col2 (type: int)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col2 (type: int)
                  Statistics: Num rows: 3 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: 0
                  value expressions: _col0 (type: int), _col1 (type: int), _col3 (type: int), _col4 (type: boolean)
                  auto parallelism: true
        Reducer 3 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                filter mappings:
                  0 [1, 1]
                filter predicates:
                  0 {VALUE._col3}
                  1 
                keys:
                  0 _col2 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col6, _col7
                Position of Big Table: 0
                Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: int), _col6 (type: int), _col7 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    bucketingVersion: 2
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          bucketing_version -1
                          columns _col0,_col1,_col2,_col3,_col4,_col5
                          columns.types int:int:int:int:int:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: select /*+ MAPJOIN(a_n4,c)*/ * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(a_n4,c)*/ * from a_n4 right outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50 AND b.value>10) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: explain extended select * from a_n4 full outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: explain extended select * from a_n4 full outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT `t`.`key`, `t`.`value`, `t0`.`key` AS `key1`, `t0`.`value` AS `value1`, `t2`.`key` AS `key2`, `t2`.`value` AS `value2`, `t4`.`key` AS `key3`, `t4`.`value` AS `value3`
FROM (SELECT `key`, `value`, `value` = 40 AS `=`, `value` = 50 AS `=3`
FROM `default`.`a_n4`) AS `t`
FULL JOIN (SELECT `key`, `value`, `value` = 60 AS `=`, `value` = 50 AS `=3`
FROM `default`.`a_n4`) AS `t0` ON `t`.`=3` AND `t0`.`=3` AND `t`.`key` = `t0`.`key`
LEFT JOIN (SELECT `key`, CAST(60 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 60 AND `key` IS NOT NULL) AS `t2` ON `t0`.`=` AND `t0`.`key` = `t2`.`key`
LEFT JOIN (SELECT `key`, CAST(40 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 40 AND `key` IS NOT NULL) AS `t4` ON `t`.`=` AND `t`.`key` = `t4`.`key`
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Map 1 (SIMPLE_EDGE), Reducer 3 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a_n4
                  Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Select Operator
                    expressions: key (type: int), value (type: int), (value = 40) (type: boolean), (value = 50) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      bucketingVersion: 2
                      key expressions: _col0 (type: int)
                      null sort order: z
                      numBuckets: -1
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      tag: 0
                      value expressions: _col1 (type: int), _col2 (type: boolean), _col3 (type: boolean)
                      auto parallelism: true
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 60) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 60 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 1
                        value expressions: _col1 (type: int)
                        auto parallelism: true
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 40) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 40 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 1
                        value expressions: _col1 (type: int)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a_n4
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns key,value
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a_n4
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a_n4
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a_n4
                  name: default.a_n4
            Truncated Path -> Alias:
              /a_n4 [a_n4]
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Select Operator
                    expressions: key (type: int), value (type: int), (value = 60) (type: boolean), (value = 50) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      bucketingVersion: 2
                      key expressions: _col0 (type: int)
                      null sort order: z
                      numBuckets: -1
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      tag: 1
                      value expressions: _col1 (type: int), _col2 (type: boolean), _col3 (type: boolean)
                      auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a_n4
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns key,value
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a_n4
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a_n4
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a_n4
                  name: default.a_n4
            Truncated Path -> Alias:
              /a_n4 [b]
        Reducer 2 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Full Outer Join 0 to 1
                filter mappings:
                  0 [1, 1]
                  1 [0, 1]
                filter predicates:
                  0 {VALUE._col2}
                  1 {VALUE._col2}
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6
                Position of Big Table: 0
                Statistics: Num rows: 9 Data size: 216 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col4 (type: int)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col4 (type: int)
                  Statistics: Num rows: 9 Data size: 216 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: 0
                  value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: boolean), _col5 (type: int), _col6 (type: boolean)
                  auto parallelism: true
        Reducer 3 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                filter mappings:
                  0 [1, 1]
                filter predicates:
                  0 {VALUE._col5}
                  1 
                keys:
                  0 _col4 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col8, _col9
                Position of Big Table: 0
                Statistics: Num rows: 9 Data size: 252 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col0 (type: int)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 9 Data size: 252 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: 0
                  value expressions: _col1 (type: int), _col2 (type: boolean), _col4 (type: int), _col5 (type: int), _col8 (type: int), _col9 (type: int)
                  auto parallelism: true
        Reducer 4 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                filter mappings:
                  0 [1, 1]
                filter predicates:
                  0 {VALUE._col1}
                  1 
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col4, _col5, _col8, _col9, _col10, _col11
                Position of Big Table: 0
                Statistics: Num rows: 9 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col8 (type: int), _col9 (type: int), _col10 (type: int), _col11 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                  Statistics: Num rows: 9 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    bucketingVersion: 2
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 9 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          bucketing_version -1
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
                          columns.types int:int:int:int:int:int:int:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a_n4 full outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from a_n4 full outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	NULL	NULL	NULL	NULL
NULL	NULL	100	40	NULL	NULL	NULL	NULL
NULL	NULL	100	60	100	60	NULL	NULL
PREHOOK: query: explain extended select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: explain extended select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT `t`.`key`, `t`.`value`, `t1`.`key` AS `key1`, `t1`.`value` AS `value1`, `t3`.`key` AS `key2`, `t3`.`value` AS `value2`, `t5`.`key` AS `key3`, `t5`.`value` AS `value3`
FROM (SELECT `key`, `value`, `value` = 40 AS `=`, `value` = 60 AS `=3`, `value` = 50 AS `=4`
FROM `default`.`a_n4`) AS `t`
LEFT JOIN (SELECT `key`, CAST(50 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 50 AND `key` IS NOT NULL) AS `t1` ON `t`.`=4` AND `t`.`key` = `t1`.`key`
LEFT JOIN (SELECT `key`, CAST(60 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 60 AND `key` IS NOT NULL) AS `t3` ON `t`.`=3` AND `t`.`key` = `t3`.`key`
LEFT JOIN (SELECT `key`, CAST(40 AS INTEGER) AS `value`
FROM `default`.`a_n4`
WHERE `value` = 40 AND `key` IS NOT NULL) AS `t5` ON `t`.`=` AND `t`.`key` = `t5`.`key`
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Map 1 (SIMPLE_EDGE), Reducer 3 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a_n4
                  Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Select Operator
                    expressions: key (type: int), value (type: int), (value = 40) (type: boolean), (value = 60) (type: boolean), (value = 50) (type: boolean)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 3 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      bucketingVersion: 2
                      key expressions: _col0 (type: int)
                      null sort order: z
                      numBuckets: -1
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 3 Data size: 60 Basic stats: COMPLETE Column stats: COMPLETE
                      tag: 0
                      value expressions: _col1 (type: int), _col2 (type: boolean), _col3 (type: boolean), _col4 (type: boolean)
                      auto parallelism: true
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 60) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 60 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 1
                        value expressions: _col1 (type: int)
                        auto parallelism: true
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 40) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 40 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 1
                        value expressions: _col1 (type: int)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a_n4
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns key,value
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a_n4
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a_n4
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a_n4
                  name: default.a_n4
            Truncated Path -> Alias:
              /a_n4 [a_n4]
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: b
                  filterExpr: ((value = 50) and key is not null) (type: boolean)
                  Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((value = 50) and key is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: int), 50 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        bucketingVersion: 2
                        key expressions: _col0 (type: int)
                        null sort order: z
                        numBuckets: -1
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        tag: 1
                        value expressions: _col1 (type: int)
                        auto parallelism: true
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a_n4
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns key,value
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a_n4
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucketing_version 2
                      column.name.delimiter ,
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a_n4
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a_n4
                  name: default.a_n4
            Truncated Path -> Alias:
              /a_n4 [b]
        Reducer 2 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                filter mappings:
                  0 [1, 1]
                filter predicates:
                  0 {VALUE._col3}
                  1 
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col5, _col6
                Position of Big Table: 0
                Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col0 (type: int)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 3 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: 0
                  value expressions: _col1 (type: int), _col2 (type: boolean), _col3 (type: boolean), _col5 (type: int), _col6 (type: int)
                  auto parallelism: true
        Reducer 3 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                filter mappings:
                  0 [1, 1]
                filter predicates:
                  0 {VALUE._col2}
                  1 
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col5, _col6, _col7, _col8
                Position of Big Table: 0
                Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  bucketingVersion: 2
                  key expressions: _col0 (type: int)
                  null sort order: z
                  numBuckets: -1
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: 0
                  value expressions: _col1 (type: int), _col2 (type: boolean), _col5 (type: int), _col6 (type: int), _col7 (type: int), _col8 (type: int)
                  auto parallelism: true
        Reducer 4 
            Execution mode: llap
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                filter mappings:
                  0 [1, 1]
                filter predicates:
                  0 {VALUE._col1}
                  1 
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col5, _col6, _col7, _col8, _col9, _col10
                Position of Big Table: 0
                Statistics: Num rows: 3 Data size: 96 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: int), _col8 (type: int), _col9 (type: int), _col10 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                  Statistics: Num rows: 3 Data size: 96 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    bucketingVersion: 2
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 3 Data size: 96 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          bucketing_version -1
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
                          columns.types int:int:int:int:int:int:int:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	100	60	NULL	NULL
PREHOOK: query: select /*+ MAPJOIN(b,c, d)*/ * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a_n4
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(b,c, d)*/ * from a_n4 left outer join a_n4 b on (a_n4.key=b.key AND a_n4.value=50 AND b.value=50) left outer join a_n4 c on (a_n4.key=c.key AND a_n4.value=60 AND c.value=60) left outer join a_n4 d on (a_n4.key=d.key AND a_n4.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a_n4
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	100	60	NULL	NULL
