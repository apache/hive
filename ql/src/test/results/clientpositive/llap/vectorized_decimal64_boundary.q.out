PREHOOK: query: drop table if exists mini_store
PREHOOK: type: DROPTABLE
PREHOOK: Output: database:default
POSTHOOK: query: drop table if exists mini_store
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: database:default
PREHOOK: query: create table mini_store
(
    s_store_sk                int,
    s_store_id                string
)
row format delimited fields terminated by '\t'
STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@mini_store
POSTHOOK: query: create table mini_store
(
    s_store_sk                int,
    s_store_id                string
)
row format delimited fields terminated by '\t'
STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@mini_store
PREHOOK: query: drop table if exists mini_sales
PREHOOK: type: DROPTABLE
PREHOOK: Output: database:default
POSTHOOK: query: drop table if exists mini_sales
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: database:default
PREHOOK: query: create table mini_sales
(
    ss_store_sk               int,
    ss_quantity               int,
    ss_sales_price            decimal(7,2)
)
row format delimited fields terminated by '\t'
STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@mini_sales
POSTHOOK: query: create table mini_sales
(
    ss_store_sk               int,
    ss_quantity               int,
    ss_sales_price            decimal(7,2)
)
row format delimited fields terminated by '\t'
STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@mini_sales
PREHOOK: query: insert into mini_store values (1, 'store')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@mini_store
POSTHOOK: query: insert into mini_store values (1, 'store')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@mini_store
POSTHOOK: Lineage: mini_store.s_store_id SCRIPT []
POSTHOOK: Lineage: mini_store.s_store_sk SCRIPT []
PREHOOK: query: insert into mini_sales values (1, 2, 1.2)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@mini_sales
POSTHOOK: query: insert into mini_sales values (1, 2, 1.2)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@mini_sales
POSTHOOK: Lineage: mini_sales.ss_quantity SCRIPT []
POSTHOOK: Lineage: mini_sales.ss_sales_price SCRIPT []
POSTHOOK: Lineage: mini_sales.ss_store_sk SCRIPT []
PREHOOK: query: explain vectorization detail
select s_store_id, coalesce(ss_sales_price*ss_quantity,0) sumsales
            from mini_sales, mini_store
       where ss_store_sk = s_store_sk
PREHOOK: type: QUERY
PREHOOK: Input: default@mini_sales
PREHOOK: Input: default@mini_store
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
select s_store_id, coalesce(ss_sales_price*ss_quantity,0) sumsales
            from mini_sales, mini_store
       where ss_store_sk = s_store_sk
POSTHOOK: type: QUERY
POSTHOOK: Input: default@mini_sales
POSTHOOK: Input: default@mini_store
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: mini_sales
                  filterExpr: ss_store_sk is not null (type: boolean)
                  Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:ss_store_sk:int, 1:ss_quantity:int, 2:ss_sales_price:decimal(7,2)/DECIMAL_64, 3:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>, 4:ROW__IS__DELETED:boolean]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: ss_store_sk is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: ss_store_sk (type: int), if((ss_sales_price is not null and CAST( ss_quantity AS decimal(10,0)) is not null), (ss_sales_price * CAST( ss_quantity AS decimal(10,0))), 0) (type: decimal(18,2))
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 18]
                          selectExpressions: IfExprDecimal64ColumnDecimal64Scalar(col 15:boolean, col 17:decimal(18,2)/DECIMAL_64, decimal64Val 0, decimalVal 0)(children: ColAndCol(col 12:boolean, col 14:boolean)(children: IsNotNull(col 2:decimal(7,2)/DECIMAL_64) -> 12:boolean, IsNotNull(col 19:decimal(10,0))(children: ConvertDecimal64ToDecimal(col 13:decimal(10,0)/DECIMAL_64)(children: CastLongToDecimal64(col 1:int) -> 13:decimal(10,0)/DECIMAL_64) -> 19:decimal(10,0)) -> 14:boolean) -> 15:boolean, Decimal64ColMultiplyDecimal64Column(col 2:decimal(7,2)/DECIMAL_64, col 16:decimal(10,0)/DECIMAL_64)(children: CastLongToDecimal64(col 1:int) -> 16:decimal(10,0)/DECIMAL_64) -> 17:decimal(18,2)/DECIMAL_64) -> 18:decimal(18,2)/DECIMAL_64
                      Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumns: 0:int
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumns: 18:decimal(18,2)
                        Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: decimal(18,2))
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    includeColumns: [0, 1, 2]
                    dataColumns: ss_store_sk:int, ss_quantity:int, ss_sales_price:decimal(7,2)/DECIMAL_64
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [bigint, decimal(10,0)/DECIMAL_64, bigint, bigint, decimal(10,0)/DECIMAL_64, decimal(18,2)/DECIMAL_64, decimal(18,2), bigint, decimal(10,0)/DECIMAL_64, bigint, bigint, decimal(10,0)/DECIMAL_64, decimal(18,2)/DECIMAL_64, decimal(18,2)/DECIMAL_64, decimal(10,0)]
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: mini_store
                  filterExpr: s_store_sk is not null (type: boolean)
                  Statistics: Num rows: 1 Data size: 93 Basic stats: COMPLETE Column stats: COMPLETE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:s_store_sk:int, 1:s_store_id:string, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>, 3:ROW__IS__DELETED:boolean]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: s_store_sk is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 93 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: s_store_sk (type: int), s_store_id (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 93 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            keyColumns: 0:int
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumns: 1:string
                        Statistics: Num rows: 1 Data size: 93 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: s_store_sk:int, s_store_id:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col1, _col3
                Statistics: Num rows: 1 Data size: 201 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col3 (type: string), _col1 (type: decimal(18,2))
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1 Data size: 201 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 201 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            MergeJoin Vectorization:
                enabled: false
                enableConditionsNotMet: Vectorizing MergeJoin Supported IS false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select s_store_id, coalesce(ss_sales_price*ss_quantity,0) sumsales
from mini_sales, mini_store
where ss_store_sk = s_store_sk
PREHOOK: type: QUERY
PREHOOK: Input: default@mini_sales
PREHOOK: Input: default@mini_store
#### A masked pattern was here ####
POSTHOOK: query: select s_store_id, coalesce(ss_sales_price*ss_quantity,0) sumsales
from mini_sales, mini_store
where ss_store_sk = s_store_sk
POSTHOOK: type: QUERY
POSTHOOK: Input: default@mini_sales
POSTHOOK: Input: default@mini_store
#### A masked pattern was here ####
store	2.40
