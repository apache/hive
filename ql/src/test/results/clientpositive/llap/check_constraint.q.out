PREHOOK: query: CREATE TABLE table1_n0(i int CHECK (-i > -10),
    j int CHECK (+j > 10),
    ij boolean CHECK (ij IS NOT NULL),
    a int CHECK (a BETWEEN i AND j),
    bb float CHECK (bb IN (23.4,56,4)),
    d bigint CHECK (d > round(567.6) AND d < round(1000.4)))
    clustered by (i) into 2 buckets stored as orc TBLPROPERTIES('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@table1_n0
POSTHOOK: query: CREATE TABLE table1_n0(i int CHECK (-i > -10),
    j int CHECK (+j > 10),
    ij boolean CHECK (ij IS NOT NULL),
    a int CHECK (a BETWEEN i AND j),
    bb float CHECK (bb IN (23.4,56,4)),
    d bigint CHECK (d > round(567.6) AND d < round(1000.4)))
    clustered by (i) into 2 buckets stored as orc TBLPROPERTIES('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@table1_n0
PREHOOK: query: DESC FORMATTED table1_n0
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@table1_n0
POSTHOOK: query: DESC FORMATTED table1_n0
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@table1_n0
# col_name            	data_type           	comment             
i                   	int                 	                    
j                   	int                 	                    
ij                  	boolean             	                    
a                   	int                 	                    
bb                  	float               	                    
d                   	bigint              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[i]                 	 
Sort Columns:       	[]                  	 
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.table1_n0   	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:a       	Check Value:`a` BETWEEN `i` AND `j`	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:d       	Check Value:`d` > round(567.6) AND `d` < round(1000.4)	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:i       	Check Value:-`i` > -10	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:j       	Check Value:+`j` > 10	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:ij      	Check Value:`ij` IS NOT NULL	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:bb      	Check Value:`bb` IN (23.4,56,4)	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO table1_n0 values(1,100,true, 5, 23.4, 700.5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@table1_n0
POSTHOOK: query: EXPLAIN INSERT INTO table1_n0 values(1,100,true, 5, 23.4, 700.5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@table1_n0
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(1,100,true,5,23.4,700.5)) (type: array<struct<col1:int,col2:int,col3:boolean,col4:int,col5:decimal(3,1),col6:decimal(4,1)>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: int), col2 (type: int), col3 (type: boolean), col4 (type: int), col5 (type: decimal(3,1)), col6 (type: decimal(4,1))
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((((((((- _col0) > -10) is not false and (_col1 > 10) is not false) and _col2 is not null is not false) and _col3 BETWEEN _col0 AND _col1 is not false) and ((_col4) IN (23.4) or (_col4) IN (56) or (_col4) IN (4)) is not false) and ((_col5 > round(567.6)) and (_col5 < round(1000.4))) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: int), _col1 (type: int), _col2 (type: boolean), _col3 (type: int), UDFToFloat(_col4) (type: float), UDFToLong(_col5) (type: bigint)
                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                            Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              key expressions: _col0 (type: int)
                              null sort order: a
                              sort order: +
                              Map-reduce partition columns: _col0 (type: int)
                              Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col1 (type: int), _col2 (type: boolean), _col3 (type: int), _col4 (type: float), _col5 (type: bigint)
            Execution mode: llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: int), VALUE._col1 (type: boolean), VALUE._col2 (type: int), VALUE._col3 (type: float), VALUE._col4 (type: bigint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.table1_n0
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.table1_n0
          Write Type: INSERT

PREHOOK: query: INSERT INTO table1_n0 values(1,100,true, 5, 23.4, 700.5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@table1_n0
POSTHOOK: query: INSERT INTO table1_n0 values(1,100,true, 5, 23.4, 700.5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@table1_n0
POSTHOOK: Lineage: table1_n0.a SCRIPT []
POSTHOOK: Lineage: table1_n0.bb SCRIPT []
POSTHOOK: Lineage: table1_n0.d SCRIPT []
POSTHOOK: Lineage: table1_n0.i SCRIPT []
POSTHOOK: Lineage: table1_n0.ij SCRIPT []
POSTHOOK: Lineage: table1_n0.j SCRIPT []
PREHOOK: query: SELECT * from table1_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@table1_n0
#### A masked pattern was here ####
POSTHOOK: query: SELECT * from table1_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table1_n0
#### A masked pattern was here ####
1	100	true	5	23.4	700
PREHOOK: query: DROP TABLE table1_n0
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@table1_n0
PREHOOK: Output: database:default
PREHOOK: Output: default@table1_n0
POSTHOOK: query: DROP TABLE table1_n0
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@table1_n0
POSTHOOK: Output: database:default
POSTHOOK: Output: default@table1_n0
PREHOOK: query: CREATE TABLE table2_n0(i int CHECK (i + NULL > 0))
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@table2_n0
POSTHOOK: query: CREATE TABLE table2_n0(i int CHECK (i + NULL > 0))
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@table2_n0
PREHOOK: query: DESC FORMATTED table2_n0
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@table2_n0
POSTHOOK: query: DESC FORMATTED table2_n0
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@table2_n0
# col_name            	data_type           	comment             
i                   	int                 	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.table2_n0   	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:i       	Check Value:`i` + NULL > 0	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO table2_n0 values(8)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@table2_n0
POSTHOOK: query: EXPLAIN INSERT INTO table2_n0 values(8)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@table2_n0
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(8)) (type: array<struct<col1:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: int)
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint(((_col0 + null) > 0) is not false) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.table2_n0
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.table2_n0

PREHOOK: query: INSERT INTO table2_n0 values(8)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@table2_n0
POSTHOOK: query: INSERT INTO table2_n0 values(8)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@table2_n0
POSTHOOK: Lineage: table2_n0.i SCRIPT []
PREHOOK: query: select * from table2_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@table2_n0
#### A masked pattern was here ####
POSTHOOK: query: select * from table2_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table2_n0
#### A masked pattern was here ####
8
PREHOOK: query: Drop table table2_n0
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@table2_n0
PREHOOK: Output: database:default
PREHOOK: Output: default@table2_n0
POSTHOOK: query: Drop table table2_n0
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@table2_n0
POSTHOOK: Output: database:default
POSTHOOK: Output: default@table2_n0
PREHOOK: query: CREATE FUNCTION test_udf2 AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestGetJavaString'
PREHOOK: type: CREATEFUNCTION
PREHOOK: Input: database:default
PREHOOK: Output: default.test_udf2
POSTHOOK: query: CREATE FUNCTION test_udf2 AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestGetJavaString'
POSTHOOK: type: CREATEFUNCTION
POSTHOOK: Input: database:default
POSTHOOK: Output: default.test_udf2
PREHOOK: query: CREATE TABLE tudf(v string CHECK (test_udf2(v) <> 'vin'))
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tudf
POSTHOOK: query: CREATE TABLE tudf(v string CHECK (test_udf2(v) <> 'vin'))
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tudf
PREHOOK: query: EXPLAIN INSERT INTO tudf values('function1')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tudf
POSTHOOK: query: EXPLAIN INSERT INTO tudf values('function1')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tudf
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('function1')) (type: array<struct<col1:string>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string)
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((GenericUDFTestGetJavaString(_col0) <> 'vin') is not false) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.tudf
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tudf

PREHOOK: query: Drop table tudf
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tudf
PREHOOK: Output: database:default
PREHOOK: Output: default@tudf
POSTHOOK: query: Drop table tudf
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tudf
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tudf
PREHOOK: query: create table tmulti(url string NOT NULL ENABLE, userName string, numClicks int CHECK (numClicks > 0), d date)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tmulti
POSTHOOK: query: create table tmulti(url string NOT NULL ENABLE, userName string, numClicks int CHECK (numClicks > 0), d date)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tmulti
PREHOOK: query: explain alter table tmulti add constraint un1 UNIQUE (userName, numClicks) DISABLE
PREHOOK: type: ALTERTABLE_ADDCONSTRAINT
PREHOOK: Input: default@tmulti
PREHOOK: Output: default@tmulti
POSTHOOK: query: explain alter table tmulti add constraint un1 UNIQUE (userName, numClicks) DISABLE
POSTHOOK: type: ALTERTABLE_ADDCONSTRAINT
POSTHOOK: Input: default@tmulti
POSTHOOK: Output: default@tmulti
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Add Constraint
      table name: default.tmulti

PREHOOK: query: alter table tmulti add constraint un1 UNIQUE (userName, numClicks) DISABLE
PREHOOK: type: ALTERTABLE_ADDCONSTRAINT
PREHOOK: Input: default@tmulti
PREHOOK: Output: default@tmulti
POSTHOOK: query: alter table tmulti add constraint un1 UNIQUE (userName, numClicks) DISABLE
POSTHOOK: type: ALTERTABLE_ADDCONSTRAINT
POSTHOOK: Input: default@tmulti
POSTHOOK: Output: default@tmulti
PREHOOK: query: DESC formatted tmulti
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tmulti
POSTHOOK: query: DESC formatted tmulti
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tmulti
# col_name            	data_type           	comment             
url                 	string              	                    
username            	string              	                    
numclicks           	int                 	                    
d                   	date                	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Unique Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	un1                 	 
Column Name:username	Key Sequence:1      	 
Column Name:numclicks	Key Sequence:2      	 
	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	url                 	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:numclicks	Check Value:`numClicks` > 0	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '2018-01-12')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tmulti
POSTHOOK: query: EXPLAIN INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '2018-01-12')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tmulti
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('hive.apache.com','user1',48,'2018-01-12')) (type: array<struct<col1:string,col2:string,col3:int,col4:string>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: string), col3 (type: int), col4 (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col0 is not null and (_col2 > 0) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), CAST( _col3 AS DATE) (type: date)
                            outputColumnNames: _col0, _col1, _col2, _col3
                            Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                            File Output Operator
                              compressed: false
                              Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                              table:
                                  input format: org.apache.hadoop.mapred.TextInputFormat
                                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                  name: default.tmulti
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tmulti

PREHOOK: query: INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '2018-01-12')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tmulti
POSTHOOK: query: INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '2018-01-12')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tmulti
POSTHOOK: Lineage: tmulti.d SCRIPT []
POSTHOOK: Lineage: tmulti.numclicks SCRIPT []
POSTHOOK: Lineage: tmulti.url SCRIPT []
POSTHOOK: Lineage: tmulti.username SCRIPT []
PREHOOK: query: Select * from tmulti
PREHOOK: type: QUERY
PREHOOK: Input: default@tmulti
#### A masked pattern was here ####
POSTHOOK: query: Select * from tmulti
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tmulti
#### A masked pattern was here ####
hive.apache.com	user1	48	2018-01-12
PREHOOK: query: truncate table tmulti
PREHOOK: type: TRUNCATETABLE
PREHOOK: Output: default@tmulti
POSTHOOK: query: truncate table tmulti
POSTHOOK: type: TRUNCATETABLE
POSTHOOK: Output: default@tmulti
PREHOOK: query: alter table tmulti add constraint chk1 CHECK (userName != NULL)
PREHOOK: type: ALTERTABLE_ADDCONSTRAINT
PREHOOK: Input: default@tmulti
PREHOOK: Output: default@tmulti
POSTHOOK: query: alter table tmulti add constraint chk1 CHECK (userName != NULL)
POSTHOOK: type: ALTERTABLE_ADDCONSTRAINT
POSTHOOK: Input: default@tmulti
POSTHOOK: Output: default@tmulti
PREHOOK: query: alter table tmulti add constraint chk2 CHECK (numClicks <= 10000 AND userName != '')
PREHOOK: type: ALTERTABLE_ADDCONSTRAINT
PREHOOK: Input: default@tmulti
PREHOOK: Output: default@tmulti
POSTHOOK: query: alter table tmulti add constraint chk2 CHECK (numClicks <= 10000 AND userName != '')
POSTHOOK: type: ALTERTABLE_ADDCONSTRAINT
POSTHOOK: Input: default@tmulti
POSTHOOK: Output: default@tmulti
PREHOOK: query: DESC formatted tmulti
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tmulti
POSTHOOK: query: DESC formatted tmulti
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tmulti
# col_name            	data_type           	comment             
url                 	string              	                    
username            	string              	                    
numclicks           	int                 	                    
d                   	date                	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\"}
	bucketing_version   	2                   
	numFiles            	0                   
	totalSize           	0                   
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Unique Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	un1                 	 
Column Name:username	Key Sequence:1      	 
Column Name:numclicks	Key Sequence:2      	 
	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	url                 	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	chk1                	 
Column Name:null    	Check Value:`userName` != NULL	 
	 	 
Constraint Name:    	chk2                	 
Column Name:null    	Check Value:`numClicks` <= 10000 AND `userName` != ''	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:numclicks	Check Value:`numClicks` > 0	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '2018-01-12')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tmulti
POSTHOOK: query: EXPLAIN INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '2018-01-12')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tmulti
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('hive.apache.com','user1',48,'2018-01-12')) (type: array<struct<col1:string,col2:string,col3:int,col4:string>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: string), col3 (type: int), col4 (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col0 is not null and (((_col2 > 0) is not false and (_col1 <> null) is not false) and ((_col2 <= 10000) and (_col1 <> '')) is not false))) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), CAST( _col3 AS DATE) (type: date)
                            outputColumnNames: _col0, _col1, _col2, _col3
                            Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                            File Output Operator
                              compressed: false
                              Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                              table:
                                  input format: org.apache.hadoop.mapred.TextInputFormat
                                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                  name: default.tmulti
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tmulti

PREHOOK: query: INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '2018-01-12')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tmulti
POSTHOOK: query: INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '2018-01-12')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tmulti
POSTHOOK: Lineage: tmulti.d SCRIPT []
POSTHOOK: Lineage: tmulti.numclicks SCRIPT []
POSTHOOK: Lineage: tmulti.url SCRIPT []
POSTHOOK: Lineage: tmulti.username SCRIPT []
PREHOOK: query: Select * from tmulti
PREHOOK: type: QUERY
PREHOOK: Input: default@tmulti
#### A masked pattern was here ####
POSTHOOK: query: Select * from tmulti
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tmulti
#### A masked pattern was here ####
hive.apache.com	user1	48	2018-01-12
PREHOOK: query: Drop table tmulti
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tmulti
PREHOOK: Output: database:default
PREHOOK: Output: default@tmulti
POSTHOOK: query: Drop table tmulti
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tmulti
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tmulti
PREHOOK: query: create table tcase(url string NOT NULL ENABLE, userName string, d date, numClicks int CHECK (numclicks > 0))
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tcase
POSTHOOK: query: create table tcase(url string NOT NULL ENABLE, userName string, d date, numClicks int CHECK (numclicks > 0))
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tcase
PREHOOK: query: DESC formatted tcase
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tcase
POSTHOOK: query: DESC formatted tcase
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tcase
# col_name            	data_type           	comment             
url                 	string              	                    
username            	string              	                    
d                   	date                	                    
numclicks           	int                 	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.tcase       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	url                 	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tcase       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:numclicks	Check Value:`numclicks` > 0	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO tcase values('hive.apache.com', 'user1', '2018-01-12', 48)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcase
POSTHOOK: query: EXPLAIN INSERT INTO tcase values('hive.apache.com', 'user1', '2018-01-12', 48)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcase
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('hive.apache.com','user1','2018-01-12',48)) (type: array<struct<col1:string,col2:string,col3:string,col4:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: string), col3 (type: string), col4 (type: int)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col0 is not null and (_col3 > 0) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: string), CAST( _col2 AS DATE) (type: date), _col3 (type: int)
                            outputColumnNames: _col0, _col1, _col2, _col3
                            Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                            File Output Operator
                              compressed: false
                              Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                              table:
                                  input format: org.apache.hadoop.mapred.TextInputFormat
                                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                  name: default.tcase
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tcase

PREHOOK: query: INSERT INTO tcase values('hive.apache.com', 'user1', '2018-01-12', 48)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcase
POSTHOOK: query: INSERT INTO tcase values('hive.apache.com', 'user1', '2018-01-12', 48)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcase
POSTHOOK: Lineage: tcase.d SCRIPT []
POSTHOOK: Lineage: tcase.numclicks SCRIPT []
POSTHOOK: Lineage: tcase.url SCRIPT []
POSTHOOK: Lineage: tcase.username SCRIPT []
PREHOOK: query: Select * from tcase
PREHOOK: type: QUERY
PREHOOK: Input: default@tcase
#### A masked pattern was here ####
POSTHOOK: query: Select * from tcase
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tcase
#### A masked pattern was here ####
hive.apache.com	user1	2018-01-12	48
PREHOOK: query: Drop table tcase
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tcase
PREHOOK: Output: database:default
PREHOOK: Output: default@tcase
POSTHOOK: query: Drop table tcase
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tcase
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tcase
PREHOOK: query: create table tcast(url string NOT NULL ENABLE, numClicks int,
    price FLOAT CHECK (cast(numClicks as FLOAT)*price > 10.00))
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tcast
POSTHOOK: query: create table tcast(url string NOT NULL ENABLE, numClicks int,
    price FLOAT CHECK (cast(numClicks as FLOAT)*price > 10.00))
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tcast
PREHOOK: query: DESC FORMATTED tcast
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tcast
POSTHOOK: query: DESC FORMATTED tcast
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tcast
# col_name            	data_type           	comment             
url                 	string              	                    
numclicks           	int                 	                    
price               	float               	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.tcast       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	url                 	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tcast       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:price   	Check Value:cast(`numClicks` as FLOAT)*`price` > 10.00	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO tcast values('www.google.com', 100, cast(0.5 as float))
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcast
POSTHOOK: query: EXPLAIN INSERT INTO tcast values('www.google.com', 100, cast(0.5 as float))
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcast
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('www.google.com',100,0.5)) (type: array<struct<col1:string,col2:int,col3:float>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int), col3 (type: float)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col0 is not null and ((UDFToFloat(_col1) * _col2) > 10) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.tcast
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tcast

PREHOOK: query: INSERT INTO tcast values('www.google.com', 100, cast(0.5 as float))
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcast
POSTHOOK: query: INSERT INTO tcast values('www.google.com', 100, cast(0.5 as float))
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcast
POSTHOOK: Lineage: tcast.numclicks SCRIPT []
POSTHOOK: Lineage: tcast.price SCRIPT []
POSTHOOK: Lineage: tcast.url SCRIPT []
PREHOOK: query: SELECT * from tcast
PREHOOK: type: QUERY
PREHOOK: Input: default@tcast
#### A masked pattern was here ####
POSTHOOK: query: SELECT * from tcast
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tcast
#### A masked pattern was here ####
www.google.com	100	0.5
PREHOOK: query: EXPLAIN INSERT INTO tcast(url, price) values('www.yahoo.com', 0.5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcast
POSTHOOK: query: EXPLAIN INSERT INTO tcast(url, price) values('www.yahoo.com', 0.5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcast
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('www.yahoo.com',0.5)) (type: array<struct<col1:string,col2:decimal(1,1)>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), null (type: int), col2 (type: decimal(1,1))
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col0 is not null and ((UDFToFloat(null) * _col2) > 10) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: int), UDFToFloat(_col2) (type: float)
                            outputColumnNames: _col0, _col1, _col2
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            File Output Operator
                              compressed: false
                              Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                              table:
                                  input format: org.apache.hadoop.mapred.TextInputFormat
                                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                  name: default.tcast
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tcast

PREHOOK: query: INSERT INTO tcast(url, price) values('www.yahoo.com', 0.5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcast
POSTHOOK: query: INSERT INTO tcast(url, price) values('www.yahoo.com', 0.5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcast
POSTHOOK: Lineage: tcast.numclicks SIMPLE []
POSTHOOK: Lineage: tcast.price SCRIPT []
POSTHOOK: Lineage: tcast.url SCRIPT []
PREHOOK: query: SELECT * FROM tcast
PREHOOK: type: QUERY
PREHOOK: Input: default@tcast
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM tcast
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tcast
#### A masked pattern was here ####
www.google.com	100	0.5
www.yahoo.com	NULL	0.5
PREHOOK: query: DROP TABLE tcast
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tcast
PREHOOK: Output: database:default
PREHOOK: Output: default@tcast
POSTHOOK: query: DROP TABLE tcast
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tcast
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tcast
PREHOOK: query: create table texpr(i int DEFAULT 89, f float NOT NULL ENABLE, d decimal(4,1),
    b boolean CHECK (((cast(d as float) + f) < cast(i as float) + (i*i))))
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@texpr
POSTHOOK: query: create table texpr(i int DEFAULT 89, f float NOT NULL ENABLE, d decimal(4,1),
    b boolean CHECK (((cast(d as float) + f) < cast(i as float) + (i*i))))
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@texpr
PREHOOK: query: DESC FORMATTED texpr
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@texpr
POSTHOOK: query: DESC FORMATTED texpr
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@texpr
# col_name            	data_type           	comment             
i                   	int                 	                    
f                   	float               	                    
d                   	decimal(4,1)        	                    
b                   	boolean             	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.texpr       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	f                   	 
	 	 
	 	 
# Default Constraints	 	 
Table:              	default.texpr       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:i       	Default Value:89    	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.texpr       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:b       	Check Value:((cast(`d` as float) + `f`) < cast(`i` as float) + (`i`*`i`))	 
	 	 
PREHOOK: query: explain insert into texpr values(3,3.4,5.6,true)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@texpr
POSTHOOK: query: explain insert into texpr values(3,3.4,5.6,true)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@texpr
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(3,3.4,5.6,true)) (type: array<struct<col1:int,col2:decimal(2,1),col3:decimal(2,1),col4:boolean>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: int), col2 (type: decimal(2,1)), col3 (type: decimal(2,1)), col4 (type: boolean)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col1 is not null and ((UDFToFloat(_col2) + _col1) < (UDFToFloat(_col0) + (_col0 * _col0))) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: int), UDFToFloat(_col1) (type: float), CAST( _col2 AS decimal(4,1)) (type: decimal(4,1)), _col3 (type: boolean)
                            outputColumnNames: _col0, _col1, _col2, _col3
                            Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: COMPLETE
                            File Output Operator
                              compressed: false
                              Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: COMPLETE
                              table:
                                  input format: org.apache.hadoop.mapred.TextInputFormat
                                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                  name: default.texpr
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.texpr

PREHOOK: query: insert into texpr values(3,3.4,5.6,true)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@texpr
POSTHOOK: query: insert into texpr values(3,3.4,5.6,true)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@texpr
POSTHOOK: Lineage: texpr.b SCRIPT []
POSTHOOK: Lineage: texpr.d SCRIPT []
POSTHOOK: Lineage: texpr.f SCRIPT []
POSTHOOK: Lineage: texpr.i SCRIPT []
PREHOOK: query: SELECT * from texpr
PREHOOK: type: QUERY
PREHOOK: Input: default@texpr
#### A masked pattern was here ####
POSTHOOK: query: SELECT * from texpr
POSTHOOK: type: QUERY
POSTHOOK: Input: default@texpr
#### A masked pattern was here ####
3	3.4	5.6	true
PREHOOK: query: DROP TABLE texpr
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@texpr
PREHOOK: Output: database:default
PREHOOK: Output: default@texpr
POSTHOOK: query: DROP TABLE texpr
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@texpr
POSTHOOK: Output: database:default
POSTHOOK: Output: default@texpr
PREHOOK: query: create table acid_uami_n0(i int,
                 de decimal(5,2) constraint nn1 not null enforced,
                 vc varchar(128) constraint ch2 CHECK (de >= cast(i as decimal(5,2))) enforced)
                 clustered by (i) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: create table acid_uami_n0(i int,
                 de decimal(5,2) constraint nn1 not null enforced,
                 vc varchar(128) constraint ch2 CHECK (de >= cast(i as decimal(5,2))) enforced)
                 clustered by (i) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@acid_uami_n0
PREHOOK: query: DESC FORMATTED acid_uami_n0
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@acid_uami_n0
POSTHOOK: query: DESC FORMATTED acid_uami_n0
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@acid_uami_n0
# col_name            	data_type           	comment             
i                   	int                 	                    
de                  	decimal(5,2)        	                    
vc                  	varchar(128)        	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[i]                 	 
Sort Columns:       	[]                  	 
	 	 
# Constraints	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.acid_uami_n0	 
Constraint Name:    	nn1                 	 
Column Name:        	de                  	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.acid_uami_n0	 
Constraint Name:    	ch2                 	 
Column Name:vc      	Check Value:`de` >= cast(`i` as decimal(5,2))	 
	 	 
PREHOOK: query: explain insert into table acid_uami_n0 select cast(key as int), cast (key as decimal(5,2)), value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: explain insert into table acid_uami_n0 select cast(key as int), cast (key as decimal(5,2)), value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami_n0
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: UDFToInteger(key) (type: int), CAST( key AS decimal(5,2)) (type: decimal(5,2)), value (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 500 Data size: 103500 Basic stats: COMPLETE Column stats: COMPLETE
                    Filter Operator
                      predicate: enforce_constraint((_col1 is not null and (_col1 >= CAST( _col0 AS decimal(5,2))) is not false)) (type: boolean)
                      Statistics: Num rows: 250 Data size: 51750 Basic stats: COMPLETE Column stats: COMPLETE
                      Select Operator
                        expressions: _col0 (type: int), _col1 (type: decimal(5,2)), CAST( _col2 AS varchar(128)) (type: varchar(128))
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 250 Data size: 82000 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 250 Data size: 82000 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: decimal(5,2)), _col2 (type: varchar(128))
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: decimal(5,2)), VALUE._col1 (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 250 Data size: 82000 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 250 Data size: 82000 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami_n0
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami_n0
          Write Type: INSERT

PREHOOK: query: insert into table acid_uami_n0 select cast(key as int), cast (key as decimal(5,2)), value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: insert into table acid_uami_n0 select cast(key as int), cast (key as decimal(5,2)), value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Lineage: acid_uami_n0.de EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami_n0.i EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami_n0.vc EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain insert overwrite table acid_uami_n0 select cast(key as int), cast (key as decimal(5,2)), value
    from src order by cast(key as int) limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: explain insert overwrite table acid_uami_n0 select cast(key as int), cast (key as decimal(5,2)), value
    from src order by cast(key as int) limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami_n0
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Top N Key Operator
                    sort order: +
                    keys: UDFToInteger(key) (type: int)
                    null sort order: z
                    Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                    top n: 10
                    Select Operator
                      expressions: UDFToInteger(key) (type: int), CAST( key AS decimal(5,2)) (type: decimal(5,2)), value (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 500 Data size: 103500 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: z
                        sort order: +
                        Statistics: Num rows: 500 Data size: 103500 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: decimal(5,2)), _col2 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: decimal(5,2)), VALUE._col1 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 500 Data size: 103500 Basic stats: COMPLETE Column stats: COMPLETE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 2070 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: enforce_constraint((_col1 is not null and (_col1 >= CAST( _col0 AS decimal(5,2))) is not false)) (type: boolean)
                    Statistics: Num rows: 5 Data size: 1035 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: decimal(5,2)), CAST( _col2 AS varchar(128)) (type: varchar(128))
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: decimal(5,2)), _col2 (type: varchar(128))
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: decimal(5,2)), VALUE._col1 (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami_n0
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami_n0
          Write Type: INSERT

PREHOOK: query: insert overwrite table acid_uami_n0 select cast(key as int), cast (key as decimal(5,2)), value
    from src order by cast(key as int) limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: insert overwrite table acid_uami_n0 select cast(key as int), cast (key as decimal(5,2)), value
    from src order by cast(key as int) limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Lineage: acid_uami_n0.de EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami_n0.i EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami_n0.vc EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain insert into table acid_uami_n0 select cast(s1.key as int) as c1, cast (s2.key as decimal(5,2)) as c2, s1.value from src s1
    left outer join src s2 on s1.key=s2.key where s1.value > 'val' limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: explain insert into table acid_uami_n0 select cast(s1.key as int) as c1, cast (s2.key as decimal(5,2)) as c2, s1.value from src s1
    left outer join src s2 on s1.key=s2.key where s1.value > 'val' limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami_n0
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: s1
                  filterExpr: (value > 'val') (type: boolean)
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (value > 'val') (type: boolean)
                    Statistics: Num rows: 166 Data size: 29548 Basic stats: COMPLETE Column stats: COMPLETE
                    Limit
                      Number of rows: 10
                      Statistics: Num rows: 10 Data size: 1780 Basic stats: COMPLETE Column stats: COMPLETE
                      Select Operator
                        expressions: key (type: string), value (type: string), UDFToInteger(key) (type: int)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 10 Data size: 1820 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: string)
                          Statistics: Num rows: 10 Data size: 1820 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: string), _col2 (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: s2
                  filterExpr: key is not null (type: boolean)
                  Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: string), CAST( key AS decimal(5,2)) (type: decimal(5,2))
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 500 Data size: 99500 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 500 Data size: 99500 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: decimal(5,2))
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col0 (type: string)
                  1 _col0 (type: string)
                outputColumnNames: _col1, _col2, _col4
                Statistics: Num rows: 25 Data size: 4167 Basic stats: COMPLETE Column stats: COMPLETE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 1734 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col2 (type: int), _col4 (type: decimal(5,2)), _col1 (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 10 Data size: 1734 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      null sort order: 
                      sort order: 
                      Statistics: Num rows: 10 Data size: 1734 Basic stats: COMPLETE Column stats: COMPLETE
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col0 (type: int), _col1 (type: decimal(5,2)), _col2 (type: string)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Limit
                Number of rows: 10
                Statistics: Num rows: 10 Data size: 1734 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: VALUE._col0 (type: int), VALUE._col1 (type: decimal(5,2)), VALUE._col2 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 10 Data size: 1734 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: enforce_constraint((_col1 is not null and (_col1 >= CAST( _col0 AS decimal(5,2))) is not false)) (type: boolean)
                    Statistics: Num rows: 5 Data size: 923 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: decimal(5,2)), CAST( _col2 AS varchar(128)) (type: varchar(128))
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 5 Data size: 1528 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 5 Data size: 1528 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: decimal(5,2)), _col2 (type: varchar(128))
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: decimal(5,2)), VALUE._col1 (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 1528 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 5 Data size: 1528 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami_n0
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami_n0
          Write Type: INSERT

PREHOOK: query: insert into table acid_uami_n0 select cast(s1.key as int) as c1, cast (s2.key as decimal(5,2)) as c2, s1.value from src s1
    left outer join src s2 on s1.key=s2.key where s1.value > 'val' limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: insert into table acid_uami_n0 select cast(s1.key as int) as c1, cast (s2.key as decimal(5,2)) as c2, s1.value from src s1
    left outer join src s2 on s1.key=s2.key where s1.value > 'val' limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Lineage: acid_uami_n0.de EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami_n0.i EXPRESSION [(src)s1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami_n0.vc EXPRESSION [(src)s1.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: select * from acid_uami_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami_n0
#### A masked pattern was here ####
POSTHOOK: query: select * from acid_uami_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami_n0
#### A masked pattern was here ####
2	2.00	val_2
0	0.00	val_0
0	0.00	val_0
0	0.00	val_0
4	4.00	val_4
5	5.00	val_5
5	5.00	val_5
5	5.00	val_5
8	8.00	val_8
9	9.00	val_9
27	27.00	val_27
165	165.00	val_165
165	165.00	val_165
238	238.00	val_238
238	238.00	val_238
255	255.00	val_255
255	255.00	val_255
311	311.00	val_311
278	278.00	val_278
278	278.00	val_278
PREHOOK: query: truncate table acid_uami_n0
PREHOOK: type: TRUNCATETABLE
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: truncate table acid_uami_n0
POSTHOOK: type: TRUNCATETABLE
POSTHOOK: Output: default@acid_uami_n0
PREHOOK: query: explain insert into table acid_uami_n0 select min(cast(key as int)) as c1, max(cast (key as decimal(5,2))) as c2, value
    from src group by key, value order by key, value limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: explain insert into table acid_uami_n0 select min(cast(key as int)) as c1, max(cast (key as decimal(5,2))) as c2, value
    from src group by key, value order by key, value limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami_n0
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Top N Key Operator
                    sort order: ++
                    keys: key (type: string), value (type: string)
                    null sort order: zz
                    Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                    top n: 10
                    Select Operator
                      expressions: key (type: string), value (type: string), UDFToInteger(key) (type: int), CAST( key AS decimal(5,2)) (type: decimal(5,2))
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: min(_col2), max(_col3)
                        keys: _col0 (type: string), _col1 (type: string)
                        minReductionHashAggr: 0.4
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 316 Data size: 92904 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: string)
                          null sort order: zz
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                          Statistics: Num rows: 316 Data size: 92904 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col2 (type: int), _col3 (type: decimal(5,2))
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1)
                keys: KEY._col0 (type: string), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 316 Data size: 92904 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col2 (type: int), _col3 (type: decimal(5,2)), _col1 (type: string), _col0 (type: string)
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num rows: 316 Data size: 92904 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col3 (type: string), _col2 (type: string)
                    null sort order: zz
                    sort order: ++
                    Statistics: Num rows: 316 Data size: 92904 Basic stats: COMPLETE Column stats: COMPLETE
                    value expressions: _col0 (type: int), _col1 (type: decimal(5,2))
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: decimal(5,2)), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 316 Data size: 65412 Basic stats: COMPLETE Column stats: COMPLETE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 2070 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: enforce_constraint((_col1 is not null and (_col1 >= CAST( _col0 AS decimal(5,2))) is not false)) (type: boolean)
                    Statistics: Num rows: 5 Data size: 1035 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: decimal(5,2)), CAST( _col2 AS varchar(128)) (type: varchar(128))
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: decimal(5,2)), _col2 (type: varchar(128))
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: decimal(5,2)), VALUE._col1 (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami_n0
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami_n0
          Write Type: INSERT

PREHOOK: query: insert into table acid_uami_n0 select min(cast(key as int)) as c1, max(cast (key as decimal(5,2))) as c2, value
    from src group by key, value order by key, value limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: insert into table acid_uami_n0 select min(cast(key as int)) as c1, max(cast (key as decimal(5,2))) as c2, value
    from src group by key, value order by key, value limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Lineage: acid_uami_n0.de EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami_n0.i EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami_n0.vc EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: select * from acid_uami_n0
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami_n0
#### A masked pattern was here ####
POSTHOOK: query: select * from acid_uami_n0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami_n0
#### A masked pattern was here ####
10	10.00	val_10
105	105.00	val_105
113	113.00	val_113
0	0.00	val_0
11	11.00	val_11
100	100.00	val_100
103	103.00	val_103
104	104.00	val_104
111	111.00	val_111
114	114.00	val_114
PREHOOK: query: truncate table acid_uami_n0
PREHOOK: type: TRUNCATETABLE
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: truncate table acid_uami_n0
POSTHOOK: type: TRUNCATETABLE
POSTHOOK: Output: default@acid_uami_n0
PREHOOK: query: create table src_multi2_n0 (i STRING, j STRING NOT NULL ENABLE)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@src_multi2_n0
POSTHOOK: query: create table src_multi2_n0 (i STRING, j STRING NOT NULL ENABLE)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@src_multi2_n0
PREHOOK: query: explain
from src
insert into table acid_uami_n0 select cast(key as int), cast(key as decimal(5,2)), value where key < 10
insert overwrite table src_multi2_n0 select * where key > 10 and key < 20
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami_n0
PREHOOK: Output: default@src_multi2_n0
POSTHOOK: query: explain
from src
insert into table acid_uami_n0 select cast(key as int), cast(key as decimal(5,2)), value where key < 10
insert overwrite table src_multi2_n0 select * where key > 10 and key < 20
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Output: default@src_multi2_n0
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-3
  Stage-1 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-2
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((key < 10) and enforce_constraint((CAST( key AS decimal(5,2)) is not null and (CAST( key AS decimal(5,2)) >= CAST( UDFToInteger(key) AS decimal(5,2))) is not false))) (type: boolean)
                    Statistics: Num rows: 83 Data size: 14774 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: UDFToInteger(key) (type: int), CAST( key AS decimal(5,2)) (type: decimal(5,2)), CAST( value AS varchar(128)) (type: varchar(128))
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 83 Data size: 27224 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 83 Data size: 27224 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: decimal(5,2)), _col2 (type: varchar(128))
                  Filter Operator
                    predicate: ((key > 10) and (key < 20) and enforce_constraint(value is not null)) (type: boolean)
                    Statistics: Num rows: 27 Data size: 4806 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 27 Data size: 4806 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        Statistics: Num rows: 27 Data size: 4806 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.TextInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                            name: default.src_multi2_n0
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: decimal(5,2)), VALUE._col1 (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 83 Data size: 27224 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 83 Data size: 27224 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami_n0
                  Write Type: INSERT

  Stage: Stage-3
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami_n0
          Write Type: INSERT

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src_multi2_n0

PREHOOK: query: drop table src_multi2_n0
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src_multi2_n0
PREHOOK: Output: database:default
PREHOOK: Output: default@src_multi2_n0
POSTHOOK: query: drop table src_multi2_n0
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src_multi2_n0
POSTHOOK: Output: database:default
POSTHOOK: Output: default@src_multi2_n0
PREHOOK: query: select * from acid_uami_n0 order by de desc limit 15
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami_n0
#### A masked pattern was here ####
POSTHOOK: query: select * from acid_uami_n0 order by de desc limit 15
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami_n0
#### A masked pattern was here ####
PREHOOK: query: explain cbo update acid_uami_n0 set de = 893.14 where de = 103.00 or de = 119.00
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: explain cbo update acid_uami_n0 set de = 893.14 where de = 103.00 or de = 119.00
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
CBO PLAN:
HiveProject(row__id=[$5], i=[$0], de=[893.14:DECIMAL(5, 2)], vc=[$2])
  HiveFilter(condition=[IN($1, 103:DECIMAL(3, 0), 119:DECIMAL(3, 0))])
    HiveTableScan(table=[[default, acid_uami_n0]], table:alias=[acid_uami_n0])

PREHOOK: query: explain update acid_uami_n0 set de = 893.14 where de = 103.00 or de = 119.00
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: explain update acid_uami_n0 set de = 893.14 where de = 103.00 or de = 119.00
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-3
  Stage-1 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-2
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: acid_uami_n0
                  filterExpr: (de) IN (103, 119) (type: boolean)
                  Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (de) IN (103, 119) (type: boolean)
                    Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), i (type: int), vc (type: varchar(128))
                      outputColumnNames: _col0, _col1, _col3
                      Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                          Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: int), 893.14 (type: decimal(5,2)), _col3 (type: varchar(128))
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                        Filter Operator
                          predicate: enforce_constraint((_col1 is not null and (893.14 >= CAST( _col0 AS decimal(5,2))) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                          Reduce Output Operator
                            key expressions: _col0 (type: int)
                            null sort order: a
                            sort order: +
                            Map-reduce partition columns: _col0 (type: int)
                            Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                            value expressions: _col1 (type: decimal(5,2)), _col2 (type: varchar(128))
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami_n0
                  Write Type: DELETE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: decimal(5,2)), VALUE._col1 (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami_n0
                  Write Type: INSERT

  Stage: Stage-3
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami_n0
          Write Type: DELETE

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami_n0
          Write Type: INSERT

PREHOOK: query: update acid_uami_n0 set de = 893.14 where de = 103.00 or de = 119.00
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: update acid_uami_n0 set de = 893.14 where de = 103.00 or de = 119.00
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Lineage: acid_uami_n0.de SIMPLE []
POSTHOOK: Lineage: acid_uami_n0.i SIMPLE [(acid_uami_n0)acid_uami_n0.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: acid_uami_n0.vc SIMPLE [(acid_uami_n0)acid_uami_n0.FieldSchema(name:vc, type:varchar(128), comment:null), ]
PREHOOK: query: select * from acid_uami_n0 order by de desc limit 15
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami_n0
#### A masked pattern was here ####
POSTHOOK: query: select * from acid_uami_n0 order by de desc limit 15
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami_n0
#### A masked pattern was here ####
PREHOOK: query: explain ALTER table acid_uami_n0 drop constraint ch2
PREHOOK: type: ALTERTABLE_DROPCONSTRAINT
PREHOOK: Input: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: explain ALTER table acid_uami_n0 drop constraint ch2
POSTHOOK: type: ALTERTABLE_DROPCONSTRAINT
POSTHOOK: Input: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Drop Constraint
      constraint name: ch2
      table name: default.acid_uami_n0

PREHOOK: query: ALTER table acid_uami_n0 drop constraint ch2
PREHOOK: type: ALTERTABLE_DROPCONSTRAINT
PREHOOK: Input: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: ALTER table acid_uami_n0 drop constraint ch2
POSTHOOK: type: ALTERTABLE_DROPCONSTRAINT
POSTHOOK: Input: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
PREHOOK: query: explain update acid_uami_n0 set vc = 'apache_hive' where de = 893.14
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: explain update acid_uami_n0 set vc = 'apache_hive' where de = 893.14
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-3
  Stage-1 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-2
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: acid_uami_n0
                  filterExpr: (de = 893.14) (type: boolean)
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (de = 893.14) (type: boolean)
                    Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), i (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                          Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col1 (type: int), 893.14 (type: decimal(5,2)), 'apache_hive' (type: string)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                        Filter Operator
                          predicate: enforce_constraint(_col1 is not null) (type: boolean)
                          Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                          Select Operator
                            expressions: _col0 (type: int), _col1 (type: decimal(5,2)), CAST( _col2 AS varchar(128)) (type: varchar(128))
                            outputColumnNames: _col0, _col1, _col2
                            Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                            Reduce Output Operator
                              key expressions: _col0 (type: int)
                              null sort order: a
                              sort order: +
                              Map-reduce partition columns: _col0 (type: int)
                              Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                              value expressions: _col1 (type: decimal(5,2)), _col2 (type: varchar(128))
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami_n0
                  Write Type: DELETE
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: decimal(5,2)), VALUE._col1 (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami_n0
                  Write Type: INSERT

  Stage: Stage-3
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami_n0
          Write Type: DELETE

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami_n0
          Write Type: INSERT

PREHOOK: query: update acid_uami_n0 set vc = 'apache_hive' where de = 893.14
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: update acid_uami_n0 set vc = 'apache_hive' where de = 893.14
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Output: default@acid_uami_n0
POSTHOOK: Lineage: acid_uami_n0.de SIMPLE []
POSTHOOK: Lineage: acid_uami_n0.i SIMPLE [(acid_uami_n0)acid_uami_n0.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: acid_uami_n0.vc EXPRESSION []
PREHOOK: query: select * from acid_uami_n0 order by vc limit 15
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami_n0
#### A masked pattern was here ####
POSTHOOK: query: select * from acid_uami_n0 order by vc limit 15
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami_n0
#### A masked pattern was here ####
PREHOOK: query: DROP TABLE acid_uami_n0
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@acid_uami_n0
PREHOOK: Output: database:default
PREHOOK: Output: default@acid_uami_n0
POSTHOOK: query: DROP TABLE acid_uami_n0
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@acid_uami_n0
POSTHOOK: Output: database:default
POSTHOOK: Output: default@acid_uami_n0
PREHOOK: query: create table tmerge(key int CHECK (key > 0 AND (key < 100 OR key = 5)) enable, a1 string NOT NULL, value string)
clustered by (value) into 2 buckets stored as orc
tblproperties ("transactional"="true")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tmerge
POSTHOOK: query: create table tmerge(key int CHECK (key > 0 AND (key < 100 OR key = 5)) enable, a1 string NOT NULL, value string)
clustered by (value) into 2 buckets stored as orc
tblproperties ("transactional"="true")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tmerge
PREHOOK: query: DESC FORMATTED tmerge
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tmerge
POSTHOOK: query: DESC FORMATTED tmerge
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tmerge
# col_name            	data_type           	comment             
key                 	int                 	                    
a1                  	string              	                    
value               	string              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[value]             	 
Sort Columns:       	[]                  	 
	 	 
# Constraints	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.tmerge      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	a1                  	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tmerge      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:key     	Check Value:`key` > 0 AND (`key` < 100 OR `key` = 5)	 
	 	 
PREHOOK: query: create table nonacid (key int, a1 string, value string) stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@nonacid
POSTHOOK: query: create table nonacid (key int, a1 string, value string) stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@nonacid
PREHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN MATCHED AND s.key < 3 THEN UPDATE set a1 = '1'
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
PREHOOK: type: QUERY
PREHOOK: Input: default@nonacid
PREHOOK: Input: default@tmerge
PREHOOK: Output: default@tmerge
PREHOOK: Output: default@tmerge
POSTHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN MATCHED AND s.key < 3 THEN UPDATE set a1 = '1'
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nonacid
POSTHOOK: Input: default@tmerge
POSTHOOK: Output: default@tmerge
POSTHOOK: Output: default@tmerge
STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-5 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-5
  Stage-1 depends on stages: Stage-5
  Stage-2 depends on stages: Stage-5
  Stage-3 depends on stages: Stage-5

STAGE PLANS:
  Stage: Stage-4
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 7 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 6 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: s
                  Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: int), a1 (type: string), value (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: string), _col2 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Map 7 
            Map Operator Tree:
                TableScan
                  alias: tmerge
                  filterExpr: key is not null (type: boolean)
                  Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col1 (type: int)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col1 (type: int)
                        Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col2 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col1 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col1 (type: string), _col0 (type: int), _col5 (type: string), _col3 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col2 (type: string), _col4 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col5 = _col1) and (_col1 < 5)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col3 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col5 = _col1) and (_col1 < 3) and (_col1 >= 5)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col3 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col5 = _col1) and (_col1 < 3) and (_col1 >= 5)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col5 (type: int), _col2 (type: string)
                      outputColumnNames: _col0, _col2
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Filter Operator
                        predicate: enforce_constraint(((_col0 > 0) and ((_col0 < 100) or (_col0 = 5))) is not false) (type: boolean)
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col2 (type: string)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col2 (type: string)
                          Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col0 (type: int)
                  Filter Operator
                    predicate: _col5 is null (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col1 (type: int), _col0 (type: string), _col4 (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Filter Operator
                        predicate: enforce_constraint((_col1 is not null and ((_col0 > 0) and ((_col0 < 100) or (_col0 = 5))) is not false)) (type: boolean)
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col2 (type: string)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col2 (type: string)
                          Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col0 (type: int), _col1 (type: string)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: DELETE
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: DELETE
        Reducer 5 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), '1' (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: INSERT
        Reducer 6 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: INSERT

  Stage: Stage-5
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: DELETE

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: DELETE

  Stage: Stage-2
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: INSERT

  Stage: Stage-3
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: INSERT

PREHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN MATCHED AND s.key < 3 THEN UPDATE set a1 = '1'
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
PREHOOK: type: QUERY
PREHOOK: Input: default@nonacid
PREHOOK: Input: default@tmerge
PREHOOK: Output: default@merge_tmp_table
PREHOOK: Output: default@tmerge
PREHOOK: Output: default@tmerge
POSTHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN MATCHED AND s.key < 3 THEN UPDATE set a1 = '1'
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nonacid
POSTHOOK: Input: default@tmerge
POSTHOOK: Output: default@merge_tmp_table
POSTHOOK: Output: default@tmerge
POSTHOOK: Output: default@tmerge
STAGE DEPENDENCIES:
  Stage-5 is a root stage
  Stage-6 depends on stages: Stage-5
  Stage-0 depends on stages: Stage-6
  Stage-1 depends on stages: Stage-6
  Stage-2 depends on stages: Stage-6
  Stage-3 depends on stages: Stage-6
  Stage-4 depends on stages: Stage-6

STAGE PLANS:
  Stage: Stage-5
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 6 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 7 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: s
                  Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: int), a1 (type: string), value (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: string), _col2 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Map 8 
            Map Operator Tree:
                TableScan
                  alias: tmerge
                  filterExpr: key is not null (type: boolean)
                  Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col1 (type: int)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col1 (type: int)
                        Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col2 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col1 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col1 (type: string), _col0 (type: int), _col5 (type: string), _col3 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col2 (type: string), _col4 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col5 = _col1) and (_col1 < 5)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col3 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col5 = _col1) and (_col1 < 3) and (_col1 >= 5)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col3 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col5 = _col1) and (_col1 < 3) and (_col1 >= 5)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col5 (type: int), _col2 (type: string)
                      outputColumnNames: _col0, _col2
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Filter Operator
                        predicate: enforce_constraint(((_col0 > 0) and ((_col0 < 100) or (_col0 = 5))) is not false) (type: boolean)
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col2 (type: string)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col2 (type: string)
                          Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col0 (type: int)
                  Filter Operator
                    predicate: _col5 is null (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col1 (type: int), _col0 (type: string), _col4 (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Filter Operator
                        predicate: enforce_constraint((_col1 is not null and ((_col0 > 0) and ((_col0 < 100) or (_col0 = 5))) is not false)) (type: boolean)
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col2 (type: string)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col2 (type: string)
                          Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col0 (type: int), _col1 (type: string)
                  Filter Operator
                    predicate: (_col5 = _col1) (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col3 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col3
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: count()
                        keys: _col3 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        minReductionHashAggr: 0.99
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                          Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: bigint)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: DELETE
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: DELETE
        Reducer 5 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), '1' (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: INSERT
        Reducer 6 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: INSERT
        Reducer 7 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: (_col1 > 1L) (type: boolean)
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: cardinality_violation(_col0) (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.merge_tmp_table

  Stage: Stage-6
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: DELETE

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: DELETE

  Stage: Stage-2
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: INSERT

  Stage: Stage-3
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: INSERT

  Stage: Stage-4
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.merge_tmp_table

PREHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
PREHOOK: type: QUERY
PREHOOK: Input: default@nonacid
PREHOOK: Input: default@tmerge
PREHOOK: Output: default@merge_tmp_table
PREHOOK: Output: default@tmerge
PREHOOK: Output: default@tmerge
POSTHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nonacid
POSTHOOK: Input: default@tmerge
POSTHOOK: Output: default@merge_tmp_table
POSTHOOK: Output: default@tmerge
POSTHOOK: Output: default@tmerge
STAGE DEPENDENCIES:
  Stage-3 is a root stage
  Stage-4 depends on stages: Stage-3
  Stage-0 depends on stages: Stage-4
  Stage-1 depends on stages: Stage-4
  Stage-2 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-3
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 6 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: s
                  Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: int), a1 (type: string), value (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: string), _col2 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: tmerge
                  filterExpr: key is not null (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), key (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col1 (type: int)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col1 (type: int)
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col1 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col1 (type: string), _col0 (type: int), _col3 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col2 (type: string), _col4 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col4 = _col1) and (_col1 < 5)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col2 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: _col4 is null (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col1 (type: int), _col0 (type: string), _col3 (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Filter Operator
                        predicate: enforce_constraint((_col1 is not null and ((_col0 > 0) and ((_col0 < 100) or (_col0 = 5))) is not false)) (type: boolean)
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col2 (type: string)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col2 (type: string)
                          Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col0 (type: int), _col1 (type: string)
                  Filter Operator
                    predicate: (_col4 = _col1) (type: boolean)
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col2 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col2
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: count()
                        keys: _col2 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        minReductionHashAggr: 0.99
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                          Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: bigint)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: DELETE
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: INSERT
        Reducer 5 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: (_col1 > 1L) (type: boolean)
                  Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: cardinality_violation(_col0) (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1 Data size: 409 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.merge_tmp_table

  Stage: Stage-4
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: DELETE

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: INSERT

  Stage: Stage-2
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.merge_tmp_table

PREHOOK: query: DROP TABLE tmerge
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tmerge
PREHOOK: Output: database:default
PREHOOK: Output: default@tmerge
POSTHOOK: query: DROP TABLE tmerge
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tmerge
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tmerge
PREHOOK: query: DROP TABLE nonacid
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@nonacid
PREHOOK: Output: database:default
PREHOOK: Output: default@nonacid
POSTHOOK: query: DROP TABLE nonacid
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@nonacid
POSTHOOK: Output: database:default
POSTHOOK: Output: default@nonacid
PREHOOK: query: CREATE TABLE numericDataType(a TINYINT CONSTRAINT tinyint_constraint DEFAULT 127Y ENABLE,
    b bigint CONSTRAINT check1 CHECK (b in(4,5)) ENABLE)
    clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@numericDataType
POSTHOOK: query: CREATE TABLE numericDataType(a TINYINT CONSTRAINT tinyint_constraint DEFAULT 127Y ENABLE,
    b bigint CONSTRAINT check1 CHECK (b in(4,5)) ENABLE)
    clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@numericDataType
PREHOOK: query: DESC FORMATTED numericDataType
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@numericdatatype
POSTHOOK: query: DESC FORMATTED numericDataType
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@numericdatatype
# col_name            	data_type           	comment             
a                   	tinyint             	                    
b                   	bigint              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[b]                 	 
Sort Columns:       	[]                  	 
	 	 
# Constraints	 	 
	 	 
# Default Constraints	 	 
Table:              	default.numericdatatype	 
Constraint Name:    	tinyint_constraint  	 
Column Name:a       	Default Value:127Y  	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.numericdatatype	 
Constraint Name:    	check1              	 
Column Name:b       	Check Value:`b` in(4,5)	 
	 	 
PREHOOK: query: ALTER TABLE numericDataType DROP CONSTRAINT check1
PREHOOK: type: ALTERTABLE_DROPCONSTRAINT
PREHOOK: Input: default@numericdatatype
PREHOOK: Output: default@numericdatatype
POSTHOOK: query: ALTER TABLE numericDataType DROP CONSTRAINT check1
POSTHOOK: type: ALTERTABLE_DROPCONSTRAINT
POSTHOOK: Input: default@numericdatatype
POSTHOOK: Output: default@numericdatatype
PREHOOK: query: DESC FORMATTED numericDataType
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@numericdatatype
POSTHOOK: query: DESC FORMATTED numericDataType
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@numericdatatype
# col_name            	data_type           	comment             
a                   	tinyint             	                    
b                   	bigint              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[b]                 	 
Sort Columns:       	[]                  	 
	 	 
# Constraints	 	 
	 	 
# Default Constraints	 	 
Table:              	default.numericdatatype	 
Constraint Name:    	tinyint_constraint  	 
Column Name:a       	Default Value:127Y  	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO numericDataType(b) values(456)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@numericdatatype
POSTHOOK: query: EXPLAIN INSERT INTO numericDataType(b) values(456)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@numericdatatype
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(456)) (type: array<struct<col1:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: 127Y (type: tinyint), UDFToLong(col1) (type: bigint)
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col1 (type: bigint)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col1 (type: bigint)
                          Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: tinyint)
            Execution mode: llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: tinyint), KEY.reducesinkkey0 (type: bigint)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.numericdatatype
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.numericdatatype
          Write Type: INSERT

PREHOOK: query: INSERT INTO numericDataType(b) values(456)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@numericdatatype
POSTHOOK: query: INSERT INTO numericDataType(b) values(456)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@numericdatatype
POSTHOOK: Lineage: numericdatatype.a SIMPLE []
POSTHOOK: Lineage: numericdatatype.b SCRIPT []
PREHOOK: query: SELECT * from numericDataType
PREHOOK: type: QUERY
PREHOOK: Input: default@numericdatatype
#### A masked pattern was here ####
POSTHOOK: query: SELECT * from numericDataType
POSTHOOK: type: QUERY
POSTHOOK: Input: default@numericdatatype
#### A masked pattern was here ####
127	456
PREHOOK: query: DROP TABLE numericDataType
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@numericdatatype
PREHOOK: Output: database:default
PREHOOK: Output: default@numericdatatype
POSTHOOK: query: DROP TABLE numericDataType
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@numericdatatype
POSTHOOK: Output: database:default
POSTHOOK: Output: default@numericdatatype
PREHOOK: query: CREATE TABLE tcheck(a TINYINT, b bigint CONSTRAINT check1 CHECK (b in(4,5)) ENABLE)
    clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tcheck
POSTHOOK: query: CREATE TABLE tcheck(a TINYINT, b bigint CONSTRAINT check1 CHECK (b in(4,5)) ENABLE)
    clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tcheck
PREHOOK: query: DESC FORMATTED tcheck
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tcheck
POSTHOOK: query: DESC FORMATTED tcheck
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tcheck
# col_name            	data_type           	comment             
a                   	tinyint             	                    
b                   	bigint              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[b]                 	 
Sort Columns:       	[]                  	 
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tcheck      	 
Constraint Name:    	check1              	 
Column Name:b       	Check Value:`b` in(4,5)	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO tcheck(a) values(1)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcheck
POSTHOOK: query: EXPLAIN INSERT INTO tcheck(a) values(1)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcheck
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(1)) (type: array<struct<col1:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: int), null (type: bigint)
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((null) IN (4, 5) is not false) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: UDFToByte(_col0) (type: tinyint), _col1 (type: bigint)
                            outputColumnNames: _col0, _col1
                            Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              key expressions: _col1 (type: bigint)
                              null sort order: a
                              sort order: +
                              Map-reduce partition columns: _col1 (type: bigint)
                              Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: tinyint)
            Execution mode: llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: tinyint), KEY.reducesinkkey0 (type: bigint)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tcheck
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tcheck
          Write Type: INSERT

PREHOOK: query: EXPLAIN INSERT INTO tcheck(b) values(4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcheck
POSTHOOK: query: EXPLAIN INSERT INTO tcheck(b) values(4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcheck
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(4)) (type: array<struct<col1:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: null (type: tinyint), col1 (type: int)
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col1) IN (4, 5) is not false) (type: boolean)
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: tinyint), UDFToLong(_col1) (type: bigint)
                            outputColumnNames: _col0, _col1
                            Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                            Reduce Output Operator
                              key expressions: _col1 (type: bigint)
                              null sort order: a
                              sort order: +
                              Map-reduce partition columns: _col1 (type: bigint)
                              Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                              value expressions: _col0 (type: tinyint)
            Execution mode: llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: tinyint), KEY.reducesinkkey0 (type: bigint)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tcheck
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tcheck
          Write Type: INSERT

PREHOOK: query: INSERT INTO tcheck(b) values(4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcheck
POSTHOOK: query: INSERT INTO tcheck(b) values(4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcheck
POSTHOOK: Lineage: tcheck.a SIMPLE []
POSTHOOK: Lineage: tcheck.b SCRIPT []
PREHOOK: query: SELECT * FROM tcheck
PREHOOK: type: QUERY
PREHOOK: Input: default@tcheck
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM tcheck
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tcheck
#### A masked pattern was here ####
NULL	4
PREHOOK: query: DROP TABLE tcheck
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tcheck
PREHOOK: Output: database:default
PREHOOK: Output: default@tcheck
POSTHOOK: query: DROP TABLE tcheck
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tcheck
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tcheck
PREHOOK: query: create table part_mm(key int check (key > 0 and key < 5000) enforced) partitioned by (key_mm int)
    stored as orc tblproperties ("transactional"="true", "transactional_properties"="insert_only")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@part_mm
POSTHOOK: query: create table part_mm(key int check (key > 0 and key < 5000) enforced) partitioned by (key_mm int)
    stored as orc tblproperties ("transactional"="true", "transactional_properties"="insert_only")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@part_mm
PREHOOK: query: explain insert into table part_mm partition(key_mm=455) select key from src order by value limit 3
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@part_mm@key_mm=455
POSTHOOK: query: explain insert into table part_mm partition(key_mm=455) select key from src order by value limit 3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@part_mm@key_mm=455
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Top N Key Operator
                    sort order: +
                    keys: value (type: string)
                    null sort order: z
                    Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                    top n: 3
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col1 (type: string)
                        null sort order: z
                        sort order: +
                        Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                Limit
                  Number of rows: 3
                  Statistics: Num rows: 3 Data size: 261 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: enforce_constraint(((_col0 > 0) and (_col0 < 5000)) is not false) (type: boolean)
                    Statistics: Num rows: 1 Data size: 87 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: UDFToInteger(_col0) (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                            name: default.part_mm
                        Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            key_mm 455
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.part_mm
          Write Type: INSERT
          micromanaged table: true

PREHOOK: query: insert into table part_mm partition(key_mm=455) select key from src order by value desc limit 3
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@part_mm@key_mm=455
POSTHOOK: query: insert into table part_mm partition(key_mm=455) select key from src order by value desc limit 3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@part_mm@key_mm=455
POSTHOOK: Lineage: part_mm PARTITION(key_mm=455).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
PREHOOK: query: select key from src order by value limit 3
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select key from src order by value limit 3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
0
0
0
PREHOOK: query: select * from part_mm
PREHOOK: type: QUERY
PREHOOK: Input: default@part_mm
PREHOOK: Input: default@part_mm@key_mm=455
#### A masked pattern was here ####
POSTHOOK: query: select * from part_mm
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part_mm
POSTHOOK: Input: default@part_mm@key_mm=455
#### A masked pattern was here ####
98	455
98	455
97	455
PREHOOK: query: drop table part_mm
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@part_mm
PREHOOK: Output: database:default
PREHOOK: Output: default@part_mm
POSTHOOK: query: drop table part_mm
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@part_mm
POSTHOOK: Output: database:default
POSTHOOK: Output: default@part_mm
PREHOOK: query: create table trely(i int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@trely
POSTHOOK: query: create table trely(i int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@trely
PREHOOK: query: ALTER TABLE trely CHANGE i i int CHECK (i>0) ENABLE NOVALIDATE RELY
PREHOOK: type: ALTERTABLE_RENAMECOL
PREHOOK: Input: default@trely
PREHOOK: Output: default@trely
POSTHOOK: query: ALTER TABLE trely CHANGE i i int CHECK (i>0) ENABLE NOVALIDATE RELY
POSTHOOK: type: ALTERTABLE_RENAMECOL
POSTHOOK: Input: default@trely
POSTHOOK: Output: default@trely
PREHOOK: query: DESC FORMATTED trely
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@trely
POSTHOOK: query: DESC FORMATTED trely
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@trely
# col_name            	data_type           	comment             
i                   	int                 	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
#### A masked pattern was here ####
	transactional       	true                
	transactional_properties	insert_only         
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.trely       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:i       	Check Value:`i`>0   	 
	 	 
PREHOOK: query: DROP TABLE trely
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@trely
PREHOOK: Output: database:default
PREHOOK: Output: default@trely
POSTHOOK: query: DROP TABLE trely
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@trely
POSTHOOK: Output: database:default
POSTHOOK: Output: default@trely
PREHOOK: query: create table tbl1_n1(a string, b int, CONSTRAINT check1 CHECK (a != '' AND b > 4))
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl1_n1
POSTHOOK: query: create table tbl1_n1(a string, b int, CONSTRAINT check1 CHECK (a != '' AND b > 4))
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl1_n1
PREHOOK: query: desc formatted tbl1_n1
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tbl1_n1
POSTHOOK: query: desc formatted tbl1_n1
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tbl1_n1
# col_name            	data_type           	comment             
a                   	string              	                    
b                   	int                 	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
	transactional       	true                
	transactional_properties	insert_only         
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tbl1_n1     	 
Constraint Name:    	check1              	 
Column Name:null    	Check Value:`a` != '' AND `b` > 4	 
	 	 
PREHOOK: query: explain insert into tbl1_n1 values('a', 69)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl1_n1
POSTHOOK: query: explain insert into tbl1_n1 values('a', 69)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl1_n1
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('a',69)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int)
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint(((_col0 <> '') and (_col1 > 4)) is not false) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.tbl1_n1
                            Write Type: INSERT
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tbl1_n1
          Write Type: INSERT
          micromanaged table: true

PREHOOK: query: insert into tbl1_n1 values('a', 69)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl1_n1
POSTHOOK: query: insert into tbl1_n1 values('a', 69)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl1_n1
POSTHOOK: Lineage: tbl1_n1.a SCRIPT []
POSTHOOK: Lineage: tbl1_n1.b SCRIPT []
PREHOOK: query: select * from tbl1_n1
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl1_n1
#### A masked pattern was here ####
POSTHOOK: query: select * from tbl1_n1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl1_n1
#### A masked pattern was here ####
a	69
PREHOOK: query: ALTER TABLE tbl1_n1 add constraint chk2 CHECK (b < 100)
PREHOOK: type: ALTERTABLE_ADDCONSTRAINT
PREHOOK: Input: default@tbl1_n1
PREHOOK: Output: default@tbl1_n1
POSTHOOK: query: ALTER TABLE tbl1_n1 add constraint chk2 CHECK (b < 100)
POSTHOOK: type: ALTERTABLE_ADDCONSTRAINT
POSTHOOK: Input: default@tbl1_n1
POSTHOOK: Output: default@tbl1_n1
PREHOOK: query: desc formatted tbl1_n1
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tbl1_n1
POSTHOOK: query: desc formatted tbl1_n1
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tbl1_n1
# col_name            	data_type           	comment             
a                   	string              	                    
b                   	int                 	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	bucketing_version   	2                   
	numFiles            	1                   
	totalSize           	5                   
	transactional       	true                
	transactional_properties	insert_only         
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tbl1_n1     	 
Constraint Name:    	check1              	 
Column Name:null    	Check Value:`a` != '' AND `b` > 4	 
	 	 
Constraint Name:    	chk2                	 
Column Name:null    	Check Value:`b` < 100	 
	 	 
PREHOOK: query: explain insert into tbl1_n1 values('a', 69)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl1_n1
POSTHOOK: query: explain insert into tbl1_n1 values('a', 69)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl1_n1
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('a',69)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int)
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((((_col0 <> '') and (_col1 > 4)) is not false and (_col1 < 100) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.tbl1_n1
                            Write Type: INSERT
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tbl1_n1
          Write Type: INSERT
          micromanaged table: true

PREHOOK: query: drop table tbl1_n1
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tbl1_n1
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl1_n1
POSTHOOK: query: drop table tbl1_n1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tbl1_n1
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl1_n1
