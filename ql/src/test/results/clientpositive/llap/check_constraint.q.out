PREHOOK: query: CREATE TABLE table1(i int CHECK -i > -10,
    j int CHECK +j > 10,
    ij boolean CHECK ij IS NOT NULL,
    a int CHECK a BETWEEN i AND j,
    bb float CHECK bb IN (23.4,56,4),
    d bigint CHECK d > round(567.6) AND d < round(1000.4))
    clustered by (i) into 2 buckets stored as orc TBLPROPERTIES('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@table1
POSTHOOK: query: CREATE TABLE table1(i int CHECK -i > -10,
    j int CHECK +j > 10,
    ij boolean CHECK ij IS NOT NULL,
    a int CHECK a BETWEEN i AND j,
    bb float CHECK bb IN (23.4,56,4),
    d bigint CHECK d > round(567.6) AND d < round(1000.4))
    clustered by (i) into 2 buckets stored as orc TBLPROPERTIES('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@table1
PREHOOK: query: DESC FORMATTED table1
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@table1
POSTHOOK: query: DESC FORMATTED table1
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@table1
# col_name            	data_type           	comment             
i                   	int                 	                    
j                   	int                 	                    
ij                  	boolean             	                    
a                   	int                 	                    
bb                  	float               	                    
d                   	bigint              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[i]                 	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.table1      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:a       	Check Value:a BETWEEN i AND j	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:d       	Check Value:d > round(567.6) AND d < round(1000.4)	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:i       	Check Value:-i > -10	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:j       	Check Value:+j > 10 	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:ij      	Check Value:ij IS NOT NULL	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:bb      	Check Value:bb IN (23.4,56,4)	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO table1 values(1,100,true, 5, 23.4, 700.5)
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO table1 values(1,100,true, 5, 23.4, 700.5)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(1,100,true,5,23.4,700.5)) (type: array<struct<col1:int,col2:int,col3:boolean,col4:int,col5:decimal(3,1),col6:decimal(4,1)>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: int), col2 (type: int), col3 (type: boolean), col4 (type: int), col5 (type: decimal(3,1)), col6 (type: decimal(4,1))
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((((((((- _col0) > (- 10)) is not false and (_col1 > 10) is not false) and _col2 is not null is not false) and _col3 BETWEEN _col0 AND _col1 is not false) and (_col4) IN (23.4, 56, 4) is not false) and ((_col5 > round(567.6)) and (_col5 < round(1000.4))) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            sort order: 
                            Map-reduce partition columns: _col0 (type: int)
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: boolean), _col3 (type: int), _col4 (type: decimal(3,1)), _col5 (type: decimal(4,1))
            Execution mode: llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: int), VALUE._col2 (type: boolean), VALUE._col3 (type: int), UDFToFloat(VALUE._col4) (type: float), UDFToLong(VALUE._col5) (type: bigint)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.table1
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.table1
          Write Type: INSERT

PREHOOK: query: INSERT INTO table1 values(1,100,true, 5, 23.4, 700.5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@table1
POSTHOOK: query: INSERT INTO table1 values(1,100,true, 5, 23.4, 700.5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@table1
POSTHOOK: Lineage: table1.a SCRIPT []
POSTHOOK: Lineage: table1.bb SCRIPT []
POSTHOOK: Lineage: table1.d SCRIPT []
POSTHOOK: Lineage: table1.i SCRIPT []
POSTHOOK: Lineage: table1.ij SCRIPT []
POSTHOOK: Lineage: table1.j SCRIPT []
PREHOOK: query: SELECT * from table1
PREHOOK: type: QUERY
PREHOOK: Input: default@table1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * from table1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table1
#### A masked pattern was here ####
1	100	true	5	23.4	700
PREHOOK: query: DROP TABLE table1
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@table1
PREHOOK: Output: default@table1
POSTHOOK: query: DROP TABLE table1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@table1
POSTHOOK: Output: default@table1
PREHOOK: query: CREATE TABLE table2(i int CHECK i + NULL > 0)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@table2
POSTHOOK: query: CREATE TABLE table2(i int CHECK i + NULL > 0)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@table2
PREHOOK: query: DESC FORMATTED table2
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@table2
POSTHOOK: query: DESC FORMATTED table2
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@table2
# col_name            	data_type           	comment             
i                   	int                 	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.table2      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:i       	Check Value:i + NULL > 0	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO table2 values(8)
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO table2 values(8)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(8)) (type: array<struct<col1:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: int)
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint(((_col0 + null) > 0) is not false) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.table2
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.table2

PREHOOK: query: INSERT INTO table2 values(8)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@table2
POSTHOOK: query: INSERT INTO table2 values(8)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@table2
POSTHOOK: Lineage: table2.i SCRIPT []
PREHOOK: query: select * from table2
PREHOOK: type: QUERY
PREHOOK: Input: default@table2
#### A masked pattern was here ####
POSTHOOK: query: select * from table2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table2
#### A masked pattern was here ####
8
PREHOOK: query: Drop table table2
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@table2
PREHOOK: Output: default@table2
POSTHOOK: query: Drop table table2
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@table2
POSTHOOK: Output: default@table2
PREHOOK: query: CREATE FUNCTION test_udf2 AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestGetJavaString'
PREHOOK: type: CREATEFUNCTION
PREHOOK: Output: database:default
PREHOOK: Output: default.test_udf2
POSTHOOK: query: CREATE FUNCTION test_udf2 AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestGetJavaString'
POSTHOOK: type: CREATEFUNCTION
POSTHOOK: Output: database:default
POSTHOOK: Output: default.test_udf2
PREHOOK: query: CREATE TABLE tudf(v string CHECK test_udf2(v) <> 'vin')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tudf
POSTHOOK: query: CREATE TABLE tudf(v string CHECK test_udf2(v) <> 'vin')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tudf
PREHOOK: query: EXPLAIN INSERT INTO tudf values('function1')
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO tudf values('function1')
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('function1')) (type: array<struct<col1:string>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string)
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((GenericUDFTestGetJavaString(_col0) <> 'vin') is not false) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.tudf
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tudf

PREHOOK: query: Drop table tudf
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tudf
PREHOOK: Output: default@tudf
POSTHOOK: query: Drop table tudf
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tudf
POSTHOOK: Output: default@tudf
PREHOOK: query: create table tmulti(url string NOT NULL ENABLE, userName string, numClicks int CHECK numClicks > 0, d date)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tmulti
POSTHOOK: query: create table tmulti(url string NOT NULL ENABLE, userName string, numClicks int CHECK numClicks > 0, d date)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tmulti
PREHOOK: query: alter table tmulti add constraint un1 UNIQUE (userName, numClicks) DISABLE
PREHOOK: type: ALTERTABLE_ADDCONSTRAINT
POSTHOOK: query: alter table tmulti add constraint un1 UNIQUE (userName, numClicks) DISABLE
POSTHOOK: type: ALTERTABLE_ADDCONSTRAINT
PREHOOK: query: DESC formatted tmulti
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tmulti
POSTHOOK: query: DESC formatted tmulti
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tmulti
# col_name            	data_type           	comment             
url                 	string              	                    
username            	string              	                    
numclicks           	int                 	                    
d                   	date                	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Unique Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	un1                 	 
Column Name:username	Key Sequence:1      	 
Column Name:numclicks	Key Sequence:2      	 
	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	url                 	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:numclicks	Check Value:numClicks > 0	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '12-01-2018')
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '12-01-2018')
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('hive.apache.com','user1',48,'12-01-2018')) (type: array<struct<col1:string,col2:string,col3:int,col4:string>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: string), col3 (type: int), col4 (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col0 is not null and (_col2 > 0) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), CAST( _col3 AS DATE) (type: date)
                            outputColumnNames: _col0, _col1, _col2, _col3
                            Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                            File Output Operator
                              compressed: false
                              Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                              table:
                                  input format: org.apache.hadoop.mapred.TextInputFormat
                                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                  name: default.tmulti
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tmulti

PREHOOK: query: INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '12-01-2018')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tmulti
POSTHOOK: query: INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '12-01-2018')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tmulti
POSTHOOK: Lineage: tmulti.d SCRIPT []
POSTHOOK: Lineage: tmulti.numclicks SCRIPT []
POSTHOOK: Lineage: tmulti.url SCRIPT []
POSTHOOK: Lineage: tmulti.username SCRIPT []
PREHOOK: query: Select * from tmulti
PREHOOK: type: QUERY
PREHOOK: Input: default@tmulti
#### A masked pattern was here ####
POSTHOOK: query: Select * from tmulti
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tmulti
#### A masked pattern was here ####
hive.apache.com	user1	48	NULL
PREHOOK: query: truncate table tmulti
PREHOOK: type: TRUNCATETABLE
PREHOOK: Output: default@tmulti
POSTHOOK: query: truncate table tmulti
POSTHOOK: type: TRUNCATETABLE
POSTHOOK: Output: default@tmulti
PREHOOK: query: alter table tmulti add constraint chk1 CHECK (userName != NULL)
PREHOOK: type: ALTERTABLE_ADDCONSTRAINT
POSTHOOK: query: alter table tmulti add constraint chk1 CHECK (userName != NULL)
POSTHOOK: type: ALTERTABLE_ADDCONSTRAINT
PREHOOK: query: alter table tmulti add constraint chk2 CHECK (numClicks <= 10000 AND userName != '')
PREHOOK: type: ALTERTABLE_ADDCONSTRAINT
POSTHOOK: query: alter table tmulti add constraint chk2 CHECK (numClicks <= 10000 AND userName != '')
POSTHOOK: type: ALTERTABLE_ADDCONSTRAINT
PREHOOK: query: DESC formatted tmulti
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tmulti
POSTHOOK: query: DESC formatted tmulti
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tmulti
# col_name            	data_type           	comment             
url                 	string              	                    
username            	string              	                    
numclicks           	int                 	                    
d                   	date                	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\"}
	numFiles            	0                   
	totalSize           	0                   
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Unique Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	un1                 	 
Column Name:username	Key Sequence:1      	 
Column Name:numclicks	Key Sequence:2      	 
	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	url                 	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tmulti      	 
Constraint Name:    	chk1                	 
Column Name:null    	Check Value:(userName != NULL)	 
	 	 
Constraint Name:    	chk2                	 
Column Name:null    	Check Value:(numClicks <= 10000 AND userName != '')	 
	 	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:numclicks	Check Value:numClicks > 0	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '12-01-2018')
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '12-01-2018')
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('hive.apache.com','user1',48,'12-01-2018')) (type: array<struct<col1:string,col2:string,col3:int,col4:string>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: string), col3 (type: int), col4 (type: string)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col0 is not null and (((_col2 > 0) is not false and (_col1 <> null) is not false) and ((_col2 <= 10000) and (_col1 <> '')) is not false))) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int), CAST( _col3 AS DATE) (type: date)
                            outputColumnNames: _col0, _col1, _col2, _col3
                            Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                            File Output Operator
                              compressed: false
                              Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                              table:
                                  input format: org.apache.hadoop.mapred.TextInputFormat
                                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                  name: default.tmulti
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tmulti

PREHOOK: query: INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '12-01-2018')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tmulti
POSTHOOK: query: INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '12-01-2018')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tmulti
POSTHOOK: Lineage: tmulti.d SCRIPT []
POSTHOOK: Lineage: tmulti.numclicks SCRIPT []
POSTHOOK: Lineage: tmulti.url SCRIPT []
POSTHOOK: Lineage: tmulti.username SCRIPT []
PREHOOK: query: Select * from tmulti
PREHOOK: type: QUERY
PREHOOK: Input: default@tmulti
#### A masked pattern was here ####
POSTHOOK: query: Select * from tmulti
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tmulti
#### A masked pattern was here ####
hive.apache.com	user1	48	NULL
PREHOOK: query: Drop table tmulti
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tmulti
PREHOOK: Output: default@tmulti
POSTHOOK: query: Drop table tmulti
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tmulti
POSTHOOK: Output: default@tmulti
PREHOOK: query: create table tcase(url string NOT NULL ENABLE, userName string, d date, numClicks int CHECK numclicks > 0)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tcase
POSTHOOK: query: create table tcase(url string NOT NULL ENABLE, userName string, d date, numClicks int CHECK numclicks > 0)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tcase
PREHOOK: query: DESC formatted tcase
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tcase
POSTHOOK: query: DESC formatted tcase
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tcase
# col_name            	data_type           	comment             
url                 	string              	                    
username            	string              	                    
d                   	date                	                    
numclicks           	int                 	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.tcase       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	url                 	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tcase       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:numclicks	Check Value:numclicks > 0	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO tcase values('hive.apache.com', 'user1', '12-01-2018', 48)
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO tcase values('hive.apache.com', 'user1', '12-01-2018', 48)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('hive.apache.com','user1','12-01-2018',48)) (type: array<struct<col1:string,col2:string,col3:string,col4:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: string), col3 (type: string), col4 (type: int)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col0 is not null and (_col3 > 0) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: string), CAST( _col2 AS DATE) (type: date), _col3 (type: int)
                            outputColumnNames: _col0, _col1, _col2, _col3
                            Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                            File Output Operator
                              compressed: false
                              Statistics: Num rows: 1 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
                              table:
                                  input format: org.apache.hadoop.mapred.TextInputFormat
                                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                  name: default.tcase
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tcase

PREHOOK: query: INSERT INTO tcase values('hive.apache.com', 'user1', '12-01-2018', 48)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcase
POSTHOOK: query: INSERT INTO tcase values('hive.apache.com', 'user1', '12-01-2018', 48)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcase
POSTHOOK: Lineage: tcase.d SCRIPT []
POSTHOOK: Lineage: tcase.numclicks SCRIPT []
POSTHOOK: Lineage: tcase.url SCRIPT []
POSTHOOK: Lineage: tcase.username SCRIPT []
PREHOOK: query: Select * from tcase
PREHOOK: type: QUERY
PREHOOK: Input: default@tcase
#### A masked pattern was here ####
POSTHOOK: query: Select * from tcase
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tcase
#### A masked pattern was here ####
hive.apache.com	user1	NULL	48
PREHOOK: query: Drop table tcase
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tcase
PREHOOK: Output: default@tcase
POSTHOOK: query: Drop table tcase
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tcase
POSTHOOK: Output: default@tcase
PREHOOK: query: create table tcast(url string NOT NULL ENABLE, numClicks int,
    price FLOAT CHECK cast(numClicks as FLOAT)*price > 10.00)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tcast
POSTHOOK: query: create table tcast(url string NOT NULL ENABLE, numClicks int,
    price FLOAT CHECK cast(numClicks as FLOAT)*price > 10.00)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tcast
PREHOOK: query: DESC FORMATTED tcast
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tcast
POSTHOOK: query: DESC FORMATTED tcast
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tcast
# col_name            	data_type           	comment             
url                 	string              	                    
numclicks           	int                 	                    
price               	float               	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.tcast       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	url                 	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tcast       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:price   	Check Value:cast(numClicks as FLOAT)*price > 10.00	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO tcast values('www.google.com', 100, cast(0.5 as float))
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO tcast values('www.google.com', 100, cast(0.5 as float))
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('www.google.com',100,0.5)) (type: array<struct<col1:string,col2:int,col3:float>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int), col3 (type: float)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col0 is not null and ((UDFToFloat(_col1) * _col2) > 10) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.tcast
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tcast

PREHOOK: query: INSERT INTO tcast values('www.google.com', 100, cast(0.5 as float))
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcast
POSTHOOK: query: INSERT INTO tcast values('www.google.com', 100, cast(0.5 as float))
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcast
POSTHOOK: Lineage: tcast.numclicks SCRIPT []
POSTHOOK: Lineage: tcast.price SCRIPT []
POSTHOOK: Lineage: tcast.url SCRIPT []
PREHOOK: query: SELECT * from tcast
PREHOOK: type: QUERY
PREHOOK: Input: default@tcast
#### A masked pattern was here ####
POSTHOOK: query: SELECT * from tcast
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tcast
#### A masked pattern was here ####
www.google.com	100	0.5
PREHOOK: query: EXPLAIN INSERT INTO tcast(url, price) values('www.yahoo.com', 0.5)
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO tcast(url, price) values('www.yahoo.com', 0.5)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('www.yahoo.com',0.5)) (type: array<struct<col1:string,col2:decimal(1,1)>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), null (type: int), col2 (type: decimal(1,1))
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col0 is not null and ((UDFToFloat(null) * _col2) > 10) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: string), _col1 (type: int), UDFToFloat(_col2) (type: float)
                            outputColumnNames: _col0, _col1, _col2
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            File Output Operator
                              compressed: false
                              Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                              table:
                                  input format: org.apache.hadoop.mapred.TextInputFormat
                                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                  name: default.tcast
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tcast

PREHOOK: query: INSERT INTO tcast(url, price) values('www.yahoo.com', 0.5)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcast
POSTHOOK: query: INSERT INTO tcast(url, price) values('www.yahoo.com', 0.5)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcast
POSTHOOK: Lineage: tcast.numclicks SIMPLE []
POSTHOOK: Lineage: tcast.price SCRIPT []
POSTHOOK: Lineage: tcast.url SCRIPT []
PREHOOK: query: SELECT * FROM tcast
PREHOOK: type: QUERY
PREHOOK: Input: default@tcast
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM tcast
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tcast
#### A masked pattern was here ####
www.google.com	100	0.5
www.yahoo.com	NULL	0.5
PREHOOK: query: DROP TABLE tcast
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tcast
PREHOOK: Output: default@tcast
POSTHOOK: query: DROP TABLE tcast
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tcast
POSTHOOK: Output: default@tcast
PREHOOK: query: create table texpr(i int DEFAULT 89, f float NOT NULL ENABLE, d decimal(4,1),
    b boolean CHECK ((cast(d as float) + f) < cast(i as float) + (i*i)))
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@texpr
POSTHOOK: query: create table texpr(i int DEFAULT 89, f float NOT NULL ENABLE, d decimal(4,1),
    b boolean CHECK ((cast(d as float) + f) < cast(i as float) + (i*i)))
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@texpr
PREHOOK: query: DESC FORMATTED texpr
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@texpr
POSTHOOK: query: DESC FORMATTED texpr
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@texpr
# col_name            	data_type           	comment             
i                   	int                 	                    
f                   	float               	                    
d                   	decimal(4,1)        	                    
b                   	boolean             	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.texpr       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	f                   	 
	 	 
	 	 
# Default Constraints	 	 
Table:              	default.texpr       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:i       	Default Value:89    	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.texpr       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:b       	Check Value:((cast(d as float) + f) < cast(i as float) + (i*i))	 
	 	 
PREHOOK: query: explain insert into texpr values(3,3.4,5.6,true)
PREHOOK: type: QUERY
POSTHOOK: query: explain insert into texpr values(3,3.4,5.6,true)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(3,3.4,5.6,true)) (type: array<struct<col1:int,col2:decimal(2,1),col3:decimal(2,1),col4:boolean>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: int), col2 (type: decimal(2,1)), col3 (type: decimal(2,1)), col4 (type: boolean)
                        outputColumnNames: _col0, _col1, _col2, _col3
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col1 is not null and ((UDFToFloat(_col2) + _col1) < (UDFToFloat(_col0) + (_col0 * _col0))) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Select Operator
                            expressions: _col0 (type: int), UDFToFloat(_col1) (type: float), CAST( _col2 AS decimal(4,1)) (type: decimal(4,1)), _col3 (type: boolean)
                            outputColumnNames: _col0, _col1, _col2, _col3
                            Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: COMPLETE
                            File Output Operator
                              compressed: false
                              Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: COMPLETE
                              table:
                                  input format: org.apache.hadoop.mapred.TextInputFormat
                                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                  name: default.texpr
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.texpr

PREHOOK: query: insert into texpr values(3,3.4,5.6,true)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@texpr
POSTHOOK: query: insert into texpr values(3,3.4,5.6,true)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@texpr
POSTHOOK: Lineage: texpr.b SCRIPT []
POSTHOOK: Lineage: texpr.d SCRIPT []
POSTHOOK: Lineage: texpr.f SCRIPT []
POSTHOOK: Lineage: texpr.i SCRIPT []
PREHOOK: query: SELECT * from texpr
PREHOOK: type: QUERY
PREHOOK: Input: default@texpr
#### A masked pattern was here ####
POSTHOOK: query: SELECT * from texpr
POSTHOOK: type: QUERY
POSTHOOK: Input: default@texpr
#### A masked pattern was here ####
3	3.4	5.6	true
PREHOOK: query: DROP TABLE texpr
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@texpr
PREHOOK: Output: default@texpr
POSTHOOK: query: DROP TABLE texpr
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@texpr
POSTHOOK: Output: default@texpr
PREHOOK: query: create table acid_uami(i int,
                 de decimal(5,2) constraint nn1 not null enforced,
                 vc varchar(128) constraint ch2 CHECK de >= cast(i as decimal(5,2)) enforced)
                 clustered by (i) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@acid_uami
POSTHOOK: query: create table acid_uami(i int,
                 de decimal(5,2) constraint nn1 not null enforced,
                 vc varchar(128) constraint ch2 CHECK de >= cast(i as decimal(5,2)) enforced)
                 clustered by (i) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@acid_uami
PREHOOK: query: DESC FORMATTED acid_uami
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@acid_uami
POSTHOOK: query: DESC FORMATTED acid_uami
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@acid_uami
# col_name            	data_type           	comment             
i                   	int                 	                    
de                  	decimal(5,2)        	                    
vc                  	varchar(128)        	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[i]                 	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.acid_uami   	 
Constraint Name:    	nn1                 	 
Column Name:        	de                  	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.acid_uami   	 
Constraint Name:    	ch2                 	 
Column Name:vc      	Check Value:de >= cast(i as decimal(5,2))	 
	 	 
PREHOOK: query: explain insert into table acid_uami select cast(key as int), cast (key as decimal(5,2)), value from src
PREHOOK: type: QUERY
POSTHOOK: query: explain insert into table acid_uami select cast(key as int), cast (key as decimal(5,2)), value from src
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: UDFToInteger(key) (type: int), CAST( key AS decimal(5,2)) (type: decimal(5,2)), value (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 500 Data size: 103500 Basic stats: COMPLETE Column stats: COMPLETE
                    Filter Operator
                      predicate: enforce_constraint((_col1 is not null and (_col1 >= CAST( _col0 AS decimal(5,2))) is not false)) (type: boolean)
                      Statistics: Num rows: 250 Data size: 51750 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        sort order: 
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 250 Data size: 51750 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: int), _col1 (type: decimal(5,2)), _col2 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: decimal(5,2)), CAST( VALUE._col2 AS varchar(128)) (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 250 Data size: 82000 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 250 Data size: 82000 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami
          Write Type: INSERT

PREHOOK: query: insert into table acid_uami select cast(key as int), cast (key as decimal(5,2)), value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami
POSTHOOK: query: insert into table acid_uami select cast(key as int), cast (key as decimal(5,2)), value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami
POSTHOOK: Lineage: acid_uami.de EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami.i EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami.vc EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain insert overwrite table acid_uami select cast(key as int), cast (key as decimal(5,2)), value
    from src order by cast(key as int) limit 10
PREHOOK: type: QUERY
POSTHOOK: query: explain insert overwrite table acid_uami select cast(key as int), cast (key as decimal(5,2)), value
    from src order by cast(key as int) limit 10
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: UDFToInteger(key) (type: int), CAST( key AS decimal(5,2)) (type: decimal(5,2)), value (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 500 Data size: 103500 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 103500 Basic stats: COMPLETE Column stats: COMPLETE
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col1 (type: decimal(5,2)), _col2 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: decimal(5,2)), VALUE._col1 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 500 Data size: 103500 Basic stats: COMPLETE Column stats: COMPLETE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 2070 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: enforce_constraint((_col1 is not null and (_col1 >= CAST( _col0 AS decimal(5,2))) is not false)) (type: boolean)
                    Statistics: Num rows: 5 Data size: 1035 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      sort order: 
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 5 Data size: 1035 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: int), _col1 (type: decimal(5,2)), _col2 (type: string)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: decimal(5,2)), CAST( VALUE._col2 AS varchar(128)) (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami
          Write Type: INSERT

PREHOOK: query: insert overwrite table acid_uami select cast(key as int), cast (key as decimal(5,2)), value
    from src order by cast(key as int) limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami
POSTHOOK: query: insert overwrite table acid_uami select cast(key as int), cast (key as decimal(5,2)), value
    from src order by cast(key as int) limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami
POSTHOOK: Lineage: acid_uami.de EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami.i EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami.vc EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain insert into table acid_uami select cast(s1.key as int) as c1, cast (s2.key as decimal(5,2)) as c2, s1.value from src s1
    left outer join src s2 on s1.key=s2.key where s1.value > 'val' limit 10
PREHOOK: type: QUERY
POSTHOOK: query: explain insert into table acid_uami select cast(s1.key as int) as c1, cast (s2.key as decimal(5,2)) as c2, s1.value from src s1
    left outer join src s2 on s1.key=s2.key where s1.value > 'val' limit 10
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: s1
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (value > 'val') (type: boolean)
                    Statistics: Num rows: 166 Data size: 29548 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 166 Data size: 29548 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 166 Data size: 29548 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: s2
                  Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col0 (type: string)
                      Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col0 (type: string)
                  1 _col0 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 268 Data size: 71020 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: UDFToInteger(_col0) (type: int), CAST( _col2 AS decimal(5,2)) (type: decimal(5,2)), _col1 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 268 Data size: 55476 Basic stats: COMPLETE Column stats: COMPLETE
                  Limit
                    Number of rows: 10
                    Statistics: Num rows: 10 Data size: 2070 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 10 Data size: 2070 Basic stats: COMPLETE Column stats: COMPLETE
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col0 (type: int), _col1 (type: decimal(5,2)), _col2 (type: string)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: decimal(5,2)), VALUE._col2 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 10 Data size: 2070 Basic stats: COMPLETE Column stats: COMPLETE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 2070 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: enforce_constraint((_col1 is not null and (_col1 >= CAST( _col0 AS decimal(5,2))) is not false)) (type: boolean)
                    Statistics: Num rows: 5 Data size: 1035 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      sort order: 
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 5 Data size: 1035 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: int), _col1 (type: decimal(5,2)), _col2 (type: string)
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: decimal(5,2)), CAST( VALUE._col2 AS varchar(128)) (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami
          Write Type: INSERT

PREHOOK: query: insert into table acid_uami select cast(s1.key as int) as c1, cast (s2.key as decimal(5,2)) as c2, s1.value from src s1
    left outer join src s2 on s1.key=s2.key where s1.value > 'val' limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami
POSTHOOK: query: insert into table acid_uami select cast(s1.key as int) as c1, cast (s2.key as decimal(5,2)) as c2, s1.value from src s1
    left outer join src s2 on s1.key=s2.key where s1.value > 'val' limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami
POSTHOOK: Lineage: acid_uami.de EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami.i EXPRESSION [(src)s1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami.vc EXPRESSION [(src)s1.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: select * from acid_uami
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami
#### A masked pattern was here ####
POSTHOOK: query: select * from acid_uami
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami
#### A masked pattern was here ####
8	8.00	val_8
4	4.00	val_4
2	2.00	val_2
0	0.00	val_0
0	0.00	val_0
0	0.00	val_0
9	9.00	val_9
5	5.00	val_5
5	5.00	val_5
5	5.00	val_5
10	10.00	val_10
0	0.00	val_0
0	0.00	val_0
0	0.00	val_0
0	0.00	val_0
0	0.00	val_0
0	0.00	val_0
0	0.00	val_0
0	0.00	val_0
0	0.00	val_0
PREHOOK: query: truncate table acid_uami
PREHOOK: type: TRUNCATETABLE
PREHOOK: Output: default@acid_uami
POSTHOOK: query: truncate table acid_uami
POSTHOOK: type: TRUNCATETABLE
POSTHOOK: Output: default@acid_uami
PREHOOK: query: explain insert into table acid_uami select min(cast(key as int)) as c1, max(cast (key as decimal(5,2))) as c2, value
    from src group by key, value order by key, value limit 10
PREHOOK: type: QUERY
POSTHOOK: query: explain insert into table acid_uami select min(cast(key as int)) as c1, max(cast (key as decimal(5,2))) as c2, value
    from src group by key, value order by key, value limit 10
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: key (type: string), value (type: string), UDFToInteger(key) (type: int), CAST( key AS decimal(5,2)) (type: decimal(5,2))
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: min(_col2), max(_col3)
                      keys: _col0 (type: string), _col1 (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 250 Data size: 73500 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string)
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                        Statistics: Num rows: 250 Data size: 73500 Basic stats: COMPLETE Column stats: COMPLETE
                        TopN Hash Memory Usage: 0.1
                        value expressions: _col2 (type: int), _col3 (type: decimal(5,2))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1)
                keys: KEY._col0 (type: string), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 250 Data size: 73500 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col2 (type: int), _col3 (type: decimal(5,2)), _col1 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 250 Data size: 51750 Basic stats: COMPLETE Column stats: COMPLETE
                  Limit
                    Number of rows: 10
                    Statistics: Num rows: 10 Data size: 2070 Basic stats: COMPLETE Column stats: COMPLETE
                    Filter Operator
                      predicate: enforce_constraint((_col1 is not null and (_col1 >= CAST( _col0 AS decimal(5,2))) is not false)) (type: boolean)
                      Statistics: Num rows: 5 Data size: 1035 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        sort order: 
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 5 Data size: 1035 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: int), _col1 (type: decimal(5,2)), _col2 (type: string)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: decimal(5,2)), CAST( VALUE._col2 AS varchar(128)) (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 5 Data size: 1640 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami
          Write Type: INSERT

PREHOOK: query: insert into table acid_uami select min(cast(key as int)) as c1, max(cast (key as decimal(5,2))) as c2, value
    from src group by key, value order by key, value limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@acid_uami
POSTHOOK: query: insert into table acid_uami select min(cast(key as int)) as c1, max(cast (key as decimal(5,2))) as c2, value
    from src group by key, value order by key, value limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@acid_uami
POSTHOOK: Lineage: acid_uami.de EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami.i EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: acid_uami.vc EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: select * from acid_uami
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami
#### A masked pattern was here ####
POSTHOOK: query: select * from acid_uami
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami
#### A masked pattern was here ####
114	114.00	val_114
104	104.00	val_104
100	100.00	val_100
10	10.00	val_10
0	0.00	val_0
113	113.00	val_113
111	111.00	val_111
11	11.00	val_11
105	105.00	val_105
103	103.00	val_103
PREHOOK: query: truncate table acid_uami
PREHOOK: type: TRUNCATETABLE
PREHOOK: Output: default@acid_uami
POSTHOOK: query: truncate table acid_uami
POSTHOOK: type: TRUNCATETABLE
POSTHOOK: Output: default@acid_uami
PREHOOK: query: create table src_multi2 (i STRING, j STRING NOT NULL ENABLE)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@src_multi2
POSTHOOK: query: create table src_multi2 (i STRING, j STRING NOT NULL ENABLE)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@src_multi2
PREHOOK: query: explain
from src
insert into table acid_uami select cast(key as int), cast(key as decimal(5,2)), value where key < 10
insert overwrite table src_multi2 select * where key > 10 and key < 20
PREHOOK: type: QUERY
POSTHOOK: query: explain
from src
insert into table acid_uami select cast(key as int), cast(key as decimal(5,2)), value where key < 10
insert overwrite table src_multi2 select * where key > 10 and key < 20
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-3
  Stage-1 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-2
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (key < 10) (type: boolean)
                    Statistics: Num rows: 166 Data size: 29548 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: UDFToInteger(key) (type: int), CAST( key AS decimal(5,2)) (type: decimal(5,2)), value (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 166 Data size: 34362 Basic stats: COMPLETE Column stats: COMPLETE
                      Filter Operator
                        predicate: enforce_constraint((_col1 is not null and (_col1 >= CAST( _col0 AS decimal(5,2))) is not false)) (type: boolean)
                        Statistics: Num rows: 83 Data size: 17181 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          sort order: 
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 83 Data size: 17181 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: int), _col1 (type: decimal(5,2)), _col2 (type: string)
                  Filter Operator
                    predicate: ((key < 20) and (key > 10) and enforce_constraint(value is not null)) (type: boolean)
                    Statistics: Num rows: 27 Data size: 4806 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 27 Data size: 4806 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        Statistics: Num rows: 27 Data size: 4806 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.mapred.TextInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                            name: default.src_multi2
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: decimal(5,2)), CAST( VALUE._col2 AS varchar(128)) (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 83 Data size: 27224 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 83 Data size: 27224 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami
                  Write Type: INSERT

  Stage: Stage-3
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami
          Write Type: INSERT

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src_multi2

PREHOOK: query: drop table src_multi2
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src_multi2
PREHOOK: Output: default@src_multi2
POSTHOOK: query: drop table src_multi2
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src_multi2
POSTHOOK: Output: default@src_multi2
PREHOOK: query: select * from acid_uami order by de desc limit 15
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami
#### A masked pattern was here ####
POSTHOOK: query: select * from acid_uami order by de desc limit 15
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami
#### A masked pattern was here ####
PREHOOK: query: explain update acid_uami set de = 893.14 where de = 103.00 or de = 119.00
PREHOOK: type: QUERY
POSTHOOK: query: explain update acid_uami set de = 893.14 where de = 103.00 or de = 119.00
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: acid_uami
                  Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (((de = 103) or (de = 119)) and enforce_constraint((893.14 >= CAST( i AS decimal(5,2))) is not false)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), i (type: int), vc (type: varchar(128))
                      outputColumnNames: _col0, _col1, _col3
                      Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        sort order: +
                        Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                        Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: int), _col3 (type: varchar(128))
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), VALUE._col0 (type: int), 893.14 (type: decimal(5,2)), VALUE._col1 (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami
                  Write Type: UPDATE

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami
          Write Type: UPDATE

PREHOOK: query: update acid_uami set de = 893.14 where de = 103.00 or de = 119.00
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami
PREHOOK: Output: default@acid_uami
POSTHOOK: query: update acid_uami set de = 893.14 where de = 103.00 or de = 119.00
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami
POSTHOOK: Output: default@acid_uami
PREHOOK: query: select * from acid_uami order by de desc limit 15
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami
#### A masked pattern was here ####
POSTHOOK: query: select * from acid_uami order by de desc limit 15
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami
#### A masked pattern was here ####
PREHOOK: query: ALTER table acid_uami drop constraint ch2
PREHOOK: type: ALTERTABLE_DROPCONSTRAINT
POSTHOOK: query: ALTER table acid_uami drop constraint ch2
POSTHOOK: type: ALTERTABLE_DROPCONSTRAINT
PREHOOK: query: explain update acid_uami set vc = 'apache_hive' where de = 893.14
PREHOOK: type: QUERY
POSTHOOK: query: explain update acid_uami set vc = 'apache_hive' where de = 893.14
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: acid_uami
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (de = 893.14) (type: boolean)
                    Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), i (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        sort order: +
                        Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                        Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: int)
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), VALUE._col0 (type: int), 893.14 (type: decimal(5,2)), 'apache_hive' (type: varchar(128))
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acid_uami
                  Write Type: UPDATE

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acid_uami
          Write Type: UPDATE

PREHOOK: query: update acid_uami set vc = 'apache_hive' where de = 893.14
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami
PREHOOK: Output: default@acid_uami
POSTHOOK: query: update acid_uami set vc = 'apache_hive' where de = 893.14
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami
POSTHOOK: Output: default@acid_uami
PREHOOK: query: select * from acid_uami order by vc limit 15
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_uami
#### A masked pattern was here ####
POSTHOOK: query: select * from acid_uami order by vc limit 15
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_uami
#### A masked pattern was here ####
PREHOOK: query: DROP TABLE acid_uami
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@acid_uami
PREHOOK: Output: default@acid_uami
POSTHOOK: query: DROP TABLE acid_uami
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@acid_uami
POSTHOOK: Output: default@acid_uami
PREHOOK: query: create table tmerge(key int CHECK key > 0 AND (key < 100 OR key = 5) enable, a1 string NOT NULL, value string)
clustered by (value) into 2 buckets stored as orc
tblproperties ("transactional"="true")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tmerge
POSTHOOK: query: create table tmerge(key int CHECK key > 0 AND (key < 100 OR key = 5) enable, a1 string NOT NULL, value string)
clustered by (value) into 2 buckets stored as orc
tblproperties ("transactional"="true")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tmerge
PREHOOK: query: DESC FORMATTED tmerge
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tmerge
POSTHOOK: query: DESC FORMATTED tmerge
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tmerge
# col_name            	data_type           	comment             
key                 	int                 	                    
a1                  	string              	                    
value               	string              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[value]             	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Not Null Constraints	 	 
Table:              	default.tmerge      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:        	a1                  	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tmerge      	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:key     	Check Value:key > 0 AND (key < 100 OR key = 5)	 
	 	 
PREHOOK: query: create table nonacid (key int, a1 string, value string) stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@nonacid
POSTHOOK: query: create table nonacid (key int, a1 string, value string) stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@nonacid
PREHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN MATCHED AND s.key < 3 THEN UPDATE set a1 = '1'
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
PREHOOK: type: QUERY
POSTHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN MATCHED AND s.key < 3 THEN UPDATE set a1 = '1'
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-3 is a root stage
  Stage-4 depends on stages: Stage-3
  Stage-0 depends on stages: Stage-4
  Stage-2 depends on stages: Stage-4
  Stage-1 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-3
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 6 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t
                  Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    value expressions: value (type: string), ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: s
                  Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                    value expressions: a1 (type: string), value (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 key (type: int)
                  1 key (type: int)
                outputColumnNames: _col0, _col2, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: ((_col0 = _col6) and (_col6 < 5)) (type: boolean)
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col5 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      sort order: +
                      Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                      Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: ((_col0 = _col6) and (_col6 < 3) and (_col6 >= 5) and enforce_constraint(((_col0 > 0) and ((_col0 < 100) or (_col0 = 5))) is not false)) (type: boolean)
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col5 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col0 (type: int), _col2 (type: string)
                    outputColumnNames: _col0, _col1, _col3
                    Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      sort order: +
                      Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                      Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: int), _col3 (type: string)
                Filter Operator
                  predicate: (_col0 is null and enforce_constraint((_col7 is not null and ((_col6 > 0) and ((_col6 < 100) or (_col6 = 5))) is not false))) (type: boolean)
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col6 (type: int), _col7 (type: string), _col8 (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Map-reduce partition columns: _col2 (type: string)
                      Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: DELETE
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), VALUE._col0 (type: int), '1' (type: string), VALUE._col1 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: UPDATE
        Reducer 5 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: string), VALUE._col2 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: INSERT

  Stage: Stage-4
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: DELETE

  Stage: Stage-2
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: UPDATE

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: INSERT

PREHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN MATCHED AND s.key < 3 THEN UPDATE set a1 = '1'
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
PREHOOK: type: QUERY
POSTHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN MATCHED AND s.key < 3 THEN UPDATE set a1 = '1'
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-5 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-5
  Stage-2 depends on stages: Stage-5
  Stage-3 depends on stages: Stage-5
  Stage-1 depends on stages: Stage-5

STAGE PLANS:
  Stage: Stage-4
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 7 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 6 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t
                  Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                    value expressions: value (type: string), ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Map 7 
            Map Operator Tree:
                TableScan
                  alias: s
                  Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                    value expressions: a1 (type: string), value (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 key (type: int)
                  1 key (type: int)
                outputColumnNames: _col0, _col2, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: ((_col0 = _col6) and (_col6 < 5)) (type: boolean)
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col5 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      sort order: +
                      Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                      Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: ((_col0 = _col6) and (_col6 < 3) and (_col6 >= 5) and enforce_constraint(((_col0 > 0) and ((_col0 < 100) or (_col0 = 5))) is not false)) (type: boolean)
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col5 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col0 (type: int), _col2 (type: string)
                    outputColumnNames: _col0, _col1, _col3
                    Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      sort order: +
                      Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                      Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: int), _col3 (type: string)
                Filter Operator
                  predicate: (_col0 = _col6) (type: boolean)
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col5 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                    outputColumnNames: _col5
                    Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count()
                      keys: _col5 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: bigint)
                Filter Operator
                  predicate: (_col0 is null and enforce_constraint((_col7 is not null and ((_col6 > 0) and ((_col6 < 100) or (_col6 = 5))) is not false))) (type: boolean)
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col6 (type: int), _col7 (type: string), _col8 (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Map-reduce partition columns: _col2 (type: string)
                      Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: DELETE
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), VALUE._col0 (type: int), '1' (type: string), VALUE._col1 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: UPDATE
        Reducer 5 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: (_col1 > 1L) (type: boolean)
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: cardinality_violation(_col0) (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.merge_tmp_table
        Reducer 6 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: string), VALUE._col2 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: INSERT

  Stage: Stage-5
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: DELETE

  Stage: Stage-2
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: UPDATE

  Stage: Stage-3
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.merge_tmp_table

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: INSERT

PREHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
PREHOOK: type: QUERY
POSTHOOK: query: explain MERGE INTO tmerge as t using nonacid as s ON t.key = s.key
WHEN MATCHED AND s.key < 5 THEN DELETE
WHEN NOT MATCHED THEN INSERT VALUES (s.key, s.a1, s.value)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-3 is a root stage
  Stage-4 depends on stages: Stage-3
  Stage-0 depends on stages: Stage-4
  Stage-2 depends on stages: Stage-4
  Stage-1 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-3
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 6 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    value expressions: ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: s
                  Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 1 Data size: 372 Basic stats: COMPLETE Column stats: NONE
                    value expressions: a1 (type: string), value (type: string)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 key (type: int)
                  1 key (type: int)
                outputColumnNames: _col0, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: ((_col0 = _col6) and (_col6 < 5)) (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col5 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      sort order: +
                      Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: (_col0 = _col6) (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col5 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                    outputColumnNames: _col5
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count()
                      keys: _col5 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: bigint)
                Filter Operator
                  predicate: (_col0 is null and enforce_constraint((_col7 is not null and ((_col6 > 0) and ((_col6 < 100) or (_col6 = 5))) is not false))) (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col6 (type: int), _col7 (type: string), _col8 (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Map-reduce partition columns: _col2 (type: string)
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: DELETE
        Reducer 4 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: (_col1 > 1L) (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: cardinality_violation(_col0) (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.merge_tmp_table
        Reducer 5 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: string), VALUE._col2 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tmerge
                  Write Type: INSERT

  Stage: Stage-4
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: DELETE

  Stage: Stage-2
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.merge_tmp_table

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tmerge
          Write Type: INSERT

PREHOOK: query: DROP TABLE tmerge
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tmerge
PREHOOK: Output: default@tmerge
POSTHOOK: query: DROP TABLE tmerge
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tmerge
POSTHOOK: Output: default@tmerge
PREHOOK: query: DROP TABLE nonacid
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@nonacid
PREHOOK: Output: default@nonacid
POSTHOOK: query: DROP TABLE nonacid
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@nonacid
POSTHOOK: Output: default@nonacid
PREHOOK: query: CREATE TABLE numericDataType(a TINYINT CONSTRAINT tinyint_constraint DEFAULT 127Y ENABLE,
    b bigint CONSTRAINT check1 CHECK b in(4,5) ENABLE)
    clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@numericDataType
POSTHOOK: query: CREATE TABLE numericDataType(a TINYINT CONSTRAINT tinyint_constraint DEFAULT 127Y ENABLE,
    b bigint CONSTRAINT check1 CHECK b in(4,5) ENABLE)
    clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@numericDataType
PREHOOK: query: DESC FORMATTED numericDataType
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@numericdatatype
POSTHOOK: query: DESC FORMATTED numericDataType
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@numericdatatype
# col_name            	data_type           	comment             
a                   	tinyint             	                    
b                   	bigint              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[b]                 	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Default Constraints	 	 
Table:              	default.numericdatatype	 
Constraint Name:    	tinyint_constraint  	 
Column Name:a       	Default Value:127Y  	 
	 	 
	 	 
# Check Constraints	 	 
Table:              	default.numericdatatype	 
Constraint Name:    	check1              	 
Column Name:b       	Check Value:b in(4,5)	 
	 	 
PREHOOK: query: ALTER TABLE numericDataType DROP CONSTRAINT check1
PREHOOK: type: ALTERTABLE_DROPCONSTRAINT
POSTHOOK: query: ALTER TABLE numericDataType DROP CONSTRAINT check1
POSTHOOK: type: ALTERTABLE_DROPCONSTRAINT
PREHOOK: query: DESC FORMATTED numericDataType
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@numericdatatype
POSTHOOK: query: DESC FORMATTED numericDataType
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@numericdatatype
# col_name            	data_type           	comment             
a                   	tinyint             	                    
b                   	bigint              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[b]                 	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Default Constraints	 	 
Table:              	default.numericdatatype	 
Constraint Name:    	tinyint_constraint  	 
Column Name:a       	Default Value:127Y  	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO numericDataType(b) values(456)
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO numericDataType(b) values(456)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(456)) (type: array<struct<col1:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: 127Y (type: tinyint), col1 (type: int)
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          sort order: 
                          Map-reduce partition columns: UDFToLong(_col1) (type: bigint)
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col0 (type: tinyint), _col1 (type: int)
            Execution mode: llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: tinyint), UDFToLong(VALUE._col1) (type: bigint)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.numericdatatype
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.numericdatatype
          Write Type: INSERT

PREHOOK: query: INSERT INTO numericDataType(b) values(456)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@numericdatatype
POSTHOOK: query: INSERT INTO numericDataType(b) values(456)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@numericdatatype
POSTHOOK: Lineage: numericdatatype.a SIMPLE []
POSTHOOK: Lineage: numericdatatype.b SCRIPT []
PREHOOK: query: SELECT * from numericDataType
PREHOOK: type: QUERY
PREHOOK: Input: default@numericdatatype
#### A masked pattern was here ####
POSTHOOK: query: SELECT * from numericDataType
POSTHOOK: type: QUERY
POSTHOOK: Input: default@numericdatatype
#### A masked pattern was here ####
127	456
PREHOOK: query: DROP TABLE numericDataType
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@numericdatatype
PREHOOK: Output: default@numericdatatype
POSTHOOK: query: DROP TABLE numericDataType
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@numericdatatype
POSTHOOK: Output: default@numericdatatype
PREHOOK: query: CREATE TABLE tcheck(a TINYINT, b bigint CONSTRAINT check1 CHECK b in(4,5) ENABLE)
    clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tcheck
POSTHOOK: query: CREATE TABLE tcheck(a TINYINT, b bigint CONSTRAINT check1 CHECK b in(4,5) ENABLE)
    clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tcheck
PREHOOK: query: DESC FORMATTED tcheck
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tcheck
POSTHOOK: query: DESC FORMATTED tcheck
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tcheck
# col_name            	data_type           	comment             
a                   	tinyint             	                    
b                   	bigint              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	transactional       	true                
	transactional_properties	default             
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	2                   	 
Bucket Columns:     	[b]                 	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tcheck      	 
Constraint Name:    	check1              	 
Column Name:b       	Check Value:b in(4,5)	 
	 	 
PREHOOK: query: EXPLAIN INSERT INTO tcheck(a) values(1)
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO tcheck(a) values(1)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(1)) (type: array<struct<col1:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: int), null (type: bigint)
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((null) IN (4, 5) is not false) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            sort order: 
                            Map-reduce partition columns: _col1 (type: bigint)
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col0 (type: int), _col1 (type: bigint)
            Execution mode: llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: UDFToByte(VALUE._col0) (type: tinyint), VALUE._col1 (type: bigint)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tcheck
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tcheck
          Write Type: INSERT

PREHOOK: query: EXPLAIN INSERT INTO tcheck(b) values(4)
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN INSERT INTO tcheck(b) values(4)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct(4)) (type: array<struct<col1:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: null (type: tinyint), col1 (type: int)
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((_col1) IN (4, 5) is not false) (type: boolean)
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                          Reduce Output Operator
                            sort order: 
                            Map-reduce partition columns: UDFToLong(_col1) (type: bigint)
                            Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                            value expressions: _col0 (type: tinyint), _col1 (type: int)
            Execution mode: llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: tinyint), UDFToLong(VALUE._col1) (type: bigint)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.tcheck
                  Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.tcheck
          Write Type: INSERT

PREHOOK: query: INSERT INTO tcheck(b) values(4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tcheck
POSTHOOK: query: INSERT INTO tcheck(b) values(4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tcheck
POSTHOOK: Lineage: tcheck.a SIMPLE []
POSTHOOK: Lineage: tcheck.b SCRIPT []
PREHOOK: query: SELECT * FROM tcheck
PREHOOK: type: QUERY
PREHOOK: Input: default@tcheck
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM tcheck
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tcheck
#### A masked pattern was here ####
NULL	4
PREHOOK: query: DROP TABLE tcheck
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tcheck
PREHOOK: Output: default@tcheck
POSTHOOK: query: DROP TABLE tcheck
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tcheck
POSTHOOK: Output: default@tcheck
PREHOOK: query: create table part_mm(key int check key > 0 and key < 5000 enforced) partitioned by (key_mm int)
    stored as orc tblproperties ("transactional"="true", "transactional_properties"="insert_only")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@part_mm
POSTHOOK: query: create table part_mm(key int check key > 0 and key < 5000 enforced) partitioned by (key_mm int)
    stored as orc tblproperties ("transactional"="true", "transactional_properties"="insert_only")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@part_mm
PREHOOK: query: explain insert into table part_mm partition(key_mm=455) select key from src order by value limit 3
PREHOOK: type: QUERY
POSTHOOK: query: explain insert into table part_mm partition(key_mm=455) select key from src order by value limit 3
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col1 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col0 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                Limit
                  Number of rows: 3
                  Statistics: Num rows: 3 Data size: 534 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: enforce_constraint(((_col0 > 0) and (_col0 < 5000)) is not false) (type: boolean)
                    Statistics: Num rows: 1 Data size: 178 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: UDFToInteger(_col0) (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                      File Output Operator
                        compressed: false
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                        table:
                            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                            name: default.part_mm
                        Write Type: INSERT

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            key_mm 455
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.part_mm
          micromanaged table: true

PREHOOK: query: insert into table part_mm partition(key_mm=455) select key from src order by value desc limit 3
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@part_mm@key_mm=455
POSTHOOK: query: insert into table part_mm partition(key_mm=455) select key from src order by value desc limit 3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@part_mm@key_mm=455
POSTHOOK: Lineage: part_mm PARTITION(key_mm=455).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
PREHOOK: query: select key from src order by value limit 3
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select key from src order by value limit 3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
0
0
0
PREHOOK: query: select * from part_mm
PREHOOK: type: QUERY
PREHOOK: Input: default@part_mm
PREHOOK: Input: default@part_mm@key_mm=455
#### A masked pattern was here ####
POSTHOOK: query: select * from part_mm
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part_mm
POSTHOOK: Input: default@part_mm@key_mm=455
#### A masked pattern was here ####
98	455
98	455
97	455
PREHOOK: query: drop table part_mm
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@part_mm
PREHOOK: Output: default@part_mm
POSTHOOK: query: drop table part_mm
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@part_mm
POSTHOOK: Output: default@part_mm
PREHOOK: query: create table trely(i int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@trely
POSTHOOK: query: create table trely(i int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@trely
PREHOOK: query: ALTER TABLE trely CHANGE i i int CHECK i>0 ENABLE NOVALIDATE RELY
PREHOOK: type: ALTERTABLE_RENAMECOL
PREHOOK: Input: default@trely
PREHOOK: Output: default@trely
POSTHOOK: query: ALTER TABLE trely CHANGE i i int CHECK i>0 ENABLE NOVALIDATE RELY
POSTHOOK: type: ALTERTABLE_RENAMECOL
POSTHOOK: Input: default@trely
POSTHOOK: Output: default@trely
PREHOOK: query: DESC FORMATTED trely
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@trely
POSTHOOK: query: DESC FORMATTED trely
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@trely
# col_name            	data_type           	comment             
i                   	int                 	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
#### A masked pattern was here ####
	transactional       	true                
	transactional_properties	insert_only         
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.trely       	 
Constraint Name:    	#### A masked pattern was here ####	 
Column Name:i       	Check Value:i>0     	 
	 	 
PREHOOK: query: DROP TABLE trely
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@trely
PREHOOK: Output: default@trely
POSTHOOK: query: DROP TABLE trely
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@trely
POSTHOOK: Output: default@trely
PREHOOK: query: create table tbl1(a string, b int, CONSTRAINT check1 CHECK a != '' AND b > 4)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tbl1
POSTHOOK: query: create table tbl1(a string, b int, CONSTRAINT check1 CHECK a != '' AND b > 4)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tbl1
PREHOOK: query: desc formatted tbl1
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tbl1
POSTHOOK: query: desc formatted tbl1
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tbl1
# col_name            	data_type           	comment             
a                   	string              	                    
b                   	int                 	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	transactional       	true                
	transactional_properties	insert_only         
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tbl1        	 
Constraint Name:    	check1              	 
Column Name:null    	Check Value:a != '' AND b > 4	 
	 	 
PREHOOK: query: explain insert into tbl1 values('a', 69)
PREHOOK: type: QUERY
POSTHOOK: query: explain insert into tbl1 values('a', 69)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('a',69)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int)
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint(((_col0 <> '') and (_col1 > 4)) is not false) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.tbl1
                            Write Type: INSERT
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tbl1
          micromanaged table: true

PREHOOK: query: insert into tbl1 values('a', 69)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@tbl1
POSTHOOK: query: insert into tbl1 values('a', 69)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@tbl1
POSTHOOK: Lineage: tbl1.a SCRIPT []
POSTHOOK: Lineage: tbl1.b SCRIPT []
PREHOOK: query: select * from tbl1
PREHOOK: type: QUERY
PREHOOK: Input: default@tbl1
#### A masked pattern was here ####
POSTHOOK: query: select * from tbl1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tbl1
#### A masked pattern was here ####
a	69
PREHOOK: query: ALTER TABLE tbl1 add constraint chk2 CHECK (b < 100)
PREHOOK: type: ALTERTABLE_ADDCONSTRAINT
POSTHOOK: query: ALTER TABLE tbl1 add constraint chk2 CHECK (b < 100)
POSTHOOK: type: ALTERTABLE_ADDCONSTRAINT
PREHOOK: query: desc formatted tbl1
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@tbl1
POSTHOOK: query: desc formatted tbl1
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@tbl1
# col_name            	data_type           	comment             
a                   	string              	                    
b                   	int                 	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	numFiles            	1                   
	totalSize           	5                   
	transactional       	true                
	transactional_properties	insert_only         
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
	 	 
# Constraints	 	 
	 	 
# Check Constraints	 	 
Table:              	default.tbl1        	 
Constraint Name:    	check1              	 
Column Name:null    	Check Value:a != '' AND b > 4	 
	 	 
Constraint Name:    	chk2                	 
Column Name:null    	Check Value:(b < 100)	 
	 	 
PREHOOK: query: explain insert into tbl1 values('a', 69)
PREHOOK: type: QUERY
POSTHOOK: query: explain insert into tbl1 values('a', 69)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: _dummy_table
                  Row Limit Per Split: 1
                  Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: array(const struct('a',69)) (type: array<struct<col1:string,col2:int>>)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                    UDTF Operator
                      Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                      function name: inline
                      Select Operator
                        expressions: col1 (type: string), col2 (type: int)
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        Filter Operator
                          predicate: enforce_constraint((((_col0 <> '') and (_col1 > 4)) is not false and (_col1 < 100) is not false)) (type: boolean)
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                name: default.tbl1
                            Write Type: INSERT
            Execution mode: llap
            LLAP IO: no inputs

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tbl1
          micromanaged table: true

PREHOOK: query: drop table tbl1
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@tbl1
PREHOOK: Output: default@tbl1
POSTHOOK: query: drop table tbl1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@tbl1
POSTHOOK: Output: default@tbl1
