PREHOOK: query: create table fact_daily_n3 (key String, value String) 
partitioned by (ds String, hr String)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@fact_daily_n3
POSTHOOK: query: create table fact_daily_n3 (key String, value String) 
partitioned by (ds String, hr String)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@fact_daily_n3
PREHOOK: query: insert overwrite table fact_daily_n3 partition (ds = '1', hr = '1')
select key, value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@fact_daily_n3@ds=1/hr=1
POSTHOOK: query: insert overwrite table fact_daily_n3 partition (ds = '1', hr = '1')
select key, value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@fact_daily_n3@ds=1/hr=1
POSTHOOK: Lineage: fact_daily_n3 PARTITION(ds=1,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: fact_daily_n3 PARTITION(ds=1,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: describe formatted fact_daily_n3 PARTITION (ds = '1', hr='1')
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@fact_daily_n3
POSTHOOK: query: describe formatted fact_daily_n3 PARTITION (ds = '1', hr='1')
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@fact_daily_n3
# col_name            	data_type           	comment             
key                 	string              	                    
value               	string              	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
hr                  	string              	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[1, 1]              	 
Database:           	default             	 
Table:              	fact_daily_n3       	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"key\":\"true\",\"value\":\"true\"}}
	numFiles            	1                   
	numRows             	500                 
	rawDataSize         	5312                
	totalSize           	5812                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: alter table fact_daily_n3 skewed by (key, value) on (('484','val_484'),('238','val_238')) stored as DIRECTORIES
PREHOOK: type: ALTERTABLE_SKEWED
PREHOOK: Input: default@fact_daily_n3
PREHOOK: Output: default@fact_daily_n3
POSTHOOK: query: alter table fact_daily_n3 skewed by (key, value) on (('484','val_484'),('238','val_238')) stored as DIRECTORIES
POSTHOOK: type: ALTERTABLE_SKEWED
POSTHOOK: Input: default@fact_daily_n3
POSTHOOK: Output: default@fact_daily_n3
PREHOOK: query: insert overwrite table fact_daily_n3 partition (ds = '1', hr = '2')
select key, value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@fact_daily_n3@ds=1/hr=2
POSTHOOK: query: insert overwrite table fact_daily_n3 partition (ds = '1', hr = '2')
select key, value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@fact_daily_n3@ds=1/hr=2
POSTHOOK: Lineage: fact_daily_n3 PARTITION(ds=1,hr=2).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: fact_daily_n3 PARTITION(ds=1,hr=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: describe formatted fact_daily_n3 PARTITION (ds = '1', hr='2')
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@fact_daily_n3
POSTHOOK: query: describe formatted fact_daily_n3 PARTITION (ds = '1', hr='2')
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@fact_daily_n3
# col_name            	data_type           	comment             
key                 	string              	                    
value               	string              	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
hr                  	string              	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[1, 2]              	 
Database:           	default             	 
Table:              	fact_daily_n3       	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"key\":\"true\",\"value\":\"true\"}}
	numFiles            	3                   
	numRows             	500                 
	rawDataSize         	5312                
	totalSize           	5812                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Stored As SubDirectories:	Yes                 	 
Skewed Columns:     	[key, value]        	 
Skewed Values:      	[[238, val_238], [484, val_484]]	 
#### A masked pattern was here ####
Skewed Value to Truncated Path:	{[238, val_238]=/fact_daily_n3/ds=1/hr=2/key=238/value=val_238, [484, val_484]=/fact_daily_n3/ds=1/hr=2/key=484/value=val_484}	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: alter table fact_daily_n3 skewed by (key, value) on (('327','val_327')) stored as DIRECTORIES
PREHOOK: type: ALTERTABLE_SKEWED
PREHOOK: Input: default@fact_daily_n3
PREHOOK: Output: default@fact_daily_n3
POSTHOOK: query: alter table fact_daily_n3 skewed by (key, value) on (('327','val_327')) stored as DIRECTORIES
POSTHOOK: type: ALTERTABLE_SKEWED
POSTHOOK: Input: default@fact_daily_n3
POSTHOOK: Output: default@fact_daily_n3
PREHOOK: query: insert overwrite table fact_daily_n3 partition (ds = '1', hr = '3')
select key, value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@fact_daily_n3@ds=1/hr=3
POSTHOOK: query: insert overwrite table fact_daily_n3 partition (ds = '1', hr = '3')
select key, value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@fact_daily_n3@ds=1/hr=3
POSTHOOK: Lineage: fact_daily_n3 PARTITION(ds=1,hr=3).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: fact_daily_n3 PARTITION(ds=1,hr=3).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: describe formatted fact_daily_n3 PARTITION (ds = '1', hr='3')
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@fact_daily_n3
POSTHOOK: query: describe formatted fact_daily_n3 PARTITION (ds = '1', hr='3')
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@fact_daily_n3
# col_name            	data_type           	comment             
key                 	string              	                    
value               	string              	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
hr                  	string              	                    
	 	 
# Detailed Partition Information	 	 
Partition Value:    	[1, 3]              	 
Database:           	default             	 
Table:              	fact_daily_n3       	 
#### A masked pattern was here ####
Partition Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"key\":\"true\",\"value\":\"true\"}}
	numFiles            	2                   
	numRows             	500                 
	rawDataSize         	5312                
	totalSize           	5812                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Stored As SubDirectories:	Yes                 	 
Skewed Columns:     	[key, value]        	 
Skewed Values:      	[[327, val_327]]    	 
#### A masked pattern was here ####
Skewed Value to Truncated Path:	{[327, val_327]=/fact_daily_n3/ds=1/hr=3/key=327/value=val_327}	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: explain extended
select * from fact_daily_n3 where ds = '1' and  hr='1' and key='145'
PREHOOK: type: QUERY
PREHOOK: Input: default@fact_daily_n3
PREHOOK: Input: default@fact_daily_n3@ds=1/hr=1
#### A masked pattern was here ####
POSTHOOK: query: explain extended
select * from fact_daily_n3 where ds = '1' and  hr='1' and key='145'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@fact_daily_n3
POSTHOOK: Input: default@fact_daily_n3@ds=1/hr=1
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT CAST('145' AS STRING) AS `key`, `value`, CAST('1' AS STRING) AS `ds`, CAST('1' AS STRING) AS `hr`
FROM `default`.`fact_daily_n3`
WHERE `key` = '145' AND `ds` = '1' AND `hr` = '1'
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: fact_daily_n3
            filterExpr: ((key = '145') and (ds = '1') and (hr = '1')) (type: boolean)
            Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (key = '145') (type: boolean)
              Statistics: Num rows: 2 Data size: 356 Basic stats: COMPLETE Column stats: COMPLETE
              Select Operator
                expressions: '145' (type: string), value (type: string), '1' (type: string), '1' (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 2 Data size: 696 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 2 Data size: 696 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0,_col1,_col2,_col3
                        columns.types string:string:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false
      Execution mode: vectorized
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: hr=1
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 1
              hr 1
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true","COLUMN_STATS":{"key":"true","value":"true"}}
              bucket_count -1
              column.name.delimiter ,
              columns key,value
              columns.comments 
              columns.types string:string
#### A masked pattern was here ####
              name default.fact_daily_n3
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct fact_daily_n3 { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 
                columns.types string:string
#### A masked pattern was here ####
                name default.fact_daily_n3
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct fact_daily_n3 { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.fact_daily_n3
            name: default.fact_daily_n3
      Truncated Path -> Alias:
        /fact_daily_n3/ds=1/hr=1 [fact_daily_n3]

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from fact_daily_n3 where ds = '1' and  hr='1' and key='145'
PREHOOK: type: QUERY
PREHOOK: Input: default@fact_daily_n3
PREHOOK: Input: default@fact_daily_n3@ds=1/hr=1
#### A masked pattern was here ####
POSTHOOK: query: select * from fact_daily_n3 where ds = '1' and  hr='1' and key='145'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@fact_daily_n3
POSTHOOK: Input: default@fact_daily_n3@ds=1/hr=1
#### A masked pattern was here ####
145	val_145	1	1
PREHOOK: query: explain extended
select count(*) from fact_daily_n3 where ds = '1' and  hr='1'
PREHOOK: type: QUERY
PREHOOK: Input: default@fact_daily_n3
#### A masked pattern was here ####
POSTHOOK: query: explain extended
select count(*) from fact_daily_n3 where ds = '1' and  hr='1'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@fact_daily_n3
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT COUNT(*) AS `$f0`
FROM `default`.`fact_daily_n3`
WHERE `ds` = '1' AND `hr` = '1'
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink

PREHOOK: query: select count(*) from fact_daily_n3 where ds = '1' and  hr='1'
PREHOOK: type: QUERY
PREHOOK: Input: default@fact_daily_n3
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from fact_daily_n3 where ds = '1' and  hr='1'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@fact_daily_n3
#### A masked pattern was here ####
500
PREHOOK: query: explain extended
SELECT * FROM fact_daily_n3 WHERE ds='1' and hr='2' and (key='484' and value='val_484')
PREHOOK: type: QUERY
PREHOOK: Input: default@fact_daily_n3
PREHOOK: Input: default@fact_daily_n3@ds=1/hr=2
#### A masked pattern was here ####
POSTHOOK: query: explain extended
SELECT * FROM fact_daily_n3 WHERE ds='1' and hr='2' and (key='484' and value='val_484')
POSTHOOK: type: QUERY
POSTHOOK: Input: default@fact_daily_n3
POSTHOOK: Input: default@fact_daily_n3@ds=1/hr=2
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT CAST('484' AS STRING) AS `$f0`, CAST('val_484' AS STRING) AS `$f1`, CAST('1' AS STRING) AS `$f2`, CAST('2' AS STRING) AS `$f3`
FROM `default`.`fact_daily_n3`
WHERE `key` = '484' AND `value` = 'val_484' AND `ds` = '1' AND `hr` = '2'
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: fact_daily_n3
            filterExpr: ((key = '484') and (value = 'val_484')) (type: boolean)
            Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: ((key = '484') and (value = 'val_484')) (type: boolean)
              Statistics: Num rows: 1 Data size: 178 Basic stats: COMPLETE Column stats: COMPLETE
              Select Operator
                expressions: '484' (type: string), 'val_484' (type: string), '1' (type: string), '2' (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 1 Data size: 348 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 1 Data size: 348 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0,_col1,_col2,_col3
                        columns.types string:string:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false
      Execution mode: vectorized
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: value=val_484
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 1
              hr 2
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true","COLUMN_STATS":{"key":"true","value":"true"}}
              bucket_count -1
              column.name.delimiter ,
              columns key,value
              columns.comments 
              columns.types string:string
#### A masked pattern was here ####
              name default.fact_daily_n3
              numFiles 3
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct fact_daily_n3 { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 
                columns.types string:string
#### A masked pattern was here ####
                name default.fact_daily_n3
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct fact_daily_n3 { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.fact_daily_n3
            name: default.fact_daily_n3
      Truncated Path -> Alias:
        /fact_daily_n3/ds=1/hr=2/key=484/value=val_484 [fact_daily_n3]

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT * FROM fact_daily_n3 WHERE ds='1' and hr='2' and (key='484' and value='val_484')
PREHOOK: type: QUERY
PREHOOK: Input: default@fact_daily_n3
PREHOOK: Input: default@fact_daily_n3@ds=1/hr=2
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM fact_daily_n3 WHERE ds='1' and hr='2' and (key='484' and value='val_484')
POSTHOOK: type: QUERY
POSTHOOK: Input: default@fact_daily_n3
POSTHOOK: Input: default@fact_daily_n3@ds=1/hr=2
#### A masked pattern was here ####
484	val_484	1	2
PREHOOK: query: explain extended
SELECT * FROM fact_daily_n3 WHERE ds='1' and hr='3' and (key='327' and value='val_327')
PREHOOK: type: QUERY
PREHOOK: Input: default@fact_daily_n3
PREHOOK: Input: default@fact_daily_n3@ds=1/hr=3
#### A masked pattern was here ####
POSTHOOK: query: explain extended
SELECT * FROM fact_daily_n3 WHERE ds='1' and hr='3' and (key='327' and value='val_327')
POSTHOOK: type: QUERY
POSTHOOK: Input: default@fact_daily_n3
POSTHOOK: Input: default@fact_daily_n3@ds=1/hr=3
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT CAST('327' AS STRING) AS `$f0`, CAST('val_327' AS STRING) AS `$f1`, CAST('1' AS STRING) AS `$f2`, CAST('3' AS STRING) AS `$f3`
FROM `default`.`fact_daily_n3`
WHERE `key` = '327' AND `value` = 'val_327' AND `ds` = '1' AND `hr` = '3'
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: fact_daily_n3
            filterExpr: ((key = '327') and (value = 'val_327')) (type: boolean)
            Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: ((key = '327') and (value = 'val_327')) (type: boolean)
              Statistics: Num rows: 1 Data size: 178 Basic stats: COMPLETE Column stats: COMPLETE
              Select Operator
                expressions: '327' (type: string), 'val_327' (type: string), '1' (type: string), '3' (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 1 Data size: 348 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 1 Data size: 348 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0,_col1,_col2,_col3
                        columns.types string:string:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false
      Execution mode: vectorized
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: value=val_327
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 1
              hr 3
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true","COLUMN_STATS":{"key":"true","value":"true"}}
              bucket_count -1
              column.name.delimiter ,
              columns key,value
              columns.comments 
              columns.types string:string
#### A masked pattern was here ####
              name default.fact_daily_n3
              numFiles 2
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct fact_daily_n3 { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 
                columns.types string:string
#### A masked pattern was here ####
                name default.fact_daily_n3
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct fact_daily_n3 { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.fact_daily_n3
            name: default.fact_daily_n3
      Truncated Path -> Alias:
        /fact_daily_n3/ds=1/hr=3/key=327/value=val_327 [fact_daily_n3]

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT * FROM fact_daily_n3 WHERE ds='1' and hr='3' and (key='327' and value='val_327')
PREHOOK: type: QUERY
PREHOOK: Input: default@fact_daily_n3
PREHOOK: Input: default@fact_daily_n3@ds=1/hr=3
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM fact_daily_n3 WHERE ds='1' and hr='3' and (key='327' and value='val_327')
POSTHOOK: type: QUERY
POSTHOOK: Input: default@fact_daily_n3
POSTHOOK: Input: default@fact_daily_n3@ds=1/hr=3
#### A masked pattern was here ####
327	val_327	1	3
327	val_327	1	3
327	val_327	1	3
