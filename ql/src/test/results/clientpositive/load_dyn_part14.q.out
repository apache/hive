PREHOOK: query: create table if not exists nzhang_part14 (key string) 
  partitioned by (value string)
PREHOOK: type: CREATETABLE
POSTHOOK: query: create table if not exists nzhang_part14 (key string) 
  partitioned by (value string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@nzhang_part14
PREHOOK: query: describe extended nzhang_part14
PREHOOK: type: DESCTABLE
POSTHOOK: query: describe extended nzhang_part14
POSTHOOK: type: DESCTABLE
key	string	
value	string	
	 	 
#### A masked pattern was here ####
PREHOOK: query: explain
insert overwrite table nzhang_part14 partition(value) 
select key, value from (
  select 'k1' as key, cast(null as string) as value from src limit 2
  union all
  select 'k2' as key, '' as value from src limit 2
  union all 
  select 'k3' as key, ' ' as value from src limit 2
) T
PREHOOK: type: QUERY
POSTHOOK: query: explain
insert overwrite table nzhang_part14 partition(value) 
select key, value from (
  select 'k1' as key, cast(null as string) as value from src limit 2
  union all
  select 'k2' as key, '' as value from src limit 2
  union all 
  select 'k3' as key, ' ' as value from src limit 2
) T
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_UNION (TOK_UNION (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR 'k1' key) (TOK_SELEXPR (TOK_FUNCTION TOK_STRING TOK_NULL) value)) (TOK_LIMIT 2))) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR 'k2' key) (TOK_SELEXPR '' value)) (TOK_LIMIT 2)))) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR 'k3' key) (TOK_SELEXPR ' ' value)) (TOK_LIMIT 2)))) T)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME nzhang_part14) (TOK_PARTSPEC (TOK_PARTVAL value)))) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1, Stage-9, Stage-10
  Stage-8 depends on stages: Stage-2 , consists of Stage-5, Stage-4, Stage-6
  Stage-5
  Stage-0 depends on stages: Stage-5, Stage-4, Stage-7
  Stage-3 depends on stages: Stage-0
  Stage-4
  Stage-6
  Stage-7 depends on stages: Stage-6
  Stage-9 is a root stage
  Stage-10 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        null-subquery1-subquery2:t-subquery1-subquery2:src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: 'k2'
                    type: string
                    expr: ''
                    type: string
              outputColumnNames: _col0, _col1
              Limit
                Reduce Output Operator
                  sort order: 
                  tag: -1
                  value expressions:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
#### A masked pattern was here ####
          TableScan
            Union
              Select Operator
                expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
                outputColumnNames: _col0, _col1
                File Output Operator
                  compressed: false
                  GlobalTableId: 1
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: default.nzhang_part14
#### A masked pattern was here ####
          TableScan
            Union
              Select Operator
                expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
                outputColumnNames: _col0, _col1
                File Output Operator
                  compressed: false
                  GlobalTableId: 1
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: default.nzhang_part14
#### A masked pattern was here ####
          TableScan
            Union
              Select Operator
                expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
                outputColumnNames: _col0, _col1
                File Output Operator
                  compressed: false
                  GlobalTableId: 1
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: default.nzhang_part14

  Stage: Stage-8
    Conditional Operator

  Stage: Stage-5
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            value 
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.nzhang_part14

  Stage: Stage-3
    Stats-Aggr Operator

  Stage: Stage-4
    Map Reduce
      Alias -> Map Operator Tree:
#### A masked pattern was here ####
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  name: default.nzhang_part14

  Stage: Stage-6
    Map Reduce
      Alias -> Map Operator Tree:
#### A masked pattern was here ####
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  name: default.nzhang_part14

  Stage: Stage-7
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-9
    Map Reduce
      Alias -> Map Operator Tree:
        null-subquery2:t-subquery2:src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: 'k3'
                    type: string
                    expr: ' '
                    type: string
              outputColumnNames: _col0, _col1
              Limit
                Reduce Output Operator
                  sort order: 
                  tag: -1
                  value expressions:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-10
    Map Reduce
      Alias -> Map Operator Tree:
        null-subquery1-subquery1:t-subquery1-subquery1:src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: 'k1'
                    type: string
                    expr: UDFToString(null)
                    type: string
              outputColumnNames: _col0, _col1
              Limit
                Reduce Output Operator
                  sort order: 
                  tag: -1
                  value expressions:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat


PREHOOK: query: insert overwrite table nzhang_part14 partition(value) 
select key, value from (
  select 'k1' as key, cast(null as string) as value from src limit 2
  union all
  select 'k2' as key, '' as value from src limit 2
  union all 
  select 'k3' as key, ' ' as value from src limit 2
) T
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@nzhang_part14
POSTHOOK: query: insert overwrite table nzhang_part14 partition(value) 
select key, value from (
  select 'k1' as key, cast(null as string) as value from src limit 2
  union all
  select 'k2' as key, '' as value from src limit 2
  union all 
  select 'k3' as key, ' ' as value from src limit 2
) T
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@nzhang_part14@value= 
POSTHOOK: Output: default@nzhang_part14@value=__HIVE_DEFAULT_PARTITION__
POSTHOOK: Lineage: nzhang_part14 PARTITION(value= ).key EXPRESSION []
POSTHOOK: Lineage: nzhang_part14 PARTITION(value=__HIVE_DEFAULT_PARTITION__).key EXPRESSION []
PREHOOK: query: show partitions nzhang_part14
PREHOOK: type: SHOWPARTITIONS
POSTHOOK: query: show partitions nzhang_part14
POSTHOOK: type: SHOWPARTITIONS
POSTHOOK: Lineage: nzhang_part14 PARTITION(value= ).key EXPRESSION []
POSTHOOK: Lineage: nzhang_part14 PARTITION(value=__HIVE_DEFAULT_PARTITION__).key EXPRESSION []
value= 
value=__HIVE_DEFAULT_PARTITION__
PREHOOK: query: select * from nzhang_part14 where value <> 'a'
order by key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@nzhang_part14@value= 
PREHOOK: Input: default@nzhang_part14@value=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: query: select * from nzhang_part14 where value <> 'a'
order by key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@nzhang_part14@value= 
POSTHOOK: Input: default@nzhang_part14@value=__HIVE_DEFAULT_PARTITION__
#### A masked pattern was here ####
POSTHOOK: Lineage: nzhang_part14 PARTITION(value= ).key EXPRESSION []
POSTHOOK: Lineage: nzhang_part14 PARTITION(value=__HIVE_DEFAULT_PARTITION__).key EXPRESSION []
k1	__HIVE_DEFAULT_PARTITION__
k1	__HIVE_DEFAULT_PARTITION__
k2	__HIVE_DEFAULT_PARTITION__
k2	__HIVE_DEFAULT_PARTITION__
k3	 
k3	 
