ECHO listPolicies originally was
Policy: RS-10-4-1024k DISABLED
Policy: RS-3-2-1024k ENABLED
Policy: RS-6-3-1024k ENABLED
Policy: RS-LEGACY-6-3-1024k DISABLED
Policy: XOR-2-1-1024k DISABLED
PREHOOK: query: show table extended like srcpart
PREHOOK: type: SHOW_TABLESTATUS
POSTHOOK: query: show table extended like srcpart
POSTHOOK: type: SHOW_TABLESTATUS
tableName:srcpart
#### A masked pattern was here ####
location:hdfs://### HDFS PATH ###
inputformat:org.apache.hadoop.mapred.TextInputFormat
outputformat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
columns:struct columns { string key, string value}
partitioned:true
partitionColumns:struct partition_columns { string ds, string hr}
totalNumberFiles:4
totalNumberErasureCodedFiles:4
totalFileSize:23248
maxFileSize:5812
minFileSize:5812
#### A masked pattern was here ####

PREHOOK: query: desc formatted srcpart
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@srcpart
POSTHOOK: query: desc formatted srcpart
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@srcpart
# col_name            	data_type           	comment             
key                 	string              	default             
value               	string              	default             
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
ds                  	string              	                    
hr                  	string              	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\"}
	bucketing_version   	2                   
	numFiles            	4                   
	numFilesErasureCoded	4                   
	numPartitions       	4                   
	numRows             	2000                
	rawDataSize         	21248               
	totalSize           	23248               
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: explain select key, value from srcpart
PREHOOK: type: QUERY
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select key, value from srcpart
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: srcpart
          Statistics: Num rows: 2000 Data size: 356000 Erasure files: 4 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: key (type: string), value (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 2000 Data size: 356000 Erasure files: 4 Basic stats: COMPLETE Column stats: COMPLETE
            ListSink

PREHOOK: query: explain extended select key, value from srcpart
PREHOOK: type: QUERY
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain extended select key, value from srcpart
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
POSTHOOK: Output: hdfs://### HDFS PATH ###
OPTIMIZED SQL: SELECT `key`, `value`
FROM `default`.`srcpart`
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Partition Description:
          Partition
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
              hr 11
            properties:
              column.name.delimiter ,
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              location hdfs://### HDFS PATH ###
              name default.srcpart
              numFilesErasureCoded 1
              partition_columns ds/hr
              partition_columns.types string:string
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                location hdfs://### HDFS PATH ###
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
          Partition
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
              hr 12
            properties:
              column.name.delimiter ,
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              location hdfs://### HDFS PATH ###
              name default.srcpart
              numFilesErasureCoded 1
              partition_columns ds/hr
              partition_columns.types string:string
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                location hdfs://### HDFS PATH ###
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
          Partition
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-09
              hr 11
            properties:
              column.name.delimiter ,
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              location hdfs://### HDFS PATH ###
              name default.srcpart
              numFilesErasureCoded 1
              partition_columns ds/hr
              partition_columns.types string:string
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                location hdfs://### HDFS PATH ###
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
          Partition
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-09
              hr 12
            properties:
              column.name.delimiter ,
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              location hdfs://### HDFS PATH ###
              name default.srcpart
              numFilesErasureCoded 1
              partition_columns ds/hr
              partition_columns.types string:string
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                location hdfs://### HDFS PATH ###
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
      Processor Tree:
        TableScan
          alias: srcpart
          Statistics: Num rows: 2000 Data size: 356000 Erasure files: 4 Basic stats: COMPLETE Column stats: COMPLETE
          GatherStats: false
          Select Operator
            expressions: key (type: string), value (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 2000 Data size: 356000 Erasure files: 4 Basic stats: COMPLETE Column stats: COMPLETE
            ListSink

PREHOOK: query: show table extended like src
PREHOOK: type: SHOW_TABLESTATUS
POSTHOOK: query: show table extended like src
POSTHOOK: type: SHOW_TABLESTATUS
tableName:src
#### A masked pattern was here ####
location:hdfs://### HDFS PATH ###
inputformat:org.apache.hadoop.mapred.TextInputFormat
outputformat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
columns:struct columns { string key, string value}
partitioned:false
partitionColumns:
totalNumberFiles:1
totalNumberErasureCodedFiles:1
totalFileSize:5812
maxFileSize:5812
minFileSize:5812
#### A masked pattern was here ####

PREHOOK: query: desc formatted src
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@src
POSTHOOK: query: desc formatted src
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@src
# col_name            	data_type           	comment             
key                 	string              	default             
value               	string              	default             
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"key\":\"true\",\"value\":\"true\"}}
	bucketing_version   	2                   
	numFiles            	1                   
	numFilesErasureCoded	1                   
	numRows             	500                 
	rawDataSize         	5312                
	totalSize           	5812                
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: explain select key, value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select key, value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: src
          Statistics: Num rows: 500 Data size: 89000 Erasure files: 1 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: key (type: string), value (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 500 Data size: 89000 Erasure files: 1 Basic stats: COMPLETE Column stats: COMPLETE
            ListSink

PREHOOK: query: explain extended select key, value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain extended select key, value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: hdfs://### HDFS PATH ###
OPTIMIZED SQL: SELECT `key`, `value`
FROM `default`.`src`
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: src
          Statistics: Num rows: 500 Data size: 89000 Erasure files: 1 Basic stats: COMPLETE Column stats: COMPLETE
          GatherStats: false
          Select Operator
            expressions: key (type: string), value (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 500 Data size: 89000 Erasure files: 1 Basic stats: COMPLETE Column stats: COMPLETE
            ListSink

