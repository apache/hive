PREHOOK: query: CREATE TABLE dest_j1(key STRING, cnt INT)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
POSTHOOK: query: CREATE TABLE dest_j1(key STRING, cnt INT)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@dest_j1
PREHOOK: query: -- Since the inputs are small, it should be automatically converted to mapjoin

EXPLAIN 
INSERT OVERWRITE TABLE dest_j1 
SELECT subq1.key, count(1) as cnt
FROM (select x.key, count(1) as cnt from src1 x group by x.key) subq1 JOIN 
     (select y.key, count(1) as cnt from src y group by y.key) subq2 ON (subq1.key = subq2.key)
group by subq1.key
PREHOOK: type: QUERY
POSTHOOK: query: -- Since the inputs are small, it should be automatically converted to mapjoin

EXPLAIN 
INSERT OVERWRITE TABLE dest_j1 
SELECT subq1.key, count(1) as cnt
FROM (select x.key, count(1) as cnt from src1 x group by x.key) subq1 JOIN 
     (select y.key, count(1) as cnt from src y group by y.key) subq2 ON (subq1.key = subq2.key)
group by subq1.key
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-8 depends on stages: Stage-1, Stage-5 , consists of Stage-9, Stage-10, Stage-2
  Stage-9 has a backup stage: Stage-2
  Stage-6 depends on stages: Stage-9
  Stage-3 depends on stages: Stage-2, Stage-6, Stage-7
  Stage-0 depends on stages: Stage-3
  Stage-4 depends on stages: Stage-0
  Stage-10 has a backup stage: Stage-2
  Stage-7 depends on stages: Stage-10
  Stage-2
  Stage-5 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: y
            Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: key (type: string)
              outputColumnNames: key
              Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1)
                keys: key (type: string)
                mode: hash
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 29 Data size: 2906 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: _col0 (type: string)
            outputColumnNames: _col0
            Statistics: Num rows: 29 Data size: 2906 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-8
    Conditional Operator

  Stage: Stage-9
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $INTNAME 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $INTNAME 
          TableScan
            HashTable Sink Operator
              condition expressions:
                0 {_col0}
                1 
              keys:
                0 _col0 (type: string)
                1 _col0 (type: string)

  Stage: Stage-6
    Map Reduce
      Map Operator Tree:
          TableScan
            Map Join Operator
              condition map:
                   Inner Join 0 to 1
              condition expressions:
                0 {_col0}
                1 
              keys:
                0 _col0 (type: string)
                1 _col0 (type: string)
              outputColumnNames: _col0
              Select Operator
                expressions: _col0 (type: string)
                outputColumnNames: _col0
                Group By Operator
                  aggregations: count(1)
                  keys: _col0 (type: string)
                  mode: hash
                  outputColumnNames: _col0, _col1
                  File Output Operator
                    compressed: false
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
      Local Work:
        Map Reduce Local Work

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Map-reduce partition columns: _col0 (type: string)
              Statistics: Num rows: 31 Data size: 3196 Basic stats: COMPLETE Column stats: NONE
              value expressions: _col1 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 15 Data size: 1546 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: _col0 (type: string), UDFToInteger(_col1) (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 15 Data size: 1546 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              Statistics: Num rows: 15 Data size: 1546 Basic stats: COMPLETE Column stats: NONE
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  name: default.dest_j1

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.dest_j1

  Stage: Stage-4
    Stats-Aggr Operator

  Stage: Stage-10
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $INTNAME1 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $INTNAME1 
          TableScan
            HashTable Sink Operator
              condition expressions:
                0 {_col0}
                1 
              keys:
                0 _col0 (type: string)
                1 _col0 (type: string)

  Stage: Stage-7
    Map Reduce
      Map Operator Tree:
          TableScan
            Map Join Operator
              condition map:
                   Inner Join 0 to 1
              condition expressions:
                0 {_col0}
                1 
              keys:
                0 _col0 (type: string)
                1 _col0 (type: string)
              outputColumnNames: _col0
              Select Operator
                expressions: _col0 (type: string)
                outputColumnNames: _col0
                Group By Operator
                  aggregations: count(1)
                  keys: _col0 (type: string)
                  mode: hash
                  outputColumnNames: _col0, _col1
                  File Output Operator
                    compressed: false
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
      Local Work:
        Map Reduce Local Work

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Map-reduce partition columns: _col0 (type: string)
              Statistics: Num rows: 29 Data size: 2906 Basic stats: COMPLETE Column stats: NONE
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Map-reduce partition columns: _col0 (type: string)
              Statistics: Num rows: 1 Data size: 108 Basic stats: COMPLETE Column stats: NONE
              value expressions: _col0 (type: string)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0}
            1 
          outputColumnNames: _col0
          Statistics: Num rows: 31 Data size: 3196 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: _col0 (type: string)
            outputColumnNames: _col0
            Statistics: Num rows: 31 Data size: 3196 Basic stats: COMPLETE Column stats: NONE
            Group By Operator
              aggregations: count(1)
              keys: _col0 (type: string)
              mode: hash
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 31 Data size: 3196 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-5
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: x
            Statistics: Num rows: 2 Data size: 216 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: key (type: string)
              outputColumnNames: key
              Statistics: Num rows: 2 Data size: 216 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1)
                keys: key (type: string)
                mode: hash
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 2 Data size: 216 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 2 Data size: 216 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 1 Data size: 108 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: _col0 (type: string)
            outputColumnNames: _col0
            Statistics: Num rows: 1 Data size: 108 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

PREHOOK: query: INSERT OVERWRITE TABLE dest_j1 
SELECT subq1.key, count(1) as cnt
FROM (select x.key, count(1) as cnt from src1 x group by x.key) subq1 JOIN 
     (select y.key, count(1) as cnt from src y group by y.key) subq2 ON (subq1.key = subq2.key)
group by subq1.key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Input: default@src1
PREHOOK: Output: default@dest_j1
POSTHOOK: query: INSERT OVERWRITE TABLE dest_j1 
SELECT subq1.key, count(1) as cnt
FROM (select x.key, count(1) as cnt from src1 x group by x.key) subq1 JOIN 
     (select y.key, count(1) as cnt from src y group by y.key) subq2 ON (subq1.key = subq2.key)
group by subq1.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Input: default@src1
POSTHOOK: Output: default@dest_j1
POSTHOOK: Lineage: dest_j1.cnt EXPRESSION [(src1)x.null, (src)y.null, ]
POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
PREHOOK: query: select * from dest_j1 x order by x.key
PREHOOK: type: QUERY
PREHOOK: Input: default@dest_j1
#### A masked pattern was here ####
POSTHOOK: query: select * from dest_j1 x order by x.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest_j1
#### A masked pattern was here ####
POSTHOOK: Lineage: dest_j1.cnt EXPRESSION [(src1)x.null, (src)y.null, ]
POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
128	1
146	1
150	1
213	1
224	1
238	1
255	1
273	1
278	1
311	1
369	1
401	1
406	1
66	1
98	1
