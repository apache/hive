PREHOOK: query: explain
select  
 'web' as channel
 ,web.item
 ,web.return_ratio
 ,web.return_rank
 ,web.currency_rank
 from (
 	select 
 	 item
 	,return_ratio
 	,currency_ratio
 	,rank() over (order by return_ratio) as return_rank
 	,rank() over (order by currency_ratio) as currency_rank
 	from
 	(	select ws.ws_item_sk as item
 		,(cast(sum(coalesce(wr.wr_return_quantity,0)) as dec(15,4))/
 		cast(sum(coalesce(ws.ws_quantity,0)) as dec(15,4) )) as return_ratio
 		,(cast(sum(coalesce(wr.wr_return_amt,0)) as dec(15,4))/
 		cast(sum(coalesce(ws.ws_net_paid,0)) as dec(15,4) )) as currency_ratio
 		from 
 		 web_sales ws left outer join web_returns wr 
 			on (ws.ws_order_number = wr.wr_order_number and 
 			ws.ws_item_sk = wr.wr_item_sk)
                 ,date_dim
 		where 
 			wr.wr_return_amt > 10000 
 			and ws.ws_net_profit > 1
                         and ws.ws_net_paid > 0
                         and ws.ws_quantity > 0
                         and ws_sold_date_sk = d_date_sk
                         and d_year = 2000
                         and d_moy = 12
 		group by ws.ws_item_sk
 	) in_web
 ) web
 where 
 (
 web.return_rank <= 10
 or
 web.currency_rank <= 10
 )
 union
 select 
 'catalog' as channel
 ,catalog.item
 ,catalog.return_ratio
 ,catalog.return_rank
 ,catalog.currency_rank
 from (
 	select 
 	 item
 	,return_ratio
 	,currency_ratio
 	,rank() over (order by return_ratio) as return_rank
 	,rank() over (order by currency_ratio) as currency_rank
 	from
 	(	select 
 		cs.cs_item_sk as item
 		,(cast(sum(coalesce(cr.cr_return_quantity,0)) as dec(15,4))/
 		cast(sum(coalesce(cs.cs_quantity,0)) as dec(15,4) )) as return_ratio
 		,(cast(sum(coalesce(cr.cr_return_amount,0)) as dec(15,4))/
 		cast(sum(coalesce(cs.cs_net_paid,0)) as dec(15,4) )) as currency_ratio
 		from 
 		catalog_sales cs left outer join catalog_returns cr
 			on (cs.cs_order_number = cr.cr_order_number and 
 			cs.cs_item_sk = cr.cr_item_sk)
                ,date_dim
 		where 
 			cr.cr_return_amount > 10000 
 			and cs.cs_net_profit > 1
                         and cs.cs_net_paid > 0
                         and cs.cs_quantity > 0
                         and cs_sold_date_sk = d_date_sk
                         and d_year = 2000
                         and d_moy = 12
                 group by cs.cs_item_sk
 	) in_cat
 ) catalog
 where 
 (
 catalog.return_rank <= 10
 or
 catalog.currency_rank <=10
 )
 union
 select 
 'store' as channel
 ,store.item
 ,store.return_ratio
 ,store.return_rank
 ,store.currency_rank
 from (
 	select 
 	 item
 	,return_ratio
 	,currency_ratio
 	,rank() over (order by return_ratio) as return_rank
 	,rank() over (order by currency_ratio) as currency_rank
 	from
 	(	select sts.ss_item_sk as item
 		,(cast(sum(coalesce(sr.sr_return_quantity,0)) as dec(15,4))/cast(sum(coalesce(sts.ss_quantity,0)) as dec(15,4) )) as return_ratio
 		,(cast(sum(coalesce(sr.sr_return_amt,0)) as dec(15,4))/cast(sum(coalesce(sts.ss_net_paid,0)) as dec(15,4) )) as currency_ratio
 		from 
 		store_sales sts left outer join store_returns sr
 			on (sts.ss_ticket_number = sr.sr_ticket_number and sts.ss_item_sk = sr.sr_item_sk)
                ,date_dim
 		where 
 			sr.sr_return_amt > 10000 
 			and sts.ss_net_profit > 1
                         and sts.ss_net_paid > 0 
                         and sts.ss_quantity > 0
                         and ss_sold_date_sk = d_date_sk
                         and d_year = 2000
                         and d_moy = 12
 		group by sts.ss_item_sk
 	) in_store
 ) store
 where  (
 store.return_rank <= 10
 or 
 store.currency_rank <= 10
 )
 order by 1,4,5
 limit 100
PREHOOK: type: QUERY
PREHOOK: Input: default@catalog_returns
PREHOOK: Input: default@catalog_sales
PREHOOK: Input: default@date_dim
PREHOOK: Input: default@store_returns
PREHOOK: Input: default@store_sales
PREHOOK: Input: default@web_returns
PREHOOK: Input: default@web_sales
#### A masked pattern was here ####
POSTHOOK: query: explain
select  
 'web' as channel
 ,web.item
 ,web.return_ratio
 ,web.return_rank
 ,web.currency_rank
 from (
 	select 
 	 item
 	,return_ratio
 	,currency_ratio
 	,rank() over (order by return_ratio) as return_rank
 	,rank() over (order by currency_ratio) as currency_rank
 	from
 	(	select ws.ws_item_sk as item
 		,(cast(sum(coalesce(wr.wr_return_quantity,0)) as dec(15,4))/
 		cast(sum(coalesce(ws.ws_quantity,0)) as dec(15,4) )) as return_ratio
 		,(cast(sum(coalesce(wr.wr_return_amt,0)) as dec(15,4))/
 		cast(sum(coalesce(ws.ws_net_paid,0)) as dec(15,4) )) as currency_ratio
 		from 
 		 web_sales ws left outer join web_returns wr 
 			on (ws.ws_order_number = wr.wr_order_number and 
 			ws.ws_item_sk = wr.wr_item_sk)
                 ,date_dim
 		where 
 			wr.wr_return_amt > 10000 
 			and ws.ws_net_profit > 1
                         and ws.ws_net_paid > 0
                         and ws.ws_quantity > 0
                         and ws_sold_date_sk = d_date_sk
                         and d_year = 2000
                         and d_moy = 12
 		group by ws.ws_item_sk
 	) in_web
 ) web
 where 
 (
 web.return_rank <= 10
 or
 web.currency_rank <= 10
 )
 union
 select 
 'catalog' as channel
 ,catalog.item
 ,catalog.return_ratio
 ,catalog.return_rank
 ,catalog.currency_rank
 from (
 	select 
 	 item
 	,return_ratio
 	,currency_ratio
 	,rank() over (order by return_ratio) as return_rank
 	,rank() over (order by currency_ratio) as currency_rank
 	from
 	(	select 
 		cs.cs_item_sk as item
 		,(cast(sum(coalesce(cr.cr_return_quantity,0)) as dec(15,4))/
 		cast(sum(coalesce(cs.cs_quantity,0)) as dec(15,4) )) as return_ratio
 		,(cast(sum(coalesce(cr.cr_return_amount,0)) as dec(15,4))/
 		cast(sum(coalesce(cs.cs_net_paid,0)) as dec(15,4) )) as currency_ratio
 		from 
 		catalog_sales cs left outer join catalog_returns cr
 			on (cs.cs_order_number = cr.cr_order_number and 
 			cs.cs_item_sk = cr.cr_item_sk)
                ,date_dim
 		where 
 			cr.cr_return_amount > 10000 
 			and cs.cs_net_profit > 1
                         and cs.cs_net_paid > 0
                         and cs.cs_quantity > 0
                         and cs_sold_date_sk = d_date_sk
                         and d_year = 2000
                         and d_moy = 12
                 group by cs.cs_item_sk
 	) in_cat
 ) catalog
 where 
 (
 catalog.return_rank <= 10
 or
 catalog.currency_rank <=10
 )
 union
 select 
 'store' as channel
 ,store.item
 ,store.return_ratio
 ,store.return_rank
 ,store.currency_rank
 from (
 	select 
 	 item
 	,return_ratio
 	,currency_ratio
 	,rank() over (order by return_ratio) as return_rank
 	,rank() over (order by currency_ratio) as currency_rank
 	from
 	(	select sts.ss_item_sk as item
 		,(cast(sum(coalesce(sr.sr_return_quantity,0)) as dec(15,4))/cast(sum(coalesce(sts.ss_quantity,0)) as dec(15,4) )) as return_ratio
 		,(cast(sum(coalesce(sr.sr_return_amt,0)) as dec(15,4))/cast(sum(coalesce(sts.ss_net_paid,0)) as dec(15,4) )) as currency_ratio
 		from 
 		store_sales sts left outer join store_returns sr
 			on (sts.ss_ticket_number = sr.sr_ticket_number and sts.ss_item_sk = sr.sr_item_sk)
                ,date_dim
 		where 
 			sr.sr_return_amt > 10000 
 			and sts.ss_net_profit > 1
                         and sts.ss_net_paid > 0 
                         and sts.ss_quantity > 0
                         and ss_sold_date_sk = d_date_sk
                         and d_year = 2000
                         and d_moy = 12
 		group by sts.ss_item_sk
 	) in_store
 ) store
 where  (
 store.return_rank <= 10
 or 
 store.currency_rank <= 10
 )
 order by 1,4,5
 limit 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@catalog_returns
POSTHOOK: Input: default@catalog_sales
POSTHOOK: Input: default@date_dim
POSTHOOK: Input: default@store_returns
POSTHOOK: Input: default@store_sales
POSTHOOK: Input: default@web_returns
POSTHOOK: Input: default@web_sales
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 10 <- Map 9 (SIMPLE_EDGE)
        Reducer 11 <- Reducer 10 (SIMPLE_EDGE), Union 4 (CONTAINS)
        Reducer 13 <- Map 12 (SIMPLE_EDGE)
        Reducer 14 <- Reducer 13 (SIMPLE_EDGE), Union 6 (CONTAINS)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE), Union 4 (CONTAINS)
        Reducer 5 <- Union 4 (SIMPLE_EDGE), Union 6 (CONTAINS)
        Reducer 7 <- Union 6 (SIMPLE_EDGE)
        Reducer 8 <- Reducer 7 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: ws
                  properties:
                    hive.sql.query SELECT "t1"."ws_item_sk", SUM("t7"."CASE") AS "$f1", SUM("t1"."CASE") AS "$f2", SUM("t7"."CASE3") AS "$f3", SUM("t1"."CASE4") AS "$f4"
FROM (SELECT "ws_sold_date_sk", "ws_item_sk", "ws_order_number", CASE WHEN "ws_quantity" IS NOT NULL THEN "ws_quantity" ELSE 0 END AS "CASE", CASE WHEN "ws_net_paid" IS NOT NULL THEN "ws_net_paid" ELSE 0 END AS "CASE4"
FROM (SELECT "ws_sold_date_sk", "ws_item_sk", "ws_order_number", "ws_quantity", "ws_net_paid", "ws_net_profit"
FROM "web_sales") AS "t"
WHERE "ws_quantity" > 0 AND ("ws_net_profit" > 1 AND "ws_net_paid" > 0) AND ("ws_order_number" IS NOT NULL AND ("ws_item_sk" IS NOT NULL AND "ws_sold_date_sk" IS NOT NULL))) AS "t1"
INNER JOIN (SELECT "d_date_sk"
FROM (SELECT "d_date_sk", "d_year", "d_moy"
FROM "date_dim") AS "t2"
WHERE "d_year" = 2000 AND ("d_moy" = 12 AND "d_date_sk" IS NOT NULL)) AS "t4" ON "t1"."ws_sold_date_sk" = "t4"."d_date_sk"
INNER JOIN (SELECT "wr_item_sk", "wr_order_number", CASE WHEN "wr_return_quantity" IS NOT NULL THEN "wr_return_quantity" ELSE 0 END AS "CASE", CASE WHEN "wr_return_amt" IS NOT NULL THEN "wr_return_amt" ELSE 0 END AS "CASE3"
FROM (SELECT "wr_item_sk", "wr_order_number", "wr_return_quantity", "wr_return_amt"
FROM "web_returns") AS "t5"
WHERE "wr_return_amt" > 10000 AND ("wr_order_number" IS NOT NULL AND "wr_item_sk" IS NOT NULL)) AS "t7" ON "t1"."ws_order_number" = "t7"."wr_order_number" AND "t1"."ws_item_sk" = "t7"."wr_item_sk"
GROUP BY "t1"."ws_item_sk"
                    hive.sql.query.fieldNames ws_item_sk,$f1,$f2,$f3,$f4
                    hive.sql.query.fieldTypes bigint,bigint,bigint,decimal(22,2),decimal(22,2)
                    hive.sql.query.split false
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: ws_item_sk (type: bigint), $f1 (type: bigint), $f2 (type: bigint), $f3 (type: decimal(22,2)), $f4 (type: decimal(22,2))
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: 0 (type: int), (CAST( _col1 AS decimal(15,4)) / CAST( _col2 AS decimal(15,4))) (type: decimal(35,20))
                      null sort order: az
                      sort order: ++
                      Map-reduce partition columns: 0 (type: int)
                      Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: decimal(22,2)), _col4 (type: decimal(22,2))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Map 12 
            Map Operator Tree:
                TableScan
                  alias: sts
                  properties:
                    hive.sql.query SELECT "t1"."ss_item_sk", SUM("t7"."CASE") AS "$f1", SUM("t1"."CASE") AS "$f2", SUM("t7"."CASE3") AS "$f3", SUM("t1"."CASE4") AS "$f4"
FROM (SELECT "ss_sold_date_sk", "ss_item_sk", "ss_ticket_number", CASE WHEN "ss_quantity" IS NOT NULL THEN "ss_quantity" ELSE 0 END AS "CASE", CASE WHEN "ss_net_paid" IS NOT NULL THEN "ss_net_paid" ELSE 0 END AS "CASE4"
FROM (SELECT "ss_sold_date_sk", "ss_item_sk", "ss_ticket_number", "ss_quantity", "ss_net_paid", "ss_net_profit"
FROM "store_sales") AS "t"
WHERE "ss_quantity" > 0 AND ("ss_net_profit" > 1 AND "ss_net_paid" > 0) AND ("ss_ticket_number" IS NOT NULL AND ("ss_item_sk" IS NOT NULL AND "ss_sold_date_sk" IS NOT NULL))) AS "t1"
INNER JOIN (SELECT "d_date_sk"
FROM (SELECT "d_date_sk", "d_year", "d_moy"
FROM "date_dim") AS "t2"
WHERE "d_year" = 2000 AND ("d_moy" = 12 AND "d_date_sk" IS NOT NULL)) AS "t4" ON "t1"."ss_sold_date_sk" = "t4"."d_date_sk"
INNER JOIN (SELECT "sr_item_sk", "sr_ticket_number", CASE WHEN "sr_return_quantity" IS NOT NULL THEN "sr_return_quantity" ELSE 0 END AS "CASE", CASE WHEN "sr_return_amt" IS NOT NULL THEN "sr_return_amt" ELSE 0 END AS "CASE3"
FROM (SELECT "sr_item_sk", "sr_ticket_number", "sr_return_quantity", "sr_return_amt"
FROM "store_returns") AS "t5"
WHERE "sr_return_amt" > 10000 AND ("sr_ticket_number" IS NOT NULL AND "sr_item_sk" IS NOT NULL)) AS "t7" ON "t1"."ss_ticket_number" = "t7"."sr_ticket_number" AND "t1"."ss_item_sk" = "t7"."sr_item_sk"
GROUP BY "t1"."ss_item_sk"
                    hive.sql.query.fieldNames ss_item_sk,$f1,$f2,$f3,$f4
                    hive.sql.query.fieldTypes bigint,bigint,bigint,decimal(22,2),decimal(22,2)
                    hive.sql.query.split false
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: ss_item_sk (type: bigint), $f1 (type: bigint), $f2 (type: bigint), $f3 (type: decimal(22,2)), $f4 (type: decimal(22,2))
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: 0 (type: int), (CAST( _col1 AS decimal(15,4)) / CAST( _col2 AS decimal(15,4))) (type: decimal(35,20))
                      null sort order: az
                      sort order: ++
                      Map-reduce partition columns: 0 (type: int)
                      Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: decimal(22,2)), _col4 (type: decimal(22,2))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Map 9 
            Map Operator Tree:
                TableScan
                  alias: cs
                  properties:
                    hive.sql.query SELECT "t1"."cs_item_sk", SUM("t7"."CASE") AS "$f1", SUM("t1"."CASE") AS "$f2", SUM("t7"."CASE3") AS "$f3", SUM("t1"."CASE4") AS "$f4"
FROM (SELECT "cs_sold_date_sk", "cs_item_sk", "cs_order_number", CASE WHEN "cs_quantity" IS NOT NULL THEN "cs_quantity" ELSE 0 END AS "CASE", CASE WHEN "cs_net_paid" IS NOT NULL THEN "cs_net_paid" ELSE 0 END AS "CASE4"
FROM (SELECT "cs_sold_date_sk", "cs_item_sk", "cs_order_number", "cs_quantity", "cs_net_paid", "cs_net_profit"
FROM "catalog_sales") AS "t"
WHERE "cs_quantity" > 0 AND ("cs_net_profit" > 1 AND "cs_net_paid" > 0) AND ("cs_order_number" IS NOT NULL AND ("cs_item_sk" IS NOT NULL AND "cs_sold_date_sk" IS NOT NULL))) AS "t1"
INNER JOIN (SELECT "d_date_sk"
FROM (SELECT "d_date_sk", "d_year", "d_moy"
FROM "date_dim") AS "t2"
WHERE "d_year" = 2000 AND ("d_moy" = 12 AND "d_date_sk" IS NOT NULL)) AS "t4" ON "t1"."cs_sold_date_sk" = "t4"."d_date_sk"
INNER JOIN (SELECT "cr_item_sk", "cr_order_number", CASE WHEN "cr_return_quantity" IS NOT NULL THEN "cr_return_quantity" ELSE 0 END AS "CASE", CASE WHEN "cr_return_amount" IS NOT NULL THEN "cr_return_amount" ELSE 0 END AS "CASE3"
FROM (SELECT "cr_item_sk", "cr_order_number", "cr_return_quantity", "cr_return_amount"
FROM "catalog_returns") AS "t5"
WHERE "cr_return_amount" > 10000 AND ("cr_order_number" IS NOT NULL AND "cr_item_sk" IS NOT NULL)) AS "t7" ON "t1"."cs_order_number" = "t7"."cr_order_number" AND "t1"."cs_item_sk" = "t7"."cr_item_sk"
GROUP BY "t1"."cs_item_sk"
                    hive.sql.query.fieldNames cs_item_sk,$f1,$f2,$f3,$f4
                    hive.sql.query.fieldTypes bigint,bigint,bigint,decimal(22,2),decimal(22,2)
                    hive.sql.query.split false
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: cs_item_sk (type: bigint), $f1 (type: bigint), $f2 (type: bigint), $f3 (type: decimal(22,2)), $f4 (type: decimal(22,2))
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: 0 (type: int), (CAST( _col1 AS decimal(15,4)) / CAST( _col2 AS decimal(15,4))) (type: decimal(35,20))
                      null sort order: az
                      sort order: ++
                      Map-reduce partition columns: 0 (type: int)
                      Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: decimal(22,2)), _col4 (type: decimal(22,2))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 10 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: bigint), VALUE._col1 (type: bigint), VALUE._col2 (type: bigint), VALUE._col3 (type: decimal(22,2)), VALUE._col4 (type: decimal(22,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: bigint, _col1: bigint, _col2: bigint, _col3: decimal(22,2), _col4: decimal(22,2)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: (CAST( _col1 AS decimal(15,4)) / CAST( _col2 AS decimal(15,4))) ASC NULLS LAST
                        partition by: 0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: (CAST( _col1 AS decimal(15,4)) / CAST( _col2 AS decimal(15,4)))
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: rank_window_0 (type: int), _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: decimal(22,2)), _col4 (type: decimal(22,2))
                    outputColumnNames: rank_window_0, _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: 0 (type: int), (CAST( _col3 AS decimal(15,4)) / CAST( _col4 AS decimal(15,4))) (type: decimal(35,20))
                      null sort order: az
                      sort order: ++
                      Map-reduce partition columns: 0 (type: int)
                      Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                      value expressions: rank_window_0 (type: int), _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: decimal(22,2)), _col4 (type: decimal(22,2))
        Reducer 11 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: bigint), VALUE._col2 (type: bigint), VALUE._col3 (type: bigint), VALUE._col4 (type: decimal(22,2)), VALUE._col5 (type: decimal(22,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: (CAST( _col4 AS decimal(15,4)) / CAST( _col5 AS decimal(15,4))) ASC NULLS LAST
                        partition by: 0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_1
                              arguments: (CAST( _col4 AS decimal(15,4)) / CAST( _col5 AS decimal(15,4)))
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col0 <= 10) or (rank_window_1 <= 10)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: 'catalog' (type: string), _col1 (type: bigint), (CAST( _col2 AS decimal(15,4)) / CAST( _col3 AS decimal(15,4))) (type: decimal(35,20)), _col0 (type: int), rank_window_1 (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: string), _col3 (type: int), _col4 (type: int), _col1 (type: bigint), _col2 (type: decimal(35,20))
                        minReductionHashAggr: 0.99
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4
                        Statistics: Num rows: 2 Data size: 496 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: int), _col3 (type: bigint), _col4 (type: decimal(35,20))
                          null sort order: zzzzz
                          sort order: +++++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: int), _col3 (type: bigint), _col4 (type: decimal(35,20))
                          Statistics: Num rows: 2 Data size: 496 Basic stats: COMPLETE Column stats: NONE
        Reducer 13 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: bigint), VALUE._col1 (type: bigint), VALUE._col2 (type: bigint), VALUE._col3 (type: decimal(22,2)), VALUE._col4 (type: decimal(22,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: bigint, _col1: bigint, _col2: bigint, _col3: decimal(22,2), _col4: decimal(22,2)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: (CAST( _col1 AS decimal(15,4)) / CAST( _col2 AS decimal(15,4))) ASC NULLS LAST
                        partition by: 0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: (CAST( _col1 AS decimal(15,4)) / CAST( _col2 AS decimal(15,4)))
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: rank_window_0 (type: int), _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: decimal(22,2)), _col4 (type: decimal(22,2))
                    outputColumnNames: rank_window_0, _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: 0 (type: int), (CAST( _col3 AS decimal(15,4)) / CAST( _col4 AS decimal(15,4))) (type: decimal(35,20))
                      null sort order: az
                      sort order: ++
                      Map-reduce partition columns: 0 (type: int)
                      Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                      value expressions: rank_window_0 (type: int), _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: decimal(22,2)), _col4 (type: decimal(22,2))
        Reducer 14 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: bigint), VALUE._col2 (type: bigint), VALUE._col3 (type: bigint), VALUE._col4 (type: decimal(22,2)), VALUE._col5 (type: decimal(22,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: (CAST( _col4 AS decimal(15,4)) / CAST( _col5 AS decimal(15,4))) ASC NULLS LAST
                        partition by: 0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_1
                              arguments: (CAST( _col4 AS decimal(15,4)) / CAST( _col5 AS decimal(15,4)))
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col0 <= 10) or (rank_window_1 <= 10)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: 'store' (type: string), _col1 (type: bigint), (CAST( _col2 AS decimal(15,4)) / CAST( _col3 AS decimal(15,4))) (type: decimal(35,20)), _col0 (type: int), rank_window_1 (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                      Top N Key Operator
                        sort order: +++++
                        keys: _col0 (type: string), _col3 (type: int), _col4 (type: int), _col1 (type: bigint), _col2 (type: decimal(35,20))
                        null sort order: zzzzz
                        Statistics: Num rows: 2 Data size: 496 Basic stats: COMPLETE Column stats: NONE
                        top n: 100
                        Group By Operator
                          keys: _col0 (type: string), _col3 (type: int), _col4 (type: int), _col1 (type: bigint), _col2 (type: decimal(35,20))
                          minReductionHashAggr: 0.99
                          mode: hash
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4
                          Statistics: Num rows: 2 Data size: 496 Basic stats: COMPLETE Column stats: NONE
                          Reduce Output Operator
                            key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: int), _col3 (type: bigint), _col4 (type: decimal(35,20))
                            null sort order: zzzzz
                            sort order: +++++
                            Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: int), _col3 (type: bigint), _col4 (type: decimal(35,20))
                            Statistics: Num rows: 2 Data size: 496 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: bigint), VALUE._col1 (type: bigint), VALUE._col2 (type: bigint), VALUE._col3 (type: decimal(22,2)), VALUE._col4 (type: decimal(22,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: bigint, _col1: bigint, _col2: bigint, _col3: decimal(22,2), _col4: decimal(22,2)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: (CAST( _col1 AS decimal(15,4)) / CAST( _col2 AS decimal(15,4))) ASC NULLS LAST
                        partition by: 0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: (CAST( _col1 AS decimal(15,4)) / CAST( _col2 AS decimal(15,4)))
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: rank_window_0 (type: int), _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: decimal(22,2)), _col4 (type: decimal(22,2))
                    outputColumnNames: rank_window_0, _col0, _col1, _col2, _col3, _col4
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: 0 (type: int), (CAST( _col3 AS decimal(15,4)) / CAST( _col4 AS decimal(15,4))) (type: decimal(35,20))
                      null sort order: az
                      sort order: ++
                      Map-reduce partition columns: 0 (type: int)
                      Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                      value expressions: rank_window_0 (type: int), _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: decimal(22,2)), _col4 (type: decimal(22,2))
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: bigint), VALUE._col2 (type: bigint), VALUE._col3 (type: bigint), VALUE._col4 (type: decimal(22,2)), VALUE._col5 (type: decimal(22,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: (CAST( _col4 AS decimal(15,4)) / CAST( _col5 AS decimal(15,4))) ASC NULLS LAST
                        partition by: 0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_1
                              arguments: (CAST( _col4 AS decimal(15,4)) / CAST( _col5 AS decimal(15,4)))
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col0 <= 10) or (rank_window_1 <= 10)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: 'web' (type: string), _col1 (type: bigint), (CAST( _col2 AS decimal(15,4)) / CAST( _col3 AS decimal(15,4))) (type: decimal(35,20)), _col0 (type: int), rank_window_1 (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: string), _col3 (type: int), _col4 (type: int), _col1 (type: bigint), _col2 (type: decimal(35,20))
                        minReductionHashAggr: 0.99
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2, _col3, _col4
                        Statistics: Num rows: 2 Data size: 496 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: int), _col3 (type: bigint), _col4 (type: decimal(35,20))
                          null sort order: zzzzz
                          sort order: +++++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: int), _col3 (type: bigint), _col4 (type: decimal(35,20))
                          Statistics: Num rows: 2 Data size: 496 Basic stats: COMPLETE Column stats: NONE
        Reducer 5 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: int), KEY._col3 (type: bigint), KEY._col4 (type: decimal(35,20))
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: string), _col3 (type: bigint), _col4 (type: decimal(35,20)), _col1 (type: int), _col2 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Top N Key Operator
                    sort order: +++++
                    keys: _col0 (type: string), _col3 (type: int), _col4 (type: int), _col1 (type: bigint), _col2 (type: decimal(35,20))
                    null sort order: zzzzz
                    Statistics: Num rows: 2 Data size: 496 Basic stats: COMPLETE Column stats: NONE
                    top n: 100
                    Group By Operator
                      keys: _col0 (type: string), _col3 (type: int), _col4 (type: int), _col1 (type: bigint), _col2 (type: decimal(35,20))
                      minReductionHashAggr: 0.99
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 2 Data size: 496 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: int), _col3 (type: bigint), _col4 (type: decimal(35,20))
                        null sort order: zzzzz
                        sort order: +++++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: int), _col3 (type: bigint), _col4 (type: decimal(35,20))
                        Statistics: Num rows: 2 Data size: 496 Basic stats: COMPLETE Column stats: NONE
        Reducer 7 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: int), KEY._col3 (type: bigint), KEY._col4 (type: decimal(35,20))
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: string), _col3 (type: bigint), _col4 (type: decimal(35,20)), _col1 (type: int), _col2 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: string), _col3 (type: int), _col4 (type: int)
                    null sort order: zzz
                    sort order: +++
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col1 (type: bigint), _col2 (type: decimal(35,20))
        Reducer 8 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: bigint), VALUE._col1 (type: decimal(35,20)), KEY.reducesinkkey1 (type: int), KEY.reducesinkkey2 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 100
                  Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 248 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Union 4 
            Vertex: Union 4
        Union 6 
            Vertex: Union 6

  Stage: Stage-0
    Fetch Operator
      limit: 100
      Processor Tree:
        ListSink

