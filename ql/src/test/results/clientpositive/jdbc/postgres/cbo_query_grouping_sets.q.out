PREHOOK: query: EXPLAIN CBO
select  
        ca_country, ca_state, i_item_id,
         avg( cast(cs_quantity as numeric(12,2))) agg1,
         avg( cast(c_birth_year as numeric(12,2))) agg6,
         avg( cast(cd1.cd_dep_count as numeric(12,2))) agg7
from catalog_sales, customer_demographics cd1,
        customer, customer_address,
        date_dim,
        item
where cs_sold_date_sk = d_date_sk and
        cs_item_sk = i_item_sk and
        cs_bill_cdemo_sk = cd1.cd_demo_sk and
        cs_bill_customer_sk = c_customer_sk and
        cd1.cd_gender = 'M' and
        cd1.cd_education_status = 'College' and
        c_current_addr_sk = ca_address_sk and
        c_birth_month in (9,5) and
        d_year = 2001 and
        ca_state in ('AL','MS','TN')
group by rollup(i_item_id, ca_country, ca_state)
order by ca_country, ca_state, i_item_id NULLS FIRST
limit 100
PREHOOK: type: QUERY
PREHOOK: Input: default@catalog_sales
PREHOOK: Input: default@customer
PREHOOK: Input: default@customer_address
PREHOOK: Input: default@customer_demographics
PREHOOK: Input: default@date_dim
PREHOOK: Input: default@item
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN CBO
select  
        ca_country, ca_state, i_item_id,
         avg( cast(cs_quantity as numeric(12,2))) agg1,
         avg( cast(c_birth_year as numeric(12,2))) agg6,
         avg( cast(cd1.cd_dep_count as numeric(12,2))) agg7
from catalog_sales, customer_demographics cd1,
        customer, customer_address,
        date_dim,
        item
where cs_sold_date_sk = d_date_sk and
        cs_item_sk = i_item_sk and
        cs_bill_cdemo_sk = cd1.cd_demo_sk and
        cs_bill_customer_sk = c_customer_sk and
        cd1.cd_gender = 'M' and
        cd1.cd_education_status = 'College' and
        c_current_addr_sk = ca_address_sk and
        c_birth_month in (9,5) and
        d_year = 2001 and
        ca_state in ('AL','MS','TN')
group by rollup(i_item_id, ca_country, ca_state)
order by ca_country, ca_state, i_item_id NULLS FIRST
limit 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@catalog_sales
POSTHOOK: Input: default@customer
POSTHOOK: Input: default@customer_address
POSTHOOK: Input: default@customer_demographics
POSTHOOK: Input: default@date_dim
POSTHOOK: Input: default@item
#### A masked pattern was here ####
CBO PLAN:
HiveSortLimit(sort0=[$0], sort1=[$1], sort2=[$2], dir0=[ASC], dir1=[ASC], dir2=[ASC-nulls-first], fetch=[100])
  HiveProject(ca_country=[$2], ca_state=[$1], i_item_id=[$0], agg1=[CAST(/($3, $4)):DECIMAL(16, 6)], agg6=[CAST(/($5, $6)):DECIMAL(16, 6)], agg7=[CAST(/($7, $8)):DECIMAL(16, 6)])
    HiveAggregate(group=[{9, 14, 15}], groups=[[{9, 14, 15}, {9, 15}, {9}, {}]], agg#0=[sum($4)], agg#1=[count($4)], agg#2=[sum($12)], agg#3=[count($12)], agg#4=[sum($7)], agg#5=[count($7)])
      HiveProject(cs_sold_date_sk=[$0], cs_bill_customer_sk=[$1], cs_bill_cdemo_sk=[$2], cs_item_sk=[$3], CAST=[$4], d_date_sk=[$5], cd_demo_sk=[$6], CAST0=[$7], i_item_sk=[$8], i_item_id=[$9], c_customer_sk=[$10], c_current_addr_sk=[$11], CAST1=[$12], ca_address_sk=[$13], ca_state=[$14], ca_country=[$15])
        HiveJdbcConverter(convention=[JDBC.POSTGRES])
          JdbcJoin(condition=[=($1, $10)], joinType=[inner])
            JdbcJoin(condition=[=($3, $8)], joinType=[inner])
              JdbcJoin(condition=[=($2, $6)], joinType=[inner])
                JdbcJoin(condition=[=($0, $5)], joinType=[inner])
                  JdbcProject(cs_sold_date_sk=[$0], cs_bill_customer_sk=[$1], cs_bill_cdemo_sk=[$2], cs_item_sk=[$3], CAST=[CAST($4):DECIMAL(12, 2)])
                    JdbcFilter(condition=[AND(IS NOT NULL($2), IS NOT NULL($1), IS NOT NULL($0), IS NOT NULL($3))])
                      JdbcProject(cs_sold_date_sk=[$0], cs_bill_customer_sk=[$3], cs_bill_cdemo_sk=[$4], cs_item_sk=[$15], cs_quantity=[$18])
                        JdbcHiveTableScan(table=[[default, catalog_sales]], table:alias=[catalog_sales])
                  JdbcProject(d_date_sk=[$0])
                    JdbcFilter(condition=[AND(=($1, 2001), IS NOT NULL($0))])
                      JdbcProject(d_date_sk=[$0], d_year=[$6])
                        JdbcHiveTableScan(table=[[default, date_dim]], table:alias=[date_dim])
                JdbcProject(cd_demo_sk=[$0], CAST=[CAST($3):DECIMAL(12, 2)])
                  JdbcFilter(condition=[AND(=($1, _UTF-16LE'M'), =($2, _UTF-16LE'College'), IS NOT NULL($0))])
                    JdbcProject(cd_demo_sk=[$0], cd_gender=[$1], cd_education_status=[$3], cd_dep_count=[$6])
                      JdbcHiveTableScan(table=[[default, customer_demographics]], table:alias=[cd1])
              JdbcProject(i_item_sk=[$0], i_item_id=[$1])
                JdbcFilter(condition=[IS NOT NULL($0)])
                  JdbcProject(i_item_sk=[$0], i_item_id=[$1])
                    JdbcHiveTableScan(table=[[default, item]], table:alias=[item])
            JdbcProject(c_customer_sk=[$0], c_current_addr_sk=[$1], CAST=[$2], ca_address_sk=[$3], ca_state=[$4], ca_country=[$5])
              JdbcJoin(condition=[=($1, $3)], joinType=[inner])
                JdbcProject(c_customer_sk=[$0], c_current_addr_sk=[$1], CAST=[CAST($3):DECIMAL(12, 2)])
                  JdbcFilter(condition=[AND(IN($2, 9, 5), IS NOT NULL($0), IS NOT NULL($1))])
                    JdbcProject(c_customer_sk=[$0], c_current_addr_sk=[$4], c_birth_month=[$12], c_birth_year=[$13])
                      JdbcHiveTableScan(table=[[default, customer]], table:alias=[customer])
                JdbcProject(ca_address_sk=[$0], ca_state=[$1], ca_country=[$2])
                  JdbcFilter(condition=[AND(IN($1, _UTF-16LE'AL':VARCHAR(2147483647) CHARACTER SET "UTF-16LE", _UTF-16LE'MS':VARCHAR(2147483647) CHARACTER SET "UTF-16LE", _UTF-16LE'TN':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"), IS NOT NULL($0))])
                    JdbcProject(ca_address_sk=[$0], ca_state=[$8], ca_country=[$10])
                      JdbcHiveTableScan(table=[[default, customer_address]], table:alias=[customer_address])

PREHOOK: query: EXPLAIN
select  
        ca_country, ca_state, i_item_id,
         avg( cast(cs_quantity as numeric(12,2))) agg1,
         avg( cast(c_birth_year as numeric(12,2))) agg6,
         avg( cast(cd1.cd_dep_count as numeric(12,2))) agg7
from catalog_sales, customer_demographics cd1,
        customer, customer_address,
        date_dim,
        item
where cs_sold_date_sk = d_date_sk and
        cs_item_sk = i_item_sk and
        cs_bill_cdemo_sk = cd1.cd_demo_sk and
        cs_bill_customer_sk = c_customer_sk and
        cd1.cd_gender = 'M' and
        cd1.cd_education_status = 'College' and
        c_current_addr_sk = ca_address_sk and
        c_birth_month in (9,5) and
        d_year = 2001 and
        ca_state in ('AL','MS','TN')
group by rollup(i_item_id, ca_country, ca_state)
order by ca_country, ca_state, i_item_id NULLS FIRST
limit 100
PREHOOK: type: QUERY
PREHOOK: Input: default@catalog_sales
PREHOOK: Input: default@customer
PREHOOK: Input: default@customer_address
PREHOOK: Input: default@customer_demographics
PREHOOK: Input: default@date_dim
PREHOOK: Input: default@item
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN
select  
        ca_country, ca_state, i_item_id,
         avg( cast(cs_quantity as numeric(12,2))) agg1,
         avg( cast(c_birth_year as numeric(12,2))) agg6,
         avg( cast(cd1.cd_dep_count as numeric(12,2))) agg7
from catalog_sales, customer_demographics cd1,
        customer, customer_address,
        date_dim,
        item
where cs_sold_date_sk = d_date_sk and
        cs_item_sk = i_item_sk and
        cs_bill_cdemo_sk = cd1.cd_demo_sk and
        cs_bill_customer_sk = c_customer_sk and
        cd1.cd_gender = 'M' and
        cd1.cd_education_status = 'College' and
        c_current_addr_sk = ca_address_sk and
        c_birth_month in (9,5) and
        d_year = 2001 and
        ca_state in ('AL','MS','TN')
group by rollup(i_item_id, ca_country, ca_state)
order by ca_country, ca_state, i_item_id NULLS FIRST
limit 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@catalog_sales
POSTHOOK: Input: default@customer
POSTHOOK: Input: default@customer_address
POSTHOOK: Input: default@customer_demographics
POSTHOOK: Input: default@date_dim
POSTHOOK: Input: default@item
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: catalog_sales
                  properties:
                    hive.sql.query SELECT "t1"."cs_sold_date_sk", "t1"."cs_bill_customer_sk", "t1"."cs_bill_cdemo_sk", "t1"."cs_item_sk", "t1"."CAST", "t4"."d_date_sk", "t7"."cd_demo_sk", "t7"."CAST" AS "CAST0", "t10"."i_item_sk", "t10"."i_item_id", "t17"."c_customer_sk", "t17"."c_current_addr_sk", "t17"."CAST" AS "CAST1", "t17"."ca_address_sk", "t17"."ca_state", "t17"."ca_country"
FROM (SELECT "cs_sold_date_sk", "cs_bill_customer_sk", "cs_bill_cdemo_sk", "cs_item_sk", CAST("cs_quantity" AS DECIMAL(12, 2)) AS "CAST"
FROM (SELECT "cs_sold_date_sk", "cs_bill_customer_sk", "cs_bill_cdemo_sk", "cs_item_sk", "cs_quantity"
FROM "catalog_sales") AS "t"
WHERE "cs_bill_cdemo_sk" IS NOT NULL AND "cs_bill_customer_sk" IS NOT NULL AND ("cs_sold_date_sk" IS NOT NULL AND "cs_item_sk" IS NOT NULL)) AS "t1"
INNER JOIN (SELECT "d_date_sk"
FROM (SELECT "d_date_sk", "d_year"
FROM "date_dim") AS "t2"
WHERE "d_year" = 2001 AND "d_date_sk" IS NOT NULL) AS "t4" ON "t1"."cs_sold_date_sk" = "t4"."d_date_sk"
INNER JOIN (SELECT "cd_demo_sk", CAST("cd_dep_count" AS DECIMAL(12, 2)) AS "CAST"
FROM (SELECT "cd_demo_sk", "cd_gender", "cd_education_status", "cd_dep_count"
FROM "customer_demographics") AS "t5"
WHERE "cd_gender" = 'M' AND ("cd_education_status" = 'College' AND "cd_demo_sk" IS NOT NULL)) AS "t7" ON "t1"."cs_bill_cdemo_sk" = "t7"."cd_demo_sk"
INNER JOIN (SELECT "i_item_sk", "i_item_id"
FROM (SELECT "i_item_sk", "i_item_id"
FROM "item") AS "t8"
WHERE "i_item_sk" IS NOT NULL) AS "t10" ON "t1"."cs_item_sk" = "t10"."i_item_sk"
INNER JOIN (SELECT "t13"."c_customer_sk", "t13"."c_current_addr_sk", "t13"."CAST", "t16"."ca_address_sk", "t16"."ca_state", "t16"."ca_country"
FROM (SELECT "c_customer_sk", "c_current_addr_sk", CAST("c_birth_year" AS DECIMAL(12, 2)) AS "CAST"
FROM (SELECT "c_customer_sk", "c_current_addr_sk", "c_birth_month", "c_birth_year"
FROM "customer") AS "t11"
WHERE "c_birth_month" IN (9, 5) AND ("c_customer_sk" IS NOT NULL AND "c_current_addr_sk" IS NOT NULL)) AS "t13"
INNER JOIN (SELECT "ca_address_sk", "ca_state", "ca_country"
FROM (SELECT "ca_address_sk", "ca_state", "ca_country"
FROM "customer_address") AS "t14"
WHERE "ca_state" IN ('AL', 'MS', 'TN') AND "ca_address_sk" IS NOT NULL) AS "t16" ON "t13"."c_current_addr_sk" = "t16"."ca_address_sk") AS "t17" ON "t1"."cs_bill_customer_sk" = "t17"."c_customer_sk"
                    hive.sql.query.fieldNames cs_sold_date_sk,cs_bill_customer_sk,cs_bill_cdemo_sk,cs_item_sk,CAST,d_date_sk,cd_demo_sk,CAST0,i_item_sk,i_item_id,c_customer_sk,c_current_addr_sk,CAST1,ca_address_sk,ca_state,ca_country
                    hive.sql.query.fieldTypes int,int,int,bigint,decimal(12,2),int,int,decimal(12,2),bigint,string,int,int,decimal(12,2),int,string,string
                    hive.sql.query.split false
                  Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: cast (type: decimal(12,2)), cast0 (type: decimal(12,2)), i_item_id (type: string), cast1 (type: decimal(12,2)), ca_state (type: string), ca_country (type: string)
                    outputColumnNames: _col4, _col7, _col9, _col12, _col14, _col15
                    Statistics: Num rows: 1 Data size: 888 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(_col4), count(_col4), sum(_col12), count(_col12), sum(_col7), count(_col7)
                      keys: _col9 (type: string), _col14 (type: string), _col15 (type: string), 0L (type: bigint)
                      grouping sets: 0, 2, 3, 7
                      minReductionHashAggr: 0.99
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                      Statistics: Num rows: 4 Data size: 3552 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: bigint)
                        null sort order: zzzz
                        sort order: ++++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: bigint)
                        Statistics: Num rows: 4 Data size: 3552 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col4 (type: decimal(22,2)), _col5 (type: bigint), _col6 (type: decimal(22,2)), _col7 (type: bigint), _col8 (type: decimal(22,2)), _col9 (type: bigint)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), sum(VALUE._col2), count(VALUE._col3), sum(VALUE._col4), count(VALUE._col5)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: string), KEY._col3 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col7, _col8, _col9
                Statistics: Num rows: 2 Data size: 1776 Basic stats: COMPLETE Column stats: NONE
                pruneGroupingSetId: true
                Top N Key Operator
                  sort order: +++
                  keys: _col2 (type: string), _col1 (type: string), _col0 (type: string)
                  null sort order: zza
                  Statistics: Num rows: 2 Data size: 1776 Basic stats: COMPLETE Column stats: NONE
                  top n: 100
                  Select Operator
                    expressions: _col2 (type: string), _col1 (type: string), _col0 (type: string), CAST( (_col4 / _col5) AS decimal(16,6)) (type: decimal(16,6)), CAST( (_col6 / _col7) AS decimal(16,6)) (type: decimal(16,6)), CAST( (_col8 / _col9) AS decimal(16,6)) (type: decimal(16,6))
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 2 Data size: 1776 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
                      null sort order: zza
                      sort order: +++
                      Statistics: Num rows: 2 Data size: 1776 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col3 (type: decimal(16,6)), _col4 (type: decimal(16,6)), _col5 (type: decimal(16,6))
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), VALUE._col0 (type: decimal(16,6)), VALUE._col1 (type: decimal(16,6)), VALUE._col2 (type: decimal(16,6))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 2 Data size: 1776 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 100
                  Statistics: Num rows: 2 Data size: 1776 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 2 Data size: 1776 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 100
      Processor Tree:
        ListSink

