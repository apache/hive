PREHOOK: query: explain
select  asceding.rnk, i1.i_product_name best_performing, i2.i_product_name worst_performing
from(select *
     from (select item_sk,rank() over (order by rank_col asc) rnk
           from (select ss_item_sk item_sk,avg(ss_net_profit) rank_col 
                 from store_sales ss1
                 where ss_store_sk = 410
                 group by ss_item_sk
                 having avg(ss_net_profit) > 0.9*(select avg(ss_net_profit) rank_col
                                                  from store_sales
                                                  where ss_store_sk = 410
                                                    and ss_hdemo_sk is null
                                                  group by ss_store_sk))V1)V11
     where rnk  < 11) asceding,
    (select *
     from (select item_sk,rank() over (order by rank_col desc) rnk
           from (select ss_item_sk item_sk,avg(ss_net_profit) rank_col
                 from store_sales ss1
                 where ss_store_sk = 410
                 group by ss_item_sk
                 having avg(ss_net_profit) > 0.9*(select avg(ss_net_profit) rank_col
                                                  from store_sales
                                                  where ss_store_sk = 410
                                                    and ss_hdemo_sk is null
                                                  group by ss_store_sk))V2)V21
     where rnk  < 11) descending,
item i1,
item i2
where asceding.rnk = descending.rnk 
  and i1.i_item_sk=asceding.item_sk
  and i2.i_item_sk=descending.item_sk
order by asceding.rnk
limit 100
PREHOOK: type: QUERY
PREHOOK: Input: default@item
PREHOOK: Input: default@store_sales
#### A masked pattern was here ####
POSTHOOK: query: explain
select  asceding.rnk, i1.i_product_name best_performing, i2.i_product_name worst_performing
from(select *
     from (select item_sk,rank() over (order by rank_col asc) rnk
           from (select ss_item_sk item_sk,avg(ss_net_profit) rank_col 
                 from store_sales ss1
                 where ss_store_sk = 410
                 group by ss_item_sk
                 having avg(ss_net_profit) > 0.9*(select avg(ss_net_profit) rank_col
                                                  from store_sales
                                                  where ss_store_sk = 410
                                                    and ss_hdemo_sk is null
                                                  group by ss_store_sk))V1)V11
     where rnk  < 11) asceding,
    (select *
     from (select item_sk,rank() over (order by rank_col desc) rnk
           from (select ss_item_sk item_sk,avg(ss_net_profit) rank_col
                 from store_sales ss1
                 where ss_store_sk = 410
                 group by ss_item_sk
                 having avg(ss_net_profit) > 0.9*(select avg(ss_net_profit) rank_col
                                                  from store_sales
                                                  where ss_store_sk = 410
                                                    and ss_hdemo_sk is null
                                                  group by ss_store_sk))V2)V21
     where rnk  < 11) descending,
item i1,
item i2
where asceding.rnk = descending.rnk 
  and i1.i_item_sk=asceding.item_sk
  and i2.i_item_sk=descending.item_sk
order by asceding.rnk
limit 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@item
POSTHOOK: Input: default@store_sales
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Reducer 8 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE), Reducer 5 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
        Reducer 5 <- Map 1 (SIMPLE_EDGE), Reducer 7 (SIMPLE_EDGE)
        Reducer 7 <- Map 6 (SIMPLE_EDGE)
        Reducer 8 <- Map 6 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: i1
                  properties:
                    hive.sql.query SELECT "i_item_sk", "i_product_name"
FROM (SELECT "i_item_sk", "i_product_name"
FROM "item") AS "t"
WHERE "i_item_sk" IS NOT NULL
                    hive.sql.query.fieldNames i_item_sk,i_product_name
                    hive.sql.query.fieldTypes bigint,string
                    hive.sql.query.split true
                  Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: i_item_sk (type: bigint), i_product_name (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: bigint)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: _col0 (type: bigint)
                      Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: string)
                    Reduce Output Operator
                      key expressions: _col0 (type: bigint)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: _col0 (type: bigint)
                      Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: string)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: ss1
                  properties:
                    hive.sql.query SELECT "t3"."$f0", "t3"."$f1", "t9"."rank_col"
FROM (SELECT "ss_item_sk" AS "$f0", CAST(SUM("ss_net_profit") / COUNT("ss_net_profit") AS DECIMAL(11, 6)) AS "$f1"
FROM (SELECT "ss_item_sk", "ss_store_sk", "ss_net_profit"
FROM "store_sales") AS "t"
WHERE "ss_store_sk" = 410
GROUP BY "ss_item_sk"
HAVING CAST(SUM("ss_net_profit") / COUNT("ss_net_profit") AS DECIMAL(11, 6)) IS NOT NULL) AS "t3"
INNER JOIN (SELECT CAST(SUM("ss_net_profit") / COUNT("ss_net_profit") AS DECIMAL(11, 6)) AS "rank_col"
FROM (SELECT "ss_hdemo_sk", "ss_store_sk", "ss_net_profit"
FROM "store_sales") AS "t4"
WHERE "ss_store_sk" = 410 AND "ss_hdemo_sk" IS NULL
GROUP BY TRUE
HAVING CAST(SUM("ss_net_profit") / COUNT("ss_net_profit") AS DECIMAL(11, 6)) IS NOT NULL) AS "t9" ON "t3"."$f1" > 0.9 * "t9"."rank_col"
                    hive.sql.query.fieldNames $f0,$f1,rank_col
                    hive.sql.query.fieldTypes bigint,decimal(11,6),decimal(11,6)
                    hive.sql.query.split false
                  Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                  Top N Key Operator
                    sort order: -
                    keys: $f1 (type: decimal(11,6))
                    null sort order: a
                    Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                    top n: 11
                    Select Operator
                      expressions: $f0 (type: bigint), $f1 (type: decimal(11,6))
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: 0 (type: int), _col1 (type: decimal(11,6))
                        null sort order: aa
                        sort order: +-
                        Map-reduce partition columns: 0 (type: int)
                        Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: bigint)
                  Top N Key Operator
                    sort order: +
                    keys: $f1 (type: decimal(11,6))
                    null sort order: z
                    Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                    top n: 11
                    Select Operator
                      expressions: $f0 (type: bigint), $f1 (type: decimal(11,6))
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: 0 (type: int), _col1 (type: decimal(11,6))
                        null sort order: az
                        sort order: ++
                        Map-reduce partition columns: 0 (type: int)
                        Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: bigint)
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: bigint)
                  1 _col0 (type: bigint)
                outputColumnNames: _col1, _col3
                Statistics: Num rows: 1 Data size: 211 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col3 (type: int)
                  null sort order: z
                  sort order: +
                  Map-reduce partition columns: _col3 (type: int)
                  Statistics: Num rows: 1 Data size: 211 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: string)
        Reducer 3 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col3 (type: int)
                  1 _col1 (type: int)
                outputColumnNames: _col1, _col3, _col7
                Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                Top N Key Operator
                  sort order: +
                  keys: _col3 (type: int)
                  null sort order: z
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  top n: 100
                  Select Operator
                    expressions: _col3 (type: int), _col1 (type: string), _col7 (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      null sort order: z
                      sort order: +
                      Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: string), _col2 (type: string)
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string), VALUE._col1 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 100
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 5 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: bigint)
                  1 _col0 (type: bigint)
                outputColumnNames: _col1, _col3
                Statistics: Num rows: 1 Data size: 132 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: int)
                  null sort order: z
                  sort order: +
                  Map-reduce partition columns: _col1 (type: int)
                  Statistics: Num rows: 1 Data size: 132 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col3 (type: string)
        Reducer 7 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: bigint), KEY.reducesinkkey1 (type: decimal(11,6))
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: bigint, _col1: decimal(11,6)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 DESC NULLS FIRST
                        partition by: 0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((rank_window_0 < 11) and _col0 is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: bigint), rank_window_0 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: bigint)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col0 (type: bigint)
                        Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: int)
        Reducer 8 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: bigint), KEY.reducesinkkey1 (type: decimal(11,6))
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: bigint, _col1: decimal(11,6)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 ASC NULLS LAST
                        partition by: 0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((rank_window_0 < 11) and _col0 is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: bigint), rank_window_0 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: bigint)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col0 (type: bigint)
                        Statistics: Num rows: 1 Data size: 120 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: int)

  Stage: Stage-0
    Fetch Operator
      limit: 100
      Processor Tree:
        ListSink

