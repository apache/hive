PREHOOK: query: explain
with v1 as(
 select i_category, i_brand,
        cc_name,
        d_year, d_moy,
        sum(cs_sales_price) sum_sales,
        avg(sum(cs_sales_price)) over
          (partition by i_category, i_brand,
                     cc_name, d_year)
          avg_monthly_sales,
        rank() over
          (partition by i_category, i_brand,
                     cc_name
           order by d_year, d_moy) rn
 from item, catalog_sales, date_dim, call_center
 where cs_item_sk = i_item_sk and
       cs_sold_date_sk = d_date_sk and
       cc_call_center_sk= cs_call_center_sk and
       (
         d_year = 2000 or
         ( d_year = 2000-1 and d_moy =12) or
         ( d_year = 2000+1 and d_moy =1)
       )
 group by i_category, i_brand,
          cc_name , d_year, d_moy),
 v2 as(
 select v1.i_category, v1.i_brand
        ,v1.d_year, v1.d_moy
        ,v1.avg_monthly_sales
        ,v1.sum_sales, v1_lag.sum_sales psum, v1_lead.sum_sales nsum
 from v1, v1 v1_lag, v1 v1_lead
 where v1.i_category = v1_lag.i_category and
       v1.i_category = v1_lead.i_category and
       v1.i_brand = v1_lag.i_brand and
       v1.i_brand = v1_lead.i_brand and
       v1. cc_name = v1_lag. cc_name and
       v1. cc_name = v1_lead. cc_name and
       v1.rn = v1_lag.rn + 1 and
       v1.rn = v1_lead.rn - 1)
  select  *
 from v2
 where  d_year = 2000 and
        avg_monthly_sales > 0 and
        case when avg_monthly_sales > 0 then abs(sum_sales - avg_monthly_sales) / avg_monthly_sales else null end > 0.1
 order by sum_sales - avg_monthly_sales, 3
 limit 100
PREHOOK: type: QUERY
PREHOOK: Input: default@call_center
PREHOOK: Input: default@catalog_sales
PREHOOK: Input: default@date_dim
PREHOOK: Input: default@item
#### A masked pattern was here ####
POSTHOOK: query: explain
with v1 as(
 select i_category, i_brand,
        cc_name,
        d_year, d_moy,
        sum(cs_sales_price) sum_sales,
        avg(sum(cs_sales_price)) over
          (partition by i_category, i_brand,
                     cc_name, d_year)
          avg_monthly_sales,
        rank() over
          (partition by i_category, i_brand,
                     cc_name
           order by d_year, d_moy) rn
 from item, catalog_sales, date_dim, call_center
 where cs_item_sk = i_item_sk and
       cs_sold_date_sk = d_date_sk and
       cc_call_center_sk= cs_call_center_sk and
       (
         d_year = 2000 or
         ( d_year = 2000-1 and d_moy =12) or
         ( d_year = 2000+1 and d_moy =1)
       )
 group by i_category, i_brand,
          cc_name , d_year, d_moy),
 v2 as(
 select v1.i_category, v1.i_brand
        ,v1.d_year, v1.d_moy
        ,v1.avg_monthly_sales
        ,v1.sum_sales, v1_lag.sum_sales psum, v1_lead.sum_sales nsum
 from v1, v1 v1_lag, v1 v1_lead
 where v1.i_category = v1_lag.i_category and
       v1.i_category = v1_lead.i_category and
       v1.i_brand = v1_lag.i_brand and
       v1.i_brand = v1_lead.i_brand and
       v1. cc_name = v1_lag. cc_name and
       v1. cc_name = v1_lead. cc_name and
       v1.rn = v1_lag.rn + 1 and
       v1.rn = v1_lead.rn - 1)
  select  *
 from v2
 where  d_year = 2000 and
        avg_monthly_sales > 0 and
        case when avg_monthly_sales > 0 then abs(sum_sales - avg_monthly_sales) / avg_monthly_sales else null end > 0.1
 order by sum_sales - avg_monthly_sales, 3
 limit 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@call_center
POSTHOOK: Input: default@catalog_sales
POSTHOOK: Input: default@date_dim
POSTHOOK: Input: default@item
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE), Reducer 7 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 4 (SIMPLE_EDGE), Reducer 7 (SIMPLE_EDGE)
        Reducer 6 <- Reducer 5 (SIMPLE_EDGE)
        Reducer 7 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: catalog_sales
                  properties:
                    hive.sql.query SELECT "t4"."cc_name", "t7"."i_brand", "t7"."i_category", "t10"."d_year", "t10"."d_moy", SUM("t1"."cs_sales_price") AS "$f5"
FROM (SELECT "cs_sold_date_sk", "cs_call_center_sk", "cs_item_sk", "cs_sales_price"
FROM (SELECT "cs_sold_date_sk", "cs_call_center_sk", "cs_item_sk", "cs_sales_price"
FROM "catalog_sales") AS "t"
WHERE "cs_item_sk" IS NOT NULL AND ("cs_sold_date_sk" IS NOT NULL AND "cs_call_center_sk" IS NOT NULL)) AS "t1"
INNER JOIN (SELECT "cc_call_center_sk", "cc_name"
FROM (SELECT "cc_call_center_sk", "cc_name"
FROM "call_center") AS "t2"
WHERE "cc_call_center_sk" IS NOT NULL AND "cc_name" IS NOT NULL) AS "t4" ON "t1"."cs_call_center_sk" = "t4"."cc_call_center_sk"
INNER JOIN (SELECT "i_item_sk", "i_brand", "i_category"
FROM (SELECT "i_item_sk", "i_brand", "i_category"
FROM "item") AS "t5"
WHERE "i_item_sk" IS NOT NULL AND ("i_category" IS NOT NULL AND "i_brand" IS NOT NULL)) AS "t7" ON "t1"."cs_item_sk" = "t7"."i_item_sk"
INNER JOIN (SELECT "d_date_sk", "d_year", "d_moy"
FROM (SELECT "d_date_sk", "d_year", "d_moy"
FROM "date_dim") AS "t8"
WHERE ("d_year" = 2000 OR ("d_year" = 1999 AND "d_moy" = 12 OR "d_year" = 2001 AND "d_moy" = 1)) AND ("d_year" IN (2000, 1999, 2001) AND "d_date_sk" IS NOT NULL)) AS "t10" ON "t1"."cs_sold_date_sk" = "t10"."d_date_sk"
GROUP BY "t4"."cc_name", "t7"."i_brand", "t7"."i_category", "t10"."d_year", "t10"."d_moy"
                    hive.sql.query.fieldNames cc_name,i_brand,i_category,d_year,d_moy,$f5
                    hive.sql.query.fieldTypes string,string,string,int,int,decimal(17,2)
                    hive.sql.query.split false
                  Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: cc_name (type: string), i_brand (type: string), i_category (type: string), d_year (type: int), d_moy (type: int), $f5 (type: decimal(17,2))
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col1 (type: string), _col0 (type: string), _col3 (type: int)
                      null sort order: aaaa
                      sort order: ++++
                      Map-reduce partition columns: _col2 (type: string), _col1 (type: string), _col0 (type: string), _col3 (type: int)
                      Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col4 (type: int), _col5 (type: decimal(17,2))
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col1 (type: string), _col0 (type: string), _col3 (type: int), _col4 (type: int)
                      null sort order: aaazz
                      sort order: +++++
                      Map-reduce partition columns: _col2 (type: string), _col1 (type: string), _col0 (type: string)
                      Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col5 (type: decimal(17,2))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey2 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), KEY.reducesinkkey3 (type: int), VALUE._col0 (type: int), VALUE._col1 (type: decimal(17,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: string, _col2: string, _col3: int, _col4: int, _col5: decimal(17,2)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col2 ASC NULLS FIRST, _col1 ASC NULLS FIRST, _col0 ASC NULLS FIRST, _col3 ASC NULLS FIRST
                        partition by: _col2, _col1, _col0, _col3
                        raw input shape:
                        window functions:
                            window function definition
                              alias: avg_window_0
                              arguments: _col5
                              name: avg
                              window function: GenericUDAFAverageEvaluatorDecimal
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                  Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: avg_window_0 (type: decimal(21,6)), _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: int), _col4 (type: int), _col5 (type: decimal(17,2))
                    outputColumnNames: avg_window_0, _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col2 (type: string), _col1 (type: string), _col0 (type: string), _col3 (type: int), _col4 (type: int)
                      null sort order: aaazz
                      sort order: +++++
                      Map-reduce partition columns: _col2 (type: string), _col1 (type: string), _col0 (type: string)
                      Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                      value expressions: avg_window_0 (type: decimal(21,6)), _col5 (type: decimal(17,2))
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: decimal(21,6)), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), KEY.reducesinkkey3 (type: int), KEY.reducesinkkey4 (type: int), VALUE._col1 (type: decimal(17,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: decimal(21,6), _col1: string, _col2: string, _col3: string, _col4: int, _col5: int, _col6: decimal(17,2)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col4 ASC NULLS LAST, _col5 ASC NULLS LAST
                        partition by: _col3, _col2, _col1
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_1
                              arguments: _col4, _col5
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((_col0 > 0) and rank_window_1 is not null and (_col4 = 2000)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: rank_window_1 (type: int), _col0 (type: decimal(21,6)), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: decimal(17,2))
                      outputColumnNames: rank_window_1, _col0, _col1, _col2, _col3, _col4, _col5, _col6
                      Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                      Filter Operator
                        predicate: if((_col0 > 0), ((abs((_col6 - _col0)) / _col0) > 0.1), false) (type: boolean)
                        Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                        Select Operator
                          expressions: _col3 (type: string), _col2 (type: string), _col1 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: decimal(17,2)), _col0 (type: decimal(21,6)), rank_window_1 (type: int)
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                          Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                          Reduce Output Operator
                            key expressions: _col0 (type: string), _col1 (type: string), _col7 (type: int), _col2 (type: string)
                            null sort order: zzzz
                            sort order: ++++
                            Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col7 (type: int), _col2 (type: string)
                            Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                            value expressions: _col3 (type: int), _col4 (type: int), _col5 (type: decimal(17,2)), _col6 (type: decimal(21,6))
        Reducer 4 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: string), _col1 (type: string), _col7 (type: int), _col2 (type: string)
                  1 _col0 (type: string), _col1 (type: string), _col4 (type: int), _col2 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col11
                Statistics: Num rows: 1 Data size: 739 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: string), _col7 (type: int), _col2 (type: string)
                  null sort order: zzzz
                  sort order: ++++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col7 (type: int), _col2 (type: string)
                  Statistics: Num rows: 1 Data size: 739 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col3 (type: int), _col4 (type: int), _col5 (type: decimal(17,2)), _col6 (type: decimal(21,6)), _col11 (type: decimal(17,2))
        Reducer 5 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: string), _col1 (type: string), _col7 (type: int), _col2 (type: string)
                  1 _col0 (type: string), _col1 (type: string), _col4 (type: int), _col2 (type: string)
                outputColumnNames: _col0, _col1, _col3, _col4, _col5, _col6, _col11, _col16
                Statistics: Num rows: 1 Data size: 812 Basic stats: COMPLETE Column stats: NONE
                Top N Key Operator
                  sort order: ++
                  keys: (_col5 - _col6) (type: decimal(22,6)), _col3 (type: int)
                  null sort order: zz
                  Statistics: Num rows: 1 Data size: 812 Basic stats: COMPLETE Column stats: NONE
                  top n: 100
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string), _col3 (type: int), _col4 (type: int), _col6 (type: decimal(21,6)), _col5 (type: decimal(17,2)), _col11 (type: decimal(17,2)), _col16 (type: decimal(17,2)), (_col5 - _col6) (type: decimal(22,6))
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 1 Data size: 812 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col8 (type: decimal(22,6)), _col2 (type: int)
                      null sort order: zz
                      sort order: ++
                      Statistics: Num rows: 1 Data size: 812 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string), _col1 (type: string), _col3 (type: int), _col4 (type: decimal(21,6)), _col5 (type: decimal(17,2)), _col6 (type: decimal(17,2)), _col7 (type: decimal(17,2))
        Reducer 6 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: string), KEY.reducesinkkey1 (type: int), VALUE._col2 (type: int), VALUE._col3 (type: decimal(21,6)), VALUE._col4 (type: decimal(17,2)), VALUE._col5 (type: decimal(17,2)), VALUE._col6 (type: decimal(17,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                Statistics: Num rows: 1 Data size: 812 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 100
                  Statistics: Num rows: 1 Data size: 812 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 812 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 7 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey2 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey0 (type: string), KEY.reducesinkkey3 (type: int), KEY.reducesinkkey4 (type: int), VALUE._col0 (type: decimal(17,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: string, _col2: string, _col3: int, _col4: int, _col5: decimal(17,2)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col3 ASC NULLS LAST, _col4 ASC NULLS LAST
                        partition by: _col2, _col1, _col0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col3, _col4
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: rank_window_0 is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col2 (type: string), _col1 (type: string), _col0 (type: string), _col5 (type: decimal(17,2)), (rank_window_0 + 1) (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col4 (type: int), _col2 (type: string)
                        null sort order: zzzz
                        sort order: ++++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col4 (type: int), _col2 (type: string)
                        Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col3 (type: decimal(17,2))
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: string, _col2: string, _col3: int, _col4: int, _col5: decimal(17,2)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col3 ASC NULLS LAST, _col4 ASC NULLS LAST
                        partition by: _col2, _col1, _col0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col3, _col4
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: rank_window_0 is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col2 (type: string), _col1 (type: string), _col0 (type: string), _col5 (type: decimal(17,2)), (rank_window_0 - 1) (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col4 (type: int), _col2 (type: string)
                        null sort order: zzzz
                        sort order: ++++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col4 (type: int), _col2 (type: string)
                        Statistics: Num rows: 1 Data size: 672 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col3 (type: decimal(17,2))

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

