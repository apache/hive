PREHOOK: query: explain
select  *
from(
select i_category, i_class, i_brand,
       s_store_name, s_company_name,
       d_moy,
       sum(ss_sales_price) sum_sales,
       avg(sum(ss_sales_price)) over
         (partition by i_category, i_brand, s_store_name, s_company_name)
         avg_monthly_sales
from item, store_sales, date_dim, store
where ss_item_sk = i_item_sk and
      ss_sold_date_sk = d_date_sk and
      ss_store_sk = s_store_sk and
      d_year in (2000) and
        ((i_category in ('Home','Books','Electronics') and
          i_class in ('wallpaper','parenting','musical')
         )
      or (i_category in ('Shoes','Jewelry','Men') and
          i_class in ('womens','birdal','pants') 
        ))
group by i_category, i_class, i_brand,
         s_store_name, s_company_name, d_moy) tmp1
where case when (avg_monthly_sales <> 0) then (abs(sum_sales - avg_monthly_sales) / avg_monthly_sales) else null end > 0.1
order by sum_sales - avg_monthly_sales, s_store_name
limit 100
PREHOOK: type: QUERY
PREHOOK: Input: default@date_dim
PREHOOK: Input: default@item
PREHOOK: Input: default@store
PREHOOK: Input: default@store_sales
#### A masked pattern was here ####
POSTHOOK: query: explain
select  *
from(
select i_category, i_class, i_brand,
       s_store_name, s_company_name,
       d_moy,
       sum(ss_sales_price) sum_sales,
       avg(sum(ss_sales_price)) over
         (partition by i_category, i_brand, s_store_name, s_company_name)
         avg_monthly_sales
from item, store_sales, date_dim, store
where ss_item_sk = i_item_sk and
      ss_sold_date_sk = d_date_sk and
      ss_store_sk = s_store_sk and
      d_year in (2000) and
        ((i_category in ('Home','Books','Electronics') and
          i_class in ('wallpaper','parenting','musical')
         )
      or (i_category in ('Shoes','Jewelry','Men') and
          i_class in ('womens','birdal','pants') 
        ))
group by i_category, i_class, i_brand,
         s_store_name, s_company_name, d_moy) tmp1
where case when (avg_monthly_sales <> 0) then (abs(sum_sales - avg_monthly_sales) / avg_monthly_sales) else null end > 0.1
order by sum_sales - avg_monthly_sales, s_store_name
limit 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@date_dim
POSTHOOK: Input: default@item
POSTHOOK: Input: default@store
POSTHOOK: Input: default@store_sales
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: store_sales
                  properties:
                    hive.sql.query SELECT "t4"."d_moy", "t7"."s_store_name", "t7"."s_company_name", "t10"."i_brand", "t10"."i_class", "t10"."i_category", SUM("t1"."ss_sales_price") AS "$f6"
FROM (SELECT "ss_sold_date_sk", "ss_item_sk", "ss_store_sk", "ss_sales_price"
FROM (SELECT "ss_sold_date_sk", "ss_item_sk", "ss_store_sk", "ss_sales_price"
FROM "store_sales") AS "t"
WHERE "ss_item_sk" IS NOT NULL AND ("ss_sold_date_sk" IS NOT NULL AND "ss_store_sk" IS NOT NULL)) AS "t1"
INNER JOIN (SELECT "d_date_sk", "d_moy"
FROM (SELECT "d_date_sk", "d_year", "d_moy"
FROM "date_dim") AS "t2"
WHERE "d_year" = 2000 AND "d_date_sk" IS NOT NULL) AS "t4" ON "t1"."ss_sold_date_sk" = "t4"."d_date_sk"
INNER JOIN (SELECT "s_store_sk", "s_store_name", "s_company_name"
FROM (SELECT "s_store_sk", "s_store_name", "s_company_name"
FROM "store") AS "t5"
WHERE "s_store_sk" IS NOT NULL) AS "t7" ON "t1"."ss_store_sk" = "t7"."s_store_sk"
INNER JOIN (SELECT "i_item_sk", "i_brand", "i_class", "i_category"
FROM (SELECT "i_item_sk", "i_brand", "i_class", "i_category"
FROM "item") AS "t8"
WHERE ("i_category" IN ('Home', 'Books', 'Electronics') AND "i_class" IN ('wallpaper', 'parenting', 'musical') OR "i_category" IN ('Shoes', 'Jewelry', 'Men') AND "i_class" IN ('womens', 'birdal', 'pants')) AND "i_class" IN ('wallpaper', 'parenting', 'musical', 'womens', 'birdal', 'pants') AND ("i_category" IN ('Home', 'Books', 'Electronics', 'Shoes', 'Jewelry', 'Men') AND "i_item_sk" IS NOT NULL)) AS "t10" ON "t1"."ss_item_sk" = "t10"."i_item_sk"
GROUP BY "t4"."d_moy", "t7"."s_store_name", "t7"."s_company_name", "t10"."i_brand", "t10"."i_class", "t10"."i_category"
                    hive.sql.query.fieldNames d_moy,s_store_name,s_company_name,i_brand,i_class,i_category,$f6
                    hive.sql.query.fieldTypes int,string,string,string,string,string,decimal(17,2)
                    hive.sql.query.split false
                  Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: d_moy (type: int), s_store_name (type: string), s_company_name (type: string), i_brand (type: string), i_class (type: string), i_category (type: string), $f6 (type: decimal(17,2))
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                    Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col5 (type: string), _col3 (type: string), _col1 (type: string), _col2 (type: string)
                      null sort order: aaaa
                      sort order: ++++
                      Map-reduce partition columns: _col5 (type: string), _col3 (type: string), _col1 (type: string), _col2 (type: string)
                      Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: int), _col4 (type: string), _col6 (type: decimal(17,2))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string), KEY.reducesinkkey1 (type: string), VALUE._col1 (type: string), KEY.reducesinkkey0 (type: string), VALUE._col2 (type: decimal(17,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: int, _col1: string, _col2: string, _col3: string, _col4: string, _col5: string, _col6: decimal(17,2)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col5 ASC NULLS FIRST, _col3 ASC NULLS FIRST, _col1 ASC NULLS FIRST, _col2 ASC NULLS FIRST
                        partition by: _col5, _col3, _col1, _col2
                        raw input shape:
                        window functions:
                            window function definition
                              alias: avg_window_0
                              arguments: _col6
                              name: avg
                              window function: GenericUDAFAverageEvaluatorDecimal
                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
                  Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: avg_window_0 (type: decimal(21,6)), _col0 (type: int), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: decimal(17,2))
                    outputColumnNames: avg_window_0, _col0, _col1, _col2, _col3, _col4, _col5, _col6
                    Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                    Filter Operator
                      predicate: if((avg_window_0 <> 0), ((abs((_col6 - avg_window_0)) / avg_window_0) > 0.1), false) (type: boolean)
                      Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                      Top N Key Operator
                        sort order: ++
                        keys: (_col6 - avg_window_0) (type: decimal(22,6)), _col1 (type: string)
                        null sort order: zz
                        Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                        top n: 100
                        Select Operator
                          expressions: _col5 (type: string), _col4 (type: string), _col3 (type: string), _col1 (type: string), _col2 (type: string), _col0 (type: int), _col6 (type: decimal(17,2)), avg_window_0 (type: decimal(21,6)), (_col6 - avg_window_0) (type: decimal(22,6))
                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                          Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                          Reduce Output Operator
                            key expressions: _col8 (type: decimal(22,6)), _col3 (type: string)
                            null sort order: zz
                            sort order: ++
                            Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                            value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col4 (type: string), _col5 (type: int), _col6 (type: decimal(17,2)), _col7 (type: decimal(21,6))
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), KEY.reducesinkkey1 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: int), VALUE._col5 (type: decimal(17,2)), VALUE._col6 (type: decimal(21,6))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 100
                  Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 1036 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

