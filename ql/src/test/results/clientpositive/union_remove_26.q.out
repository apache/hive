PREHOOK: query: -- This is to test the union remove optimization with stats optimization

create table inputSrcTbl1(key string, val int) stored as textfile
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@inputSrcTbl1
POSTHOOK: query: -- This is to test the union remove optimization with stats optimization

create table inputSrcTbl1(key string, val int) stored as textfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@inputSrcTbl1
PREHOOK: query: create table inputSrcTbl2(key string, val int) stored as textfile
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@inputSrcTbl2
POSTHOOK: query: create table inputSrcTbl2(key string, val int) stored as textfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@inputSrcTbl2
PREHOOK: query: create table inputSrcTbl3(key string, val int) stored as textfile
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@inputSrcTbl3
POSTHOOK: query: create table inputSrcTbl3(key string, val int) stored as textfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@inputSrcTbl3
PREHOOK: query: load data local inpath '../../data/files/T1.txt' into table inputSrcTbl1
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@inputsrctbl1
POSTHOOK: query: load data local inpath '../../data/files/T1.txt' into table inputSrcTbl1
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@inputsrctbl1
PREHOOK: query: load data local inpath '../../data/files/T2.txt' into table inputSrcTbl2
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@inputsrctbl2
POSTHOOK: query: load data local inpath '../../data/files/T2.txt' into table inputSrcTbl2
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@inputsrctbl2
PREHOOK: query: load data local inpath '../../data/files/T3.txt' into table inputSrcTbl3
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@inputsrctbl3
POSTHOOK: query: load data local inpath '../../data/files/T3.txt' into table inputSrcTbl3
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@inputsrctbl3
PREHOOK: query: create table inputTbl1(key string, val int) stored as textfile
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@inputTbl1
POSTHOOK: query: create table inputTbl1(key string, val int) stored as textfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@inputTbl1
PREHOOK: query: create table inputTbl2(key string, val int) stored as textfile
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@inputTbl2
POSTHOOK: query: create table inputTbl2(key string, val int) stored as textfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@inputTbl2
PREHOOK: query: create table inputTbl3(key string, val int) stored as textfile
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@inputTbl3
POSTHOOK: query: create table inputTbl3(key string, val int) stored as textfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@inputTbl3
PREHOOK: query: insert into inputTbl1 select * from inputSrcTbl1
PREHOOK: type: QUERY
PREHOOK: Input: default@inputsrctbl1
PREHOOK: Output: default@inputtbl1
POSTHOOK: query: insert into inputTbl1 select * from inputSrcTbl1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputsrctbl1
POSTHOOK: Output: default@inputtbl1
POSTHOOK: Lineage: inputtbl1.key SIMPLE [(inputsrctbl1)inputsrctbl1.FieldSchema(name:key, type:string, comment:null), ]
POSTHOOK: Lineage: inputtbl1.val SIMPLE [(inputsrctbl1)inputsrctbl1.FieldSchema(name:val, type:int, comment:null), ]
PREHOOK: query: insert into inputTbl2 select * from inputSrcTbl2
PREHOOK: type: QUERY
PREHOOK: Input: default@inputsrctbl2
PREHOOK: Output: default@inputtbl2
POSTHOOK: query: insert into inputTbl2 select * from inputSrcTbl2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputsrctbl2
POSTHOOK: Output: default@inputtbl2
POSTHOOK: Lineage: inputtbl2.key SIMPLE [(inputsrctbl2)inputsrctbl2.FieldSchema(name:key, type:string, comment:null), ]
POSTHOOK: Lineage: inputtbl2.val SIMPLE [(inputsrctbl2)inputsrctbl2.FieldSchema(name:val, type:int, comment:null), ]
PREHOOK: query: insert into inputTbl3 select * from inputSrcTbl3
PREHOOK: type: QUERY
PREHOOK: Input: default@inputsrctbl3
PREHOOK: Output: default@inputtbl3
POSTHOOK: query: insert into inputTbl3 select * from inputSrcTbl3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputsrctbl3
POSTHOOK: Output: default@inputtbl3
POSTHOOK: Lineage: inputtbl3.key SIMPLE [(inputsrctbl3)inputsrctbl3.FieldSchema(name:key, type:string, comment:null), ]
POSTHOOK: Lineage: inputtbl3.val SIMPLE [(inputsrctbl3)inputsrctbl3.FieldSchema(name:val, type:int, comment:null), ]
PREHOOK: query: --- union remove optimization effects, stats optimization does not though it is on since inputTbl2 column stats is not available
analyze table inputTbl1 compute statistics for columns
PREHOOK: type: QUERY
PREHOOK: Input: default@inputtbl1
#### A masked pattern was here ####
POSTHOOK: query: --- union remove optimization effects, stats optimization does not though it is on since inputTbl2 column stats is not available
analyze table inputTbl1 compute statistics for columns
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputtbl1
#### A masked pattern was here ####
PREHOOK: query: analyze table inputTbl3 compute statistics for columns
PREHOOK: type: QUERY
PREHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
POSTHOOK: query: analyze table inputTbl3 compute statistics for columns
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
PREHOOK: query: explain
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3
PREHOOK: type: QUERY
POSTHOOK: query: explain
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 is a root stage
  Stage-4 is a root stage
  Stage-1 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl1
            Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: val (type: int)
              outputColumnNames: _col1
              Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col1), max(_col1)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl2
            Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: val (type: int)
              outputColumnNames: _col1
              Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col1), max(_col1)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-4
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl3
            Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: val (type: int)
              outputColumnNames: _col1
              Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col1), max(_col1)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(*) from (
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3) t
PREHOOK: type: QUERY
PREHOOK: Input: default@inputtbl1
PREHOOK: Input: default@inputtbl2
PREHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from (
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3) t
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputtbl1
POSTHOOK: Input: default@inputtbl2
POSTHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
3
PREHOOK: query: --- union remove optimization and stats optimization are effective after inputTbl2 column stats is calculated
analyze table inputTbl2 compute statistics for columns
PREHOOK: type: QUERY
PREHOOK: Input: default@inputtbl2
#### A masked pattern was here ####
POSTHOOK: query: --- union remove optimization and stats optimization are effective after inputTbl2 column stats is calculated
analyze table inputTbl2 compute statistics for columns
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputtbl2
#### A masked pattern was here ####
PREHOOK: query: explain
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3
PREHOOK: type: QUERY
POSTHOOK: query: explain
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: 3
      Processor Tree:
        ListSink

PREHOOK: query: select count(*) from (
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3) t
PREHOOK: type: QUERY
PREHOOK: Input: default@inputtbl1
PREHOOK: Input: default@inputtbl2
PREHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from (
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3) t
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputtbl1
POSTHOOK: Input: default@inputtbl2
POSTHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
3
PREHOOK: query: --- union remove optimization effects but stats optimization does not (with group by) though it is on
explain
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1 group by key
  UNION ALL
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2 group by key
  UNION ALL
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3 group by key
PREHOOK: type: QUERY
POSTHOOK: query: --- union remove optimization effects but stats optimization does not (with group by) though it is on
explain
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1 group by key
  UNION ALL
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2 group by key
  UNION ALL
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3 group by key
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 is a root stage
  Stage-3 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl1
            Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: key (type: string), val (type: int)
              outputColumnNames: _col0, _col2
              Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col2), max(_col2)
                keys: _col0 (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: bigint), _col2 (type: int), _col3 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Statistics: Num rows: 3 Data size: 12 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 3 Data size: 12 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl2
            Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: key (type: string), val (type: int)
              outputColumnNames: _col0, _col2
              Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col2), max(_col2)
                keys: _col0 (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: bigint), _col2 (type: int), _col3 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Statistics: Num rows: 3 Data size: 12 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 3 Data size: 12 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl3
            Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: key (type: string), val (type: int)
              outputColumnNames: _col0, _col2
              Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col2), max(_col2)
                keys: _col0 (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: bigint), _col2 (type: int), _col3 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(*) from (
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1 group by key
  UNION ALL
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2 group by key
  UNION ALL
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3 group by key) t
PREHOOK: type: QUERY
PREHOOK: Input: default@inputtbl1
PREHOOK: Input: default@inputtbl2
PREHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from (
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1 group by key
  UNION ALL
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2 group by key
  UNION ALL
  SELECT key, count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3 group by key) t
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputtbl1
POSTHOOK: Input: default@inputtbl2
POSTHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
14
PREHOOK: query: explain
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3
PREHOOK: type: QUERY
POSTHOOK: query: explain
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 is a root stage
  Stage-3 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl1
            Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: val (type: int)
              outputColumnNames: _col1
              Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col1), max(_col1)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl2
            Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: val (type: int)
              outputColumnNames: _col1
              Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col1), max(_col1)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl3
            Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: val (type: int)
              outputColumnNames: _col1
              Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col1), max(_col1)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(*) from (
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3) t
PREHOOK: type: QUERY
PREHOOK: Input: default@inputtbl1
PREHOOK: Input: default@inputtbl2
PREHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from (
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3) t
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputtbl1
POSTHOOK: Input: default@inputtbl2
POSTHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
3
PREHOOK: query: explain
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3
PREHOOK: type: QUERY
POSTHOOK: query: explain
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1, Stage-3, Stage-4
  Stage-3 is a root stage
  Stage-4 is a root stage
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl1
            Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: val (type: int)
              outputColumnNames: _col1
              Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col1), max(_col1)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Union
              Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: NONE
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          TableScan
            Union
              Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: NONE
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          TableScan
            Union
              Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: NONE
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl2
            Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: val (type: int)
              outputColumnNames: _col1
              Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col1), max(_col1)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-4
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: inputtbl3
            Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: val (type: int)
              outputColumnNames: _col1
              Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(1), min(_col1), max(_col1)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint), _col1 (type: int), _col2 (type: int)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), min(VALUE._col1), max(VALUE._col2)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(*) from (
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3) t
PREHOOK: type: QUERY
PREHOOK: Input: default@inputtbl1
PREHOOK: Input: default@inputtbl2
PREHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from (
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl1
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl2
  UNION ALL
  SELECT count(1) as rowcnt, min(val) as ms, max(val) as mx from inputTbl3) t
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inputtbl1
POSTHOOK: Input: default@inputtbl2
POSTHOOK: Input: default@inputtbl3
#### A masked pattern was here ####
3
