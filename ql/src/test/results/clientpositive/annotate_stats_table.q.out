PREHOOK: query: create table if not exists emp_staging (
  lastname string,
  deptid int
) row format delimited fields terminated by '|' stored as textfile
PREHOOK: type: CREATETABLE
POSTHOOK: query: create table if not exists emp_staging (
  lastname string,
  deptid int
) row format delimited fields terminated by '|' stored as textfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@emp_staging
PREHOOK: query: create table if not exists emp_orc like emp_staging
PREHOOK: type: CREATETABLE
POSTHOOK: query: create table if not exists emp_orc like emp_staging
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@emp_orc
PREHOOK: query: alter table emp_orc set fileformat orc
PREHOOK: type: ALTERTABLE_FILEFORMAT
PREHOOK: Input: default@emp_orc
PREHOOK: Output: default@emp_orc
POSTHOOK: query: alter table emp_orc set fileformat orc
POSTHOOK: type: ALTERTABLE_FILEFORMAT
POSTHOOK: Input: default@emp_orc
POSTHOOK: Output: default@emp_orc
PREHOOK: query: -- basicStatState: NONE colStatState: NONE
explain extended select * from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: NONE colStatState: NONE
explain extended select * from emp_orc
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME emp_orc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_orc
          Statistics:
              numRows: 0 dataSize: 0 basicStatsState: NONE colStatsState: NONE
          GatherStats: false
          Select Operator
            expressions:
                  expr: lastname
                  type: string
                  expr: deptid
                  type: int
            outputColumnNames: _col0, _col1
            Statistics:
                numRows: 0 dataSize: 0 basicStatsState: NONE colStatsState: NONE
            ListSink

PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/emp.txt' OVERWRITE INTO TABLE emp_staging
PREHOOK: type: LOAD
PREHOOK: Output: default@emp_staging
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/emp.txt' OVERWRITE INTO TABLE emp_staging
POSTHOOK: type: LOAD
POSTHOOK: Output: default@emp_staging
PREHOOK: query: insert overwrite table emp_orc select * from emp_staging
PREHOOK: type: QUERY
PREHOOK: Input: default@emp_staging
PREHOOK: Output: default@emp_orc
POSTHOOK: query: insert overwrite table emp_orc select * from emp_staging
POSTHOOK: type: QUERY
POSTHOOK: Input: default@emp_staging
POSTHOOK: Output: default@emp_orc
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
PREHOOK: query: -- stats are disabled. basic stats will report the file size but not raw data size. so initial statistics will be PARTIAL

-- basicStatState: PARTIAL colStatState: NONE
explain extended select * from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- stats are disabled. basic stats will report the file size but not raw data size. so initial statistics will be PARTIAL

-- basicStatState: PARTIAL colStatState: NONE
explain extended select * from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME emp_orc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_orc
          Statistics:
              numRows: 3 dataSize: 349 basicStatsState: COMPLETE colStatsState: NONE
          GatherStats: false
          Select Operator
            expressions:
                  expr: lastname
                  type: string
                  expr: deptid
                  type: int
            outputColumnNames: _col0, _col1
            Statistics:
                numRows: 3 dataSize: 349 basicStatsState: COMPLETE colStatsState: NONE
            ListSink

PREHOOK: query: -- table level analyze statistics
analyze table emp_orc compute statistics
PREHOOK: type: QUERY
PREHOOK: Input: default@emp_orc
PREHOOK: Output: default@emp_orc
POSTHOOK: query: -- table level analyze statistics
analyze table emp_orc compute statistics
POSTHOOK: type: QUERY
POSTHOOK: Input: default@emp_orc
POSTHOOK: Output: default@emp_orc
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
PREHOOK: query: -- basicStatState: COMPLETE colStatState: NONE
explain extended select * from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: NONE
explain extended select * from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME emp_orc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_orc
          Statistics:
              numRows: 6 dataSize: 349 basicStatsState: COMPLETE colStatsState: NONE
          GatherStats: false
          Select Operator
            expressions:
                  expr: lastname
                  type: string
                  expr: deptid
                  type: int
            outputColumnNames: _col0, _col1
            Statistics:
                numRows: 6 dataSize: 349 basicStatsState: COMPLETE colStatsState: NONE
            ListSink

PREHOOK: query: -- column level partial statistics
analyze table emp_orc compute statistics for columns deptid
PREHOOK: type: QUERY
PREHOOK: Input: default@emp_orc
#### A masked pattern was here ####
POSTHOOK: query: -- column level partial statistics
analyze table emp_orc compute statistics for columns deptid
POSTHOOK: type: QUERY
POSTHOOK: Input: default@emp_orc
#### A masked pattern was here ####
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
PREHOOK: query: -- basicStatState: COMPLETE colStatState: PARTIAL
explain extended select * from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: PARTIAL
explain extended select * from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME emp_orc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_orc
          Statistics:
              numRows: 6 dataSize: 349 basicStatsState: COMPLETE colStatsState: PARTIAL
          GatherStats: false
          Select Operator
            expressions:
                  expr: lastname
                  type: string
                  expr: deptid
                  type: int
            outputColumnNames: _col0, _col1
            Statistics:
                numRows: 6 dataSize: 349 basicStatsState: COMPLETE colStatsState: PARTIAL
            ListSink

PREHOOK: query: -- all selected columns have statistics
-- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select deptid from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- all selected columns have statistics
-- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select deptid from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME emp_orc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL deptid)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        emp_orc 
          TableScan
            alias: emp_orc
            Statistics:
                numRows: 6 dataSize: 349 basicStatsState: COMPLETE colStatsState: COMPLETE
            GatherStats: false
            Select Operator
              expressions:
                    expr: deptid
                    type: int
              outputColumnNames: _col0
              Statistics:
                  numRows: 6 dataSize: 20 basicStatsState: COMPLETE colStatsState: COMPLETE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics:
                    numRows: 6 dataSize: 20 basicStatsState: COMPLETE colStatsState: COMPLETE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types int
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: emp_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns lastname,deptid
              columns.types string:int
              field.delim |
#### A masked pattern was here ####
              name default.emp_orc
              numFiles 1
              numRows 6
              rawDataSize 0
              serialization.ddl struct emp_orc { string lastname, i32 deptid}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 349
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns lastname,deptid
                columns.types string:int
                field.delim |
#### A masked pattern was here ####
                name default.emp_orc
                numFiles 1
                numRows 6
                rawDataSize 0
                serialization.ddl struct emp_orc { string lastname, i32 deptid}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 349
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.emp_orc
            name: default.emp_orc
      Truncated Path -> Alias:
        /emp_orc [emp_orc]

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- column level complete statistics
analyze table emp_orc compute statistics for columns lastname,deptid
PREHOOK: type: QUERY
PREHOOK: Input: default@emp_orc
#### A masked pattern was here ####
POSTHOOK: query: -- column level complete statistics
analyze table emp_orc compute statistics for columns lastname,deptid
POSTHOOK: type: QUERY
POSTHOOK: Input: default@emp_orc
#### A masked pattern was here ####
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
PREHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select * from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select * from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME emp_orc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_orc
          Statistics:
              numRows: 6 dataSize: 349 basicStatsState: COMPLETE colStatsState: COMPLETE
          GatherStats: false
          Select Operator
            expressions:
                  expr: lastname
                  type: string
                  expr: deptid
                  type: int
            outputColumnNames: _col0, _col1
            Statistics:
                numRows: 6 dataSize: 349 basicStatsState: COMPLETE colStatsState: COMPLETE
            ListSink

PREHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select lastname from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select lastname from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME emp_orc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL lastname)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        emp_orc 
          TableScan
            alias: emp_orc
            Statistics:
                numRows: 6 dataSize: 349 basicStatsState: COMPLETE colStatsState: COMPLETE
            GatherStats: false
            Select Operator
              expressions:
                    expr: lastname
                    type: string
              outputColumnNames: _col0
              Statistics:
                  numRows: 6 dataSize: 546 basicStatsState: COMPLETE colStatsState: COMPLETE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics:
                    numRows: 6 dataSize: 546 basicStatsState: COMPLETE colStatsState: COMPLETE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: emp_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns lastname,deptid
              columns.types string:int
              field.delim |
#### A masked pattern was here ####
              name default.emp_orc
              numFiles 1
              numRows 6
              rawDataSize 0
              serialization.ddl struct emp_orc { string lastname, i32 deptid}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 349
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns lastname,deptid
                columns.types string:int
                field.delim |
#### A masked pattern was here ####
                name default.emp_orc
                numFiles 1
                numRows 6
                rawDataSize 0
                serialization.ddl struct emp_orc { string lastname, i32 deptid}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 349
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.emp_orc
            name: default.emp_orc
      Truncated Path -> Alias:
        /emp_orc [emp_orc]

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select deptid from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select deptid from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME emp_orc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL deptid)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        emp_orc 
          TableScan
            alias: emp_orc
            Statistics:
                numRows: 6 dataSize: 349 basicStatsState: COMPLETE colStatsState: COMPLETE
            GatherStats: false
            Select Operator
              expressions:
                    expr: deptid
                    type: int
              outputColumnNames: _col0
              Statistics:
                  numRows: 6 dataSize: 20 basicStatsState: COMPLETE colStatsState: COMPLETE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics:
                    numRows: 6 dataSize: 20 basicStatsState: COMPLETE colStatsState: COMPLETE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types int
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: emp_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns lastname,deptid
              columns.types string:int
              field.delim |
#### A masked pattern was here ####
              name default.emp_orc
              numFiles 1
              numRows 6
              rawDataSize 0
              serialization.ddl struct emp_orc { string lastname, i32 deptid}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 349
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns lastname,deptid
                columns.types string:int
                field.delim |
#### A masked pattern was here ####
                name default.emp_orc
                numFiles 1
                numRows 6
                rawDataSize 0
                serialization.ddl struct emp_orc { string lastname, i32 deptid}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 349
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.emp_orc
            name: default.emp_orc
      Truncated Path -> Alias:
        /emp_orc [emp_orc]

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select lastname,deptid from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select lastname,deptid from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME emp_orc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL lastname)) (TOK_SELEXPR (TOK_TABLE_OR_COL deptid)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        emp_orc 
          TableScan
            alias: emp_orc
            Statistics:
                numRows: 6 dataSize: 349 basicStatsState: COMPLETE colStatsState: COMPLETE
            GatherStats: false
            Select Operator
              expressions:
                    expr: lastname
                    type: string
                    expr: deptid
                    type: int
              outputColumnNames: _col0, _col1
              Statistics:
                  numRows: 6 dataSize: 566 basicStatsState: COMPLETE colStatsState: COMPLETE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics:
                    numRows: 6 dataSize: 566 basicStatsState: COMPLETE colStatsState: COMPLETE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0,_col1
                      columns.types string:int
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: emp_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns lastname,deptid
              columns.types string:int
              field.delim |
#### A masked pattern was here ####
              name default.emp_orc
              numFiles 1
              numRows 6
              rawDataSize 0
              serialization.ddl struct emp_orc { string lastname, i32 deptid}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 349
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns lastname,deptid
                columns.types string:int
                field.delim |
#### A masked pattern was here ####
                name default.emp_orc
                numFiles 1
                numRows 6
                rawDataSize 0
                serialization.ddl struct emp_orc { string lastname, i32 deptid}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 349
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.emp_orc
            name: default.emp_orc
      Truncated Path -> Alias:
        /emp_orc [emp_orc]

  Stage: Stage-0
    Fetch Operator
      limit: -1

