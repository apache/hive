PREHOOK: query: -- EXCLUDE_HADOOP_MAJOR_VERSIONS( 0.20S)

-- create file inputs
create table sih_i_part (key int, value string) partitioned by (p string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@sih_i_part
POSTHOOK: query: -- EXCLUDE_HADOOP_MAJOR_VERSIONS( 0.20S)

-- create file inputs
create table sih_i_part (key int, value string) partitioned by (p string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@sih_i_part
PREHOOK: query: insert overwrite table sih_i_part partition (p='1') select key, value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@sih_i_part@p=1
POSTHOOK: query: insert overwrite table sih_i_part partition (p='1') select key, value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@sih_i_part@p=1
POSTHOOK: Lineage: sih_i_part PARTITION(p=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: sih_i_part PARTITION(p=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: insert overwrite table sih_i_part partition (p='2') select key+10000, value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@sih_i_part@p=2
POSTHOOK: query: insert overwrite table sih_i_part partition (p='2') select key+10000, value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@sih_i_part@p=2
POSTHOOK: Lineage: sih_i_part PARTITION(p=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: sih_i_part PARTITION(p=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: insert overwrite table sih_i_part partition (p='3') select key+20000, value from src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@sih_i_part@p=3
POSTHOOK: query: insert overwrite table sih_i_part partition (p='3') select key+20000, value from src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@sih_i_part@p=3
POSTHOOK: Lineage: sih_i_part PARTITION(p=3).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: sih_i_part PARTITION(p=3).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: create table sih_src as select key, value from sih_i_part order by key, value
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@sih_i_part
PREHOOK: Input: default@sih_i_part@p=1
PREHOOK: Input: default@sih_i_part@p=2
PREHOOK: Input: default@sih_i_part@p=3
PREHOOK: Output: database:default
PREHOOK: Output: default@sih_src
POSTHOOK: query: create table sih_src as select key, value from sih_i_part order by key, value
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@sih_i_part
POSTHOOK: Input: default@sih_i_part@p=1
POSTHOOK: Input: default@sih_i_part@p=2
POSTHOOK: Input: default@sih_i_part@p=3
POSTHOOK: Output: database:default
POSTHOOK: Output: default@sih_src
POSTHOOK: Lineage: sih_src.key SIMPLE [(sih_i_part)sih_i_part.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: sih_src.value SIMPLE [(sih_i_part)sih_i_part.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: create table sih_src2 as select key, value from sih_src order by key, value
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@sih_src
PREHOOK: Output: database:default
PREHOOK: Output: default@sih_src2
POSTHOOK: query: create table sih_src2 as select key, value from sih_src order by key, value
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@sih_src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@sih_src2
POSTHOOK: Lineage: sih_src2.key SIMPLE [(sih_src)sih_src.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: sih_src2.value SIMPLE [(sih_src)sih_src.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: -- Relaxing hive.exec.mode.local.auto.input.files.max=1.
-- Hadoop20 will not generate more splits than there are files (one).
-- Hadoop23 generate splits correctly (four), hence the max needs to be adjusted to ensure running in local mode.
-- Default value is hive.exec.mode.local.auto.input.files.max=4 which produces expected behavior on Hadoop23.
-- hive.sample.seednumber is required because Hadoop23 generates multiple splits and tablesample is non-repeatable without it.

-- sample split, running locally limited by num tasks
select count(1) from sih_src tablesample(1 percent)
PREHOOK: type: QUERY
PREHOOK: Input: default@sih_src
#### A masked pattern was here ####
25
PREHOOK: query: -- sample two tables
select count(1) from sih_src tablesample(1 percent) a join sih_src2 tablesample(1 percent) b on a.key = b.key
PREHOOK: type: QUERY
PREHOOK: Input: default@sih_src
PREHOOK: Input: default@sih_src2
#### A masked pattern was here ####
49
PREHOOK: query: -- sample split, running locally limited by max bytes
select count(1) from sih_src tablesample(1 percent)
PREHOOK: type: QUERY
PREHOOK: Input: default@sih_src
#### A masked pattern was here ####
25
