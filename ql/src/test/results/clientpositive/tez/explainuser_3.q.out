PREHOOK: query: CREATE TABLE acid_vectorized_n0(a INT, b STRING) CLUSTERED BY(a) INTO 2 BUCKETS STORED AS ORC TBLPROPERTIES ('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@acid_vectorized_n0
POSTHOOK: query: CREATE TABLE acid_vectorized_n0(a INT, b STRING) CLUSTERED BY(a) INTO 2 BUCKETS STORED AS ORC TBLPROPERTIES ('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@acid_vectorized_n0
PREHOOK: query: insert into table acid_vectorized_n0 select cint, cstring1 from alltypesorc where cint is not null order by cint limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@alltypesorc
PREHOOK: Output: default@acid_vectorized_n0
POSTHOOK: query: insert into table acid_vectorized_n0 select cint, cstring1 from alltypesorc where cint is not null order by cint limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@alltypesorc
POSTHOOK: Output: default@acid_vectorized_n0
POSTHOOK: Lineage: acid_vectorized_n0.a SIMPLE [(alltypesorc)alltypesorc.FieldSchema(name:cint, type:int, comment:null), ]
POSTHOOK: Lineage: acid_vectorized_n0.b SIMPLE [(alltypesorc)alltypesorc.FieldSchema(name:cstring1, type:string, comment:null), ]
PREHOOK: query: analyze table acid_vectorized_n0 compute statistics for columns
PREHOOK: type: ANALYZE_TABLE
PREHOOK: Input: default@acid_vectorized_n0
PREHOOK: Output: default@acid_vectorized_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: analyze table acid_vectorized_n0 compute statistics for columns
POSTHOOK: type: ANALYZE_TABLE
POSTHOOK: Input: default@acid_vectorized_n0
POSTHOOK: Output: default@acid_vectorized_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
PREHOOK: query: explain select a, b from acid_vectorized_n0 order by a, b
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_vectorized_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select a, b from acid_vectorized_n0 order by a, b
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_vectorized_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 2 <- Map 1 (SIMPLE_EDGE)

Stage-0
  Fetch Operator
    limit:-1
    Stage-1
      Reducer 2 vectorized
      File Output Operator [FS_8]
        Select Operator [SEL_7] (rows=10 width=101)
          Output:["_col0","_col1"]
        <-Map 1 [SIMPLE_EDGE] vectorized
          SHUFFLE [RS_6]
            Select Operator [SEL_5] (rows=10 width=101)
              Output:["_col0","_col1"]
              TableScan [TS_0] (rows=10 width=101)
                default@acid_vectorized_n0,acid_vectorized_n0, ACID table,Tbl:COMPLETE,Col:COMPLETE,Output:["a","b"]

PREHOOK: query: explain select key, value
FROM srcpart LATERAL VIEW explode(array(1,2,3)) myTable AS myCol
PREHOOK: type: QUERY
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select key, value
FROM srcpart LATERAL VIEW explode(array(1,2,3)) myTable AS myCol
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan not optimized by CBO because the statement has lateral views

Stage-0
  Fetch Operator
    limit:-1
    Select Operator [SEL_6]
      Output:["_col0","_col1"]
      Lateral View Join Operator [LVJ_5]
        Output:["_col0","_col1","_col7"]
        Select Operator [SEL_2]
          Output:["key","value"]
          Lateral View Forward [LVF_1]
            TableScan [TS_0]
              Output:["key","value"]
    Select Operator [SEL_6]
      Output:["_col0","_col1"]
      Lateral View Join Operator [LVJ_5]
        Output:["_col0","_col1","_col7"]
        UDTF Operator [UDTF_4]
          function name:explode
          Select Operator [SEL_3]
            Output:["_col0"]
             Please refer to the previous Lateral View Forward [LVF_1]

PREHOOK: query: explain show tables
PREHOOK: type: SHOWTABLES
PREHOOK: Input: database:default
POSTHOOK: query: explain show tables
POSTHOOK: type: SHOWTABLES
POSTHOOK: Input: database:default
Stage-1
  Fetch Operator
    limit:-1
    Stage-0
      Show Tables{"database name:":"default"}

#### A masked pattern was here ####
PREHOOK: type: CREATEDATABASE
PREHOOK: Output: database:newDB
PREHOOK: Output: hdfs://### HDFS PATH ###
#### A masked pattern was here ####
POSTHOOK: type: CREATEDATABASE
POSTHOOK: Output: database:newDB
POSTHOOK: Output: hdfs://### HDFS PATH ###
Stage-0
  Create Database{"name:":"newDB"}

#### A masked pattern was here ####
PREHOOK: type: CREATEDATABASE
PREHOOK: Output: database:newDB
PREHOOK: Output: hdfs://### HDFS PATH ###
#### A masked pattern was here ####
POSTHOOK: type: CREATEDATABASE
POSTHOOK: Output: database:newDB
POSTHOOK: Output: hdfs://### HDFS PATH ###
PREHOOK: query: explain describe database extended newDB
PREHOOK: type: DESCDATABASE
PREHOOK: Input: database:newdb
POSTHOOK: query: explain describe database extended newDB
POSTHOOK: type: DESCDATABASE
POSTHOOK: Input: database:newdb
Stage-1
  Fetch Operator
    limit:-1
    Stage-0
      Describe Database{"database:":"newDB","extended:":"true"}

PREHOOK: query: describe database extended newDB
PREHOOK: type: DESCDATABASE
PREHOOK: Input: database:newdb
POSTHOOK: query: describe database extended newDB
POSTHOOK: type: DESCDATABASE
POSTHOOK: Input: database:newdb
newdb		location/in/test		hive_test_user	USER	
PREHOOK: query: explain use newDB
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:newdb
POSTHOOK: query: explain use newDB
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:newdb
Stage-0
  Switch Database{"name:":"newDB"}

PREHOOK: query: use newDB
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:newdb
POSTHOOK: query: use newDB
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:newdb
PREHOOK: query: create table tab_n1 (name string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:newdb
PREHOOK: Output: newDB@tab_n1
POSTHOOK: query: create table tab_n1 (name string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:newdb
POSTHOOK: Output: newDB@tab_n1
PREHOOK: query: explain alter table tab_n1 rename to newName
PREHOOK: type: ALTERTABLE_RENAME
PREHOOK: Input: newdb@tab_n1
PREHOOK: Output: newdb@tab_n1
POSTHOOK: query: explain alter table tab_n1 rename to newName
POSTHOOK: type: ALTERTABLE_RENAME
POSTHOOK: Input: newdb@tab_n1
POSTHOOK: Output: newdb@tab_n1
Stage-0
  Rename Table{"table name:":"newDB.tab_n1","new table name:":"newDB.newName"}

PREHOOK: query: explain drop table tab_n1
PREHOOK: type: DROPTABLE
PREHOOK: Input: newdb@tab_n1
PREHOOK: Output: newdb@tab_n1
POSTHOOK: query: explain drop table tab_n1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: newdb@tab_n1
POSTHOOK: Output: newdb@tab_n1
Stage-0
  Drop Table{"table:":"tab_n1"}

PREHOOK: query: drop table tab_n1
PREHOOK: type: DROPTABLE
PREHOOK: Input: newdb@tab_n1
PREHOOK: Output: newdb@tab_n1
POSTHOOK: query: drop table tab_n1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: newdb@tab_n1
POSTHOOK: Output: newdb@tab_n1
PREHOOK: query: explain use default
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:default
POSTHOOK: query: explain use default
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:default
Stage-0
  Switch Database{"name:":"default"}

PREHOOK: query: use default
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:default
POSTHOOK: query: use default
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:default
PREHOOK: query: drop database newDB
PREHOOK: type: DROPDATABASE
PREHOOK: Input: database:newdb
PREHOOK: Output: database:newdb
POSTHOOK: query: drop database newDB
POSTHOOK: type: DROPDATABASE
POSTHOOK: Input: database:newdb
POSTHOOK: Output: database:newdb
PREHOOK: query: explain analyze table src compute statistics
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@src
POSTHOOK: query: explain analyze table src compute statistics
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@src
Stage-2
  Stats Work{}
    Stage-0
      Map 1
      TableScan [TS_0]

PREHOOK: query: explain analyze table src compute statistics for columns
PREHOOK: type: ANALYZE_TABLE
PREHOOK: Input: default@src
PREHOOK: Output: default@src
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain analyze table src compute statistics for columns
POSTHOOK: type: ANALYZE_TABLE
POSTHOOK: Input: default@src
POSTHOOK: Output: default@src
POSTHOOK: Output: hdfs://### HDFS PATH ###
Vertex dependency in root stage
Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)

Stage-2
  Stats Work{}
    Stage-0
      Reducer 2 vectorized
      File Output Operator [FS_9]
        Select Operator [SEL_8] (rows=1 width=532)
          Output:["_col0","_col1","_col2","_col3","_col4","_col5","_col6","_col7","_col8","_col9","_col10","_col11"]
          Group By Operator [GBY_7] (rows=1 width=336)
            Output:["_col0","_col1","_col2","_col3","_col4","_col5","_col6","_col7","_col8"],aggregations:["max(VALUE._col0)","avg(VALUE._col1)","count(VALUE._col2)","count(VALUE._col3)","compute_bit_vector_hll(VALUE._col4)","max(VALUE._col5)","avg(VALUE._col6)","count(VALUE._col7)","compute_bit_vector_hll(VALUE._col8)"]
          <-Map 1 [CUSTOM_SIMPLE_EDGE]
            PARTITION_ONLY_SHUFFLE [RS_3]
              Group By Operator [GBY_2] (rows=1 width=472)
                Output:["_col0","_col1","_col2","_col3","_col4","_col5","_col6","_col7","_col8"],aggregations:["max(length(key))","avg(COALESCE(length(key),0))","count(1)","count(key)","compute_bit_vector_hll(key)","max(length(value))","avg(COALESCE(length(value),0))","count(value)","compute_bit_vector_hll(value)"]
                Select Operator [SEL_1] (rows=500 width=178)
                  Output:["key","value"]
                  TableScan [TS_0] (rows=500 width=178)
                    default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]

PREHOOK: query: explain
CREATE TEMPORARY MACRO SIGMOID (x DOUBLE) 1.0 / (1.0 + EXP(-x))
PREHOOK: type: CREATEMACRO
PREHOOK: Output: database:default
POSTHOOK: query: explain
CREATE TEMPORARY MACRO SIGMOID (x DOUBLE) 1.0 / (1.0 + EXP(-x))
POSTHOOK: type: CREATEMACRO
POSTHOOK: Output: database:default
Stage-0
  Create Macro{"body:":"GenericUDFOPDivide(Const decimal(1,0) 1, GenericUDFOPPlus(Const decimal(1,0) 1, GenericUDFBridge ==> exp (GenericUDFOPNegative(Column[x]))))","column names:":["x"],"column types:":["double"],"name:":"SIGMOID"}

PREHOOK: query: CREATE TEMPORARY MACRO SIGMOID (x DOUBLE) 1.0 / (1.0 + EXP(-x))
PREHOOK: type: CREATEMACRO
PREHOOK: Output: database:default
POSTHOOK: query: CREATE TEMPORARY MACRO SIGMOID (x DOUBLE) 1.0 / (1.0 + EXP(-x))
POSTHOOK: type: CREATEMACRO
POSTHOOK: Output: database:default
PREHOOK: query: EXPLAIN SELECT SIGMOID(2) FROM src LIMIT 1
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: EXPLAIN SELECT SIGMOID(2) FROM src LIMIT 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan optimized by CBO.

Stage-0
  Fetch Operator
    limit:1
    Select Operator [SEL_1]
      Output:["_col0"]
      Limit [LIM_2]
        Number of rows:1
        TableScan [TS_0]

PREHOOK: query: explain DROP TEMPORARY MACRO SIGMOID
PREHOOK: type: DROPMACRO
PREHOOK: Output: database:default
POSTHOOK: query: explain DROP TEMPORARY MACRO SIGMOID
POSTHOOK: type: DROPMACRO
POSTHOOK: Output: database:default
Stage-0
  Drop Macro{"name:":"SIGMOID"}

PREHOOK: query: DROP TEMPORARY MACRO SIGMOID
PREHOOK: type: DROPMACRO
PREHOOK: Output: database:default
POSTHOOK: query: DROP TEMPORARY MACRO SIGMOID
POSTHOOK: type: DROPMACRO
POSTHOOK: Output: database:default
PREHOOK: query: explain create table src_autho_test_n3 as select * from src
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: explain create table src_autho_test_n3 as select * from src
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@src_autho_test_n3
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)

Stage-3
  Stats Work{}
    Stage-4
      Create Table{"name:":"default.src_autho_test_n3"}
        Stage-0
          Move Operator
            Stage-1
              Reducer 2 vectorized
              File Output Operator [FS_20]
                Select Operator [SEL_19] (rows=1 width=532)
                  Output:["_col0","_col1","_col2","_col3","_col4","_col5","_col6","_col7","_col8","_col9","_col10","_col11"]
                  Group By Operator [GBY_18] (rows=1 width=336)
                    Output:["_col0","_col1","_col2","_col3","_col4","_col5","_col6","_col7","_col8"],aggregations:["max(VALUE._col0)","avg(VALUE._col1)","count(VALUE._col2)","count(VALUE._col3)","compute_bit_vector_hll(VALUE._col4)","max(VALUE._col5)","avg(VALUE._col6)","count(VALUE._col7)","compute_bit_vector_hll(VALUE._col8)"]
                  <-Map 1 [CUSTOM_SIMPLE_EDGE] vectorized
                    File Output Operator [FS_14]
                      table:{"name:":"default.src_autho_test_n3"}
                      Select Operator [SEL_13] (rows=500 width=178)
                        Output:["_col0","_col1"]
                        TableScan [TS_0] (rows=500 width=178)
                          default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
                    PARTITION_ONLY_SHUFFLE [RS_17]
                      Group By Operator [GBY_16] (rows=1 width=472)
                        Output:["_col0","_col1","_col2","_col3","_col4","_col5","_col6","_col7","_col8"],aggregations:["max(length(col1))","avg(COALESCE(length(col1),0))","count(1)","count(col1)","compute_bit_vector_hll(col1)","max(length(col2))","avg(COALESCE(length(col2),0))","count(col2)","compute_bit_vector_hll(col2)"]
                        Select Operator [SEL_15] (rows=500 width=178)
                          Output:["col1","col2"]
                           Please refer to the previous Select Operator [SEL_13]
        Stage-2
          Dependency Collection{}
             Please refer to the previous Stage-1

PREHOOK: query: create table src_autho_test_n3 as select * from src
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: create table src_autho_test_n3 as select * from src
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@src_autho_test_n3
POSTHOOK: Lineage: src_autho_test_n3.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: src_autho_test_n3.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain grant select on table src_autho_test_n3 to user hive_test_user
PREHOOK: type: GRANT_PRIVILEGE
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: explain grant select on table src_autho_test_n3 to user hive_test_user
POSTHOOK: type: GRANT_PRIVILEGE
POSTHOOK: Output: default@src_autho_test_n3
Stage-0
  Grant{"Principals:":[{"Principal":{"name:":"hive_test_user"}}],"privilege subject":{"object:":"default.src_autho_test_n3"},"Privileges:":[{"Privilege":{"privilege:":{"type:":"Select"}}}],"grant option:":"false"}

PREHOOK: query: grant select on table src_autho_test_n3 to user hive_test_user
PREHOOK: type: GRANT_PRIVILEGE
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: grant select on table src_autho_test_n3 to user hive_test_user
POSTHOOK: type: GRANT_PRIVILEGE
POSTHOOK: Output: default@src_autho_test_n3
PREHOOK: query: explain show grant user hive_test_user on table src_autho_test_n3
PREHOOK: type: SHOW_GRANT
POSTHOOK: query: explain show grant user hive_test_user on table src_autho_test_n3
POSTHOOK: type: SHOW_GRANT
Stage-1
  Fetch Operator
    limit:-1
    Stage-0
      Show grant desc{"privilege subject":{"object:":"default.src_autho_test_n3"},"principal desc:":{"Principal":{"name:":"hive_test_user"}}}

PREHOOK: query: explain show grant user hive_test_user on table src_autho_test_n3(key)
PREHOOK: type: SHOW_GRANT
POSTHOOK: query: explain show grant user hive_test_user on table src_autho_test_n3(key)
POSTHOOK: type: SHOW_GRANT
Stage-1
  Fetch Operator
    limit:-1
    Stage-0
      Show grant desc{"privilege subject":{"object:":"default.src_autho_test_n3"},"principal desc:":{"Principal":{"name:":"hive_test_user"}}}

PREHOOK: query: select key from src_autho_test_n3 order by key limit 20
PREHOOK: type: QUERY
PREHOOK: Input: default@src_autho_test_n3
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select key from src_autho_test_n3 order by key limit 20
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src_autho_test_n3
POSTHOOK: Output: hdfs://### HDFS PATH ###
0
0
0
10
100
100
103
103
104
104
105
11
111
113
113
114
116
118
118
119
PREHOOK: query: explain revoke select on table src_autho_test_n3 from user hive_test_user
PREHOOK: type: REVOKE_PRIVILEGE
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: explain revoke select on table src_autho_test_n3 from user hive_test_user
POSTHOOK: type: REVOKE_PRIVILEGE
POSTHOOK: Output: default@src_autho_test_n3
Stage-0
  Revoke{"Principals:":[{"Principal":{"name:":"hive_test_user"}}],"privilege subject":{"object:":"default.src_autho_test_n3"},"Privileges:":[{"Privilege":{"privilege:":{"type:":"Select"}}}]}

PREHOOK: query: explain grant select(key) on table src_autho_test_n3 to user hive_test_user
PREHOOK: type: GRANT_PRIVILEGE
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: explain grant select(key) on table src_autho_test_n3 to user hive_test_user
POSTHOOK: type: GRANT_PRIVILEGE
POSTHOOK: Output: default@src_autho_test_n3
Stage-0
  Grant{"Principals:":[{"Principal":{"name:":"hive_test_user"}}],"privilege subject":{"object:":"default.src_autho_test_n3"},"Privileges:":[{"Privilege":{"columns:":["key"],"privilege:":{"type:":"Select"}}}],"grant option:":"false"}

PREHOOK: query: explain revoke select(key) on table src_autho_test_n3 from user hive_test_user
PREHOOK: type: REVOKE_PRIVILEGE
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: explain revoke select(key) on table src_autho_test_n3 from user hive_test_user
POSTHOOK: type: REVOKE_PRIVILEGE
POSTHOOK: Output: default@src_autho_test_n3
Stage-0
  Revoke{"Principals:":[{"Principal":{"name:":"hive_test_user"}}],"privilege subject":{"object:":"default.src_autho_test_n3"},"Privileges:":[{"Privilege":{"columns:":["key"],"privilege:":{"type:":"Select"}}}]}

PREHOOK: query: explain 
create role sRc_roLE
PREHOOK: type: CREATEROLE
POSTHOOK: query: explain 
create role sRc_roLE
POSTHOOK: type: CREATEROLE
Stage-0
  Create Role{"name:":"sRc_roLE"}

PREHOOK: query: create role sRc_roLE
PREHOOK: type: CREATEROLE
POSTHOOK: query: create role sRc_roLE
POSTHOOK: type: CREATEROLE
PREHOOK: query: explain
grant role sRc_roLE to user hive_test_user
PREHOOK: type: GRANT_ROLE
POSTHOOK: query: explain
grant role sRc_roLE to user hive_test_user
POSTHOOK: type: GRANT_ROLE
Stage-0
  Grant roles{"principals:":[{"Principal":{"name:":"hive_test_user"}}],"roles:":["sRc_roLE"]}

PREHOOK: query: grant role sRc_roLE to user hive_test_user
PREHOOK: type: GRANT_ROLE
POSTHOOK: query: grant role sRc_roLE to user hive_test_user
POSTHOOK: type: GRANT_ROLE
PREHOOK: query: explain show role grant user hive_test_user
PREHOOK: type: SHOW_ROLE_GRANT
POSTHOOK: query: explain show role grant user hive_test_user
POSTHOOK: type: SHOW_ROLE_GRANT
Stage-1
  Fetch Operator
    limit:-1
    Stage-0
      Show Role Grant{"name:":"hive_test_user"}

PREHOOK: query: explain drop role sRc_roLE
PREHOOK: type: DROPROLE
POSTHOOK: query: explain drop role sRc_roLE
POSTHOOK: type: DROPROLE
Stage-0
  Drop Role{"name:":"sRc_roLE"}

PREHOOK: query: drop role sRc_roLE
PREHOOK: type: DROPROLE
POSTHOOK: query: drop role sRc_roLE
POSTHOOK: type: DROPROLE
PREHOOK: query: drop table src_autho_test_n3
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src_autho_test_n3
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: drop table src_autho_test_n3
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src_autho_test_n3
POSTHOOK: Output: default@src_autho_test_n3
PREHOOK: query: explain drop view v_n1
PREHOOK: type: DROPVIEW
POSTHOOK: query: explain drop view v_n1
POSTHOOK: type: DROPVIEW
Stage-0
  Drop View{"view name:":"v_n1"}

PREHOOK: query: explain create view v_n1 as with cte as (select * from src  order by key limit 5)
select * from cte
PREHOOK: type: CREATEVIEW
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@v_n1
POSTHOOK: query: explain create view v_n1 as with cte as (select * from src  order by key limit 5)
select * from cte
POSTHOOK: type: CREATEVIEW
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@v_n1
Plan optimized by CBO.

Stage-0
  Create View{"original text:":"with cte as (select * from src  order by key limit 5)\nselect * from cte","name:":"default.v_n1"}

PREHOOK: query: explain with cte as (select * from src  order by key limit 5)
select * from cte
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain with cte as (select * from src  order by key limit 5)
select * from cte
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 2 <- Map 1 (SIMPLE_EDGE)

Stage-0
  Fetch Operator
    limit:5
    Stage-1
      Reducer 2 vectorized
      File Output Operator [FS_12]
        Limit [LIM_11] (rows=5 width=178)
          Number of rows:5
          Select Operator [SEL_10] (rows=500 width=178)
            Output:["_col0","_col1"]
          <-Map 1 [SIMPLE_EDGE] vectorized
            SHUFFLE [RS_9]
              Select Operator [SEL_8] (rows=500 width=178)
                Output:["_col0","_col1"]
                Top N Key Operator [TNK_7] (rows=500 width=178)
                  keys:key,top n:5
                  TableScan [TS_0] (rows=500 width=178)
                    default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]

PREHOOK: query: create table orc_merge5_n0 (userid bigint, string1 string, subtype double, decimal1 decimal, ts timestamp) stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@orc_merge5_n0
POSTHOOK: query: create table orc_merge5_n0 (userid bigint, string1 string, subtype double, decimal1 decimal, ts timestamp) stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orc_merge5_n0
PREHOOK: query: load data local inpath '../../data/files/orc_split_elim.orc' into table orc_merge5_n0
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@orc_merge5_n0
POSTHOOK: query: load data local inpath '../../data/files/orc_split_elim.orc' into table orc_merge5_n0
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@orc_merge5_n0
PREHOOK: query: explain insert overwrite table orc_merge5_n0 select userid,string1,subtype,decimal1,ts from orc_merge5_n0 where userid<=13
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_merge5_n0
PREHOOK: Output: default@orc_merge5_n0
POSTHOOK: query: explain insert overwrite table orc_merge5_n0 select userid,string1,subtype,decimal1,ts from orc_merge5_n0 where userid<=13
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_merge5_n0
POSTHOOK: Output: default@orc_merge5_n0
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)

Stage-3
  Stats Work{}
    Stage-0
      Move Operator
        table:{"name:":"default.orc_merge5_n0"}
        Stage-2
          Dependency Collection{}
            Stage-5(CONDITIONAL)
              Move Operator
                Stage-8(CONDITIONAL CHILD TASKS: Stage-5, Stage-4, Stage-6)
                  Conditional Operator
                    Stage-1
                      Reducer 2 vectorized
                      File Output Operator [FS_21]
                        Select Operator [SEL_20] (rows=1 width=1536)
                          Output:["_col0","_col1","_col2","_col3","_col4","_col5","_col6","_col7","_col8","_col9","_col10","_col11","_col12","_col13","_col14","_col15","_col16","_col17","_col18","_col19","_col20","_col21","_col22","_col23","_col24","_col25","_col26","_col27","_col28","_col29"]
                          Group By Operator [GBY_19] (rows=1 width=1536)
                            Output:["_col0","_col1","_col2","_col3","_col4","_col5","_col6","_col7","_col8","_col9","_col10","_col11","_col12","_col13","_col14","_col15","_col16","_col17","_col18","_col19","_col20"],aggregations:["min(VALUE._col0)","max(VALUE._col1)","count(VALUE._col2)","count(VALUE._col3)","compute_bit_vector_hll(VALUE._col4)","max(VALUE._col5)","avg(VALUE._col6)","count(VALUE._col7)","compute_bit_vector_hll(VALUE._col8)","min(VALUE._col9)","max(VALUE._col10)","count(VALUE._col11)","compute_bit_vector_hll(VALUE._col12)","min(VALUE._col13)","max(VALUE._col14)","count(VALUE._col15)","compute_bit_vector_hll(VALUE._col16)","min(VALUE._col17)","max(VALUE._col18)","count(VALUE._col19)","compute_bit_vector_hll(VALUE._col20)"]
                          <-Map 1 [CUSTOM_SIMPLE_EDGE] vectorized
                            File Output Operator [FS_15]
                              table:{"name:":"default.orc_merge5_n0"}
                              Select Operator [SEL_14] (rows=1 width=352)
                                Output:["_col0","_col1","_col2","_col3","_col4"]
                                Filter Operator [FIL_13] (rows=1 width=352)
                                  predicate:(userid <= 13L)
                                  TableScan [TS_0] (rows=1 width=352)
                                    default@orc_merge5_n0,orc_merge5_n0,Tbl:COMPLETE,Col:NONE,Output:["userid","string1","subtype","decimal1","ts"]
                            PARTITION_ONLY_SHUFFLE [RS_18]
                              Group By Operator [GBY_17] (rows=1 width=1536)
                                Output:["_col0","_col1","_col2","_col3","_col4","_col5","_col6","_col7","_col8","_col9","_col10","_col11","_col12","_col13","_col14","_col15","_col16","_col17","_col18","_col19","_col20"],aggregations:["min(userid)","max(userid)","count(1)","count(userid)","compute_bit_vector_hll(userid)","max(length(string1))","avg(COALESCE(length(string1),0))","count(string1)","compute_bit_vector_hll(string1)","min(subtype)","max(subtype)","count(subtype)","compute_bit_vector_hll(subtype)","min(decimal1)","max(decimal1)","count(decimal1)","compute_bit_vector_hll(decimal1)","min(ts)","max(ts)","count(ts)","compute_bit_vector_hll(ts)"]
                                Select Operator [SEL_16] (rows=1 width=352)
                                  Output:["userid","string1","subtype","decimal1","ts"]
                                   Please refer to the previous Select Operator [SEL_14]
            Stage-4(CONDITIONAL)
              File Merge
                 Please refer to the previous Stage-8(CONDITIONAL CHILD TASKS: Stage-5, Stage-4, Stage-6)
            Stage-7
              Move Operator
                Stage-6(CONDITIONAL)
                  File Merge
                     Please refer to the previous Stage-8(CONDITIONAL CHILD TASKS: Stage-5, Stage-4, Stage-6)

PREHOOK: query: drop table orc_merge5_n0
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@orc_merge5_n0
PREHOOK: Output: default@orc_merge5_n0
POSTHOOK: query: drop table orc_merge5_n0
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@orc_merge5_n0
POSTHOOK: Output: default@orc_merge5_n0
PREHOOK: query: CREATE TABLE srcbucket_mapjoin_n3(key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@srcbucket_mapjoin_n3
POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_n3(key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@srcbucket_mapjoin_n3
PREHOOK: query: CREATE TABLE tab_part_n2 (key int, value string) PARTITIONED BY(ds STRING) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tab_part_n2
POSTHOOK: query: CREATE TABLE tab_part_n2 (key int, value string) PARTITIONED BY(ds STRING) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tab_part_n2
PREHOOK: query: CREATE TABLE srcbucket_mapjoin_part_n3 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@srcbucket_mapjoin_part_n3
POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_part_n3 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3
PREHOOK: query: load data local inpath '../../data/files/bmj/000000_0' INTO TABLE srcbucket_mapjoin_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_n3
POSTHOOK: query: load data local inpath '../../data/files/bmj/000000_0' INTO TABLE srcbucket_mapjoin_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_n3
POSTHOOK: Output: default@srcbucket_mapjoin_n3@ds=2008-04-08
PREHOOK: query: load data local inpath '../../data/files/bmj1/000001_0' INTO TABLE srcbucket_mapjoin_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_n3@ds=2008-04-08
POSTHOOK: query: load data local inpath '../../data/files/bmj1/000001_0' INTO TABLE srcbucket_mapjoin_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_n3@ds=2008-04-08
PREHOOK: query: load data local inpath '../../data/files/bmj/000000_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_part_n3
POSTHOOK: query: load data local inpath '../../data/files/bmj/000000_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
PREHOOK: query: load data local inpath '../../data/files/bmj/000001_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
POSTHOOK: query: load data local inpath '../../data/files/bmj/000001_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
PREHOOK: query: load data local inpath '../../data/files/bmj/000002_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
POSTHOOK: query: load data local inpath '../../data/files/bmj/000002_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
PREHOOK: query: load data local inpath '../../data/files/bmj/000003_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
POSTHOOK: query: load data local inpath '../../data/files/bmj/000003_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
PREHOOK: query: insert overwrite table tab_part_n2 partition (ds='2008-04-08')
select key,value from srcbucket_mapjoin_part_n3
PREHOOK: type: QUERY
PREHOOK: Input: default@srcbucket_mapjoin_part_n3
PREHOOK: Input: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
PREHOOK: Output: default@tab_part_n2@ds=2008-04-08
POSTHOOK: query: insert overwrite table tab_part_n2 partition (ds='2008-04-08')
select key,value from srcbucket_mapjoin_part_n3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcbucket_mapjoin_part_n3
POSTHOOK: Input: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
POSTHOOK: Output: default@tab_part_n2@ds=2008-04-08
POSTHOOK: Lineage: tab_part_n2 PARTITION(ds=2008-04-08).key SIMPLE [(srcbucket_mapjoin_part_n3)srcbucket_mapjoin_part_n3.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: tab_part_n2 PARTITION(ds=2008-04-08).value SIMPLE [(srcbucket_mapjoin_part_n3)srcbucket_mapjoin_part_n3.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: CREATE TABLE tab_n1(key int, value string) PARTITIONED BY(ds STRING) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tab_n1
POSTHOOK: query: CREATE TABLE tab_n1(key int, value string) PARTITIONED BY(ds STRING) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tab_n1
PREHOOK: query: insert overwrite table tab_n1 partition (ds='2008-04-08')
select key,value from srcbucket_mapjoin_n3
PREHOOK: type: QUERY
PREHOOK: Input: default@srcbucket_mapjoin_n3
PREHOOK: Input: default@srcbucket_mapjoin_n3@ds=2008-04-08
PREHOOK: Output: default@tab_n1@ds=2008-04-08
POSTHOOK: query: insert overwrite table tab_n1 partition (ds='2008-04-08')
select key,value from srcbucket_mapjoin_n3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcbucket_mapjoin_n3
POSTHOOK: Input: default@srcbucket_mapjoin_n3@ds=2008-04-08
POSTHOOK: Output: default@tab_n1@ds=2008-04-08
POSTHOOK: Lineage: tab_n1 PARTITION(ds=2008-04-08).key SIMPLE [(srcbucket_mapjoin_n3)srcbucket_mapjoin_n3.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: tab_n1 PARTITION(ds=2008-04-08).value SIMPLE [(srcbucket_mapjoin_n3)srcbucket_mapjoin_n3.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: explain
select a.key, a.value, b.value
from tab_n1 a join tab_part_n2 b on a.key = b.key
PREHOOK: type: QUERY
PREHOOK: Input: default@tab_n1
PREHOOK: Input: default@tab_n1@ds=2008-04-08
PREHOOK: Input: default@tab_part_n2
PREHOOK: Input: default@tab_part_n2@ds=2008-04-08
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain
select a.key, a.value, b.value
from tab_n1 a join tab_part_n2 b on a.key = b.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tab_n1
POSTHOOK: Input: default@tab_n1@ds=2008-04-08
POSTHOOK: Input: default@tab_part_n2
POSTHOOK: Input: default@tab_part_n2@ds=2008-04-08
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan optimized by CBO.

Vertex dependency in root stage
Map 2 <- Map 1 (CUSTOM_EDGE)

Stage-0
  Fetch Operator
    limit:-1
    Stage-1
      Map 2 vectorized
      File Output Operator [FS_34]
        Select Operator [SEL_33] (rows=399 width=186)
          Output:["_col0","_col1","_col2"]
          Map Join Operator [MAPJOIN_32] (rows=399 width=186)
            BucketMapJoin:true,Conds:RS_29._col0=SEL_31._col0(Inner),Output:["_col0","_col1","_col3"]
          <-Map 1 [CUSTOM_EDGE] vectorized
            MULTICAST [RS_29]
              PartitionCols:_col0
              Select Operator [SEL_28] (rows=242 width=95)
                Output:["_col0","_col1"]
                Filter Operator [FIL_27] (rows=242 width=95)
                  predicate:key is not null
                  TableScan [TS_0] (rows=242 width=95)
                    default@tab_n1,a,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
          <-Select Operator [SEL_31] (rows=500 width=95)
              Output:["_col0","_col1"]
              Filter Operator [FIL_30] (rows=500 width=95)
                predicate:key is not null
                TableScan [TS_3] (rows=500 width=95)
                  default@tab_part_n2,b,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]

