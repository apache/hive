PREHOOK: query: CREATE TABLE acid_vectorized_n0(a INT, b STRING) CLUSTERED BY(a) INTO 2 BUCKETS STORED AS ORC TBLPROPERTIES ('transactional'='true')
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@acid_vectorized_n0
POSTHOOK: query: CREATE TABLE acid_vectorized_n0(a INT, b STRING) CLUSTERED BY(a) INTO 2 BUCKETS STORED AS ORC TBLPROPERTIES ('transactional'='true')
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@acid_vectorized_n0
PREHOOK: query: insert into table acid_vectorized_n0 select cint, cstring1 from alltypesorc where cint is not null order by cint limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@alltypesorc
PREHOOK: Output: default@acid_vectorized_n0
POSTHOOK: query: insert into table acid_vectorized_n0 select cint, cstring1 from alltypesorc where cint is not null order by cint limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@alltypesorc
POSTHOOK: Output: default@acid_vectorized_n0
POSTHOOK: Lineage: acid_vectorized_n0.a SIMPLE [(alltypesorc)alltypesorc.FieldSchema(name:cint, type:int, comment:null), ]
POSTHOOK: Lineage: acid_vectorized_n0.b SIMPLE [(alltypesorc)alltypesorc.FieldSchema(name:cstring1, type:string, comment:null), ]
PREHOOK: query: analyze table acid_vectorized_n0 compute statistics for columns
PREHOOK: type: ANALYZE_TABLE
PREHOOK: Input: default@acid_vectorized_n0
PREHOOK: Output: default@acid_vectorized_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: analyze table acid_vectorized_n0 compute statistics for columns
POSTHOOK: type: ANALYZE_TABLE
POSTHOOK: Input: default@acid_vectorized_n0
POSTHOOK: Output: default@acid_vectorized_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
PREHOOK: query: explain select a, b from acid_vectorized_n0 order by a, b
PREHOOK: type: QUERY
PREHOOK: Input: default@acid_vectorized_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select a, b from acid_vectorized_n0 order by a, b
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid_vectorized_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 2 <- Map 1 (SIMPLE_EDGE)

Stage-0
  Fetch Operator
    limit:-1
    Stage-1
      Reducer 2 vectorized
      File Output Operator [FS_8]
        Select Operator [SEL_7] (rows=10 width=101)
          Output:["_col0","_col1"]
        <-Map 1 [SIMPLE_EDGE] vectorized
          SHUFFLE [RS_6]
            Select Operator [SEL_5] (rows=10 width=101)
              Output:["_col0","_col1"]
              TableScan [TS_0] (rows=10 width=101)
                default@acid_vectorized_n0,acid_vectorized_n0, ACID table,Tbl:COMPLETE,Col:COMPLETE,Output:["a","b"]

PREHOOK: query: explain select key, value
FROM srcpart LATERAL VIEW explode(array(1,2,3)) myTable AS myCol
PREHOOK: type: QUERY
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain select key, value
FROM srcpart LATERAL VIEW explode(array(1,2,3)) myTable AS myCol
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan not optimized by CBO because the statement has lateral views

Stage-0
  Fetch Operator
    limit:-1
    Select Operator [SEL_6]
      Output:["_col0","_col1"]
      Lateral View Join Operator [LVJ_5]
        Output:["_col0","_col1","_col7"]
        Select Operator [SEL_2]
          Output:["key","value"]
          Lateral View Forward [LVF_1]
            TableScan [TS_0]
              Output:["key","value"]
    Select Operator [SEL_6]
      Output:["_col0","_col1"]
      Lateral View Join Operator [LVJ_5]
        Output:["_col0","_col1","_col7"]
        UDTF Operator [UDTF_4]
          function name:explode
          Select Operator [SEL_3]
            Output:["_col0"]
             Please refer to the previous Lateral View Forward [LVF_1]

PREHOOK: query: explain show tables
PREHOOK: type: SHOWTABLES
PREHOOK: Input: database:default
POSTHOOK: query: explain show tables
POSTHOOK: type: SHOWTABLES
POSTHOOK: Input: database:default
Stage-1
  Fetch Operator
    limit:-1
    Stage-0
      Show Table Operator:
        database name:default

#### A masked pattern was here ####
PREHOOK: type: CREATEDATABASE
PREHOOK: Output: database:newDB
PREHOOK: Output: hdfs://### HDFS PATH ###
#### A masked pattern was here ####
POSTHOOK: type: CREATEDATABASE
POSTHOOK: Output: database:newDB
POSTHOOK: Output: hdfs://### HDFS PATH ###
Stage-0

#### A masked pattern was here ####
PREHOOK: type: CREATEDATABASE
PREHOOK: Output: database:newDB
PREHOOK: Output: hdfs://### HDFS PATH ###
#### A masked pattern was here ####
POSTHOOK: type: CREATEDATABASE
POSTHOOK: Output: database:newDB
POSTHOOK: Output: hdfs://### HDFS PATH ###
PREHOOK: query: explain describe database extended newDB
PREHOOK: type: DESCDATABASE
PREHOOK: Input: database:newdb
POSTHOOK: query: explain describe database extended newDB
POSTHOOK: type: DESCDATABASE
POSTHOOK: Input: database:newdb
Stage-1
  Fetch Operator
    limit:-1
    Stage-0

PREHOOK: query: describe database extended newDB
PREHOOK: type: DESCDATABASE
PREHOOK: Input: database:newdb
POSTHOOK: query: describe database extended newDB
POSTHOOK: type: DESCDATABASE
POSTHOOK: Input: database:newdb
newdb		location/in/test	hive_test_user	USER	
PREHOOK: query: explain use newDB
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:newdb
POSTHOOK: query: explain use newDB
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:newdb
Stage-0

PREHOOK: query: use newDB
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:newdb
POSTHOOK: query: use newDB
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:newdb
PREHOOK: query: create table tab_n1 (name string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:newdb
PREHOOK: Output: newDB@tab_n1
POSTHOOK: query: create table tab_n1 (name string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:newdb
POSTHOOK: Output: newDB@tab_n1
PREHOOK: query: explain alter table tab_n1 rename to newName
PREHOOK: type: ALTERTABLE_RENAME
PREHOOK: Input: newdb@tab_n1
PREHOOK: Output: newdb@tab_n1
POSTHOOK: query: explain alter table tab_n1 rename to newName
POSTHOOK: type: ALTERTABLE_RENAME
POSTHOOK: Input: newdb@tab_n1
POSTHOOK: Output: newdb@tab_n1
Stage-0
  Alter Table Operator:
    new name:newDB.newName,old name:newDB.tab_n1,type:rename

PREHOOK: query: explain drop table tab_n1
PREHOOK: type: DROPTABLE
PREHOOK: Input: newdb@tab_n1
PREHOOK: Output: newdb@tab_n1
POSTHOOK: query: explain drop table tab_n1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: newdb@tab_n1
POSTHOOK: Output: newdb@tab_n1
Stage-0
  Drop Table Operator:
    table:tab_n1

PREHOOK: query: drop table tab_n1
PREHOOK: type: DROPTABLE
PREHOOK: Input: newdb@tab_n1
PREHOOK: Output: newdb@tab_n1
POSTHOOK: query: drop table tab_n1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: newdb@tab_n1
POSTHOOK: Output: newdb@tab_n1
PREHOOK: query: explain use default
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:default
POSTHOOK: query: explain use default
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:default
Stage-0

PREHOOK: query: use default
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:default
POSTHOOK: query: use default
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:default
PREHOOK: query: drop database newDB
PREHOOK: type: DROPDATABASE
PREHOOK: Input: database:newdb
PREHOOK: Output: database:newdb
POSTHOOK: query: drop database newDB
POSTHOOK: type: DROPDATABASE
POSTHOOK: Input: database:newdb
POSTHOOK: Output: database:newdb
PREHOOK: query: explain analyze table src compute statistics
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@src
POSTHOOK: query: explain analyze table src compute statistics
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@src
Stage-2
  Stats Work{}
    Stage-0
      Map 1
      TableScan [TS_0] (rows=500 width=10)
        default@src,src,Tbl:COMPLETE,Col:COMPLETE

PREHOOK: query: explain analyze table src compute statistics for columns
PREHOOK: type: ANALYZE_TABLE
PREHOOK: Input: default@src
PREHOOK: Output: default@src
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain analyze table src compute statistics for columns
POSTHOOK: type: ANALYZE_TABLE
POSTHOOK: Input: default@src
POSTHOOK: Output: default@src
POSTHOOK: Output: hdfs://### HDFS PATH ###
Vertex dependency in root stage
Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)

Stage-2
  Stats Work{}
    Stage-0
      Reducer 2
      File Output Operator [FS_6]
        Group By Operator [GBY_4] (rows=1 width=880)
          Output:["_col0","_col1"],aggregations:["compute_stats(VALUE._col0)","compute_stats(VALUE._col1)"]
        <-Map 1 [CUSTOM_SIMPLE_EDGE]
          PARTITION_ONLY_SHUFFLE [RS_3]
            Group By Operator [GBY_2] (rows=1 width=880)
              Output:["_col0","_col1"],aggregations:["compute_stats(key, 'hll')","compute_stats(value, 'hll')"]
              Select Operator [SEL_1] (rows=500 width=178)
                Output:["key","value"]
                TableScan [TS_0] (rows=500 width=178)
                  default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]

PREHOOK: query: explain
CREATE TEMPORARY MACRO SIGMOID (x DOUBLE) 1.0 / (1.0 + EXP(-x))
PREHOOK: type: CREATEMACRO
PREHOOK: Output: database:default
POSTHOOK: query: explain
CREATE TEMPORARY MACRO SIGMOID (x DOUBLE) 1.0 / (1.0 + EXP(-x))
POSTHOOK: type: CREATEMACRO
POSTHOOK: Output: database:default
Stage-0

PREHOOK: query: CREATE TEMPORARY MACRO SIGMOID (x DOUBLE) 1.0 / (1.0 + EXP(-x))
PREHOOK: type: CREATEMACRO
PREHOOK: Output: database:default
POSTHOOK: query: CREATE TEMPORARY MACRO SIGMOID (x DOUBLE) 1.0 / (1.0 + EXP(-x))
POSTHOOK: type: CREATEMACRO
POSTHOOK: Output: database:default
PREHOOK: query: EXPLAIN SELECT SIGMOID(2) FROM src LIMIT 1
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: EXPLAIN SELECT SIGMOID(2) FROM src LIMIT 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan optimized by CBO.

Stage-0
  Fetch Operator
    limit:1
    Limit [LIM_2]
      Number of rows:1
      Select Operator [SEL_1]
        Output:["_col0"]
        TableScan [TS_0]

PREHOOK: query: explain DROP TEMPORARY MACRO SIGMOID
PREHOOK: type: DROPMACRO
PREHOOK: Output: database:default
POSTHOOK: query: explain DROP TEMPORARY MACRO SIGMOID
POSTHOOK: type: DROPMACRO
POSTHOOK: Output: database:default
Stage-0

PREHOOK: query: DROP TEMPORARY MACRO SIGMOID
PREHOOK: type: DROPMACRO
PREHOOK: Output: database:default
POSTHOOK: query: DROP TEMPORARY MACRO SIGMOID
POSTHOOK: type: DROPMACRO
POSTHOOK: Output: database:default
PREHOOK: query: explain create table src_autho_test_n3 as select * from src
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: explain create table src_autho_test_n3 as select * from src
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@src_autho_test_n3
Plan optimized by CBO.

Stage-3
  Stats Work{}
    Stage-4
      Create Table Operator:
        name:default.src_autho_test_n3
        Stage-2
          Dependency Collection{}
            Stage-1
              Map 1 vectorized
              File Output Operator [FS_4]
                table:{"name:":"default.src_autho_test_n3"}
                Select Operator [SEL_3] (rows=500 width=178)
                  Output:["_col0","_col1"]
                  TableScan [TS_0] (rows=500 width=178)
                    default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
        Stage-0
          Move Operator
             Please refer to the previous Stage-1

PREHOOK: query: create table src_autho_test_n3 as select * from src
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: create table src_autho_test_n3 as select * from src
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@src_autho_test_n3
POSTHOOK: Lineage: src_autho_test_n3.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: src_autho_test_n3.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain grant select on table src_autho_test_n3 to user hive_test_user
PREHOOK: type: GRANT_PRIVILEGE
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: explain grant select on table src_autho_test_n3 to user hive_test_user
POSTHOOK: type: GRANT_PRIVILEGE
POSTHOOK: Output: default@src_autho_test_n3
Stage-0

PREHOOK: query: grant select on table src_autho_test_n3 to user hive_test_user
PREHOOK: type: GRANT_PRIVILEGE
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: grant select on table src_autho_test_n3 to user hive_test_user
POSTHOOK: type: GRANT_PRIVILEGE
POSTHOOK: Output: default@src_autho_test_n3
PREHOOK: query: explain show grant user hive_test_user on table src_autho_test_n3
PREHOOK: type: SHOW_GRANT
POSTHOOK: query: explain show grant user hive_test_user on table src_autho_test_n3
POSTHOOK: type: SHOW_GRANT
Stage-1
  Fetch Operator
    limit:-1
    Stage-0

PREHOOK: query: explain show grant user hive_test_user on table src_autho_test_n3(key)
PREHOOK: type: SHOW_GRANT
POSTHOOK: query: explain show grant user hive_test_user on table src_autho_test_n3(key)
POSTHOOK: type: SHOW_GRANT
Stage-1
  Fetch Operator
    limit:-1
    Stage-0

PREHOOK: query: select key from src_autho_test_n3 order by key limit 20
PREHOOK: type: QUERY
PREHOOK: Input: default@src_autho_test_n3
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select key from src_autho_test_n3 order by key limit 20
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src_autho_test_n3
POSTHOOK: Output: hdfs://### HDFS PATH ###
0
0
0
10
100
100
103
103
104
104
105
11
111
113
113
114
116
118
118
119
PREHOOK: query: explain revoke select on table src_autho_test_n3 from user hive_test_user
PREHOOK: type: REVOKE_PRIVILEGE
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: explain revoke select on table src_autho_test_n3 from user hive_test_user
POSTHOOK: type: REVOKE_PRIVILEGE
POSTHOOK: Output: default@src_autho_test_n3
Stage-0

PREHOOK: query: explain grant select(key) on table src_autho_test_n3 to user hive_test_user
PREHOOK: type: GRANT_PRIVILEGE
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: explain grant select(key) on table src_autho_test_n3 to user hive_test_user
POSTHOOK: type: GRANT_PRIVILEGE
POSTHOOK: Output: default@src_autho_test_n3
Stage-0

PREHOOK: query: explain revoke select(key) on table src_autho_test_n3 from user hive_test_user
PREHOOK: type: REVOKE_PRIVILEGE
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: explain revoke select(key) on table src_autho_test_n3 from user hive_test_user
POSTHOOK: type: REVOKE_PRIVILEGE
POSTHOOK: Output: default@src_autho_test_n3
Stage-0

PREHOOK: query: explain 
create role sRc_roLE
PREHOOK: type: CREATEROLE
POSTHOOK: query: explain 
create role sRc_roLE
POSTHOOK: type: CREATEROLE
Stage-0

PREHOOK: query: create role sRc_roLE
PREHOOK: type: CREATEROLE
POSTHOOK: query: create role sRc_roLE
POSTHOOK: type: CREATEROLE
PREHOOK: query: explain
grant role sRc_roLE to user hive_test_user
PREHOOK: type: GRANT_ROLE
POSTHOOK: query: explain
grant role sRc_roLE to user hive_test_user
POSTHOOK: type: GRANT_ROLE
Stage-0

PREHOOK: query: grant role sRc_roLE to user hive_test_user
PREHOOK: type: GRANT_ROLE
POSTHOOK: query: grant role sRc_roLE to user hive_test_user
POSTHOOK: type: GRANT_ROLE
PREHOOK: query: explain show role grant user hive_test_user
PREHOOK: type: SHOW_ROLE_GRANT
POSTHOOK: query: explain show role grant user hive_test_user
POSTHOOK: type: SHOW_ROLE_GRANT
Stage-1
  Fetch Operator
    limit:-1
    Stage-0

PREHOOK: query: explain drop role sRc_roLE
PREHOOK: type: DROPROLE
POSTHOOK: query: explain drop role sRc_roLE
POSTHOOK: type: DROPROLE
Stage-0

PREHOOK: query: drop role sRc_roLE
PREHOOK: type: DROPROLE
POSTHOOK: query: drop role sRc_roLE
POSTHOOK: type: DROPROLE
PREHOOK: query: drop table src_autho_test_n3
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src_autho_test_n3
PREHOOK: Output: default@src_autho_test_n3
POSTHOOK: query: drop table src_autho_test_n3
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src_autho_test_n3
POSTHOOK: Output: default@src_autho_test_n3
PREHOOK: query: explain drop view v_n1
PREHOOK: type: DROPVIEW
POSTHOOK: query: explain drop view v_n1
POSTHOOK: type: DROPVIEW
Stage-0
  Drop Table Operator:
    table:v_n1

PREHOOK: query: explain create view v_n1 as with cte as (select * from src  order by key limit 5)
select * from cte
PREHOOK: type: CREATEVIEW
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@v_n1
POSTHOOK: query: explain create view v_n1 as with cte as (select * from src  order by key limit 5)
select * from cte
POSTHOOK: type: CREATEVIEW
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@v_n1
Plan optimized by CBO.

Stage-1
  Create View Operator:
    name:default.v_n1,original text:with cte as (select * from src  order by key limit 5)
select * from cte

PREHOOK: query: explain with cte as (select * from src  order by key limit 5)
select * from cte
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain with cte as (select * from src  order by key limit 5)
select * from cte
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 2 <- Map 1 (SIMPLE_EDGE)

Stage-0
  Fetch Operator
    limit:5
    Stage-1
      Reducer 2 vectorized
      File Output Operator [FS_10]
        Limit [LIM_9] (rows=5 width=178)
          Number of rows:5
          Select Operator [SEL_8] (rows=500 width=178)
            Output:["_col0","_col1"]
          <-Map 1 [SIMPLE_EDGE] vectorized
            SHUFFLE [RS_7]
              Select Operator [SEL_6] (rows=500 width=178)
                Output:["_col0","_col1"]
                TableScan [TS_0] (rows=500 width=178)
                  default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]

PREHOOK: query: create table orc_merge5_n0 (userid bigint, string1 string, subtype double, decimal1 decimal, ts timestamp) stored as orc
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@orc_merge5_n0
POSTHOOK: query: create table orc_merge5_n0 (userid bigint, string1 string, subtype double, decimal1 decimal, ts timestamp) stored as orc
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orc_merge5_n0
PREHOOK: query: load data local inpath '../../data/files/orc_split_elim.orc' into table orc_merge5_n0
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@orc_merge5_n0
POSTHOOK: query: load data local inpath '../../data/files/orc_split_elim.orc' into table orc_merge5_n0
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@orc_merge5_n0
PREHOOK: query: explain insert overwrite table orc_merge5_n0 select userid,string1,subtype,decimal1,ts from orc_merge5_n0 where userid<=13
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_merge5_n0
PREHOOK: Output: default@orc_merge5_n0
POSTHOOK: query: explain insert overwrite table orc_merge5_n0 select userid,string1,subtype,decimal1,ts from orc_merge5_n0 where userid<=13
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_merge5_n0
POSTHOOK: Output: default@orc_merge5_n0
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)

Stage-3
  Stats Work{}
    Stage-0
      Move Operator
        table:{"name:":"default.orc_merge5_n0"}
        Stage-2
          Dependency Collection{}
            Stage-5(CONDITIONAL)
              Move Operator
                Stage-8(CONDITIONAL CHILD TASKS: Stage-5, Stage-4, Stage-6)
                  Conditional Operator
                    Stage-1
                      Reducer 2
                      File Output Operator [FS_10]
                        Group By Operator [GBY_8] (rows=1 width=2760)
                          Output:["_col0","_col1","_col2","_col3","_col4"],aggregations:["compute_stats(VALUE._col0)","compute_stats(VALUE._col1)","compute_stats(VALUE._col2)","compute_stats(VALUE._col3)","compute_stats(VALUE._col4)"]
                        <-Map 1 [CUSTOM_SIMPLE_EDGE]
                          File Output Operator [FS_3]
                            table:{"name:":"default.orc_merge5_n0"}
                            Select Operator [SEL_2] (rows=1 width=352)
                              Output:["_col0","_col1","_col2","_col3","_col4"]
                              Filter Operator [FIL_11] (rows=1 width=352)
                                predicate:(userid <= 13L)
                                TableScan [TS_0] (rows=1 width=352)
                                  default@orc_merge5_n0,orc_merge5_n0,Tbl:COMPLETE,Col:NONE,Output:["userid","string1","subtype","decimal1","ts"]
                          PARTITION_ONLY_SHUFFLE [RS_7]
                            Group By Operator [GBY_6] (rows=1 width=2696)
                              Output:["_col0","_col1","_col2","_col3","_col4"],aggregations:["compute_stats(userid, 'hll')","compute_stats(string1, 'hll')","compute_stats(subtype, 'hll')","compute_stats(decimal1, 'hll')","compute_stats(ts, 'hll')"]
                              Select Operator [SEL_5] (rows=1 width=352)
                                Output:["userid","string1","subtype","decimal1","ts"]
                                 Please refer to the previous Select Operator [SEL_2]
            Stage-4(CONDITIONAL)
              File Merge
                 Please refer to the previous Stage-8(CONDITIONAL CHILD TASKS: Stage-5, Stage-4, Stage-6)
            Stage-7
              Move Operator
                Stage-6(CONDITIONAL)
                  File Merge
                     Please refer to the previous Stage-8(CONDITIONAL CHILD TASKS: Stage-5, Stage-4, Stage-6)

PREHOOK: query: drop table orc_merge5_n0
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@orc_merge5_n0
PREHOOK: Output: default@orc_merge5_n0
POSTHOOK: query: drop table orc_merge5_n0
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@orc_merge5_n0
POSTHOOK: Output: default@orc_merge5_n0
PREHOOK: query: CREATE TABLE srcbucket_mapjoin_n3(key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@srcbucket_mapjoin_n3
POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_n3(key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@srcbucket_mapjoin_n3
PREHOOK: query: CREATE TABLE tab_part_n2 (key int, value string) PARTITIONED BY(ds STRING) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tab_part_n2
POSTHOOK: query: CREATE TABLE tab_part_n2 (key int, value string) PARTITIONED BY(ds STRING) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tab_part_n2
PREHOOK: query: CREATE TABLE srcbucket_mapjoin_part_n3 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@srcbucket_mapjoin_part_n3
POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_part_n3 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3
PREHOOK: query: load data local inpath '../../data/files/bmj/000000_0' INTO TABLE srcbucket_mapjoin_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_n3
POSTHOOK: query: load data local inpath '../../data/files/bmj/000000_0' INTO TABLE srcbucket_mapjoin_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_n3
POSTHOOK: Output: default@srcbucket_mapjoin_n3@ds=2008-04-08
PREHOOK: query: load data local inpath '../../data/files/bmj1/000001_0' INTO TABLE srcbucket_mapjoin_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_n3@ds=2008-04-08
POSTHOOK: query: load data local inpath '../../data/files/bmj1/000001_0' INTO TABLE srcbucket_mapjoin_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_n3@ds=2008-04-08
PREHOOK: query: load data local inpath '../../data/files/bmj/000000_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_part_n3
POSTHOOK: query: load data local inpath '../../data/files/bmj/000000_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
PREHOOK: query: load data local inpath '../../data/files/bmj/000001_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
POSTHOOK: query: load data local inpath '../../data/files/bmj/000001_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
PREHOOK: query: load data local inpath '../../data/files/bmj/000002_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
POSTHOOK: query: load data local inpath '../../data/files/bmj/000002_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
PREHOOK: query: load data local inpath '../../data/files/bmj/000003_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
POSTHOOK: query: load data local inpath '../../data/files/bmj/000003_0' INTO TABLE srcbucket_mapjoin_part_n3 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
PREHOOK: query: insert overwrite table tab_part_n2 partition (ds='2008-04-08')
select key,value from srcbucket_mapjoin_part_n3
PREHOOK: type: QUERY
PREHOOK: Input: default@srcbucket_mapjoin_part_n3
PREHOOK: Input: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
PREHOOK: Output: default@tab_part_n2@ds=2008-04-08
POSTHOOK: query: insert overwrite table tab_part_n2 partition (ds='2008-04-08')
select key,value from srcbucket_mapjoin_part_n3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcbucket_mapjoin_part_n3
POSTHOOK: Input: default@srcbucket_mapjoin_part_n3@ds=2008-04-08
POSTHOOK: Output: default@tab_part_n2@ds=2008-04-08
POSTHOOK: Lineage: tab_part_n2 PARTITION(ds=2008-04-08).key SIMPLE [(srcbucket_mapjoin_part_n3)srcbucket_mapjoin_part_n3.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: tab_part_n2 PARTITION(ds=2008-04-08).value SIMPLE [(srcbucket_mapjoin_part_n3)srcbucket_mapjoin_part_n3.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: CREATE TABLE tab_n1(key int, value string) PARTITIONED BY(ds STRING) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tab_n1
POSTHOOK: query: CREATE TABLE tab_n1(key int, value string) PARTITIONED BY(ds STRING) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tab_n1
PREHOOK: query: insert overwrite table tab_n1 partition (ds='2008-04-08')
select key,value from srcbucket_mapjoin_n3
PREHOOK: type: QUERY
PREHOOK: Input: default@srcbucket_mapjoin_n3
PREHOOK: Input: default@srcbucket_mapjoin_n3@ds=2008-04-08
PREHOOK: Output: default@tab_n1@ds=2008-04-08
POSTHOOK: query: insert overwrite table tab_n1 partition (ds='2008-04-08')
select key,value from srcbucket_mapjoin_n3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcbucket_mapjoin_n3
POSTHOOK: Input: default@srcbucket_mapjoin_n3@ds=2008-04-08
POSTHOOK: Output: default@tab_n1@ds=2008-04-08
POSTHOOK: Lineage: tab_n1 PARTITION(ds=2008-04-08).key SIMPLE [(srcbucket_mapjoin_n3)srcbucket_mapjoin_n3.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: tab_n1 PARTITION(ds=2008-04-08).value SIMPLE [(srcbucket_mapjoin_n3)srcbucket_mapjoin_n3.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: explain
select a.key, a.value, b.value
from tab_n1 a join tab_part_n2 b on a.key = b.key
PREHOOK: type: QUERY
PREHOOK: Input: default@tab_n1
PREHOOK: Input: default@tab_n1@ds=2008-04-08
PREHOOK: Input: default@tab_part_n2
PREHOOK: Input: default@tab_part_n2@ds=2008-04-08
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: explain
select a.key, a.value, b.value
from tab_n1 a join tab_part_n2 b on a.key = b.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tab_n1
POSTHOOK: Input: default@tab_n1@ds=2008-04-08
POSTHOOK: Input: default@tab_part_n2
POSTHOOK: Input: default@tab_part_n2@ds=2008-04-08
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan optimized by CBO.

Vertex dependency in root stage
Map 2 <- Map 1 (CUSTOM_EDGE)

Stage-0
  Fetch Operator
    limit:-1
    Stage-1
      Map 2 vectorized
      File Output Operator [FS_34]
        Select Operator [SEL_33] (rows=399 width=186)
          Output:["_col0","_col1","_col2"]
          Map Join Operator [MAPJOIN_32] (rows=399 width=186)
            BucketMapJoin:true,Conds:RS_29._col0=SEL_31._col0(Inner),HybridGraceHashJoin:true,Output:["_col0","_col1","_col3"]
          <-Map 1 [CUSTOM_EDGE] vectorized
            MULTICAST [RS_29]
              PartitionCols:_col0
              Select Operator [SEL_28] (rows=242 width=95)
                Output:["_col0","_col1"]
                Filter Operator [FIL_27] (rows=242 width=95)
                  predicate:key is not null
                  TableScan [TS_0] (rows=242 width=95)
                    default@tab_n1,a,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
          <-Select Operator [SEL_31] (rows=500 width=95)
              Output:["_col0","_col1"]
              Filter Operator [FIL_30] (rows=500 width=95)
                predicate:key is not null
                TableScan [TS_3] (rows=500 width=95)
                  default@tab_part_n2,b,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]

