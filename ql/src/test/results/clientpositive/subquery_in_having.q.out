PREHOOK: query: -- data setup
CREATE TABLE part( 
    p_partkey INT,
    p_name STRING,
    p_mfgr STRING,
    p_brand STRING,
    p_type STRING,
    p_size INT,
    p_container STRING,
    p_retailprice DOUBLE,
    p_comment STRING
)
PREHOOK: type: CREATETABLE
POSTHOOK: query: -- data setup
CREATE TABLE part( 
    p_partkey INT,
    p_name STRING,
    p_mfgr STRING,
    p_brand STRING,
    p_type STRING,
    p_size INT,
    p_container STRING,
    p_retailprice DOUBLE,
    p_comment STRING
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@part
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/part_tiny.txt' overwrite into table part
PREHOOK: type: LOAD
PREHOOK: Output: default@part
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/part_tiny.txt' overwrite into table part
POSTHOOK: type: LOAD
POSTHOOK: Output: default@part
PREHOOK: query: -- non agg, non corr
explain
 select key, count(*) 
from src 
group by key
having count(*) in (select count(*) from src s1 where s1.key > '9' group by s1.key )
PREHOOK: type: QUERY
POSTHOOK: query: -- non agg, non corr
explain
 select key, count(*) 
from src 
group by key
having count(*) in (select count(*) from src s1 where s1.key > '9' group by s1.key )
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_FUNCTIONSTAR count))) (TOK_GROUPBY (TOK_TABLE_OR_COL key)) (TOK_HAVING (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) s1)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONSTAR count))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL s1) key) '9')) (TOK_GROUPBY (. (TOK_TABLE_OR_COL s1) key)))) (TOK_FUNCTIONSTAR count)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1, Stage-3
  Stage-3 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        sq_1:s1 
          TableScan
            alias: s1
            Filter Operator
              predicate:
                  expr: (key > '9')
                  type: boolean
              Select Operator
                expressions:
                      expr: key
                      type: string
                outputColumnNames: key
                Group By Operator
                  aggregations:
                        expr: count()
                  bucketGroup: false
                  keys:
                        expr: key
                        type: string
                  mode: hash
                  outputColumnNames: _col0, _col1
                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: string
                    sort order: +
                    Map-reduce partition columns:
                          expr: _col0
                          type: string
                    tag: -1
                    value expressions:
                          expr: _col1
                          type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Select Operator
            expressions:
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0
            Group By Operator
              bucketGroup: false
              keys:
                    expr: _col0
                    type: bigint
              mode: hash
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: bigint
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: bigint
              tag: 1
        $INTNAME1 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col1
                    type: bigint
              sort order: +
              Map-reduce partition columns:
                    expr: _col1
                    type: bigint
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: bigint
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1
          Filter Operator
            predicate:
                expr: (1 = 1)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: bigint
              outputColumnNames: _col0, _col1
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: key
                    type: string
              outputColumnNames: key
              Group By Operator
                aggregations:
                      expr: count()
                bucketGroup: false
                keys:
                      expr: key
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: select s1.key, count(*) from src s1 where s1.key > '9' group by s1.key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select s1.key, count(*) from src s1 where s1.key > '9' group by s1.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
90	3
92	1
95	2
96	1
97	2
98	2
PREHOOK: query: select key, count(*) 
from src 
group by key
having count(*) in (select count(*) from src s1 where s1.key = '90' group by s1.key )
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select key, count(*) 
from src 
group by key
having count(*) in (select count(*) from src s1 where s1.key = '90' group by s1.key )
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
409	3
187	3
403	3
396	3
384	3
369	3
498	3
5	3
35	3
327	3
167	3
318	3
316	3
311	3
298	3
70	3
90	3
128	3
273	3
208	3
199	3
193	3
0	3
119	3
480	3
466	3
454	3
438	3
431	3
430	3
417	3
PREHOOK: query: -- non agg, corr
explain
 select key, value, count(*) 
from src b
group by key, value
having count(*) in (select count(*) from src s1 where s1.key > '9'  and s1.value = b.value group by s1.key )
PREHOOK: type: QUERY
POSTHOOK: query: -- non agg, corr
explain
 select key, value, count(*) 
from src b
group by key, value
having count(*) in (select count(*) from src s1 where s1.key > '9'  and s1.value = b.value group by s1.key )
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) b)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_FUNCTIONSTAR count))) (TOK_GROUPBY (TOK_TABLE_OR_COL key) (TOK_TABLE_OR_COL value)) (TOK_HAVING (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) s1)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONSTAR count))) (TOK_WHERE (and (> (. (TOK_TABLE_OR_COL s1) key) '9') (= (. (TOK_TABLE_OR_COL s1) value) (. (TOK_TABLE_OR_COL b) value)))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL s1) key)))) (TOK_FUNCTIONSTAR count)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1, Stage-3
  Stage-3 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        b 
          TableScan
            alias: b
            Select Operator
              expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              outputColumnNames: key, value
              Group By Operator
                aggregations:
                      expr: count()
                bucketGroup: false
                keys:
                      expr: key
                      type: string
                      expr: value
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
                  sort order: ++
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col2
                        type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
                expr: KEY._col1
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col2
                    type: bigint
                    expr: _col1
                    type: string
              sort order: ++
              Map-reduce partition columns:
                    expr: _col2
                    type: bigint
                    expr: _col1
                    type: string
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _col2
                    type: bigint
        $INTNAME1 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: bigint
                    expr: _col1
                    type: string
              sort order: ++
              Map-reduce partition columns:
                    expr: _col0
                    type: bigint
                    expr: _col1
                    type: string
              tag: 1
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Filter Operator
            predicate:
                expr: (1 = 1)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _col2
                    type: bigint
              outputColumnNames: _col0, _col1, _col2
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        sq_1:s1 
          TableScan
            alias: s1
            Filter Operator
              predicate:
                  expr: (key > '9')
                  type: boolean
              Select Operator
                expressions:
                      expr: value
                      type: string
                      expr: key
                      type: string
                outputColumnNames: value, key
                Group By Operator
                  aggregations:
                        expr: count()
                  bucketGroup: false
                  keys:
                        expr: value
                        type: string
                        expr: key
                        type: string
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2
                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: string
                          expr: _col1
                          type: string
                    sort order: ++
                    Map-reduce partition columns:
                          expr: _col0
                          type: string
                          expr: _col1
                          type: string
                    tag: -1
                    value expressions:
                          expr: _col2
                          type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
                expr: KEY._col1
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Select Operator
            expressions:
                  expr: _col2
                  type: bigint
                  expr: _col0
                  type: string
            outputColumnNames: _col0, _col1
            Group By Operator
              bucketGroup: false
              keys:
                    expr: _col0
                    type: bigint
                    expr: _col1
                    type: string
              mode: hash
              outputColumnNames: _col0, _col1
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- agg, non corr
explain
select p_mfgr, avg(p_size)
from part b
group by b.p_mfgr
having b.p_mfgr in 
   (select p_mfgr 
    from part
    group by p_mfgr
    having max(p_size) - min(p_size) < 20
   )
PREHOOK: type: QUERY
POSTHOOK: query: -- agg, non corr
explain
select p_mfgr, avg(p_size)
from part b
group by b.p_mfgr
having b.p_mfgr in 
   (select p_mfgr 
    from part
    group by p_mfgr
    having max(p_size) - min(p_size) < 20
   )
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME part) b)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL p_mfgr)) (TOK_SELEXPR (TOK_FUNCTION avg (TOK_TABLE_OR_COL p_size)))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL b) p_mfgr)) (TOK_HAVING (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME part))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL p_mfgr))) (TOK_GROUPBY (TOK_TABLE_OR_COL p_mfgr)) (TOK_HAVING (< (- (TOK_FUNCTION max (TOK_TABLE_OR_COL p_size)) (TOK_FUNCTION min (TOK_TABLE_OR_COL p_size))) 20)))) (. (TOK_TABLE_OR_COL b) p_mfgr)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1, Stage-3
  Stage-3 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        b 
          TableScan
            alias: b
            Select Operator
              expressions:
                    expr: p_mfgr
                    type: string
                    expr: p_size
                    type: int
              outputColumnNames: p_mfgr, p_size
              Group By Operator
                aggregations:
                      expr: avg(p_size)
                bucketGroup: false
                keys:
                      expr: p_mfgr
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: struct<count:bigint,sum:double>
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: avg(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: string
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
        $INTNAME1 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: string
              tag: 1
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1
          Filter Operator
            predicate:
                expr: (1 = 1)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: double
              outputColumnNames: _col0, _col1
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        sq_1:part 
          TableScan
            alias: part
            Select Operator
              expressions:
                    expr: p_mfgr
                    type: string
                    expr: p_size
                    type: int
              outputColumnNames: p_mfgr, p_size
              Group By Operator
                aggregations:
                      expr: max(p_size)
                      expr: min(p_size)
                bucketGroup: false
                keys:
                      expr: p_mfgr
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: int
                        expr: _col2
                        type: int
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: max(VALUE._col0)
                expr: min(VALUE._col1)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Filter Operator
            predicate:
                expr: ((_col1 - _col2) < 20)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
              outputColumnNames: _col0
              Group By Operator
                bucketGroup: false
                keys:
                      expr: _col0
                      type: string
                mode: hash
                outputColumnNames: _col0
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- join on agg
select b.key, min(b.value)
from src b
group by b.key
having b.key in ( select a.key
                from src a
                where a.value > 'val_9' and a.value = min(b.value)
                )
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: -- join on agg
select b.key, min(b.value)
from src b
group by b.key
having b.key in ( select a.key
                from src a
                where a.value > 'val_9' and a.value = min(b.value)
                )
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
90	val_90
92	val_92
95	val_95
96	val_96
97	val_97
98	val_98
PREHOOK: query: -- where and having
-- Plan is:
-- Stage 1: b semijoin sq1:src (subquery in where)
-- Stage 2: group by Stage 1 o/p
-- Stage 5: group by on sq2:src (subquery in having)
-- Stage 6: Stage 2 o/p semijoin Stage 5
explain
select key, value, count(*) 
from src b
where b.key in (select key from src where src.key > '8')
group by key, value
having count(*) in (select count(*) from src s1 where s1.key > '9' group by s1.key )
PREHOOK: type: QUERY
POSTHOOK: query: -- where and having
-- Plan is:
-- Stage 1: b semijoin sq1:src (subquery in where)
-- Stage 2: group by Stage 1 o/p
-- Stage 5: group by on sq2:src (subquery in having)
-- Stage 6: Stage 2 o/p semijoin Stage 5
explain
select key, value, count(*) 
from src b
where b.key in (select key from src where src.key > '8')
group by key, value
having count(*) in (select count(*) from src s1 where s1.key > '9' group by s1.key )
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) b)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_FUNCTIONSTAR count))) (TOK_WHERE (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL src) key) '8')))) (. (TOK_TABLE_OR_COL b) key))) (TOK_GROUPBY (TOK_TABLE_OR_COL key) (TOK_TABLE_OR_COL value)) (TOK_HAVING (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) s1)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONSTAR count))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL s1) key) '9')) (TOK_GROUPBY (. (TOK_TABLE_OR_COL s1) key)))) (TOK_FUNCTIONSTAR count)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-3 depends on stages: Stage-2, Stage-5
  Stage-5 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        b 
          TableScan
            alias: b
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 0
              value expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
        sq_1:src 
          TableScan
            alias: src
            Filter Operator
              predicate:
                  expr: (key > '8')
                  type: boolean
              Select Operator
                expressions:
                      expr: key
                      type: string
                outputColumnNames: _col0
                Group By Operator
                  bucketGroup: false
                  keys:
                        expr: _col0
                        type: string
                  mode: hash
                  outputColumnNames: _col0
                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: string
                    sort order: +
                    Map-reduce partition columns:
                          expr: _col0
                          type: string
                    tag: 1
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1
          Filter Operator
            predicate:
                expr: (1 = 1)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
              outputColumnNames: _col0, _col1
              Group By Operator
                aggregations:
                      expr: count()
                bucketGroup: false
                keys:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
#### A masked pattern was here ####
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
              sort order: ++
              Map-reduce partition columns:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
              tag: -1
              value expressions:
                    expr: _col2
                    type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
                expr: KEY._col1
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col2
                    type: bigint
              sort order: +
              Map-reduce partition columns:
                    expr: _col2
                    type: bigint
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _col2
                    type: bigint
        $INTNAME1 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: bigint
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: bigint
              tag: 1
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Filter Operator
            predicate:
                expr: (1 = 1)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _col2
                    type: bigint
              outputColumnNames: _col0, _col1, _col2
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-5
    Map Reduce
      Alias -> Map Operator Tree:
        sq_2:s1 
          TableScan
            alias: s1
            Filter Operator
              predicate:
                  expr: (key > '9')
                  type: boolean
              Select Operator
                expressions:
                      expr: key
                      type: string
                outputColumnNames: key
                Group By Operator
                  aggregations:
                        expr: count()
                  bucketGroup: false
                  keys:
                        expr: key
                        type: string
                  mode: hash
                  outputColumnNames: _col0, _col1
                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: string
                    sort order: +
                    Map-reduce partition columns:
                          expr: _col0
                          type: string
                    tag: -1
                    value expressions:
                          expr: _col1
                          type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Select Operator
            expressions:
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0
            Group By Operator
              bucketGroup: false
              keys:
                    expr: _col0
                    type: bigint
              mode: hash
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- Plan is:
-- Stage  5: group by on sq2:src (subquery in having)
-- Stage 10: hashtable for sq1:src (subquery in where)
-- Stage  2: b map-side semijoin Stage 10 o/p
-- Stage  3: Stage 2 semijoin Stage 5
-- Stage  9: construct hastable for Stage 5 o/p
-- Stage  6: Stage 2 map-side semijoin Stage 9
explain
select key, value, count(*) 
from src b
where b.key in (select key from src where src.key > '8')
group by key, value
having count(*) in (select count(*) from src s1 where s1.key > '9' group by s1.key )
PREHOOK: type: QUERY
POSTHOOK: query: -- Plan is:
-- Stage  5: group by on sq2:src (subquery in having)
-- Stage 10: hashtable for sq1:src (subquery in where)
-- Stage  2: b map-side semijoin Stage 10 o/p
-- Stage  3: Stage 2 semijoin Stage 5
-- Stage  9: construct hastable for Stage 5 o/p
-- Stage  6: Stage 2 map-side semijoin Stage 9
explain
select key, value, count(*) 
from src b
where b.key in (select key from src where src.key > '8')
group by key, value
having count(*) in (select count(*) from src s1 where s1.key > '9' group by s1.key )
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) b)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_FUNCTIONSTAR count))) (TOK_WHERE (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL src) key) '8')))) (. (TOK_TABLE_OR_COL b) key))) (TOK_GROUPBY (TOK_TABLE_OR_COL key) (TOK_TABLE_OR_COL value)) (TOK_HAVING (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) s1)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONSTAR count))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL s1) key) '9')) (TOK_GROUPBY (. (TOK_TABLE_OR_COL s1) key)))) (TOK_FUNCTIONSTAR count)))))

STAGE DEPENDENCIES:
  Stage-5 is a root stage
  Stage-7 depends on stages: Stage-2, Stage-5 , consists of Stage-9, Stage-3
  Stage-9 has a backup stage: Stage-3
  Stage-6 depends on stages: Stage-9
  Stage-3
  Stage-10 is a root stage
  Stage-2 depends on stages: Stage-10
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-5
    Map Reduce
      Alias -> Map Operator Tree:
        sq_2:s1 
          TableScan
            alias: s1
            Filter Operator
              predicate:
                  expr: (key > '9')
                  type: boolean
              Select Operator
                expressions:
                      expr: key
                      type: string
                outputColumnNames: key
                Group By Operator
                  aggregations:
                        expr: count()
                  bucketGroup: false
                  keys:
                        expr: key
                        type: string
                  mode: hash
                  outputColumnNames: _col0, _col1
                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: string
                    sort order: +
                    Map-reduce partition columns:
                          expr: _col0
                          type: string
                    tag: -1
                    value expressions:
                          expr: _col1
                          type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Select Operator
            expressions:
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0
            Group By Operator
              bucketGroup: false
              keys:
                    expr: _col0
                    type: bigint
              mode: hash
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-7
    Conditional Operator

  Stage: Stage-9
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $INTNAME1 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $INTNAME1 
          TableScan
            HashTable Sink Operator
              condition expressions:
                0 {_col0} {_col1} {_col2}
                1 
              handleSkewJoin: false
              keys:
                0 [Column[_col2]]
                1 [Column[_col0]]
              Position of Big Table: 0

  Stage: Stage-6
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Map Join Operator
              condition map:
                   Left Semi Join 0 to 1
              condition expressions:
                0 {_col0} {_col1} {_col2}
                1 
              handleSkewJoin: false
              keys:
                0 [Column[_col2]]
                1 [Column[_col0]]
              outputColumnNames: _col0, _col1, _col2
              Position of Big Table: 0
              Filter Operator
                predicate:
                    expr: (1 = 1)
                    type: boolean
                Select Operator
                  expressions:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
                        expr: _col2
                        type: bigint
                  outputColumnNames: _col0, _col1, _col2
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Local Work:
        Map Reduce Local Work

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col2
                    type: bigint
              sort order: +
              Map-reduce partition columns:
                    expr: _col2
                    type: bigint
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _col2
                    type: bigint
        $INTNAME1 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: bigint
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: bigint
              tag: 1
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Filter Operator
            predicate:
                expr: (1 = 1)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _col2
                    type: bigint
              outputColumnNames: _col0, _col1, _col2
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-10
    Map Reduce Local Work
      Alias -> Map Local Tables:
        sq_1:src 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        sq_1:src 
          TableScan
            alias: src
            Filter Operator
              predicate:
                  expr: (key > '8')
                  type: boolean
              Select Operator
                expressions:
                      expr: key
                      type: string
                outputColumnNames: _col0
                Group By Operator
                  bucketGroup: false
                  keys:
                        expr: _col0
                        type: string
                  mode: hash
                  outputColumnNames: _col0
                  HashTable Sink Operator
                    condition expressions:
                      0 {key} {value}
                      1 
                    handleSkewJoin: false
                    keys:
                      0 [Column[key]]
                      1 [Column[_col0]]
                    Position of Big Table: 0

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        b 
          TableScan
            alias: b
            Map Join Operator
              condition map:
                   Left Semi Join 0 to 1
              condition expressions:
                0 {key} {value}
                1 
              handleSkewJoin: false
              keys:
                0 [Column[key]]
                1 [Column[_col0]]
              outputColumnNames: _col0, _col1
              Position of Big Table: 0
              Filter Operator
                predicate:
                    expr: (1 = 1)
                    type: boolean
                Select Operator
                  expressions:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
                  outputColumnNames: _col0, _col1
                  Group By Operator
                    aggregations:
                          expr: count()
                    bucketGroup: false
                    keys:
                          expr: _col0
                          type: string
                          expr: _col1
                          type: string
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2
                    Reduce Output Operator
                      key expressions:
                            expr: _col0
                            type: string
                            expr: _col1
                            type: string
                      sort order: ++
                      Map-reduce partition columns:
                            expr: _col0
                            type: string
                            expr: _col1
                            type: string
                      tag: -1
                      value expressions:
                            expr: _col2
                            type: bigint
      Local Work:
        Map Reduce Local Work
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
                expr: KEY._col1
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- non agg, non corr, windowing
explain
select p_mfgr, p_name, avg(p_size) 
from part 
group by p_mfgr, p_name
having p_name in 
  (select first_value(p_name) over(partition by p_mfgr order by p_size) from part)
PREHOOK: type: QUERY
POSTHOOK: query: -- non agg, non corr, windowing
explain
select p_mfgr, p_name, avg(p_size) 
from part 
group by p_mfgr, p_name
having p_name in 
  (select first_value(p_name) over(partition by p_mfgr order by p_size) from part)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME part))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL p_mfgr)) (TOK_SELEXPR (TOK_TABLE_OR_COL p_name)) (TOK_SELEXPR (TOK_FUNCTION avg (TOK_TABLE_OR_COL p_size)))) (TOK_GROUPBY (TOK_TABLE_OR_COL p_mfgr) (TOK_TABLE_OR_COL p_name)) (TOK_HAVING (TOK_SUBQUERY_EXPR (TOK_SUBQUERY_OP in) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME part))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION first_value (TOK_TABLE_OR_COL p_name) (TOK_WINDOWSPEC (TOK_PARTITIONINGSPEC (TOK_DISTRIBUTEBY (TOK_TABLE_OR_COL p_mfgr)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL p_size)))))))))) (TOK_TABLE_OR_COL p_name)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-5 depends on stages: Stage-1, Stage-3 , consists of Stage-6, Stage-2
  Stage-6 has a backup stage: Stage-2
  Stage-4 depends on stages: Stage-6
  Stage-2
  Stage-3 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        sq_1:part 
          TableScan
            alias: part
            Reduce Output Operator
              key expressions:
                    expr: p_mfgr
                    type: string
                    expr: p_size
                    type: int
              sort order: ++
              Map-reduce partition columns:
                    expr: p_mfgr
                    type: string
              tag: -1
              value expressions:
                    expr: p_name
                    type: string
                    expr: p_mfgr
                    type: string
                    expr: p_size
                    type: int
      Reduce Operator Tree:
        Extract
          PTF Operator
            Select Operator
              expressions:
                    expr: _wcol0
                    type: string
              outputColumnNames: _col0
              Group By Operator
                bucketGroup: false
                keys:
                      expr: _col0
                      type: string
                mode: hash
                outputColumnNames: _col0
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-5
    Conditional Operator

  Stage: Stage-6
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $INTNAME 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $INTNAME 
          TableScan
            HashTable Sink Operator
              condition expressions:
                0 {_col0} {_col1} {_col2}
                1 
              handleSkewJoin: false
              keys:
                0 [Column[_col1]]
                1 [Column[_col0]]
              Position of Big Table: 0

  Stage: Stage-4
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME1 
          TableScan
            Map Join Operator
              condition map:
                   Left Semi Join 0 to 1
              condition expressions:
                0 {_col0} {_col1} {_col2}
                1 
              handleSkewJoin: false
              keys:
                0 [Column[_col1]]
                1 [Column[_col0]]
              outputColumnNames: _col0, _col1, _col2
              Position of Big Table: 0
              Filter Operator
                predicate:
                    expr: (1 = 1)
                    type: boolean
                Select Operator
                  expressions:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
                        expr: _col2
                        type: double
                  outputColumnNames: _col0, _col1, _col2
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Local Work:
        Map Reduce Local Work

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: string
              tag: 1
        $INTNAME1 
          TableScan
            Reduce Output Operator
              key expressions:
                    expr: _col1
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: _col1
                    type: string
              tag: 0
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _col2
                    type: double
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Filter Operator
            predicate:
                expr: (1 = 1)
                type: boolean
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _col2
                    type: double
              outputColumnNames: _col0, _col1, _col2
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        part 
          TableScan
            alias: part
            Select Operator
              expressions:
                    expr: p_mfgr
                    type: string
                    expr: p_name
                    type: string
                    expr: p_size
                    type: int
              outputColumnNames: p_mfgr, p_name, p_size
              Group By Operator
                aggregations:
                      expr: avg(p_size)
                bucketGroup: false
                keys:
                      expr: p_mfgr
                      type: string
                      expr: p_name
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
                  sort order: ++
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col2
                        type: struct<count:bigint,sum:double>
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: avg(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
                expr: KEY._col1
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1

