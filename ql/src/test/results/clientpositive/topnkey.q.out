PREHOOK: query: EXPLAIN EXTENDED
SELECT key, SUM(CAST(SUBSTR(value,5) AS INT)) FROM src GROUP BY key ORDER BY key LIMIT 5
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN EXTENDED
SELECT key, SUM(CAST(SUBSTR(value,5) AS INT)) FROM src GROUP BY key ORDER BY key LIMIT 5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
OPTIMIZED SQL: SELECT `key` AS `$f0`, SUM(CAST(SUBSTR(`value`, 5) AS INTEGER)) AS `$f1`
FROM `default`.`src`
GROUP BY `key`
ORDER BY `key`
LIMIT 5
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: key (type: string), UDFToInteger(substr(value, 5)) (type: int)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                aggregations: sum(_col1)
                keys: _col0 (type: string)
                minReductionHashAggr: 0.99
                mode: hash
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 250 Data size: 23750 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  null sort order: z
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 250 Data size: 23750 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
                  TopN: 5
                  TopN Hash Memory Usage: 0.1
                  value expressions: _col1 (type: bigint)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true","COLUMN_STATS":{"key":"true","value":"true"}}
              bucket_count -1
              bucketing_version 2
              column.name.delimiter ,
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numRows 500
              rawDataSize 5312
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE {"BASIC_STATS":"true","COLUMN_STATS":{"key":"true","value":"true"}}
                bucket_count -1
                bucketing_version 2
                column.name.delimiter ,
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numRows 500
                rawDataSize 5312
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
      Truncated Path -> Alias:
        /src [$hdt$_0:src]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          aggregations: sum(VALUE._col0)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 250 Data size: 23750 Basic stats: COMPLETE Column stats: COMPLETE
          File Output Operator
            compressed: false
            GlobalTableId: 0
#### A masked pattern was here ####
            NumFilesPerFileSink: 1
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                properties:
                  column.name.delimiter ,
                  columns _col0,_col1
                  columns.types string,bigint
                  escape.delim \
                  serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
            TotalFiles: 1
            GatherStats: false
            MultiFileSpray: false

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            GatherStats: false
            Reduce Output Operator
              key expressions: _col0 (type: string)
              null sort order: z
              sort order: +
              Statistics: Num rows: 250 Data size: 23750 Basic stats: COMPLETE Column stats: COMPLETE
              tag: -1
              TopN: 5
              TopN Hash Memory Usage: 0.1
              value expressions: _col1 (type: bigint)
              auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: -mr-10004
            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
            properties:
              column.name.delimiter ,
              columns _col0,_col1
              columns.types string,bigint
              escape.delim \
              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
          
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              properties:
                column.name.delimiter ,
                columns _col0,_col1
                columns.types string,bigint
                escape.delim \
                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
      Truncated Path -> Alias:
#### A masked pattern was here ####
      Needs Tagging: false
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: bigint)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 250 Data size: 23750 Basic stats: COMPLETE Column stats: COMPLETE
          Limit
            Number of rows: 5
            Statistics: Num rows: 5 Data size: 475 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 5 Data size: 475 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string:bigint
                    escape.delim \
                    hive.serialization.extend.additional.nesting.levels true
                    serialization.escape.crlf true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 5
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key, SUM(CAST(SUBSTR(value,5) AS INT)) FROM src GROUP BY key ORDER BY key LIMIT 5
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, SUM(CAST(SUBSTR(value,5) AS INT)) FROM src GROUP BY key ORDER BY key LIMIT 5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
0	0
10	10
100	200
103	206
104	208
PREHOOK: query: EXPLAIN
SELECT key FROM src GROUP BY key ORDER BY key LIMIT 5
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN
SELECT key FROM src GROUP BY key ORDER BY key LIMIT 5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
            Select Operator
              expressions: key (type: string)
              outputColumnNames: key
              Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: key (type: string)
                minReductionHashAggr: 0.99
                mode: hash
                outputColumnNames: _col0
                Statistics: Num rows: 250 Data size: 21750 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 250 Data size: 21750 Basic stats: COMPLETE Column stats: COMPLETE
                  TopN Hash Memory Usage: 0.1
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0
          Statistics: Num rows: 250 Data size: 21750 Basic stats: COMPLETE Column stats: COMPLETE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Statistics: Num rows: 250 Data size: 21750 Basic stats: COMPLETE Column stats: COMPLETE
              TopN Hash Memory Usage: 0.1
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: string)
          outputColumnNames: _col0
          Statistics: Num rows: 250 Data size: 21750 Basic stats: COMPLETE Column stats: COMPLETE
          Limit
            Number of rows: 5
            Statistics: Num rows: 5 Data size: 435 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              Statistics: Num rows: 5 Data size: 435 Basic stats: COMPLETE Column stats: COMPLETE
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 5
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key FROM src GROUP BY key ORDER BY key LIMIT 5
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: SELECT key FROM src GROUP BY key ORDER BY key LIMIT 5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
0
10
100
103
104
PREHOOK: query: explain vectorization detail
SELECT src1.key, src2.value FROM src src1 JOIN src src2 ON (src1.key = src2.key) ORDER BY src1.key LIMIT 5
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: explain vectorization detail
SELECT src1.key, src2.value FROM src src1 JOIN src src2 ON (src1.key = src2.key) ORDER BY src1.key LIMIT 5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: false
  enabledConditionsNotMet: [hive.vectorized.execution.enabled IS false]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src1
            filterExpr: key is not null (type: boolean)
            Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
              Select Operator
                expressions: key (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 500 Data size: 43500 Basic stats: COMPLETE Column stats: COMPLETE
          TableScan
            alias: src2
            filterExpr: key is not null (type: boolean)
            Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                  value expressions: _col1 (type: string)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 _col0 (type: string)
            1 _col0 (type: string)
          outputColumnNames: _col0, _col2
          Statistics: Num rows: 791 Data size: 140798 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), _col2 (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 791 Data size: 140798 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Statistics: Num rows: 791 Data size: 140798 Basic stats: COMPLETE Column stats: COMPLETE
              TopN Hash Memory Usage: 0.1
              value expressions: _col1 (type: string)
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 791 Data size: 140798 Basic stats: COMPLETE Column stats: COMPLETE
          Limit
            Number of rows: 5
            Statistics: Num rows: 5 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              Statistics: Num rows: 5 Data size: 890 Basic stats: COMPLETE Column stats: COMPLETE
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 5
      Processor Tree:
        ListSink

PREHOOK: query: SELECT src1.key, src2.value FROM src src1 JOIN src src2 ON (src1.key = src2.key) ORDER BY src1.key LIMIT 5
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: SELECT src1.key, src2.value FROM src src1 JOIN src src2 ON (src1.key = src2.key) ORDER BY src1.key LIMIT 5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
PREHOOK: query: CREATE TABLE t_test(
  a int,
  b int,
  c int
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@t_test
POSTHOOK: query: CREATE TABLE t_test(
  a int,
  b int,
  c int
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@t_test
PREHOOK: query: INSERT INTO t_test VALUES
(NULL, NULL, NULL),
(5, 2, 3),
(NULL, NULL, NULL),
(NULL, NULL, NULL),
(6, 2, 1),
(7, 8, 4), (7, 8, 4), (7, 8, 4),
(5, 1, 2), (5, 1, 2), (5, 1, 2),
(NULL, NULL, NULL)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@t_test
POSTHOOK: query: INSERT INTO t_test VALUES
(NULL, NULL, NULL),
(5, 2, 3),
(NULL, NULL, NULL),
(NULL, NULL, NULL),
(6, 2, 1),
(7, 8, 4), (7, 8, 4), (7, 8, 4),
(5, 1, 2), (5, 1, 2), (5, 1, 2),
(NULL, NULL, NULL)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@t_test
POSTHOOK: Lineage: t_test.a SCRIPT []
POSTHOOK: Lineage: t_test.b SCRIPT []
POSTHOOK: Lineage: t_test.c SCRIPT []
PREHOOK: query: EXPLAIN
SELECT a, b FROM t_test GROUP BY a, b ORDER BY a, b LIMIT 3
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN
SELECT a, b FROM t_test GROUP BY a, b ORDER BY a, b LIMIT 3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: t_test
            Statistics: Num rows: 12 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
            Select Operator
              expressions: a (type: int), b (type: int)
              outputColumnNames: a, b
              Statistics: Num rows: 12 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: a (type: int), b (type: int)
                minReductionHashAggr: 0.99
                mode: hash
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 6 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: int), _col1 (type: int)
                  sort order: ++
                  Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
                  Statistics: Num rows: 6 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
                  TopN Hash Memory Usage: 0.1
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: int), KEY._col1 (type: int)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 6 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: int), _col1 (type: int)
              sort order: ++
              Statistics: Num rows: 6 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
              TopN Hash Memory Usage: 0.1
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 6 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
          Limit
            Number of rows: 3
            Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              Statistics: Num rows: 3 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 3
      Processor Tree:
        ListSink

PREHOOK: query: SELECT a, b FROM t_test GROUP BY a, b ORDER BY a, b LIMIT 3
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: SELECT a, b FROM t_test GROUP BY a, b ORDER BY a, b LIMIT 3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
5	1
5	2
6	2
PREHOOK: query: EXPLAIN
SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a LIMIT 2
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN
SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a LIMIT 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: t_test
            Statistics: Num rows: 12 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
            Select Operator
              expressions: a (type: int), b (type: int)
              outputColumnNames: a, b
              Statistics: Num rows: 12 Data size: 72 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                aggregations: count(b)
                keys: a (type: int)
                minReductionHashAggr: 0.99
                mode: hash
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 4 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 4 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                  TopN Hash Memory Usage: 0.1
                  value expressions: _col1 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0)
          keys: KEY._col0 (type: int)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 4 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: int)
              sort order: +
              Statistics: Num rows: 4 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
              TopN Hash Memory Usage: 0.1
              value expressions: _col1 (type: bigint)
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: bigint)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 4 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
          Limit
            Number of rows: 2
            Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              Statistics: Num rows: 2 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 2
      Processor Tree:
        ListSink

PREHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a LIMIT 2
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a LIMIT 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
5	4
6	1
PREHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a NULLS FIRST LIMIT 2
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a NULLS FIRST LIMIT 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
NULL	0
5	4
PREHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a NULLS LAST LIMIT 2
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a NULLS LAST LIMIT 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
5	4
6	1
PREHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a ASC LIMIT 2
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a ASC LIMIT 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
5	4
6	1
PREHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a ASC NULLS FIRST LIMIT 2
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a ASC NULLS FIRST LIMIT 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
NULL	0
5	4
PREHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a ASC NULLS LAST LIMIT 2
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a ASC NULLS LAST LIMIT 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
5	4
6	1
PREHOOK: query: DROP TABLE IF EXISTS t_test
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@t_test
PREHOOK: Output: default@t_test
POSTHOOK: query: DROP TABLE IF EXISTS t_test
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@t_test
POSTHOOK: Output: default@t_test
PREHOOK: query: CREATE TABLE t_test(
  a int,
  b int,
  c int
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@t_test
POSTHOOK: query: CREATE TABLE t_test(
  a int,
  b int,
  c int
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@t_test
PREHOOK: query: INSERT INTO t_test VALUES
(7, 8, 4), (7, 8, 4), (7, 8, 4),
(NULL, NULL, NULL),
(5, 2, 3),
(NULL, NULL, NULL),
(NULL, NULL, NULL),
(6, 2, 1),
(5, 1, 2), (5, 1, 2), (5, 1, 2),
(NULL, NULL, NULL)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@t_test
POSTHOOK: query: INSERT INTO t_test VALUES
(7, 8, 4), (7, 8, 4), (7, 8, 4),
(NULL, NULL, NULL),
(5, 2, 3),
(NULL, NULL, NULL),
(NULL, NULL, NULL),
(6, 2, 1),
(5, 1, 2), (5, 1, 2), (5, 1, 2),
(NULL, NULL, NULL)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@t_test
POSTHOOK: Lineage: t_test.a SCRIPT []
POSTHOOK: Lineage: t_test.b SCRIPT []
POSTHOOK: Lineage: t_test.c SCRIPT []
PREHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a DESC LIMIT 2
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a DESC LIMIT 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
7	3
6	1
PREHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a DESC NULLS FIRST LIMIT 2
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a DESC NULLS FIRST LIMIT 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
NULL	0
7	3
PREHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a DESC NULLS LAST LIMIT 2
PREHOOK: type: QUERY
PREHOOK: Input: default@t_test
#### A masked pattern was here ####
POSTHOOK: query: SELECT a, count(b) FROM t_test GROUP BY a ORDER BY a DESC NULLS LAST LIMIT 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t_test
#### A masked pattern was here ####
7	3
6	1
PREHOOK: query: DROP TABLE IF EXISTS t_test
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@t_test
PREHOOK: Output: default@t_test
POSTHOOK: query: DROP TABLE IF EXISTS t_test
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@t_test
POSTHOOK: Output: default@t_test
