PREHOOK: query: CREATE TABLE dest1_n28(c1 STRING, c2 INT, c3 DOUBLE) STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@dest1_n28
POSTHOOK: query: CREATE TABLE dest1_n28(c1 STRING, c2 INT, c3 DOUBLE) STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@dest1_n28
PREHOOK: query: EXPLAIN
FROM src1 
INSERT OVERWRITE TABLE dest1_n28 SELECT 4 + NULL, src1.key - NULL, NULL + NULL
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN
FROM src1 
INSERT OVERWRITE TABLE dest1_n28 SELECT 4 + NULL, src1.key - NULL, NULL + NULL
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-7 depends on stages: Stage-1 , consists of Stage-4, Stage-3, Stage-5
  Stage-4
  Stage-0 depends on stages: Stage-4, Stage-3, Stage-6
  Stage-2 depends on stages: Stage-0
  Stage-3
  Stage-5
  Stage-6 depends on stages: Stage-5

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src1
            Statistics: Num rows: 25 Data size: 191 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: null (type: string), UDFToInteger((UDFToDouble(key) - null)) (type: int), null (type: double)
              outputColumnNames: _col0, _col1, _col2
              Statistics: Num rows: 25 Data size: 191 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                Statistics: Num rows: 25 Data size: 191 Basic stats: COMPLETE Column stats: NONE
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.dest1_n28
              Select Operator
                expressions: _col0 (type: string), _col1 (type: int), _col2 (type: double)
                outputColumnNames: c1, c2, c3
                Statistics: Num rows: 25 Data size: 191 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: compute_stats(c1, 'hll'), compute_stats(c2, 'hll'), compute_stats(c3, 'hll')
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 1 Data size: 1288 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Statistics: Num rows: 1 Data size: 1288 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col2 (type: struct<columntype:string,min:double,max:double,countnulls:bigint,bitvector:binary>)
      Reduce Operator Tree:
        Group By Operator
          aggregations: compute_stats(VALUE._col0), compute_stats(VALUE._col1), compute_stats(VALUE._col2)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 1 Data size: 1320 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 1320 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-7
    Conditional Operator

  Stage: Stage-4
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.dest1_n28

  Stage: Stage-2
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: c1, c2, c3
          Column Types: string, int, double
          Table: default.dest1_n28

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  name: default.dest1_n28

  Stage: Stage-5
    Map Reduce
      Map Operator Tree:
          TableScan
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  name: default.dest1_n28

  Stage: Stage-6
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

PREHOOK: query: FROM src1 
INSERT OVERWRITE TABLE dest1_n28 SELECT 4 + NULL, src1.key - NULL, NULL + NULL
PREHOOK: type: QUERY
PREHOOK: Input: default@src1
PREHOOK: Output: default@dest1_n28
POSTHOOK: query: FROM src1 
INSERT OVERWRITE TABLE dest1_n28 SELECT 4 + NULL, src1.key - NULL, NULL + NULL
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src1
POSTHOOK: Output: default@dest1_n28
POSTHOOK: Lineage: dest1_n28.c1 EXPRESSION []
POSTHOOK: Lineage: dest1_n28.c2 EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: dest1_n28.c3 EXPRESSION []
PREHOOK: query: SELECT dest1_n28.* FROM dest1_n28
PREHOOK: type: QUERY
PREHOOK: Input: default@dest1_n28
#### A masked pattern was here ####
POSTHOOK: query: SELECT dest1_n28.* FROM dest1_n28
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest1_n28
#### A masked pattern was here ####
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
NULL	NULL	NULL
