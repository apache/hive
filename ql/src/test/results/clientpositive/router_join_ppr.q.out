PREHOOK: query: -- SORT_QUERY_RESULTS

EXPLAIN EXTENDED
 FROM 
  src a
 RIGHT OUTER JOIN 
  srcpart b 
 ON (a.key = b.key AND b.ds = '2008-04-08')
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25
PREHOOK: type: QUERY
POSTHOOK: query: -- SORT_QUERY_RESULTS

EXPLAIN EXTENDED
 FROM 
  src a
 RIGHT OUTER JOIN 
  srcpart b 
 ON (a.key = b.key AND b.ds = '2008-04-08')
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_RIGHTOUTERJOIN
         TOK_TABREF
            TOK_TABNAME
               src
            a
         TOK_TABREF
            TOK_TABNAME
               srcpart
            b
         AND
            =
               .
                  TOK_TABLE_OR_COL
                     a
                  key
               .
                  TOK_TABLE_OR_COL
                     b
                  key
            =
               .
                  TOK_TABLE_OR_COL
                     b
                  ds
               '2008-04-08'
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               key
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               value
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  b
               key
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  b
               value
      TOK_WHERE
         AND
            AND
               AND
                  >
                     .
                        TOK_TABLE_OR_COL
                           a
                        key
                     10
                  <
                     .
                        TOK_TABLE_OR_COL
                           a
                        key
                     20
               >
                  .
                     TOK_TABLE_OR_COL
                        b
                     key
                  15
            <
               .
                  TOK_TABLE_OR_COL
                     b
                  key
               25


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: b
            Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: ((UDFToDouble(key) > 15.0) and (UDFToDouble(key) < 25.0)) (type: boolean)
              Statistics: Num rows: 222 Data size: 2358 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string), ds (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 222 Data size: 2358 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 222 Data size: 2358 Basic stats: COMPLETE Column stats: NONE
                  tag: 0
                  value expressions: _col1 (type: string), _col2 (type: string)
                  auto parallelism: false
          TableScan
            alias: a
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: ((UDFToDouble(key) > 15.0) and (UDFToDouble(key) < 25.0)) (type: boolean)
              Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
                  tag: 1
                  value expressions: _col1 (type: string)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numRows 500
              rawDataSize 5312
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numRows 500
                rawDataSize 5312
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
#### A masked pattern was here ####
          Partition
            base file name: hr=11
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
              hr 11
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.srcpart
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct srcpart { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct srcpart { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
#### A masked pattern was here ####
          Partition
            base file name: hr=12
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
              hr 12
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.srcpart
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct srcpart { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct srcpart { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
#### A masked pattern was here ####
          Partition
            base file name: hr=11
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-09
              hr 11
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.srcpart
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct srcpart { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct srcpart { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
#### A masked pattern was here ####
          Partition
            base file name: hr=12
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-09
              hr 12
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.srcpart
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct srcpart { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct srcpart { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
      Truncated Path -> Alias:
        /src [$hdt$_0:$hdt$_1:a]
        /srcpart/ds=2008-04-08/hr=11 [$hdt$_0:$hdt$_0:b]
        /srcpart/ds=2008-04-08/hr=12 [$hdt$_0:$hdt$_0:b]
        /srcpart/ds=2008-04-09/hr=11 [$hdt$_0:$hdt$_0:b]
        /srcpart/ds=2008-04-09/hr=12 [$hdt$_0:$hdt$_0:b]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Outer Join0 to 1
          filter mappings:
            0 [1, 1]
          filter predicates:
            0 {(VALUE._col1 = '2008-04-08')}
            1 
          keys:
            0 _col0 (type: string)
            1 _col0 (type: string)
          outputColumnNames: _col0, _col1, _col3, _col4
          Statistics: Num rows: 244 Data size: 2593 Basic stats: COMPLETE Column stats: NONE
          Filter Operator
            isSamplingPred: false
            predicate: ((UDFToDouble(_col3) > 10.0) and (UDFToDouble(_col3) < 20.0)) (type: boolean)
            Statistics: Num rows: 27 Data size: 286 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: _col3 (type: string), _col4 (type: string), _col0 (type: string), _col1 (type: string)
              outputColumnNames: _col0, _col1, _col2, _col3
              Statistics: Num rows: 27 Data size: 286 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics: Num rows: 27 Data size: 286 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0,_col1,_col2,_col3
                      columns.types string:string:string:string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM 
  src a
 RIGHT OUTER JOIN 
  srcpart b 
 ON (a.key = b.key AND b.ds = '2008-04-08')
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
#### A masked pattern was here ####
POSTHOOK: query: FROM 
  src a
 RIGHT OUTER JOIN 
  srcpart b 
 ON (a.key = b.key AND b.ds = '2008-04-08')
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
#### A masked pattern was here ####
17	val_17	17	val_17
17	val_17	17	val_17
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
19	val_19	19	val_19
19	val_19	19	val_19
PREHOOK: query: EXPLAIN EXTENDED
 FROM 
  srcpart a
 RIGHT OUTER JOIN 
  src b 
 ON (a.key = b.key AND a.ds = '2008-04-08')
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN EXTENDED
 FROM 
  srcpart a
 RIGHT OUTER JOIN 
  src b 
 ON (a.key = b.key AND a.ds = '2008-04-08')
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_RIGHTOUTERJOIN
         TOK_TABREF
            TOK_TABNAME
               srcpart
            a
         TOK_TABREF
            TOK_TABNAME
               src
            b
         AND
            =
               .
                  TOK_TABLE_OR_COL
                     a
                  key
               .
                  TOK_TABLE_OR_COL
                     b
                  key
            =
               .
                  TOK_TABLE_OR_COL
                     a
                  ds
               '2008-04-08'
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               key
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               value
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  b
               key
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  b
               value
      TOK_WHERE
         AND
            AND
               AND
                  >
                     .
                        TOK_TABLE_OR_COL
                           a
                        key
                     10
                  <
                     .
                        TOK_TABLE_OR_COL
                           a
                        key
                     20
               >
                  .
                     TOK_TABLE_OR_COL
                        b
                     key
                  15
            <
               .
                  TOK_TABLE_OR_COL
                     b
                  key
               25


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: a
            Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: ((UDFToDouble(key) > 15.0) and (UDFToDouble(key) < 25.0)) (type: boolean)
              Statistics: Num rows: 111 Data size: 1179 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 111 Data size: 1179 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 111 Data size: 1179 Basic stats: COMPLETE Column stats: NONE
                  tag: 0
                  value expressions: _col1 (type: string)
                  auto parallelism: false
          TableScan
            alias: b
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: ((UDFToDouble(key) > 15.0) and (UDFToDouble(key) < 25.0)) (type: boolean)
              Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
                  tag: 1
                  value expressions: _col1 (type: string)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numRows 500
              rawDataSize 5312
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numRows 500
                rawDataSize 5312
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
#### A masked pattern was here ####
          Partition
            base file name: hr=11
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
              hr 11
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.srcpart
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct srcpart { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct srcpart { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
#### A masked pattern was here ####
          Partition
            base file name: hr=12
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
              hr 12
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.srcpart
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct srcpart { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct srcpart { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
      Truncated Path -> Alias:
        /src [$hdt$_1:b]
        /srcpart/ds=2008-04-08/hr=11 [$hdt$_0:$hdt$_0:a]
        /srcpart/ds=2008-04-08/hr=12 [$hdt$_0:$hdt$_0:a]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Right Outer Join0 to 1
          keys:
            0 _col0 (type: string)
            1 _col0 (type: string)
          outputColumnNames: _col0, _col1, _col3, _col4
          Statistics: Num rows: 122 Data size: 1296 Basic stats: COMPLETE Column stats: NONE
          Filter Operator
            isSamplingPred: false
            predicate: ((UDFToDouble(_col0) > 10.0) and (UDFToDouble(_col0) < 20.0)) (type: boolean)
            Statistics: Num rows: 13 Data size: 138 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: _col0 (type: string), _col1 (type: string), _col3 (type: string), _col4 (type: string)
              outputColumnNames: _col0, _col1, _col2, _col3
              Statistics: Num rows: 13 Data size: 138 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics: Num rows: 13 Data size: 138 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0,_col1,_col2,_col3
                      columns.types string:string:string:string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM 
  srcpart a
 RIGHT OUTER JOIN 
  src b 
 ON (a.key = b.key AND a.ds = '2008-04-08')
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
#### A masked pattern was here ####
POSTHOOK: query: FROM 
  srcpart a
 RIGHT OUTER JOIN 
  src b 
 ON (a.key = b.key AND a.ds = '2008-04-08')
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
#### A masked pattern was here ####
17	val_17	17	val_17
17	val_17	17	val_17
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
19	val_19	19	val_19
19	val_19	19	val_19
PREHOOK: query: EXPLAIN EXTENDED
 FROM 
  src a
 RIGHT OUTER JOIN 
  srcpart b 
 ON (a.key = b.key)
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25 AND b.ds = '2008-04-08'
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN EXTENDED
 FROM 
  src a
 RIGHT OUTER JOIN 
  srcpart b 
 ON (a.key = b.key)
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25 AND b.ds = '2008-04-08'
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_RIGHTOUTERJOIN
         TOK_TABREF
            TOK_TABNAME
               src
            a
         TOK_TABREF
            TOK_TABNAME
               srcpart
            b
         =
            .
               TOK_TABLE_OR_COL
                  a
               key
            .
               TOK_TABLE_OR_COL
                  b
               key
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               key
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               value
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  b
               key
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  b
               value
      TOK_WHERE
         AND
            AND
               AND
                  AND
                     >
                        .
                           TOK_TABLE_OR_COL
                              a
                           key
                        10
                     <
                        .
                           TOK_TABLE_OR_COL
                              a
                           key
                        20
                  >
                     .
                        TOK_TABLE_OR_COL
                           b
                        key
                     15
               <
                  .
                     TOK_TABLE_OR_COL
                        b
                     key
                  25
            =
               .
                  TOK_TABLE_OR_COL
                     b
                  ds
               '2008-04-08'


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: b
            Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: ((UDFToDouble(key) > 15.0) and (UDFToDouble(key) < 25.0)) (type: boolean)
              Statistics: Num rows: 111 Data size: 1179 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 111 Data size: 1179 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 111 Data size: 1179 Basic stats: COMPLETE Column stats: NONE
                  tag: 0
                  value expressions: _col1 (type: string)
                  auto parallelism: false
          TableScan
            alias: a
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: ((UDFToDouble(key) > 15.0) and (UDFToDouble(key) < 25.0)) (type: boolean)
              Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 55 Data size: 584 Basic stats: COMPLETE Column stats: NONE
                  tag: 1
                  value expressions: _col1 (type: string)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numRows 500
              rawDataSize 5312
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numRows 500
                rawDataSize 5312
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
#### A masked pattern was here ####
          Partition
            base file name: hr=11
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
              hr 11
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.srcpart
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct srcpart { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct srcpart { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
#### A masked pattern was here ####
          Partition
            base file name: hr=12
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
              hr 12
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.srcpart
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct srcpart { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct srcpart { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
      Truncated Path -> Alias:
        /src [$hdt$_0:$hdt$_1:a]
        /srcpart/ds=2008-04-08/hr=11 [$hdt$_0:$hdt$_0:b]
        /srcpart/ds=2008-04-08/hr=12 [$hdt$_0:$hdt$_0:b]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Left Outer Join0 to 1
          keys:
            0 _col0 (type: string)
            1 _col0 (type: string)
          outputColumnNames: _col0, _col1, _col3, _col4
          Statistics: Num rows: 122 Data size: 1296 Basic stats: COMPLETE Column stats: NONE
          Filter Operator
            isSamplingPred: false
            predicate: ((UDFToDouble(_col3) > 10.0) and (UDFToDouble(_col3) < 20.0)) (type: boolean)
            Statistics: Num rows: 13 Data size: 138 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: _col3 (type: string), _col4 (type: string), _col0 (type: string), _col1 (type: string)
              outputColumnNames: _col0, _col1, _col2, _col3
              Statistics: Num rows: 13 Data size: 138 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics: Num rows: 13 Data size: 138 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0,_col1,_col2,_col3
                      columns.types string:string:string:string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM 
  src a
 RIGHT OUTER JOIN 
  srcpart b 
 ON (a.key = b.key)
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25 AND b.ds = '2008-04-08'
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
#### A masked pattern was here ####
POSTHOOK: query: FROM 
  src a
 RIGHT OUTER JOIN 
  srcpart b 
 ON (a.key = b.key)
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25 AND b.ds = '2008-04-08'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
#### A masked pattern was here ####
17	val_17	17	val_17
17	val_17	17	val_17
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
19	val_19	19	val_19
19	val_19	19	val_19
PREHOOK: query: EXPLAIN EXTENDED
 FROM 
  srcpart a
 RIGHT OUTER JOIN 
  src b 
 ON (a.key = b.key)
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25 AND a.ds = '2008-04-08'
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN EXTENDED
 FROM 
  srcpart a
 RIGHT OUTER JOIN 
  src b 
 ON (a.key = b.key)
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25 AND a.ds = '2008-04-08'
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_RIGHTOUTERJOIN
         TOK_TABREF
            TOK_TABNAME
               srcpart
            a
         TOK_TABREF
            TOK_TABNAME
               src
            b
         =
            .
               TOK_TABLE_OR_COL
                  a
               key
            .
               TOK_TABLE_OR_COL
                  b
               key
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               key
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               value
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  b
               key
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  b
               value
      TOK_WHERE
         AND
            AND
               AND
                  AND
                     >
                        .
                           TOK_TABLE_OR_COL
                              a
                           key
                        10
                     <
                        .
                           TOK_TABLE_OR_COL
                              a
                           key
                        20
                  >
                     .
                        TOK_TABLE_OR_COL
                           b
                        key
                     15
               <
                  .
                     TOK_TABLE_OR_COL
                        b
                     key
                  25
            =
               .
                  TOK_TABLE_OR_COL
                     a
                  ds
               '2008-04-08'


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: a
            Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (((((UDFToDouble(key) > 10.0) and (UDFToDouble(key) < 20.0)) and (UDFToDouble(key) > 15.0)) and (UDFToDouble(key) < 25.0)) and key is not null) (type: boolean)
              Statistics: Num rows: 6 Data size: 63 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 6 Data size: 63 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 6 Data size: 63 Basic stats: COMPLETE Column stats: NONE
                  tag: 0
                  value expressions: _col1 (type: string)
                  auto parallelism: false
          TableScan
            alias: b
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: (((((UDFToDouble(key) > 15.0) and (UDFToDouble(key) < 25.0)) and (UDFToDouble(key) > 10.0)) and (UDFToDouble(key) < 20.0)) and key is not null) (type: boolean)
              Statistics: Num rows: 3 Data size: 31 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 3 Data size: 31 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 3 Data size: 31 Basic stats: COMPLETE Column stats: NONE
                  tag: 1
                  value expressions: _col1 (type: string)
                  auto parallelism: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numRows 500
              rawDataSize 5312
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numRows 500
                rawDataSize 5312
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
#### A masked pattern was here ####
          Partition
            base file name: hr=11
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
              hr 11
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.srcpart
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct srcpart { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct srcpart { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
#### A masked pattern was here ####
          Partition
            base file name: hr=12
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
              hr 12
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 'default','default'
              columns.types string:string
#### A masked pattern was here ####
              name default.srcpart
              numFiles 1
              numRows 500
              partition_columns ds/hr
              partition_columns.types string:string
              rawDataSize 5312
              serialization.ddl struct srcpart { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 'default','default'
                columns.types string:string
#### A masked pattern was here ####
                name default.srcpart
                partition_columns ds/hr
                partition_columns.types string:string
                serialization.ddl struct srcpart { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcpart
            name: default.srcpart
      Truncated Path -> Alias:
        /src [$hdt$_1:$hdt$_1:b]
        /srcpart/ds=2008-04-08/hr=11 [$hdt$_0:$hdt$_0:a]
        /srcpart/ds=2008-04-08/hr=12 [$hdt$_0:$hdt$_0:a]
      Needs Tagging: true
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 _col0 (type: string)
            1 _col0 (type: string)
          outputColumnNames: _col0, _col1, _col3, _col4
          Statistics: Num rows: 6 Data size: 69 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: string), _col3 (type: string), _col4 (type: string)
            outputColumnNames: _col0, _col1, _col2, _col3
            Statistics: Num rows: 6 Data size: 69 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 6 Data size: 69 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1,_col2,_col3
                    columns.types string:string:string:string
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM 
  srcpart a
 RIGHT OUTER JOIN 
  src b 
 ON (a.key = b.key)
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25 AND a.ds = '2008-04-08'
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
#### A masked pattern was here ####
POSTHOOK: query: FROM 
  srcpart a
 RIGHT OUTER JOIN 
  src b 
 ON (a.key = b.key)
 SELECT a.key, a.value, b.key, b.value
 WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25 AND a.ds = '2008-04-08'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
#### A masked pattern was here ####
17	val_17	17	val_17
17	val_17	17	val_17
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
18	val_18	18	val_18
19	val_19	19	val_19
19	val_19	19	val_19
