PREHOOK: query: drop table if exists vectortab2k
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists vectortab2k
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table if exists vectortab2korc
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists vectortab2korc
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table vectortab2k(
            t tinyint,
            si smallint,
            i int,
            b bigint,
            f float,
            d double,
            dc decimal(38,18),
            bo boolean,
            s string,
            s2 string,
            ts timestamp,
            ts2 timestamp,
            dt date)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@vectortab2k
POSTHOOK: query: create table vectortab2k(
            t tinyint,
            si smallint,
            i int,
            b bigint,
            f float,
            d double,
            dc decimal(38,18),
            bo boolean,
            s string,
            s2 string,
            ts timestamp,
            ts2 timestamp,
            dt date)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@vectortab2k
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/vectortab2k' OVERWRITE INTO TABLE vectortab2k
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@vectortab2k
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/vectortab2k' OVERWRITE INTO TABLE vectortab2k
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@vectortab2k
PREHOOK: query: create table vectortab2korc(
            t tinyint,
            si smallint,
            i int,
            b bigint,
            f float,
            d double,
            dc decimal(38,18),
            bo boolean,
            s string,
            s2 string,
            ts timestamp,
            ts2 timestamp,
            dt date)
STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@vectortab2korc
POSTHOOK: query: create table vectortab2korc(
            t tinyint,
            si smallint,
            i int,
            b bigint,
            f float,
            d double,
            dc decimal(38,18),
            bo boolean,
            s string,
            s2 string,
            ts timestamp,
            ts2 timestamp,
            dt date)
STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@vectortab2korc
PREHOOK: query: INSERT INTO TABLE vectortab2korc SELECT * FROM vectortab2k
PREHOOK: type: QUERY
PREHOOK: Input: default@vectortab2k
PREHOOK: Output: default@vectortab2korc
POSTHOOK: query: INSERT INTO TABLE vectortab2korc SELECT * FROM vectortab2k
POSTHOOK: type: QUERY
POSTHOOK: Input: default@vectortab2k
POSTHOOK: Output: default@vectortab2korc
POSTHOOK: Lineage: vectortab2korc.b SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:b, type:bigint, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.bo SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:bo, type:boolean, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.d SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:d, type:double, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.dc SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:dc, type:decimal(38,18), comment:null), ]
POSTHOOK: Lineage: vectortab2korc.dt SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:dt, type:date, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.f SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:f, type:float, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.i SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:i, type:int, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.s SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:s, type:string, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.s2 SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:s2, type:string, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.si SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:si, type:smallint, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.t SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:t, type:tinyint, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.ts SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:ts, type:timestamp, comment:null), ]
POSTHOOK: Lineage: vectortab2korc.ts2 SIMPLE [(vectortab2k)vectortab2k.FieldSchema(name:ts2, type:timestamp, comment:null), ]
PREHOOK: query: drop table if exists char_lazy_binary_columnar
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists char_lazy_binary_columnar
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table char_lazy_binary_columnar(ct char(10), csi char(10), ci char(20), cb char(30), cf char(20), cd char(20), cs char(50)) row format serde 'org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe' stored as rcfile
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@char_lazy_binary_columnar
POSTHOOK: query: create table char_lazy_binary_columnar(ct char(10), csi char(10), ci char(20), cb char(30), cf char(20), cd char(20), cs char(50)) row format serde 'org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe' stored as rcfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@char_lazy_binary_columnar
PREHOOK: query: explain vectorization expression
insert overwrite table char_lazy_binary_columnar select t, si, i, b, f, d, s from vectortab2korc
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
insert overwrite table char_lazy_binary_columnar select t, si, i, b, f, d, s from vectortab2korc
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-7 depends on stages: Stage-1 , consists of Stage-4, Stage-3, Stage-5
  Stage-4
  Stage-0 depends on stages: Stage-4, Stage-3, Stage-6
  Stage-2 depends on stages: Stage-0
  Stage-3
  Stage-5
  Stage-6 depends on stages: Stage-5

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: vectortab2korc
            Statistics: Num rows: 2000 Data size: 918712 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
            Select Operator
              expressions: CAST( t AS CHAR(10)) (type: char(10)), CAST( si AS CHAR(10)) (type: char(10)), CAST( i AS CHAR(20)) (type: char(20)), CAST( b AS CHAR(30)) (type: char(30)), CAST( f AS CHAR(20)) (type: char(20)), CAST( d AS CHAR(20)) (type: char(20)), CAST( s AS CHAR(50)) (type: char(50))
              outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumnNums: [14, 15, 16, 17, 18, 19, 20]
                  selectExpressions: CastLongToChar(col 0:tinyint, maxLength 10) -> 14:char(10), CastLongToChar(col 1:smallint, maxLength 10) -> 15:char(10), CastLongToChar(col 2:int, maxLength 20) -> 16:char(20), CastLongToChar(col 3:bigint, maxLength 30) -> 17:char(30), CastFloatToChar(col 4:float, maxLength 20) -> 18:char(20), CastDoubleToChar(col 5:double, maxLength 20) -> 19:char(20), CastStringGroupToChar(col 8:string, maxLength 50) -> 20:char(50)
              Statistics: Num rows: 2000 Data size: 918712 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                File Sink Vectorization:
                    className: VectorFileSinkOperator
                    native: false
                Statistics: Num rows: 2000 Data size: 918712 Basic stats: COMPLETE Column stats: NONE
                table:
                    input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe
                    name: default.char_lazy_binary_columnar
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          inputFormatFeatureSupport: [DECIMAL_64]
          featureSupportInUse: [DECIMAL_64]
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true

  Stage: Stage-7
    Conditional Operator

  Stage: Stage-4
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe
              name: default.char_lazy_binary_columnar

  Stage: Stage-2
    Stats Work
      Basic Stats Work:

  Stage: Stage-3
    Merge File Operator
      Map Operator Tree:
          RCFile Merge Operator
      merge level: block
      input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat

  Stage: Stage-5
    Merge File Operator
      Map Operator Tree:
          RCFile Merge Operator
      merge level: block
      input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat

  Stage: Stage-6
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

