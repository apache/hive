PREHOOK: query: create table srcpart_date_n3 as select ds as ds, ds as ds2 from srcpart group by ds
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
PREHOOK: Output: database:default
PREHOOK: Output: default@srcpart_date_n3
POSTHOOK: query: create table srcpart_date_n3 as select ds as ds, ds as ds2 from srcpart group by ds
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
POSTHOOK: Output: database:default
POSTHOOK: Output: default@srcpart_date_n3
POSTHOOK: Lineage: srcpart_date_n3.ds SIMPLE [(srcpart)srcpart.FieldSchema(name:ds, type:string, comment:null), ]
POSTHOOK: Lineage: srcpart_date_n3.ds2 SIMPLE [(srcpart)srcpart.FieldSchema(name:ds, type:string, comment:null), ]
PREHOOK: query: create table srcpart2 as select * from srcpart
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
PREHOOK: Output: database:default
PREHOOK: Output: default@srcpart2
POSTHOOK: query: create table srcpart2 as select * from srcpart
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
POSTHOOK: Output: database:default
POSTHOOK: Output: default@srcpart2
POSTHOOK: Lineage: srcpart2.ds SIMPLE [(srcpart)srcpart.FieldSchema(name:ds, type:string, comment:null), ]
POSTHOOK: Lineage: srcpart2.hr SIMPLE [(srcpart)srcpart.FieldSchema(name:hr, type:string, comment:null), ]
POSTHOOK: Lineage: srcpart2.key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: srcpart2.value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: EXPLAIN select *
 from srcpart
 join srcpart_date_n3 on (srcpart.ds = srcpart_date_n3.ds)
 join srcpart2 on (srcpart.hr = srcpart2.hr)
 where srcpart_date_n3.ds2 = '2008-04-08'
 and srcpart2.hr = 11
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN select *
 from srcpart
 join srcpart_date_n3 on (srcpart.ds = srcpart_date_n3.ds)
 join srcpart2 on (srcpart.hr = srcpart2.hr)
 where srcpart_date_n3.ds2 = '2008-04-08'
 and srcpart2.hr = 11
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: srcpart_date_n3
                  filterExpr: ((ds2 = '2008-04-08') and ds is not null) (type: boolean)
                  Statistics: Num rows: 2 Data size: 42 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((ds2 = '2008-04-08') and ds is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ds (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        keys:
                          0 _col2 (type: string)
                          1 _col0 (type: string)
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 3 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  filterExpr: ((11.0D = 11.0D) and ds is not null) (type: boolean)
                  Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col3 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col3 (type: string)
                      Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: srcpart2
                  filterExpr: (UDFToDouble(hr) = 11.0D) (type: boolean)
                  Statistics: Num rows: 2000 Data size: 49248 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (UDFToDouble(hr) = 11.0D) (type: boolean)
                    Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col3 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col3 (type: string)
                        Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col3 (type: string)
                  1 _col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  keys:
                    0 _col2 (type: string)
                    1 _col0 (type: string)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                  input vertices:
                    1 Map 4
                  Statistics: Num rows: 1210 Data size: 12854 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col8 (type: string), '2008-04-08' (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                    Statistics: Num rows: 1210 Data size: 12854 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1210 Data size: 12854 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: EXPLAIN select *
 from srcpart
 join srcpart_date_n3 on (srcpart.ds = srcpart_date_n3.ds)
 join srcpart2 on (srcpart.hr = srcpart2.hr)
 where srcpart_date_n3.ds2 = '2008-04-08'
 and srcpart2.hr = 11
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN select *
 from srcpart
 join srcpart_date_n3 on (srcpart.ds = srcpart_date_n3.ds)
 join srcpart2 on (srcpart.hr = srcpart2.hr)
 where srcpart_date_n3.ds2 = '2008-04-08'
 and srcpart2.hr = 11
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 depends on stages: Stage-2
  Stage-1 depends on stages: Stage-3
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: srcpart2
                  filterExpr: (UDFToDouble(hr) = 11.0D) (type: boolean)
                  Statistics: Num rows: 2000 Data size: 49248 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (UDFToDouble(hr) = 11.0D) (type: boolean)
                    Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col3 (type: string)
                        outputColumnNames: _col0
                        Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                        Group By Operator
                          keys: _col0 (type: string)
                          mode: hash
                          outputColumnNames: _col0
                          Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                          Spark Partition Pruning Sink Operator
                            Target Columns: [Map 1 -> [hr:string (hr)]]
                            Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE

  Stage: Stage-3
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: srcpart_date_n3
                  filterExpr: ((ds2 = '2008-04-08') and ds is not null) (type: boolean)
                  Statistics: Num rows: 2 Data size: 42 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((ds2 = '2008-04-08') and ds is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ds (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        keys:
                          0 _col2 (type: string)
                          1 _col0 (type: string)
                      Select Operator
                        expressions: _col0 (type: string)
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
                        Group By Operator
                          keys: _col0 (type: string)
                          mode: hash
                          outputColumnNames: _col0
                          Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
                          Spark Partition Pruning Sink Operator
                            Target Columns: [Map 1 -> [ds:string (ds)]]
                            Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 3 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col3 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col3 (type: string)
                      Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: srcpart2
                  filterExpr: (UDFToDouble(hr) = 11.0D) (type: boolean)
                  Statistics: Num rows: 2000 Data size: 49248 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (UDFToDouble(hr) = 11.0D) (type: boolean)
                    Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col3 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col3 (type: string)
                        Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col3 (type: string)
                  1 _col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  keys:
                    0 _col2 (type: string)
                    1 _col0 (type: string)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                  input vertices:
                    1 Map 4
                  Statistics: Num rows: 1210 Data size: 12854 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col8 (type: string), '2008-04-08' (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                    Statistics: Num rows: 1210 Data size: 12854 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1210 Data size: 12854 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: EXPLAIN select *
 from srcpart
 join srcpart_date_n3 on (srcpart.ds = srcpart_date_n3.ds)
 join srcpart2 on (srcpart.hr = srcpart2.hr)
 where srcpart_date_n3.ds2 = '2008-04-08'
 and srcpart2.hr = 11
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN select *
 from srcpart
 join srcpart_date_n3 on (srcpart.ds = srcpart_date_n3.ds)
 join srcpart2 on (srcpart.hr = srcpart2.hr)
 where srcpart_date_n3.ds2 = '2008-04-08'
 and srcpart2.hr = 11
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: srcpart_date_n3
                  filterExpr: ((ds2 = '2008-04-08') and ds is not null) (type: boolean)
                  Statistics: Num rows: 2 Data size: 42 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((ds2 = '2008-04-08') and ds is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ds (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        keys:
                          0 _col2 (type: string)
                          1 _col0 (type: string)
                      Select Operator
                        expressions: _col0 (type: string)
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
                        Group By Operator
                          keys: _col0 (type: string)
                          mode: hash
                          outputColumnNames: _col0
                          Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
                          Spark Partition Pruning Sink Operator
                            Target Columns: [Map 1 -> [ds:string (ds)]]
                            Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 3 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col3 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col3 (type: string)
                      Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: srcpart2
                  filterExpr: (UDFToDouble(hr) = 11.0D) (type: boolean)
                  Statistics: Num rows: 2000 Data size: 49248 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (UDFToDouble(hr) = 11.0D) (type: boolean)
                    Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col3 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col3 (type: string)
                        Statistics: Num rows: 1000 Data size: 24624 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col3 (type: string)
                  1 _col3 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  keys:
                    0 _col2 (type: string)
                    1 _col0 (type: string)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                  input vertices:
                    1 Map 4
                  Statistics: Num rows: 1210 Data size: 12854 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col8 (type: string), '2008-04-08' (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                    Statistics: Num rows: 1210 Data size: 12854 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1210 Data size: 12854 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: drop table srcpart_date_n3
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@srcpart_date_n3
PREHOOK: Output: default@srcpart_date_n3
POSTHOOK: query: drop table srcpart_date_n3
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@srcpart_date_n3
POSTHOOK: Output: default@srcpart_date_n3
PREHOOK: query: drop table srcpart2
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@srcpart2
PREHOOK: Output: default@srcpart2
POSTHOOK: query: drop table srcpart2
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@srcpart2
POSTHOOK: Output: default@srcpart2
