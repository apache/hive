PREHOOK: query: CREATE TABLE orc_table_1a(a INT) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@orc_table_1a
POSTHOOK: query: CREATE TABLE orc_table_1a(a INT) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orc_table_1a
PREHOOK: query: CREATE TABLE orc_table_2a(c INT) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@orc_table_2a
POSTHOOK: query: CREATE TABLE orc_table_2a(c INT) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orc_table_2a
PREHOOK: query: insert into table orc_table_1a values(1),(1), (2),(3)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@orc_table_1a
POSTHOOK: query: insert into table orc_table_1a values(1),(1), (2),(3)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@orc_table_1a
POSTHOOK: Lineage: orc_table_1a.a SCRIPT []
PREHOOK: query: insert into table orc_table_2a values(0),(2), (3),(null),(4)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@orc_table_2a
POSTHOOK: query: insert into table orc_table_2a values(0),(2), (3),(null),(4)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@orc_table_2a
POSTHOOK: Lineage: orc_table_2a.c SCRIPT []
PREHOOK: query: explain vectorization detail
select t1.a from orc_table_2a t2 join orc_table_1a t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.a from orc_table_2a t2 join orc_table_1a t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 5 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c:int, 1:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (c > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 3 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: c (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 3 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        Spark Hash Table Sink Vectorization:
                            className: VectorSparkHashTableSinkOperator
                            native: true
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    includeColumns: [0]
                    dataColumns: c:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:a:int, 1:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (a > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: a (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [0]
                            bigTableRetainedColumnNums: [0]
                            bigTableValueColumnNums: [0]
                            className: VectorMapJoinInnerBigOnlyLongOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0]
                        outputColumnNames: _col1
                        input vertices:
                          0 Map 1
                        Statistics: Num rows: 1 Data size: 3 Basic stats: COMPLETE Column stats: NONE
                        Select Operator
                          expressions: _col1 (type: int)
                          outputColumnNames: _col0
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [0]
                          Statistics: Num rows: 1 Data size: 3 Basic stats: COMPLETE Column stats: NONE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 1 Data size: 3 Basic stats: COMPLETE Column stats: NONE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    includeColumns: [0]
                    dataColumns: a:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.a from orc_table_2a t2 join orc_table_1a t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1a
PREHOOK: Input: default@orc_table_2a
#### A masked pattern was here ####
POSTHOOK: query: select t1.a from orc_table_2a t2 join orc_table_1a t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1a
POSTHOOK: Input: default@orc_table_2a
#### A masked pattern was here ####
3
PREHOOK: query: explain vectorization detail
select t2.c from orc_table_2a t2 left semi join orc_table_1a t1 on t1.a = t2.c where t2.c > 2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t2.c from orc_table_2a t2 left semi join orc_table_1a t1 on t1.a = t2.c where t2.c > 2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 4 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:a:int, 1:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (a > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: a (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        Group By Vectorization:
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 0:int
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: []
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Spark HashTable Sink Operator
                          Spark Hash Table Sink Vectorization:
                              className: VectorSparkHashTableSinkOperator
                              native: true
                          keys:
                            0 _col0 (type: int)
                            1 _col0 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    includeColumns: [0]
                    dataColumns: a:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 5 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c:int, 1:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (c > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 3 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: c (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 3 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Left Semi Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [0]
                            bigTableRetainedColumnNums: [0]
                            bigTableValueColumnNums: [0]
                            className: VectorMapJoinLeftSemiLongOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0]
                        outputColumnNames: _col0
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 1 Data size: 3 Basic stats: COMPLETE Column stats: NONE
                        File Output Operator
                          compressed: false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
                          Statistics: Num rows: 1 Data size: 3 Basic stats: COMPLETE Column stats: NONE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 1
                    includeColumns: [0]
                    dataColumns: c:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t2.c from orc_table_2a t2 left semi join orc_table_1a t1 on t1.a = t2.c where t2.c > 2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1a
PREHOOK: Input: default@orc_table_2a
#### A masked pattern was here ####
POSTHOOK: query: select t2.c from orc_table_2a t2 left semi join orc_table_1a t1 on t1.a = t2.c where t2.c > 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1a
POSTHOOK: Input: default@orc_table_2a
#### A masked pattern was here ####
3
PREHOOK: query: CREATE TABLE orc_table_1b(v1 STRING, a INT) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@orc_table_1b
POSTHOOK: query: CREATE TABLE orc_table_1b(v1 STRING, a INT) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orc_table_1b
PREHOOK: query: CREATE TABLE orc_table_2b(c INT, v2 STRING) STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@orc_table_2b
POSTHOOK: query: CREATE TABLE orc_table_2b(c INT, v2 STRING) STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@orc_table_2b
PREHOOK: query: insert into table orc_table_1b values("one", 1),("one", 1), ("two", 2),("three", 3)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@orc_table_1b
POSTHOOK: query: insert into table orc_table_1b values("one", 1),("one", 1), ("two", 2),("three", 3)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@orc_table_1b
POSTHOOK: Lineage: orc_table_1b.a SCRIPT []
POSTHOOK: Lineage: orc_table_1b.v1 SCRIPT []
PREHOOK: query: insert into table orc_table_2b values(0, "ZERO"),(2, "TWO"), (3, "THREE"),(null, "<NULL>"),(4, "FOUR")
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@orc_table_2b
POSTHOOK: query: insert into table orc_table_2b values(0, "ZERO"),(2, "TWO"), (3, "THREE"),(null, "<NULL>"),(4, "FOUR")
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@orc_table_2b
POSTHOOK: Lineage: orc_table_2b.c SCRIPT []
POSTHOOK: Lineage: orc_table_2b.v2 SCRIPT []
PREHOOK: query: explain vectorization detail
select t1.v1, t1.a from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.v1, t1.a from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 4 Data size: 364 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:v1:string, 1:a:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 1:int, val 2)
                    predicate: (a > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: v1 (type: string), a (type: int)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        Spark Hash Table Sink Vectorization:
                            className: VectorSparkHashTableSinkOperator
                            native: true
                        keys:
                          0 _col0 (type: int)
                          1 _col1 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: v1:string, a:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 5 Data size: 456 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c:int, 1:v2:string, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (c > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: c (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col1 (type: int)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [0]
                            bigTableRetainedColumnNums: [0]
                            className: VectorMapJoinInnerLongOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [3, 0]
                            smallTableMapping: [3]
                        outputColumnNames: _col1, _col2
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        Select Operator
                          expressions: _col1 (type: string), _col2 (type: int)
                          outputColumnNames: _col0, _col1
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [3, 0]
                          Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0]
                    dataColumns: c:int, v2:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string]
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.v1, t1.a from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1b
PREHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
POSTHOOK: query: select t1.v1, t1.a from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1b
POSTHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
three	3
PREHOOK: query: explain vectorization detail
select t1.v1, t1.a, t2.c, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.v1, t1.a, t2.c, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 5 Data size: 456 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c:int, 1:v2:string, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (c > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: c (type: int), v2 (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        Spark Hash Table Sink Vectorization:
                            className: VectorSparkHashTableSinkOperator
                            native: true
                        keys:
                          0 _col1 (type: int)
                          1 _col0 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: c:int, v2:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 4 Data size: 364 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:v1:string, 1:a:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 1:int, val 2)
                    predicate: (a > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: v1 (type: string), a (type: int)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col1 (type: int)
                          1 _col0 (type: int)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [1]
                            bigTableRetainedColumnNums: [0, 1]
                            bigTableValueColumnNums: [0, 1]
                            className: VectorMapJoinInnerLongOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0, 1, 1, 3]
                            smallTableMapping: [3]
                        outputColumnNames: _col0, _col1, _col2, _col3
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        File Output Operator
                          compressed: false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
                          Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: v1:string, a:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string]
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.v1, t1.a, t2.c, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1b
PREHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
POSTHOOK: query: select t1.v1, t1.a, t2.c, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1b
POSTHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
three	3	3	THREE
PREHOOK: query: explain vectorization detail
select t1.v1, t1.a*2, t2.c*5, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.v1, t1.a*2, t2.c*5, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 4 Data size: 364 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:v1:string, 1:a:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 1:int, val 2)
                    predicate: (a > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: v1 (type: string), a (type: int)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        Spark Hash Table Sink Vectorization:
                            className: VectorSparkHashTableSinkOperator
                            native: true
                        keys:
                          0 _col0 (type: int)
                          1 _col1 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: v1:string, a:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 5 Data size: 456 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c:int, 1:v2:string, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (c > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: c (type: int), v2 (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col1 (type: int)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [0]
                            bigTableRetainedColumnNums: [0, 1]
                            bigTableValueColumnNums: [0, 1]
                            className: VectorMapJoinInnerLongOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0, 1, 3, 0]
                            smallTableMapping: [3]
                        outputColumnNames: _col0, _col1, _col2, _col3
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        Select Operator
                          expressions: _col2 (type: string), (_col3 * 2) (type: int), (_col0 * 5) (type: int), _col1 (type: string)
                          outputColumnNames: _col0, _col1, _col2, _col3
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [3, 4, 5, 1]
                              selectExpressions: LongColMultiplyLongScalar(col 0:int, val 2) -> 4:int, LongColMultiplyLongScalar(col 0:int, val 5) -> 5:int
                          Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: c:int, v2:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string, bigint, bigint]
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.v1, t1.a*2, t2.c*5, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1b
PREHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
POSTHOOK: query: select t1.v1, t1.a*2, t2.c*5, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1b
POSTHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
three	6	15	THREE
PREHOOK: query: explain vectorization detail
select t1.v1, t2.v2, t2.c from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.v1, t2.v2, t2.c from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 4 Data size: 364 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:v1:string, 1:a:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 1:int, val 2)
                    predicate: (a > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: v1 (type: string), a (type: int)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        Spark Hash Table Sink Vectorization:
                            className: VectorSparkHashTableSinkOperator
                            native: true
                        keys:
                          0 _col0 (type: int)
                          1 _col1 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: v1:string, a:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 5 Data size: 456 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c:int, 1:v2:string, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (c > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: c (type: int), v2 (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col1 (type: int)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [0]
                            bigTableRetainedColumnNums: [0, 1]
                            bigTableValueColumnNums: [0, 1]
                            className: VectorMapJoinInnerLongOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0, 1, 3]
                            smallTableMapping: [3]
                        outputColumnNames: _col0, _col1, _col2
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        Select Operator
                          expressions: _col2 (type: string), _col1 (type: string), _col0 (type: int)
                          outputColumnNames: _col0, _col1, _col2
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [3, 1, 0]
                          Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: c:int, v2:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string]
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.v1, t2.v2, t2.c from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1b
PREHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
POSTHOOK: query: select t1.v1, t2.v2, t2.c from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1b
POSTHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
three	THREE	3
PREHOOK: query: explain vectorization detail
select t1.a, t1.v1, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.a, t1.v1, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 4 Data size: 364 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:v1:string, 1:a:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 1:int, val 2)
                    predicate: (a > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: v1 (type: string), a (type: int)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        Spark Hash Table Sink Vectorization:
                            className: VectorSparkHashTableSinkOperator
                            native: true
                        keys:
                          0 _col0 (type: int)
                          1 _col1 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: v1:string, a:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 5 Data size: 456 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c:int, 1:v2:string, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (c > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: c (type: int), v2 (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col1 (type: int)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [0]
                            bigTableRetainedColumnNums: [0, 1]
                            bigTableValueColumnNums: [1]
                            className: VectorMapJoinInnerLongOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [1, 3, 0]
                            smallTableMapping: [3]
                        outputColumnNames: _col1, _col2, _col3
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        Select Operator
                          expressions: _col3 (type: int), _col2 (type: string), _col1 (type: string)
                          outputColumnNames: _col0, _col1, _col2
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [0, 3, 1]
                          Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: c:int, v2:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string]
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.a, t1.v1, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1b
PREHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
POSTHOOK: query: select t1.a, t1.v1, t2.v2 from orc_table_2b t2 join orc_table_1b t1 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1b
POSTHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
3	three	THREE
PREHOOK: query: explain vectorization detail
select t1.v1, t2.v2, t2.c from orc_table_1b t1 join orc_table_2b t2 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.v1, t2.v2, t2.c from orc_table_1b t1 join orc_table_2b t2 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 5 Data size: 456 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c:int, 1:v2:string, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (c > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: c (type: int), v2 (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        Spark Hash Table Sink Vectorization:
                            className: VectorSparkHashTableSinkOperator
                            native: true
                        keys:
                          0 _col1 (type: int)
                          1 _col0 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: c:int, v2:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 4 Data size: 364 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:v1:string, 1:a:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 1:int, val 2)
                    predicate: (a > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: v1 (type: string), a (type: int)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col1 (type: int)
                          1 _col0 (type: int)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [1]
                            bigTableRetainedColumnNums: [0, 1]
                            bigTableValueColumnNums: [0]
                            className: VectorMapJoinInnerLongOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0, 1, 3]
                            smallTableMapping: [3]
                        outputColumnNames: _col0, _col2, _col3
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        Select Operator
                          expressions: _col0 (type: string), _col3 (type: string), _col2 (type: int)
                          outputColumnNames: _col0, _col1, _col2
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [0, 3, 1]
                          Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: v1:string, a:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string]
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.v1, t2.v2, t2.c from orc_table_1b t1 join orc_table_2b t2 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1b
PREHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
POSTHOOK: query: select t1.v1, t2.v2, t2.c from orc_table_1b t1 join orc_table_2b t2 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1b
POSTHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
three	THREE	3
PREHOOK: query: explain vectorization detail
select t1.a, t1.v1, t2.v2 from orc_table_1b t1 join orc_table_2b t2 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization detail
select t1.a, t1.v1, t2.v2 from orc_table_1b t1 join orc_table_2b t2 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 5 Data size: 456 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:c:int, 1:v2:string, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 0:int, val 2)
                    predicate: (c > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: c (type: int), v2 (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        Spark Hash Table Sink Vectorization:
                            className: VectorSparkHashTableSinkOperator
                            native: true
                        keys:
                          0 _col1 (type: int)
                          1 _col0 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: c:int, v2:string
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 4 Data size: 364 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      vectorizationSchemaColumns: [0:v1:string, 1:a:int, 2:ROW__ID:struct<transactionid:bigint,bucketid:int,rowid:bigint>]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterLongColGreaterLongScalar(col 1:int, val 2)
                    predicate: (a > 2) (type: boolean)
                    Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: v1 (type: string), a (type: int)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 91 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col1 (type: int)
                          1 _col0 (type: int)
                        Map Join Vectorization:
                            bigTableKeyColumnNums: [1]
                            bigTableRetainedColumnNums: [0, 1]
                            bigTableValueColumnNums: [0, 1]
                            className: VectorMapJoinInnerLongOperator
                            native: true
                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                            projectedOutputColumnNums: [0, 1, 3]
                            smallTableMapping: [3]
                        outputColumnNames: _col0, _col1, _col3
                        input vertices:
                          1 Map 2
                        Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        Select Operator
                          expressions: _col1 (type: int), _col0 (type: string), _col3 (type: string)
                          outputColumnNames: _col0, _col1, _col2
                          Select Vectorization:
                              className: VectorSelectOperator
                              native: true
                              projectedOutputColumnNums: [1, 0, 3]
                          Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                          File Output Operator
                            compressed: false
                            File Sink Vectorization:
                                className: VectorFileSinkOperator
                                native: false
                            Statistics: Num rows: 1 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                            table:
                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: []
                featureSupportInUse: []
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: v1:string, a:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [string]
            Local Work:
              Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t1.a, t1.v1, t2.v2 from orc_table_1b t1 join orc_table_2b t2 on t1.a = t2.c where t1.a > 2
PREHOOK: type: QUERY
PREHOOK: Input: default@orc_table_1b
PREHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
POSTHOOK: query: select t1.a, t1.v1, t2.v2 from orc_table_1b t1 join orc_table_2b t2 on t1.a = t2.c where t1.a > 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@orc_table_1b
POSTHOOK: Input: default@orc_table_2b
#### A masked pattern was here ####
3	three	THREE
