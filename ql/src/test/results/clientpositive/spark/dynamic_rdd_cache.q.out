PREHOOK: query: EXPLAIN
FROM
(SELECT src.* FROM src sort by key) X
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (X.key = Y.key)
JOIN
(SELECT src.* FROM src sort by value) Z
ON (X.key = Z.key)
SELECT sum(hash(Y.key,Y.value)) GROUP BY Y.key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: EXPLAIN
FROM
(SELECT src.* FROM src sort by key) X
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (X.key = Y.key)
JOIN
(SELECT src.* FROM src sort by value) Z
ON (X.key = Z.key)
SELECT sum(hash(Y.key,Y.value)) GROUP BY Y.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 31), Map 4 (PARTITION-LEVEL SORT, 31), Map 5 (PARTITION-LEVEL SORT, 31)
        Reducer 3 <- Reducer 2 (GROUP, 31)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col0 (type: string)
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col0 (type: string)
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col1 (type: string)
            Execution mode: vectorized
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col0 (type: string)
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Right Outer Join 0 to 1
                     Inner Join 0 to 2
                keys:
                  0 _col0 (type: string)
                  1 _col0 (type: string)
                  2 _col0 (type: string)
                outputColumnNames: _col2, _col3
                Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: sum(hash(_col2,_col3))
                  keys: _col2 (type: string)
                  mode: hash
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: string)
                    sort order: +
                    Map-reduce partition columns: _col0 (type: string)
                    Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col1 (type: bigint)
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col1 (type: bigint)
                  outputColumnNames: _col0
                  Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: true
                    Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: CREATE TABLE dest1_n90(key INT, value STRING)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@dest1_n90
POSTHOOK: query: CREATE TABLE dest1_n90(key INT, value STRING)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@dest1_n90
PREHOOK: query: CREATE TABLE dest2_n24(key INT, value STRING)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@dest2_n24
POSTHOOK: query: CREATE TABLE dest2_n24(key INT, value STRING)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@dest2_n24
PREHOOK: query: EXPLAIN
FROM src
INSERT OVERWRITE TABLE dest1_n90 SELECT src.key, sum(SUBSTR(src.value,5)) GROUP BY src.key
INSERT OVERWRITE TABLE dest2_n24 SELECT src.key, sum(SUBSTR(src.value,5)) GROUP BY src.key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@dest1_n90
PREHOOK: Output: default@dest2_n24
POSTHOOK: query: EXPLAIN
FROM src
INSERT OVERWRITE TABLE dest1_n90 SELECT src.key, sum(SUBSTR(src.value,5)) GROUP BY src.key
INSERT OVERWRITE TABLE dest2_n24 SELECT src.key, sum(SUBSTR(src.value,5)) GROUP BY src.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@dest1_n90
POSTHOOK: Output: default@dest2_n24
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-2
  Stage-4 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      Edges:
        Reducer 2 <- Map 4 (GROUP, 31)
        Reducer 3 <- Map 4 (GROUP, 31)
#### A masked pattern was here ####
      Vertices:
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: key, value
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(substr(value, 5))
                      keys: key (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: double)
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: UDFToInteger(_col0) (type: int), CAST( _col1 AS STRING) (type: string)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: true
                    Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: default.dest1_n90
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: UDFToInteger(_col0) (type: int), CAST( _col1 AS STRING) (type: string)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: true
                    Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: default.dest2_n24

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.dest1_n90

  Stage: Stage-3
    Stats Work
      Basic Stats Work:

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.dest2_n24

  Stage: Stage-4
    Stats Work
      Basic Stats Work:

PREHOOK: query: SELECT dest1_n90.* FROM dest1_n90
PREHOOK: type: QUERY
PREHOOK: Input: default@dest1_n90
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: SELECT dest1_n90.* FROM dest1_n90
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest1_n90
POSTHOOK: Output: hdfs://### HDFS PATH ###
PREHOOK: query: SELECT dest2_n24.* FROM dest2_n24
PREHOOK: type: QUERY
PREHOOK: Input: default@dest2_n24
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: SELECT dest2_n24.* FROM dest2_n24
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest2_n24
POSTHOOK: Output: hdfs://### HDFS PATH ###
PREHOOK: query: DROP TABLE dest1_n90
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@dest1_n90
PREHOOK: Output: default@dest1_n90
POSTHOOK: query: DROP TABLE dest1_n90
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@dest1_n90
POSTHOOK: Output: default@dest1_n90
PREHOOK: query: DROP TABLE dest2_n24
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@dest2_n24
PREHOOK: Output: default@dest2_n24
POSTHOOK: query: DROP TABLE dest2_n24
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@dest2_n24
POSTHOOK: Output: default@dest2_n24
PREHOOK: query: CREATE TABLE tmptable_n8(key STRING, value INT)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tmptable_n8
POSTHOOK: query: CREATE TABLE tmptable_n8(key STRING, value INT)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tmptable_n8
PREHOOK: query: EXPLAIN
INSERT OVERWRITE TABLE tmptable_n8
  SELECT unionsrc.key, unionsrc.value FROM (SELECT 'tst1' AS key, count(1) AS value FROM src s1
                                        UNION  ALL
                                            SELECT 'tst2' AS key, count(1) AS value FROM src s2
                                        UNION ALL
                                            SELECT 'tst3' AS key, count(1) AS value FROM src s3) unionsrc
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@tmptable_n8
POSTHOOK: query: EXPLAIN
INSERT OVERWRITE TABLE tmptable_n8
  SELECT unionsrc.key, unionsrc.value FROM (SELECT 'tst1' AS key, count(1) AS value FROM src s1
                                        UNION  ALL
                                            SELECT 'tst2' AS key, count(1) AS value FROM src s2
                                        UNION ALL
                                            SELECT 'tst3' AS key, count(1) AS value FROM src s3) unionsrc
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@tmptable_n8
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1
  Stage-2 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP, 1)
        Reducer 4 <- Map 1 (GROUP, 1)
        Reducer 6 <- Map 1 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: s1
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: count()
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        sort order: 
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: bigint)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'tst1' (type: string), _col0 (type: bigint)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1 Data size: 96 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: string), UDFToInteger(_col1) (type: int)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 3 Data size: 276 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: true
                      Statistics: Num rows: 3 Data size: 276 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.tmptable_n8
        Reducer 4 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'tst2' (type: string), _col0 (type: bigint)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1 Data size: 96 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: string), UDFToInteger(_col1) (type: int)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 3 Data size: 276 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: true
                      Statistics: Num rows: 3 Data size: 276 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.tmptable_n8
        Reducer 6 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'tst3' (type: string), _col0 (type: bigint)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1 Data size: 96 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: string), UDFToInteger(_col1) (type: int)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 3 Data size: 276 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: true
                      Statistics: Num rows: 3 Data size: 276 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.tmptable_n8

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.tmptable_n8

  Stage: Stage-2
    Stats Work
      Basic Stats Work:

PREHOOK: query: SELECT * FROM tmptable_n8 x SORT BY x.key
PREHOOK: type: QUERY
PREHOOK: Input: default@tmptable_n8
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: SELECT * FROM tmptable_n8 x SORT BY x.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@tmptable_n8
POSTHOOK: Output: hdfs://### HDFS PATH ###
PREHOOK: query: DROP TABLE tmtable
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE tmtable
POSTHOOK: type: DROPTABLE
PREHOOK: query: EXPLAIN
SELECT unionsrc1.key, unionsrc1.value, unionsrc2.key, unionsrc2.value
FROM (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s1
                         UNION  ALL
      SELECT s2.key AS key, s2.value AS value FROM src s2 WHERE s2.key < 10) unionsrc1
JOIN
     (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s3
                         UNION  ALL
      SELECT s4.key AS key, s4.value AS value FROM src s4 WHERE s4.key < 10) unionsrc2
ON (unionsrc1.key = unionsrc2.key)
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: EXPLAIN
SELECT unionsrc1.key, unionsrc1.value, unionsrc2.key, unionsrc2.value
FROM (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s1
                         UNION  ALL
      SELECT s2.key AS key, s2.value AS value FROM src s2 WHERE s2.key < 10) unionsrc1
JOIN
     (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s3
                         UNION  ALL
      SELECT s4.key AS key, s4.value AS value FROM src s4 WHERE s4.key < 10) unionsrc2
ON (unionsrc1.key = unionsrc2.key)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP, 1)
        Reducer 3 <- Map 4 (PARTITION-LEVEL SORT, 31), Map 7 (PARTITION-LEVEL SORT, 31), Reducer 2 (PARTITION-LEVEL SORT, 31), Reducer 6 (PARTITION-LEVEL SORT, 31)
        Reducer 6 <- Map 1 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: s1
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
                    Group By Operator
                      aggregations: count()
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        sort order: 
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: bigint)
            Execution mode: vectorized
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: s2
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (UDFToDouble(key) < 10.0D) (type: boolean)
                    Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 167 Data size: 2035 Basic stats: COMPLETE Column stats: PARTIAL
                        value expressions: _col1 (type: string)
            Execution mode: vectorized
        Map 7 
            Map Operator Tree:
                TableScan
                  alias: s4
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (UDFToDouble(key) < 10.0D) (type: boolean)
                    Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 167 Data size: 2035 Basic stats: COMPLETE Column stats: PARTIAL
                        value expressions: _col1 (type: string)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'tst1' (type: string), CAST( _col0 AS STRING) (type: string)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: string)
                    sort order: +
                    Map-reduce partition columns: _col0 (type: string)
                    Statistics: Num rows: 167 Data size: 2035 Basic stats: COMPLETE Column stats: PARTIAL
                    value expressions: _col1 (type: string)
        Reducer 3 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: string)
                  1 _col0 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 27889 Data size: 15171616 Basic stats: COMPLETE Column stats: PARTIAL
                File Output Operator
                  compressed: true
                  Statistics: Num rows: 27889 Data size: 15171616 Basic stats: COMPLETE Column stats: PARTIAL
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 6 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'tst1' (type: string), CAST( _col0 AS STRING) (type: string)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1 Data size: 272 Basic stats: COMPLETE Column stats: COMPLETE
                  Reduce Output Operator
                    key expressions: _col0 (type: string)
                    sort order: +
                    Map-reduce partition columns: _col0 (type: string)
                    Statistics: Num rows: 167 Data size: 2035 Basic stats: COMPLETE Column stats: PARTIAL
                    value expressions: _col1 (type: string)

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: CREATE TABLE inv(w_warehouse_name STRING , w_warehouse_sk INT , stdev INT , d_moy INT , mean INT , cov INT , inv_quantity_on_hand INT)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@inv
POSTHOOK: query: CREATE TABLE inv(w_warehouse_name STRING , w_warehouse_sk INT , stdev INT , d_moy INT , mean INT , cov INT , inv_quantity_on_hand INT)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@inv
PREHOOK: query: CREATE TABLE inventory(inv_date_sk INT , inv_item_sk INT ,inv_quantity_on_hand INT ,inv_warehouse_sk INT)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@inventory
POSTHOOK: query: CREATE TABLE inventory(inv_date_sk INT , inv_item_sk INT ,inv_quantity_on_hand INT ,inv_warehouse_sk INT)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@inventory
PREHOOK: query: CREATE TABLE item(i_item_sk INT)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@item
POSTHOOK: query: CREATE TABLE item(i_item_sk INT)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@item
PREHOOK: query: CREATE TABLE warehouse(w_warehouse_sk INT , w_warehouse_name STRING)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@warehouse
POSTHOOK: query: CREATE TABLE warehouse(w_warehouse_sk INT , w_warehouse_name STRING)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@warehouse
PREHOOK: query: CREATE TABLE date_dim(d_date_sk INT , d_year INT , d_moy INT)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@date_dim
POSTHOOK: query: CREATE TABLE date_dim(d_date_sk INT , d_year INT , d_moy INT)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@date_dim
PREHOOK: query: EXPLAIN
WITH inv AS
(SELECT w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
       ,stdev,mean, CASE mean WHEN 0 THEN null ELSE stdev/mean END cov
FROM(SELECT w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
            ,STDDEV_SAMP(inv_quantity_on_hand) stdev,AVG(inv_quantity_on_hand) mean
      FROM inventory
          ,item
          ,warehouse
          ,date_dim
      WHERE inv_item_sk = i_item_sk
        AND inv_warehouse_sk = w_warehouse_sk
        AND inv_date_sk = d_date_sk
        AND d_year =1999
      GROUP BY w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy) foo
 WHERE CASE mean WHEN 0 THEN 0 ELSE stdev/mean END > 1)
SELECT inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean, inv1.cov
        ,inv2.w_warehouse_sk,inv2.i_item_sk,inv2.d_moy,inv2.mean, inv2.cov
FROM inv inv1,inv inv2
WHERE inv1.i_item_sk = inv2.i_item_sk
  AND inv1.w_warehouse_sk =  inv2.w_warehouse_sk
  AND inv1.d_moy=3
  AND inv2.d_moy=3+1
ORDER BY inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean,inv1.cov
        ,inv2.d_moy,inv2.mean, inv2.cov
PREHOOK: type: QUERY
PREHOOK: Input: default@date_dim
PREHOOK: Input: default@inventory
PREHOOK: Input: default@item
PREHOOK: Input: default@warehouse
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: EXPLAIN
WITH inv AS
(SELECT w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
       ,stdev,mean, CASE mean WHEN 0 THEN null ELSE stdev/mean END cov
FROM(SELECT w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
            ,STDDEV_SAMP(inv_quantity_on_hand) stdev,AVG(inv_quantity_on_hand) mean
      FROM inventory
          ,item
          ,warehouse
          ,date_dim
      WHERE inv_item_sk = i_item_sk
        AND inv_warehouse_sk = w_warehouse_sk
        AND inv_date_sk = d_date_sk
        AND d_year =1999
      GROUP BY w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy) foo
 WHERE CASE mean WHEN 0 THEN 0 ELSE stdev/mean END > 1)
SELECT inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean, inv1.cov
        ,inv2.w_warehouse_sk,inv2.i_item_sk,inv2.d_moy,inv2.mean, inv2.cov
FROM inv inv1,inv inv2
WHERE inv1.i_item_sk = inv2.i_item_sk
  AND inv1.w_warehouse_sk =  inv2.w_warehouse_sk
  AND inv1.d_moy=3
  AND inv2.d_moy=3+1
ORDER BY inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean,inv1.cov
        ,inv2.d_moy,inv2.mean, inv2.cov
POSTHOOK: type: QUERY
POSTHOOK: Input: default@date_dim
POSTHOOK: Input: default@inventory
POSTHOOK: Input: default@item
POSTHOOK: Input: default@warehouse
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 12 <- Map 11 (PARTITION-LEVEL SORT, 31), Map 16 (PARTITION-LEVEL SORT, 31)
        Reducer 13 <- Map 17 (PARTITION-LEVEL SORT, 31), Reducer 12 (PARTITION-LEVEL SORT, 31)
        Reducer 14 <- Map 18 (PARTITION-LEVEL SORT, 31), Reducer 13 (PARTITION-LEVEL SORT, 31)
        Reducer 15 <- Reducer 14 (GROUP, 31)
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 31), Map 8 (PARTITION-LEVEL SORT, 31)
        Reducer 3 <- Map 9 (PARTITION-LEVEL SORT, 31), Reducer 2 (PARTITION-LEVEL SORT, 31)
        Reducer 4 <- Map 10 (PARTITION-LEVEL SORT, 31), Reducer 3 (PARTITION-LEVEL SORT, 31)
        Reducer 5 <- Reducer 4 (GROUP, 31)
        Reducer 6 <- Reducer 15 (PARTITION-LEVEL SORT, 31), Reducer 5 (PARTITION-LEVEL SORT, 31)
        Reducer 7 <- Reducer 6 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: inventory
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: (inv_date_sk is not null and inv_item_sk is not null and inv_warehouse_sk is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Select Operator
                      expressions: inv_date_sk (type: int), inv_item_sk (type: int), inv_quantity_on_hand (type: int), inv_warehouse_sk (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col1 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col1 (type: int)
                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                        value expressions: _col0 (type: int), _col2 (type: int), _col3 (type: int)
            Execution mode: vectorized
        Map 10 
            Map Operator Tree:
                TableScan
                  alias: date_dim
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: ((d_moy = 3) and (d_year = 1999) and d_date_sk is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Select Operator
                      expressions: d_date_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Execution mode: vectorized
        Map 11 
            Map Operator Tree:
                TableScan
                  alias: inventory
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: (inv_date_sk is not null and inv_item_sk is not null and inv_warehouse_sk is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Select Operator
                      expressions: inv_date_sk (type: int), inv_item_sk (type: int), inv_quantity_on_hand (type: int), inv_warehouse_sk (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col1 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col1 (type: int)
                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                        value expressions: _col0 (type: int), _col2 (type: int), _col3 (type: int)
            Execution mode: vectorized
        Map 16 
            Map Operator Tree:
                TableScan
                  alias: item
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: i_item_sk is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Select Operator
                      expressions: i_item_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Execution mode: vectorized
        Map 17 
            Map Operator Tree:
                TableScan
                  alias: warehouse
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: w_warehouse_sk is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Select Operator
                      expressions: w_warehouse_sk (type: int), w_warehouse_name (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                        value expressions: _col1 (type: string)
            Execution mode: vectorized
        Map 18 
            Map Operator Tree:
                TableScan
                  alias: date_dim
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: ((d_moy = 4) and (d_year = 1999) and d_date_sk is not null) (type: boolean)
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Select Operator
                      expressions: d_date_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Execution mode: vectorized
        Map 8 
            Map Operator Tree:
                TableScan
                  alias: item
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: i_item_sk is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Select Operator
                      expressions: i_item_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Execution mode: vectorized
        Map 9 
            Map Operator Tree:
                TableScan
                  alias: warehouse
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: w_warehouse_sk is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Select Operator
                      expressions: w_warehouse_sk (type: int), w_warehouse_name (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                        value expressions: _col1 (type: string)
            Execution mode: vectorized
        Reducer 12 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col3 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col3 (type: int)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col0 (type: int), _col2 (type: int), _col4 (type: int)
        Reducer 13 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col3 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col2, _col4, _col5, _col6
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col2 (type: int), _col4 (type: int), _col5 (type: int), _col6 (type: string)
        Reducer 14 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col2, _col4, _col5, _col6
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Select Operator
                  expressions: _col6 (type: string), _col5 (type: int), _col4 (type: int), _col2 (type: int), UDFToDouble(_col2) (type: double), (UDFToDouble(_col2) * UDFToDouble(_col2)) (type: double)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Group By Operator
                    aggregations: sum(_col3), count(_col3), sum(_col5), sum(_col4)
                    keys: _col1 (type: int), _col2 (type: int), _col0 (type: string)
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: string)
                      sort order: +++
                      Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: string)
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      value expressions: _col3 (type: bigint), _col4 (type: bigint), _col5 (type: double), _col6 (type: double)
        Reducer 15 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), sum(VALUE._col2), sum(VALUE._col3)
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: double), _col6 (type: double)
                  outputColumnNames: _col0, _col1, _col3, _col4, _col5, _col6
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: CASE WHEN (((UDFToDouble(_col3) / _col4) = 0)) THEN (false) ELSE (((power(((_col5 - ((_col6 * _col6) / _col4)) / CASE WHEN ((_col4 = 1L)) THEN (null) ELSE ((_col4 - 1)) END), 0.5) / (UDFToDouble(_col3) / _col4)) > 1.0D)) END (type: boolean)
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: int), (UDFToDouble(_col3) / _col4) (type: double), CASE WHEN (((UDFToDouble(_col3) / _col4) = 0)) THEN (null) ELSE ((power(((_col5 - ((_col6 * _col6) / _col4)) / CASE WHEN ((_col4 = 1L)) THEN (null) ELSE ((_col4 - 1)) END), 0.5) / (UDFToDouble(_col3) / _col4))) END (type: double)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int)
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                        value expressions: _col2 (type: double), _col3 (type: double)
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col2, _col3, _col4
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col3 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col3 (type: int)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col0 (type: int), _col2 (type: int), _col4 (type: int)
        Reducer 3 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col3 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col2, _col4, _col5, _col6
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col2 (type: int), _col4 (type: int), _col5 (type: int), _col6 (type: string)
        Reducer 4 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col2, _col4, _col5, _col6
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Select Operator
                  expressions: _col6 (type: string), _col5 (type: int), _col4 (type: int), _col2 (type: int), UDFToDouble(_col2) (type: double), (UDFToDouble(_col2) * UDFToDouble(_col2)) (type: double)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Group By Operator
                    aggregations: sum(_col3), count(_col3), sum(_col5), sum(_col4)
                    keys: _col1 (type: int), _col2 (type: int), _col0 (type: string)
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: string)
                      sort order: +++
                      Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: string)
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      value expressions: _col3 (type: bigint), _col4 (type: bigint), _col5 (type: double), _col6 (type: double)
        Reducer 5 
            Execution mode: vectorized
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), sum(VALUE._col2), sum(VALUE._col3)
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: double), _col6 (type: double)
                  outputColumnNames: _col0, _col1, _col3, _col4, _col5, _col6
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Filter Operator
                    predicate: CASE WHEN (((UDFToDouble(_col3) / _col4) = 0)) THEN (false) ELSE (((power(((_col5 - ((_col6 * _col6) / _col4)) / CASE WHEN ((_col4 = 1L)) THEN (null) ELSE ((_col4 - 1)) END), 0.5) / (UDFToDouble(_col3) / _col4)) > 1.0D)) END (type: boolean)
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: int), (UDFToDouble(_col3) / _col4) (type: double), CASE WHEN (((UDFToDouble(_col3) / _col4) = 0)) THEN (null) ELSE ((power(((_col5 - ((_col6 * _col6) / _col4)) / CASE WHEN ((_col4 = 1L)) THEN (null) ELSE ((_col4 - 1)) END), 0.5) / (UDFToDouble(_col3) / _col4))) END (type: double)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int)
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
                        Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                        value expressions: _col2 (type: double), _col3 (type: double)
        Reducer 6 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: int), _col1 (type: int)
                  1 _col0 (type: int), _col1 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: double), _col3 (type: double), _col6 (type: double), _col7 (type: double)
                  sort order: ++++++
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col4 (type: int), _col5 (type: int)
        Reducer 7 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int), 3 (type: int), KEY.reducesinkkey2 (type: double), KEY.reducesinkkey3 (type: double), VALUE._col0 (type: int), VALUE._col1 (type: int), 4 (type: int), KEY.reducesinkkey4 (type: double), KEY.reducesinkkey5 (type: double)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                File Output Operator
                  compressed: true
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: EXPLAIN
WITH test AS
(SELECT inv_date_sk , inv_item_sk ,inv_quantity_on_hand FROM inventory
  UNION ALL
 SELECT inv_date_sk , inv_item_sk ,inv_quantity_on_hand FROM inventory)
SELECT inv_date_sk , inv_item_sk ,inv_quantity_on_hand FROM test SORT BY inv_quantity_on_hand
PREHOOK: type: QUERY
PREHOOK: Input: default@inventory
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: EXPLAIN
WITH test AS
(SELECT inv_date_sk , inv_item_sk ,inv_quantity_on_hand FROM inventory
  UNION ALL
 SELECT inv_date_sk , inv_item_sk ,inv_quantity_on_hand FROM inventory)
SELECT inv_date_sk , inv_item_sk ,inv_quantity_on_hand FROM test SORT BY inv_quantity_on_hand
POSTHOOK: type: QUERY
POSTHOOK: Input: default@inventory
POSTHOOK: Output: hdfs://### HDFS PATH ###
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 31), Map 1 (PARTITION-LEVEL SORT, 31)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: inventory
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  Select Operator
                    expressions: inv_date_sk (type: int), inv_item_sk (type: int), inv_quantity_on_hand (type: int)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col2 (type: int)
                      sort order: +
                      Statistics: Num rows: 2 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                      value expressions: _col0 (type: int), _col1 (type: int)
            Execution mode: vectorized
        Reducer 2 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), VALUE._col1 (type: int), KEY.reducesinkkey0 (type: int)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 2 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                File Output Operator
                  compressed: true
                  Statistics: Num rows: 2 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: DROP TABLE inv
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@inv
PREHOOK: Output: default@inv
POSTHOOK: query: DROP TABLE inv
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@inv
POSTHOOK: Output: default@inv
PREHOOK: query: DROP TABLE inventory
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@inventory
PREHOOK: Output: default@inventory
POSTHOOK: query: DROP TABLE inventory
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@inventory
POSTHOOK: Output: default@inventory
PREHOOK: query: DROP TABLE item
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@item
PREHOOK: Output: default@item
POSTHOOK: query: DROP TABLE item
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@item
POSTHOOK: Output: default@item
PREHOOK: query: DROP TABLE warehouse
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@warehouse
PREHOOK: Output: default@warehouse
POSTHOOK: query: DROP TABLE warehouse
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@warehouse
POSTHOOK: Output: default@warehouse
PREHOOK: query: DROP TABLE date_dim
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@date_dim
PREHOOK: Output: default@date_dim
POSTHOOK: query: DROP TABLE date_dim
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@date_dim
POSTHOOK: Output: default@date_dim
