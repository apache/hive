PREHOOK: query: CREATE TABLE src_4(
  key STRING, 
  value STRING
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@src_4
POSTHOOK: query: CREATE TABLE src_4(
  key STRING, 
  value STRING
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@src_4
RUN: Stage-0:DDL
PREHOOK: query: CREATE TABLE src_5( 
  key STRING, 
  value STRING
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@src_5
POSTHOOK: query: CREATE TABLE src_5( 
  key STRING, 
  value STRING
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@src_5
RUN: Stage-0:DDL
PREHOOK: query: explain
from src b 
INSERT OVERWRITE TABLE src_4 
  select * 
  where b.key in 
   (select a.key 
    from src a 
    where b.value = a.value and a.key > '9'
   ) 
INSERT OVERWRITE TABLE src_5 
  select *  
  where b.key not in  ( select key from src s1 where s1.key > '2') 
  order by key
PREHOOK: type: QUERY
POSTHOOK: query: explain
from src b 
INSERT OVERWRITE TABLE src_4 
  select * 
  where b.key in 
   (select a.key 
    from src a 
    where b.value = a.value and a.key > '9'
   ) 
INSERT OVERWRITE TABLE src_5 
  select *  
  where b.key not in  ( select key from src s1 where s1.key > '2') 
  order by key
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-4 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-5, Stage-4
  Stage-0 depends on stages: Stage-3
  Stage-6 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-3
  Stage-7 depends on stages: Stage-1
  Stage-5 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  File Output Operator
                    compressed: false
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-4
    Spark
      Edges:
        Reducer 10 <- Map 9 (GROUP)
        Reducer 11 <- Map 1 (GROUP PARTITION-LEVEL SORT), Reducer 10 (GROUP PARTITION-LEVEL SORT)
        Reducer 7 <- Map 6 (GROUP PARTITION-LEVEL SORT), Reducer 11 (GROUP PARTITION-LEVEL SORT)
        Reducer 8 <- Reducer 7 (GROUP SORT)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  Reduce Output Operator
                    sort order: 
                    value expressions: key (type: string), value (type: string)
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: s1
                  Filter Operator
                    predicate: (key > '2') (type: boolean)
                    Select Operator
                      expressions: key (type: string)
                      outputColumnNames: _col0
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
        Map 9 
            Map Operator Tree:
                TableScan
                  alias: s1
                  Filter Operator
                    predicate: ((key > '2') and key is null) (type: boolean)
                    Select Operator
                      Group By Operator
                        aggregations: count()
                        mode: hash
                        outputColumnNames: _col0
                        Reduce Output Operator
                          sort order: 
                          value expressions: _col0 (type: bigint)
        Reducer 10 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Filter Operator
                  predicate: (_col0 = 0) (type: boolean)
                  Select Operator
                    expressions: 0 (type: bigint)
                    outputColumnNames: _col0
                    Group By Operator
                      keys: _col0 (type: bigint)
                      mode: hash
                      outputColumnNames: _col0
                      Reduce Output Operator
                        sort order: 
        Reducer 11 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                condition expressions:
                  0 {VALUE._col0} {VALUE._col1}
                  1 
                outputColumnNames: _col0, _col1
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  value expressions: _col1 (type: string)
        Reducer 7 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Outer Join0 to 1
                condition expressions:
                  0 {KEY.reducesinkkey0} {VALUE._col0}
                  1 {KEY.reducesinkkey0}
                outputColumnNames: _col0, _col1, _col5
                Filter Operator
                  predicate: _col5 is null (type: boolean)
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string)
                    outputColumnNames: _col0, _col1
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      value expressions: _col1 (type: string)
        Reducer 8 
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string)
                outputColumnNames: _col0, _col1
                File Output Operator
                  compressed: false
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: default.src_5

  Stage: Stage-3
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src_4

  Stage: Stage-6
    Stats-Aggr Operator

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src_5

  Stage: Stage-7
    Stats-Aggr Operator

  Stage: Stage-5
    Spark
      Edges:
        Reducer 5 <- Map 2 (GROUP PARTITION-LEVEL SORT), Map 4 (GROUP PARTITION-LEVEL SORT)
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  Reduce Output Operator
                    key expressions: key (type: string), value (type: string)
                    sort order: ++
                    Map-reduce partition columns: key (type: string), value (type: string)
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: a
                  Filter Operator
                    predicate: (((key > '9') and key is not null) and value is not null) (type: boolean)
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Group By Operator
                        keys: _col0 (type: string), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: string)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
        Reducer 5 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                condition expressions:
                  0 {KEY.reducesinkkey0} {KEY.reducesinkkey1}
                  1 
                outputColumnNames: _col0, _col1
                Select Operator
                  expressions: _col0 (type: string), _col1 (type: string)
                  outputColumnNames: _col0, _col1
                  File Output Operator
                    compressed: false
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: default.src_4

PREHOOK: query: from src b 
INSERT OVERWRITE TABLE src_4 
  select * 
  where b.key in 
   (select a.key 
    from src a 
    where b.value = a.value and a.key > '9'
   ) 
INSERT OVERWRITE TABLE src_5 
  select *  
  where b.key not in  ( select key from src s1 where s1.key > '2') 
  order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@src_4
PREHOOK: Output: default@src_5
[Error 30017]: Skipping stats aggregation by error org.apache.hadoop.hive.ql.metadata.HiveException: [Error 30015]: Stats aggregator of type counter cannot be connected to
[Error 30017]: Skipping stats aggregation by error org.apache.hadoop.hive.ql.metadata.HiveException: [Error 30015]: Stats aggregator of type counter cannot be connected to
POSTHOOK: query: from src b 
INSERT OVERWRITE TABLE src_4 
  select * 
  where b.key in 
   (select a.key 
    from src a 
    where b.value = a.value and a.key > '9'
   ) 
INSERT OVERWRITE TABLE src_5 
  select *  
  where b.key not in  ( select key from src s1 where s1.key > '2') 
  order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@src_4
POSTHOOK: Output: default@src_5
POSTHOOK: Lineage: src_4.key EXPRESSION [(src)b.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: src_4.value EXPRESSION [(src)b.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: src_5.key EXPRESSION [(src)b.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: src_5.value EXPRESSION [(src)b.FieldSchema(name:value, type:string, comment:default), ]
RUN: Stage-2:MAPRED
RUN: Stage-4:MAPRED
RUN: Stage-5:MAPRED
RUN: Stage-3:DEPENDENCY_COLLECTION
RUN: Stage-0:MOVE
RUN: Stage-1:MOVE
RUN: Stage-6:STATS
RUN: Stage-7:STATS
PREHOOK: query: select * from src_4
PREHOOK: type: QUERY
PREHOOK: Input: default@src_4
#### A masked pattern was here ####
POSTHOOK: query: select * from src_4
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src_4
#### A masked pattern was here ####
90	val_90
90	val_90
90	val_90
92	val_92
95	val_95
95	val_95
96	val_96
97	val_97
97	val_97
98	val_98
98	val_98
PREHOOK: query: select * from src_5
PREHOOK: type: QUERY
PREHOOK: Input: default@src_5
#### A masked pattern was here ####
POSTHOOK: query: select * from src_5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src_5
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_10
100	val_100
100	val_100
103	val_103
103	val_103
104	val_104
104	val_104
105	val_105
11	val_11
111	val_111
113	val_113
113	val_113
114	val_114
116	val_116
118	val_118
118	val_118
119	val_119
119	val_119
119	val_119
12	val_12
12	val_12
120	val_120
120	val_120
125	val_125
125	val_125
126	val_126
128	val_128
128	val_128
128	val_128
129	val_129
129	val_129
131	val_131
133	val_133
134	val_134
134	val_134
136	val_136
137	val_137
137	val_137
138	val_138
138	val_138
138	val_138
138	val_138
143	val_143
145	val_145
146	val_146
146	val_146
149	val_149
149	val_149
15	val_15
15	val_15
150	val_150
152	val_152
152	val_152
153	val_153
155	val_155
156	val_156
157	val_157
158	val_158
160	val_160
162	val_162
163	val_163
164	val_164
164	val_164
165	val_165
165	val_165
166	val_166
167	val_167
167	val_167
167	val_167
168	val_168
169	val_169
169	val_169
169	val_169
169	val_169
17	val_17
170	val_170
172	val_172
172	val_172
174	val_174
174	val_174
175	val_175
175	val_175
176	val_176
176	val_176
177	val_177
178	val_178
179	val_179
179	val_179
18	val_18
18	val_18
180	val_180
181	val_181
183	val_183
186	val_186
187	val_187
187	val_187
187	val_187
189	val_189
19	val_19
190	val_190
191	val_191
191	val_191
192	val_192
193	val_193
193	val_193
193	val_193
194	val_194
195	val_195
195	val_195
196	val_196
197	val_197
197	val_197
199	val_199
199	val_199
199	val_199
2	val_2
PREHOOK: query: explain
from src b 
INSERT OVERWRITE TABLE src_4 
  select * 
  where b.key in 
   (select a.key 
    from src a 
    where b.value = a.value and a.key > '9'
   ) 
INSERT OVERWRITE TABLE src_5 
  select *  
  where b.key not in  ( select key from src s1 where s1.key > '2') 
  order by key
PREHOOK: type: QUERY
POSTHOOK: query: explain
from src b 
INSERT OVERWRITE TABLE src_4 
  select * 
  where b.key in 
   (select a.key 
    from src a 
    where b.value = a.value and a.key > '9'
   ) 
INSERT OVERWRITE TABLE src_5 
  select *  
  where b.key not in  ( select key from src s1 where s1.key > '2') 
  order by key
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-4 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-5, Stage-4
  Stage-0 depends on stages: Stage-3
  Stage-6 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-3
  Stage-7 depends on stages: Stage-1
  Stage-5 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  File Output Operator
                    compressed: false
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-4
    Spark
      Edges:
        Reducer 10 <- Map 9 (GROUP)
        Reducer 11 <- Map 1 (GROUP PARTITION-LEVEL SORT), Reducer 10 (GROUP PARTITION-LEVEL SORT)
        Reducer 7 <- Map 6 (GROUP PARTITION-LEVEL SORT), Reducer 11 (GROUP PARTITION-LEVEL SORT)
        Reducer 8 <- Reducer 7 (GROUP SORT)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  Reduce Output Operator
                    sort order: 
                    value expressions: key (type: string), value (type: string)
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: s1
                  Filter Operator
                    predicate: (key > '2') (type: boolean)
                    Select Operator
                      expressions: key (type: string)
                      outputColumnNames: _col0
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
        Map 9 
            Map Operator Tree:
                TableScan
                  alias: s1
                  Filter Operator
                    predicate: ((key > '2') and key is null) (type: boolean)
                    Select Operator
                      Group By Operator
                        aggregations: count()
                        mode: hash
                        outputColumnNames: _col0
                        Reduce Output Operator
                          sort order: 
                          value expressions: _col0 (type: bigint)
        Reducer 10 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Filter Operator
                  predicate: (_col0 = 0) (type: boolean)
                  Select Operator
                    expressions: 0 (type: bigint)
                    outputColumnNames: _col0
                    Group By Operator
                      keys: _col0 (type: bigint)
                      mode: hash
                      outputColumnNames: _col0
                      Reduce Output Operator
                        sort order: 
        Reducer 11 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                condition expressions:
                  0 {VALUE._col0} {VALUE._col1}
                  1 
                outputColumnNames: _col0, _col1
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  value expressions: _col1 (type: string)
        Reducer 7 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Outer Join0 to 1
                condition expressions:
                  0 {KEY.reducesinkkey0} {VALUE._col0}
                  1 {KEY.reducesinkkey0}
                outputColumnNames: _col0, _col1, _col5
                Filter Operator
                  predicate: _col5 is null (type: boolean)
                  Select Operator
                    expressions: _col0 (type: string), _col1 (type: string)
                    outputColumnNames: _col0, _col1
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      value expressions: _col1 (type: string)
        Reducer 8 
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string)
                outputColumnNames: _col0, _col1
                File Output Operator
                  compressed: false
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: default.src_5

  Stage: Stage-3
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src_4

  Stage: Stage-6
    Stats-Aggr Operator

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src_5

  Stage: Stage-7
    Stats-Aggr Operator

  Stage: Stage-5
    Spark
      Edges:
        Reducer 5 <- Map 2 (GROUP PARTITION-LEVEL SORT), Map 4 (GROUP PARTITION-LEVEL SORT)
#### A masked pattern was here ####
      Vertices:
        Map 2 
            Map Operator Tree:
                TableScan
                  Reduce Output Operator
                    key expressions: key (type: string), value (type: string)
                    sort order: ++
                    Map-reduce partition columns: key (type: string), value (type: string)
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: a
                  Filter Operator
                    predicate: (((key > '9') and key is not null) and value is not null) (type: boolean)
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Group By Operator
                        keys: _col0 (type: string), _col1 (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Reduce Output Operator
                          key expressions: _col0 (type: string), _col1 (type: string)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
        Reducer 5 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                condition expressions:
                  0 {KEY.reducesinkkey0} {KEY.reducesinkkey1}
                  1 
                outputColumnNames: _col0, _col1
                Select Operator
                  expressions: _col0 (type: string), _col1 (type: string)
                  outputColumnNames: _col0, _col1
                  File Output Operator
                    compressed: false
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: default.src_4

PREHOOK: query: from src b 
INSERT OVERWRITE TABLE src_4 
  select * 
  where b.key in 
   (select a.key 
    from src a 
    where b.value = a.value and a.key > '9'
   ) 
INSERT OVERWRITE TABLE src_5 
  select *  
  where b.key not in  ( select key from src s1 where s1.key > '2') 
  order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@src_4
PREHOOK: Output: default@src_5
[Error 30017]: Skipping stats aggregation by error org.apache.hadoop.hive.ql.metadata.HiveException: [Error 30015]: Stats aggregator of type counter cannot be connected to
[Error 30017]: Skipping stats aggregation by error org.apache.hadoop.hive.ql.metadata.HiveException: [Error 30015]: Stats aggregator of type counter cannot be connected to
POSTHOOK: query: from src b 
INSERT OVERWRITE TABLE src_4 
  select * 
  where b.key in 
   (select a.key 
    from src a 
    where b.value = a.value and a.key > '9'
   ) 
INSERT OVERWRITE TABLE src_5 
  select *  
  where b.key not in  ( select key from src s1 where s1.key > '2') 
  order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@src_4
POSTHOOK: Output: default@src_5
POSTHOOK: Lineage: src_4.key EXPRESSION [(src)b.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: src_4.value EXPRESSION [(src)b.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: src_5.key EXPRESSION [(src)b.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: src_5.value EXPRESSION [(src)b.FieldSchema(name:value, type:string, comment:default), ]
RUN: Stage-2:MAPRED
RUN: Stage-4:MAPRED
RUN: Stage-5:MAPRED
RUN: Stage-3:DEPENDENCY_COLLECTION
RUN: Stage-0:MOVE
RUN: Stage-1:MOVE
RUN: Stage-6:STATS
RUN: Stage-7:STATS
PREHOOK: query: select * from src_4
PREHOOK: type: QUERY
PREHOOK: Input: default@src_4
#### A masked pattern was here ####
POSTHOOK: query: select * from src_4
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src_4
#### A masked pattern was here ####
90	val_90
90	val_90
90	val_90
92	val_92
95	val_95
95	val_95
96	val_96
97	val_97
97	val_97
98	val_98
98	val_98
PREHOOK: query: select * from src_5
PREHOOK: type: QUERY
PREHOOK: Input: default@src_5
#### A masked pattern was here ####
POSTHOOK: query: select * from src_5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src_5
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_10
100	val_100
100	val_100
103	val_103
103	val_103
104	val_104
104	val_104
105	val_105
11	val_11
111	val_111
113	val_113
113	val_113
114	val_114
116	val_116
118	val_118
118	val_118
119	val_119
119	val_119
119	val_119
12	val_12
12	val_12
120	val_120
120	val_120
125	val_125
125	val_125
126	val_126
128	val_128
128	val_128
128	val_128
129	val_129
129	val_129
131	val_131
133	val_133
134	val_134
134	val_134
136	val_136
137	val_137
137	val_137
138	val_138
138	val_138
138	val_138
138	val_138
143	val_143
145	val_145
146	val_146
146	val_146
149	val_149
149	val_149
15	val_15
15	val_15
150	val_150
152	val_152
152	val_152
153	val_153
155	val_155
156	val_156
157	val_157
158	val_158
160	val_160
162	val_162
163	val_163
164	val_164
164	val_164
165	val_165
165	val_165
166	val_166
167	val_167
167	val_167
167	val_167
168	val_168
169	val_169
169	val_169
169	val_169
169	val_169
17	val_17
170	val_170
172	val_172
172	val_172
174	val_174
174	val_174
175	val_175
175	val_175
176	val_176
176	val_176
177	val_177
178	val_178
179	val_179
179	val_179
18	val_18
18	val_18
180	val_180
181	val_181
183	val_183
186	val_186
187	val_187
187	val_187
187	val_187
189	val_189
19	val_19
190	val_190
191	val_191
191	val_191
192	val_192
193	val_193
193	val_193
193	val_193
194	val_194
195	val_195
195	val_195
196	val_196
197	val_197
197	val_197
199	val_199
199	val_199
199	val_199
2	val_2
