PREHOOK: query: CREATE TABLE T1(key STRING, val STRING) STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@T1
POSTHOOK: query: CREATE TABLE T1(key STRING, val STRING) STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@T1
PREHOOK: query: CREATE TABLE T2(key STRING, val STRING) STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@T2
POSTHOOK: query: CREATE TABLE T2(key STRING, val STRING) STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@T2
PREHOOK: query: CREATE TABLE T3(key STRING, val STRING) STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@T3
POSTHOOK: query: CREATE TABLE T3(key STRING, val STRING) STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@T3
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/T1.txt' INTO TABLE T1
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@t1
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/T1.txt' INTO TABLE T1
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@t1
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/T2.txt' INTO TABLE T2
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@t2
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/T2.txt' INTO TABLE T2
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@t2
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/T3.txt' INTO TABLE T3
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@t3
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/T3.txt' INTO TABLE T3
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@t3
PREHOOK: query: EXPLAIN FROM T1 a JOIN src c ON c.key+1=a.key
SELECT a.key, a.val, c.key
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN FROM T1 a JOIN src c ON c.key+1=a.key
SELECT a.key, a.val, c.key
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 3 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: UDFToDouble(key) is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: UDFToDouble(key) (type: double)
                      sort order: +
                      Map-reduce partition columns: UDFToDouble(key) (type: double)
                      Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                      value expressions: key (type: string), val (type: string)
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (key + 1) is not null (type: boolean)
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: (key + 1) (type: double)
                      sort order: +
                      Map-reduce partition columns: (key + 1) (type: double)
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: key (type: string)
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 UDFToDouble(key) (type: double)
                  1 (key + 1) (type: double)
                outputColumnNames: _col0, _col1, _col5
                Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: string), _col1 (type: string), _col5 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: EXPLAIN FROM T1 a JOIN src c ON c.key+1=a.key
SELECT /*+ STREAMTABLE(a) */ a.key, a.val, c.key
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN FROM T1 a JOIN src c ON c.key+1=a.key
SELECT /*+ STREAMTABLE(a) */ a.key, a.val, c.key
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 3 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: UDFToDouble(key) is not null (type: boolean)
                    Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: UDFToDouble(key) (type: double)
                      sort order: +
                      Map-reduce partition columns: UDFToDouble(key) (type: double)
                      Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                      value expressions: key (type: string), val (type: string)
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (key + 1) is not null (type: boolean)
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: (key + 1) (type: double)
                      sort order: +
                      Map-reduce partition columns: (key + 1) (type: double)
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: key (type: string)
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 UDFToDouble(key) (type: double)
                  1 (key + 1) (type: double)
                outputColumnNames: _col0, _col1, _col5
                Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: string), _col1 (type: string), _col5 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM T1 a JOIN src c ON c.key+1=a.key
SELECT a.key, a.val, c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Input: default@t1
#### A masked pattern was here ####
POSTHOOK: query: FROM T1 a JOIN src c ON c.key+1=a.key
SELECT a.key, a.val, c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Input: default@t1
#### A masked pattern was here ####
1	11	0
1	11	0
1	11	0
3	13	2
PREHOOK: query: FROM T1 a JOIN src c ON c.key+1=a.key
SELECT /*+ STREAMTABLE(a) */ a.key, a.val, c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Input: default@t1
#### A masked pattern was here ####
POSTHOOK: query: FROM T1 a JOIN src c ON c.key+1=a.key
SELECT /*+ STREAMTABLE(a) */ a.key, a.val, c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Input: default@t1
#### A masked pattern was here ####
1	11	0
1	11	0
1	11	0
3	13	2
PREHOOK: query: EXPLAIN FROM T1 a
  LEFT OUTER JOIN T2 b ON (b.key=a.key)
  RIGHT OUTER JOIN T3 c ON (c.val = a.val)
SELECT a.key, b.key, a.val, c.val
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN FROM T1 a
  LEFT OUTER JOIN T2 b ON (b.key=a.key)
  RIGHT OUTER JOIN T3 c ON (c.val = a.val)
SELECT a.key, b.key, a.val, c.val
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Map 5 (PARTITION-LEVEL SORT, 2), Reducer 2 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: string)
                    sort order: +
                    Map-reduce partition columns: key (type: string)
                    Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                    value expressions: val (type: string)
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: string)
                    sort order: +
                    Map-reduce partition columns: key (type: string)
                    Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: val (type: string)
                    sort order: +
                    Map-reduce partition columns: val (type: string)
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 key (type: string)
                  1 key (type: string)
                outputColumnNames: _col0, _col1, _col5
                Statistics: Num rows: 1 Data size: 33 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col1 (type: string)
                  Statistics: Num rows: 1 Data size: 33 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: string), _col5 (type: string)
        Reducer 3 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 _col1 (type: string)
                  1 val (type: string)
                outputColumnNames: _col0, _col1, _col5, _col11
                Statistics: Num rows: 1 Data size: 36 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: string), _col5 (type: string), _col1 (type: string), _col11 (type: string)
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num rows: 1 Data size: 36 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 36 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: EXPLAIN FROM T1 a
  LEFT OUTER JOIN T2 b ON (b.key=a.key)
  RIGHT OUTER JOIN T3 c ON (c.val = a.val)
SELECT /*+ STREAMTABLE(a) */ a.key, b.key, a.val, c.val
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN FROM T1 a
  LEFT OUTER JOIN T2 b ON (b.key=a.key)
  RIGHT OUTER JOIN T3 c ON (c.val = a.val)
SELECT /*+ STREAMTABLE(a) */ a.key, b.key, a.val, c.val
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Map 5 (PARTITION-LEVEL SORT, 2), Reducer 2 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: string)
                    sort order: +
                    Map-reduce partition columns: key (type: string)
                    Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                    value expressions: val (type: string)
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: string)
                    sort order: +
                    Map-reduce partition columns: key (type: string)
                    Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: val (type: string)
                    sort order: +
                    Map-reduce partition columns: val (type: string)
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 key (type: string)
                  1 key (type: string)
                outputColumnNames: _col0, _col1, _col5
                Statistics: Num rows: 1 Data size: 33 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col1 (type: string)
                  Statistics: Num rows: 1 Data size: 33 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: string), _col5 (type: string)
        Reducer 3 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Right Outer Join 0 to 1
                keys:
                  0 _col1 (type: string)
                  1 val (type: string)
                outputColumnNames: _col0, _col1, _col5, _col11
                Statistics: Num rows: 1 Data size: 36 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: string), _col5 (type: string), _col1 (type: string), _col11 (type: string)
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num rows: 1 Data size: 36 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 36 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM T1 a
  LEFT OUTER JOIN T2 b ON (b.key=a.key)
  RIGHT OUTER JOIN T3 c ON (c.val = a.val)
SELECT a.key, b.key, a.val, c.val
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
PREHOOK: Input: default@t2
PREHOOK: Input: default@t3
#### A masked pattern was here ####
POSTHOOK: query: FROM T1 a
  LEFT OUTER JOIN T2 b ON (b.key=a.key)
  RIGHT OUTER JOIN T3 c ON (c.val = a.val)
SELECT a.key, b.key, a.val, c.val
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
POSTHOOK: Input: default@t2
POSTHOOK: Input: default@t3
#### A masked pattern was here ####
2	2	12	12
7	NULL	17	17
NULL	NULL	NULL	14
NULL	NULL	NULL	16
PREHOOK: query: FROM T1 a
  LEFT OUTER JOIN T2 b ON (b.key=a.key)
  RIGHT OUTER JOIN T3 c ON (c.val = a.val)
SELECT /*+ STREAMTABLE(a) */ a.key, b.key, a.val, c.val
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
PREHOOK: Input: default@t2
PREHOOK: Input: default@t3
#### A masked pattern was here ####
POSTHOOK: query: FROM T1 a
  LEFT OUTER JOIN T2 b ON (b.key=a.key)
  RIGHT OUTER JOIN T3 c ON (c.val = a.val)
SELECT /*+ STREAMTABLE(a) */ a.key, b.key, a.val, c.val
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
POSTHOOK: Input: default@t2
POSTHOOK: Input: default@t3
#### A masked pattern was here ####
2	2	12	12
7	NULL	17	17
NULL	NULL	NULL	14
NULL	NULL	NULL	16
PREHOOK: query: EXPLAIN FROM UNIQUEJOIN
  PRESERVE T1 a (a.key, a.val),
  PRESERVE T2 b (b.key, b.val),
  PRESERVE T3 c (c.key, c.val)
SELECT a.key, b.key, c.key
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN FROM UNIQUEJOIN
  PRESERVE T1 a (a.key, a.val),
  PRESERVE T2 b (b.key, b.val),
  PRESERVE T3 c (c.key, c.val)
SELECT a.key, b.key, c.key
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 3 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: string), val (type: string)
                    sort order: ++
                    Map-reduce partition columns: key (type: string), val (type: string)
                    Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: string), val (type: string)
                    sort order: ++
                    Map-reduce partition columns: key (type: string), val (type: string)
                    Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: string), val (type: string)
                    sort order: ++
                    Map-reduce partition columns: key (type: string), val (type: string)
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Unique Join 0 to 0
                     Unique Join 0 to 0
                     Unique Join 0 to 0
                keys:
                  0 key (type: string), val (type: string)
                  1 key (type: string), val (type: string)
                  2 key (type: string), val (type: string)
                outputColumnNames: _col0, _col5, _col10
                Statistics: Num rows: 2 Data size: 66 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: string), _col5 (type: string), _col10 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 2 Data size: 66 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 2 Data size: 66 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: EXPLAIN FROM UNIQUEJOIN
  PRESERVE T1 a (a.key, a.val),
  PRESERVE T2 b (b.key, b.val),
  PRESERVE T3 c (c.key, c.val)
SELECT /*+ STREAMTABLE(b) */ a.key, b.key, c.key
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN FROM UNIQUEJOIN
  PRESERVE T1 a (a.key, a.val),
  PRESERVE T2 b (b.key, b.val),
  PRESERVE T3 c (c.key, c.val)
SELECT /*+ STREAMTABLE(b) */ a.key, b.key, c.key
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 3 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: string), val (type: string)
                    sort order: ++
                    Map-reduce partition columns: key (type: string), val (type: string)
                    Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: string), val (type: string)
                    sort order: ++
                    Map-reduce partition columns: key (type: string), val (type: string)
                    Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: key (type: string), val (type: string)
                    sort order: ++
                    Map-reduce partition columns: key (type: string), val (type: string)
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Unique Join 0 to 0
                     Unique Join 0 to 0
                     Unique Join 0 to 0
                keys:
                  0 key (type: string), val (type: string)
                  1 key (type: string), val (type: string)
                  2 key (type: string), val (type: string)
                outputColumnNames: _col0, _col5, _col10
                Statistics: Num rows: 2 Data size: 66 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: string), _col5 (type: string), _col10 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 2 Data size: 66 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 2 Data size: 66 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM UNIQUEJOIN
  PRESERVE T1 a (a.key, a.val),
  PRESERVE T2 b (b.key, b.val),
  PRESERVE T3 c (c.key, c.val)
SELECT a.key, b.key, c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
PREHOOK: Input: default@t2
PREHOOK: Input: default@t3
#### A masked pattern was here ####
POSTHOOK: query: FROM UNIQUEJOIN
  PRESERVE T1 a (a.key, a.val),
  PRESERVE T2 b (b.key, b.val),
  PRESERVE T3 c (c.key, c.val)
SELECT a.key, b.key, c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
POSTHOOK: Input: default@t2
POSTHOOK: Input: default@t3
#### A masked pattern was here ####
1	NULL	NULL
2	NULL	2
3	3	NULL
7	NULL	7
8	8	NULL
8	8	NULL
8	NULL	NULL
NULL	2	NULL
NULL	4	4
NULL	5	NULL
NULL	NULL	6
PREHOOK: query: FROM UNIQUEJOIN
  PRESERVE T1 a (a.key, a.val),
  PRESERVE T2 b (b.key, b.val),
  PRESERVE T3 c (c.key, c.val)
SELECT /*+ STREAMTABLE(b) */ a.key, b.key, c.key
PREHOOK: type: QUERY
PREHOOK: Input: default@t1
PREHOOK: Input: default@t2
PREHOOK: Input: default@t3
#### A masked pattern was here ####
POSTHOOK: query: FROM UNIQUEJOIN
  PRESERVE T1 a (a.key, a.val),
  PRESERVE T2 b (b.key, b.val),
  PRESERVE T3 c (c.key, c.val)
SELECT /*+ STREAMTABLE(b) */ a.key, b.key, c.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@t1
POSTHOOK: Input: default@t2
POSTHOOK: Input: default@t3
#### A masked pattern was here ####
1	NULL	NULL
2	NULL	2
3	3	NULL
7	NULL	7
8	8	NULL
8	8	NULL
8	NULL	NULL
NULL	2	NULL
NULL	4	4
NULL	5	NULL
NULL	NULL	6
