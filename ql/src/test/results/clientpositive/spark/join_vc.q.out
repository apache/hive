PREHOOK: query: explain select t3.BLOCK__OFFSET__INSIDE__FILE,t3.key,t3.value from src t1 join src t2 on t1.key = t2.key join src t3 on t2.value = t3.value order by t3.BLOCK__OFFSET__INSIDE__FILE,t3.key,t3.value limit 3
PREHOOK: type: QUERY
POSTHOOK: query: explain select t3.BLOCK__OFFSET__INSIDE__FILE,t3.key,t3.value from src t1 join src t2 on t1.key = t2.key join src t3 on t2.value = t3.value order by t3.BLOCK__OFFSET__INSIDE__FILE,t3.key,t3.value limit 3
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 5 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Map 6 (PARTITION-LEVEL SORT, 2), Reducer 2 (PARTITION-LEVEL SORT, 2)
        Reducer 4 <- Reducer 3 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (key is not null and value is not null) (type: boolean)
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: string)
            Execution mode: vectorized
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: t3
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: value is not null (type: boolean)
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), value (type: string), BLOCK__OFFSET__INSIDE__FILE (type: bigint)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col1 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col1 (type: string)
                        Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: string), _col2 (type: bigint)
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: string)
                  1 _col0 (type: string)
                outputColumnNames: _col2
                Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col2 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col2 (type: string)
                  Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col2 (type: string)
                  1 _col1 (type: string)
                outputColumnNames: _col3, _col4, _col5
                Statistics: Num rows: 605 Data size: 6427 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col5 (type: bigint), _col3 (type: string), _col4 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 605 Data size: 6427 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: bigint), _col1 (type: string), _col2 (type: string)
                    sort order: +++
                    Statistics: Num rows: 605 Data size: 6427 Basic stats: COMPLETE Column stats: NONE
                    TopN Hash Memory Usage: 0.1
        Reducer 4 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: bigint), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 605 Data size: 6427 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 3
                  Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 3
      Processor Tree:
        ListSink

PREHOOK: query: select t3.BLOCK__OFFSET__INSIDE__FILE,t3.key,t3.value from src t1 join src t2 on t1.key = t2.key join src t3 on t2.value = t3.value order by t3.BLOCK__OFFSET__INSIDE__FILE,t3.key,t3.value limit 3
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select t3.BLOCK__OFFSET__INSIDE__FILE,t3.key,t3.value from src t1 join src t2 on t1.key = t2.key join src t3 on t2.value = t3.value order by t3.BLOCK__OFFSET__INSIDE__FILE,t3.key,t3.value limit 3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
0	238	val_238
0	238	val_238
0	238	val_238
PREHOOK: query: explain
select t2.BLOCK__OFFSET__INSIDE__FILE
from src t1 join src t2 on t1.key = t2.key where t1.key < 100 order by t2.BLOCK__OFFSET__INSIDE__FILE
PREHOOK: type: QUERY
POSTHOOK: query: explain
select t2.BLOCK__OFFSET__INSIDE__FILE
from src t1 join src t2 on t1.key = t2.key where t1.key < 100 order by t2.BLOCK__OFFSET__INSIDE__FILE
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Reducer 2 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (UDFToDouble(key) < 100.0D) (type: boolean)
                    Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (UDFToDouble(key) < 100.0D) (type: boolean)
                    Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), BLOCK__OFFSET__INSIDE__FILE (type: bigint)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: bigint)
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: string)
                  1 _col0 (type: string)
                outputColumnNames: _col2
                Statistics: Num rows: 182 Data size: 1939 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col2 (type: bigint)
                  outputColumnNames: _col0
                  Statistics: Num rows: 182 Data size: 1939 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: bigint)
                    sort order: +
                    Statistics: Num rows: 182 Data size: 1939 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: bigint)
                outputColumnNames: _col0
                Statistics: Num rows: 182 Data size: 1939 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 182 Data size: 1939 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select t2.BLOCK__OFFSET__INSIDE__FILE
from src t1 join src t2 on t1.key = t2.key where t1.key < 100 order by t2.BLOCK__OFFSET__INSIDE__FILE
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select t2.BLOCK__OFFSET__INSIDE__FILE
from src t1 join src t2 on t1.key = t2.key where t1.key < 100 order by t2.BLOCK__OFFSET__INSIDE__FILE
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
1024
1118
1176
1198
12
1208
1208
1218
1238
1238
1238
1440
1462
1462
1592
1674
1674
1720
1720
1754
1754
1872
1872
1906
1906
1916
1972
1972
198
2030
2030
2088
2088
2088
2216
2226
2226
2308
2308
2330
2400
2400
2458
2458
2612
2622
2632
2632
2632
2652
2770
2770
2792
2792
2802
2802
2802
2824
2846
3060
3060
3060
3128
3128
3138
3138
3138
3160
3160
3170
3192
328
328
3298
3298
3368
3378
3378
3388
34
3494
3516
3538
3538
3548
3570
3592
3794
3794
3794
386
386
3864
3864
3864
396
4004
4012
4012
4012
4058
4068
4186
4304
4304
4304
4362
4362
4540
4540
4540
4548
4548
4548
4594
4594
4640
4640
4640
5070
5070
5284
5284
5306
5306
5340
5340
5398
5514
5514
5572
5572
5606
5606
5616
5626
5626
5744
5744
5744
5802
5802
910
92
92
968
968
968
