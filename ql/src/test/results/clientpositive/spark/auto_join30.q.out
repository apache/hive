PREHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
POSTHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      Edges:
        Reducer 5 <- Map 4 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col1 (type: string)
                        sort order: +
                        Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: string)
        Reducer 5 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Reducer 2 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                  outputColumnNames: _col2, _col3
                  input vertices:
                    1 Reducer 5
                  Statistics: Num rows: 275 Data size: 2921 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: sum(hash(_col2,_col3))
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint)
        Reducer 3 
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM 
(SELECT src.* FROM src sort by key) x
JOIN 
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: FROM 
(SELECT src.* FROM src sort by key) x
JOIN 
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
103231310608
PREHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
POSTHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      Edges:
        Reducer 5 <- Map 4 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col1 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string)
        Reducer 5 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Reducer 2 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Left Outer Join0 to 1
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                  outputColumnNames: _col2, _col3
                  input vertices:
                    1 Reducer 5
                  Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: sum(hash(_col2,_col3))
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint)
        Reducer 3 
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM 
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN 
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: FROM 
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN 
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
103231310608
PREHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
POSTHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)

  Stage: Stage-1
    Spark
      Edges:
        Reducer 4 <- Map 3 (PARTITION-LEVEL SORT, 2)
        Reducer 5 <- Reducer 4 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col1 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string)
        Reducer 4 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Right Outer Join0 to 1
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                  outputColumnNames: _col2, _col3
                  input vertices:
                    0 Reducer 2
                  Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: sum(hash(_col2,_col3))
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint)
        Reducer 5 
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM 
(SELECT src.* FROM src sort by key) x
RIGHT OUTER JOIN 
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: FROM 
(SELECT src.* FROM src sort by key) x
RIGHT OUTER JOIN 
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
103231310608
PREHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
POSTHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      Edges:
        Reducer 5 <- Map 4 (PARTITION-LEVEL SORT, 2)
        Reducer 7 <- Map 4 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col1 (type: string)
                        sort order: +
                        Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: string)
        Reducer 5 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)
        Reducer 7 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Reducer 2 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                       Inner Join 0 to 2
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)
                  outputColumnNames: _col2, _col3
                  input vertices:
                    1 Reducer 5
                    2 Reducer 7
                  Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: sum(hash(_col2,_col3))
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint)
        Reducer 3 
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM
(SELECT src.* FROM src sort by key) x
JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: FROM
(SELECT src.* FROM src sort by key) x
JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
348019368476
PREHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
POSTHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      Edges:
        Reducer 5 <- Map 4 (PARTITION-LEVEL SORT, 2)
        Reducer 7 <- Map 4 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col1 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string)
        Reducer 5 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)
        Reducer 7 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Reducer 2 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                       Left Outer Join0 to 2
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)
                  outputColumnNames: _col2, _col3
                  input vertices:
                    1 Reducer 5
                    2 Reducer 7
                  Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: sum(hash(_col2,_col3))
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint)
        Reducer 3 
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM
(SELECT src.* FROM src sort by key) x
JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: FROM
(SELECT src.* FROM src sort by key) x
JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
348019368476
PREHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
POSTHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      Edges:
        Reducer 5 <- Map 4 (PARTITION-LEVEL SORT, 2)
        Reducer 7 <- Map 4 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col1 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string)
        Reducer 5 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)
        Reducer 7 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Reducer 2 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Left Outer Join0 to 1
                       Left Outer Join0 to 2
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)
                  outputColumnNames: _col2, _col3
                  input vertices:
                    1 Reducer 5
                    2 Reducer 7
                  Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: sum(hash(_col2,_col3))
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint)
        Reducer 3 
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: FROM
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
348019368476
PREHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
POSTHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2)
        Reducer 4 <- Map 3 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col1 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string)
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)
        Reducer 4 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)

  Stage: Stage-1
    Spark
      Edges:
        Reducer 6 <- Map 5 (PARTITION-LEVEL SORT, 2)
        Reducer 7 <- Reducer 6 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col1 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string)
        Reducer 6 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Left Outer Join0 to 1
                       Right Outer Join0 to 2
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)
                  outputColumnNames: _col2, _col3
                  input vertices:
                    0 Reducer 2
                    1 Reducer 4
                  Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: sum(hash(_col2,_col3))
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint)
        Reducer 7 
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: FROM
(SELECT src.* FROM src sort by key) x
LEFT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
348019368476
PREHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
POSTHOOK: query: explain
FROM 
(SELECT src.* FROM src sort by key) x
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2)
        Reducer 4 <- Map 3 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string)
                    outputColumnNames: _col0
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col1 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string)
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)
        Reducer 4 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Spark HashTable Sink Operator
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)

  Stage: Stage-1
    Spark
      Edges:
        Reducer 6 <- Map 5 (PARTITION-LEVEL SORT, 2)
        Reducer 7 <- Reducer 6 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col1 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: string)
        Reducer 6 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Right Outer Join0 to 1
                       Right Outer Join0 to 2
                  keys:
                    0 _col0 (type: string)
                    1 _col0 (type: string)
                    2 _col0 (type: string)
                  outputColumnNames: _col2, _col3
                  input vertices:
                    0 Reducer 2
                    1 Reducer 4
                  Statistics: Num rows: 1100 Data size: 11686 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    aggregations: sum(hash(_col2,_col3))
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col0 (type: bigint)
        Reducer 7 
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: FROM
(SELECT src.* FROM src sort by key) x
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: FROM
(SELECT src.* FROM src sort by key) x
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Y
ON (x.key = Y.key)
RIGHT OUTER JOIN
(SELECT src.* FROM src sort by value) Z
ON (x.key = Z.key)
select sum(hash(Y.key,Y.value))
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
348019368476
