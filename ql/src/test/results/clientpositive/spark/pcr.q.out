PREHOOK: query: drop table pcr_t1
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table pcr_t1
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table pcr_t2
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table pcr_t2
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table pcr_t3
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table pcr_t3
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table pcr_t1 (key int, value string) partitioned by (ds string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@pcr_t1
POSTHOOK: query: create table pcr_t1 (key int, value string) partitioned by (ds string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@pcr_t1
PREHOOK: query: insert overwrite table pcr_t1 partition (ds='2000-04-08') select * from src where key < 20 order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@pcr_t1@ds=2000-04-08
POSTHOOK: query: insert overwrite table pcr_t1 partition (ds='2000-04-08') select * from src where key < 20 order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@pcr_t1@ds=2000-04-08
POSTHOOK: Lineage: pcr_t1 PARTITION(ds=2000-04-08).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: pcr_t1 PARTITION(ds=2000-04-08).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: insert overwrite table pcr_t1 partition (ds='2000-04-09') select * from src where key < 20 order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@pcr_t1@ds=2000-04-09
POSTHOOK: query: insert overwrite table pcr_t1 partition (ds='2000-04-09') select * from src where key < 20 order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@pcr_t1@ds=2000-04-09
POSTHOOK: Lineage: pcr_t1 PARTITION(ds=2000-04-09).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: pcr_t1 PARTITION(ds=2000-04-09).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: insert overwrite table pcr_t1 partition (ds='2000-04-10') select * from src where key < 20 order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@pcr_t1@ds=2000-04-10
POSTHOOK: query: insert overwrite table pcr_t1 partition (ds='2000-04-10') select * from src where key < 20 order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@pcr_t1@ds=2000-04-10
POSTHOOK: Lineage: pcr_t1 PARTITION(ds=2000-04-10).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: pcr_t1 PARTITION(ds=2000-04-10).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain extended select key, value, ds from pcr_t1 where ds<='2000-04-09' and key<5 order by key, ds
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value, ds from pcr_t1 where ds<='2000-04-09' and key<5 order by key, ds
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               ds
      TOK_WHERE
         and
            <=
               TOK_TABLE_OR_COL
                  ds
               '2000-04-09'
            <
               TOK_TABLE_OR_COL
                  key
               5
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               ds


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (key < 5) (type: boolean)
                    Statistics: Num rows: 13 Data size: 104 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string), ds (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 13 Data size: 104 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col2 (type: string)
                        sort order: ++
                        Statistics: Num rows: 13 Data size: 104 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col1 (type: string)
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 13 Data size: 104 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 13 Data size: 104 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types int:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value, ds from pcr_t1 where ds<='2000-04-09' and key<5 order by key, ds
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
POSTHOOK: query: select key, value, ds from pcr_t1 where ds<='2000-04-09' and key<5 order by key, ds
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
0	val_0	2000-04-08
0	val_0	2000-04-08
0	val_0	2000-04-08
0	val_0	2000-04-09
0	val_0	2000-04-09
0	val_0	2000-04-09
2	val_2	2000-04-08
2	val_2	2000-04-09
4	val_4	2000-04-08
4	val_4	2000-04-09
PREHOOK: query: explain extended select key, value from pcr_t1 where ds<='2000-04-09' or key<5 order by key
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value from pcr_t1 where ds<='2000-04-09' or key<5 order by key
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
      TOK_WHERE
         or
            <=
               TOK_TABLE_OR_COL
                  ds
               '2000-04-09'
            <
               TOK_TABLE_OR_COL
                  key
               5
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 60 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((ds <= '2000-04-09') or (key < 5)) (type: boolean)
                    Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col1 (type: string)
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-10
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
              /pcr_t1/ds=2000-04-10 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types int:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value from pcr_t1 where ds<='2000-04-09' or key<5 order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
PREHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
POSTHOOK: query: select key, value from pcr_t1 where ds<='2000-04-09' or key<5 order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
POSTHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
2	val_2
2	val_2
2	val_2
4	val_4
4	val_4
4	val_4
5	val_5
5	val_5
5	val_5
5	val_5
5	val_5
5	val_5
8	val_8
8	val_8
9	val_9
9	val_9
10	val_10
10	val_10
11	val_11
11	val_11
12	val_12
12	val_12
12	val_12
12	val_12
15	val_15
15	val_15
15	val_15
15	val_15
17	val_17
17	val_17
18	val_18
18	val_18
18	val_18
18	val_18
19	val_19
19	val_19
PREHOOK: query: explain extended select key, value, ds from pcr_t1 where ds<='2000-04-09' and key<5 and value != 'val_2' order by key, ds
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value, ds from pcr_t1 where ds<='2000-04-09' and key<5 and value != 'val_2' order by key, ds
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               ds
      TOK_WHERE
         and
            and
               <=
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-09'
               <
                  TOK_TABLE_OR_COL
                     key
                  5
            !=
               TOK_TABLE_OR_COL
                  value
               'val_2'
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               ds


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((key < 5) and (value <> 'val_2')) (type: boolean)
                    Statistics: Num rows: 13 Data size: 104 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string), ds (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 13 Data size: 104 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col2 (type: string)
                        sort order: ++
                        Statistics: Num rows: 13 Data size: 104 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col1 (type: string)
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 13 Data size: 104 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 13 Data size: 104 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types int:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value, ds from pcr_t1 where ds<='2000-04-09' and key<5 and value != 'val_2' order by key, ds
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
POSTHOOK: query: select key, value, ds from pcr_t1 where ds<='2000-04-09' and key<5 and value != 'val_2' order by key, ds
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
0	val_0	2000-04-08
0	val_0	2000-04-08
0	val_0	2000-04-08
0	val_0	2000-04-09
0	val_0	2000-04-09
0	val_0	2000-04-09
4	val_4	2000-04-08
4	val_4	2000-04-09
PREHOOK: query: explain extended
select key, value, ds from pcr_t1
where (ds < '2000-04-09' and key < 5) or (ds > '2000-04-09' and value == 'val_5') order by key, ds
PREHOOK: type: QUERY
POSTHOOK: query: explain extended
select key, value, ds from pcr_t1
where (ds < '2000-04-09' and key < 5) or (ds > '2000-04-09' and value == 'val_5') order by key, ds
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               ds
      TOK_WHERE
         or
            and
               <
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-09'
               <
                  TOK_TABLE_OR_COL
                     key
                  5
            and
               >
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-09'
               ==
                  TOK_TABLE_OR_COL
                     value
                  'val_5'
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               ds


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (((ds < '2000-04-09') and (key < 5)) or ((ds > '2000-04-09') and (value = 'val_5'))) (type: boolean)
                    Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string), ds (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col2 (type: string)
                        sort order: ++
                        Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col1 (type: string)
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-10
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-10 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types int:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value, ds from pcr_t1
where (ds < '2000-04-09' and key < 5) or (ds > '2000-04-09' and value == 'val_5') order by key, ds
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
POSTHOOK: query: select key, value, ds from pcr_t1
where (ds < '2000-04-09' and key < 5) or (ds > '2000-04-09' and value == 'val_5') order by key, ds
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
0	val_0	2000-04-08
0	val_0	2000-04-08
0	val_0	2000-04-08
2	val_2	2000-04-08
4	val_4	2000-04-08
5	val_5	2000-04-10
5	val_5	2000-04-10
5	val_5	2000-04-10
PREHOOK: query: explain extended
select key, value, ds from pcr_t1
where (ds < '2000-04-10' and key < 5) or (ds > '2000-04-08' and value == 'val_5') order by key, ds
PREHOOK: type: QUERY
POSTHOOK: query: explain extended
select key, value, ds from pcr_t1
where (ds < '2000-04-10' and key < 5) or (ds > '2000-04-08' and value == 'val_5') order by key, ds
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               ds
      TOK_WHERE
         or
            and
               <
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-10'
               <
                  TOK_TABLE_OR_COL
                     key
                  5
            and
               >
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-08'
               ==
                  TOK_TABLE_OR_COL
                     value
                  'val_5'
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               ds


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 60 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (((ds < '2000-04-10') and (key < 5)) or ((ds > '2000-04-08') and (value = 'val_5'))) (type: boolean)
                    Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string), ds (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col2 (type: string)
                        sort order: ++
                        Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col1 (type: string)
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-10
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
              /pcr_t1/ds=2000-04-10 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 16 Data size: 128 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types int:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value, ds from pcr_t1
where (ds < '2000-04-10' and key < 5) or (ds > '2000-04-08' and value == 'val_5') order by key, ds
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
PREHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
POSTHOOK: query: select key, value, ds from pcr_t1
where (ds < '2000-04-10' and key < 5) or (ds > '2000-04-08' and value == 'val_5') order by key, ds
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
POSTHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
0	val_0	2000-04-08
0	val_0	2000-04-08
0	val_0	2000-04-08
0	val_0	2000-04-09
0	val_0	2000-04-09
0	val_0	2000-04-09
2	val_2	2000-04-08
2	val_2	2000-04-09
4	val_4	2000-04-08
4	val_4	2000-04-09
5	val_5	2000-04-09
5	val_5	2000-04-09
5	val_5	2000-04-09
5	val_5	2000-04-10
5	val_5	2000-04-10
5	val_5	2000-04-10
PREHOOK: query: explain extended
select key, value, ds from pcr_t1
where (ds < '2000-04-10' or key < 5) and (ds > '2000-04-08' or value == 'val_5') order by key, ds
PREHOOK: type: QUERY
POSTHOOK: query: explain extended
select key, value, ds from pcr_t1
where (ds < '2000-04-10' or key < 5) and (ds > '2000-04-08' or value == 'val_5') order by key, ds
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               ds
      TOK_WHERE
         and
            or
               <
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-10'
               <
                  TOK_TABLE_OR_COL
                     key
                  5
            or
               >
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-08'
               ==
                  TOK_TABLE_OR_COL
                     value
                  'val_5'
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               ds


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 60 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (((ds < '2000-04-10') or (key < 5)) and ((ds > '2000-04-08') or (value = 'val_5'))) (type: boolean)
                    Statistics: Num rows: 33 Data size: 264 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string), ds (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 33 Data size: 264 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col2 (type: string)
                        sort order: ++
                        Statistics: Num rows: 33 Data size: 264 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col1 (type: string)
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-10
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
              /pcr_t1/ds=2000-04-10 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 33 Data size: 264 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 33 Data size: 264 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types int:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value, ds from pcr_t1
where (ds < '2000-04-10' or key < 5) and (ds > '2000-04-08' or value == 'val_5') order by key, ds
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
PREHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
POSTHOOK: query: select key, value, ds from pcr_t1
where (ds < '2000-04-10' or key < 5) and (ds > '2000-04-08' or value == 'val_5') order by key, ds
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
POSTHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
0	val_0	2000-04-09
0	val_0	2000-04-09
0	val_0	2000-04-09
0	val_0	2000-04-10
0	val_0	2000-04-10
0	val_0	2000-04-10
2	val_2	2000-04-09
2	val_2	2000-04-10
4	val_4	2000-04-09
4	val_4	2000-04-10
5	val_5	2000-04-08
5	val_5	2000-04-08
5	val_5	2000-04-08
5	val_5	2000-04-09
5	val_5	2000-04-09
5	val_5	2000-04-09
8	val_8	2000-04-09
9	val_9	2000-04-09
10	val_10	2000-04-09
11	val_11	2000-04-09
12	val_12	2000-04-09
12	val_12	2000-04-09
15	val_15	2000-04-09
15	val_15	2000-04-09
17	val_17	2000-04-09
18	val_18	2000-04-09
18	val_18	2000-04-09
19	val_19	2000-04-09
PREHOOK: query: explain extended select key, value from pcr_t1 where (ds='2000-04-08' or ds='2000-04-09') and key=14 order by key, value
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value from pcr_t1 where (ds='2000-04-08' or ds='2000-04-09') and key=14 order by key, value
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
      TOK_WHERE
         and
            or
               =
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-08'
               =
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-09'
            =
               TOK_TABLE_OR_COL
                  key
               14
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               value


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (key = 14) (type: boolean)
                    Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: value (type: string)
                      outputColumnNames: _col1
                      Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: 14 (type: int), _col1 (type: string)
                        sort order: ++
                        Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: 14 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types int:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value from pcr_t1 where (ds='2000-04-08' or ds='2000-04-09') and key=14 order by key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
POSTHOOK: query: select key, value from pcr_t1 where (ds='2000-04-08' or ds='2000-04-09') and key=14 order by key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
PREHOOK: query: explain extended select key, value from pcr_t1 where ds='2000-04-08' or ds='2000-04-09' order by key, value
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value from pcr_t1 where ds='2000-04-08' or ds='2000-04-09' order by key, value
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
      TOK_WHERE
         or
            =
               TOK_TABLE_OR_COL
                  ds
               '2000-04-08'
            =
               TOK_TABLE_OR_COL
                  ds
               '2000-04-09'
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               value


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: key (type: int), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int), _col1 (type: string)
                      sort order: ++
                      Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                      tag: -1
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types int:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value from pcr_t1 where ds='2000-04-08' or ds='2000-04-09' order by key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
POSTHOOK: query: select key, value from pcr_t1 where ds='2000-04-08' or ds='2000-04-09' order by key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
2	val_2
2	val_2
4	val_4
4	val_4
5	val_5
5	val_5
5	val_5
5	val_5
5	val_5
5	val_5
8	val_8
8	val_8
9	val_9
9	val_9
10	val_10
10	val_10
11	val_11
11	val_11
12	val_12
12	val_12
12	val_12
12	val_12
15	val_15
15	val_15
15	val_15
15	val_15
17	val_17
17	val_17
18	val_18
18	val_18
18	val_18
18	val_18
19	val_19
19	val_19
PREHOOK: query: explain extended select key, value from pcr_t1 where ds>='2000-04-08' or ds<'2000-04-10' order by key, value
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value from pcr_t1 where ds>='2000-04-08' or ds<'2000-04-10' order by key, value
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
      TOK_WHERE
         or
            >=
               TOK_TABLE_OR_COL
                  ds
               '2000-04-08'
            <
               TOK_TABLE_OR_COL
                  ds
               '2000-04-10'
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               value


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 60 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: key (type: int), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 60 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int), _col1 (type: string)
                      sort order: ++
                      Statistics: Num rows: 60 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                      tag: -1
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-10
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
              /pcr_t1/ds=2000-04-10 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 60 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 60 Data size: 480 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types int:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value from pcr_t1 where ds>='2000-04-08' or ds<'2000-04-10' order by key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
PREHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
POSTHOOK: query: select key, value from pcr_t1 where ds>='2000-04-08' or ds<'2000-04-10' order by key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
POSTHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
0	val_0
2	val_2
2	val_2
2	val_2
4	val_4
4	val_4
4	val_4
5	val_5
5	val_5
5	val_5
5	val_5
5	val_5
5	val_5
5	val_5
5	val_5
5	val_5
8	val_8
8	val_8
8	val_8
9	val_9
9	val_9
9	val_9
10	val_10
10	val_10
10	val_10
11	val_11
11	val_11
11	val_11
12	val_12
12	val_12
12	val_12
12	val_12
12	val_12
12	val_12
15	val_15
15	val_15
15	val_15
15	val_15
15	val_15
15	val_15
17	val_17
17	val_17
17	val_17
18	val_18
18	val_18
18	val_18
18	val_18
18	val_18
18	val_18
19	val_19
19	val_19
19	val_19
PREHOOK: query: explain extended select key, value, ds from pcr_t1 where (ds='2000-04-08' and key=1) or (ds='2000-04-09' and key=2) order by key, value, ds
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value, ds from pcr_t1 where (ds='2000-04-08' and key=1) or (ds='2000-04-09' and key=2) order by key, value, ds
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               ds
      TOK_WHERE
         or
            and
               =
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-08'
               =
                  TOK_TABLE_OR_COL
                     key
                  1
            and
               =
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-09'
               =
                  TOK_TABLE_OR_COL
                     key
                  2
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               value
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               ds


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (((ds = '2000-04-08') and (key = 1)) or ((ds = '2000-04-09') and (key = 2))) (type: boolean)
                    Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string), ds (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
                        sort order: +++
                        Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 40 Data size: 320 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types int:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value, ds from pcr_t1 where (ds='2000-04-08' and key=1) or (ds='2000-04-09' and key=2) order by key, value, ds
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
POSTHOOK: query: select key, value, ds from pcr_t1 where (ds='2000-04-08' and key=1) or (ds='2000-04-09' and key=2) order by key, value, ds
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
2	val_2	2000-04-09
PREHOOK: query: explain extended select * from pcr_t1 t1 join pcr_t1 t2 on t1.key=t2.key and t1.ds='2000-04-08' and t2.ds='2000-04-08' order by t1.key
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select * from pcr_t1 t1 join pcr_t1 t2 on t1.key=t2.key and t1.ds='2000-04-08' and t2.ds='2000-04-08' order by t1.key
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_JOIN
         TOK_TABREF
            TOK_TABNAME
               pcr_t1
            t1
         TOK_TABREF
            TOK_TABNAME
               pcr_t1
            t2
         and
            and
               =
                  .
                     TOK_TABLE_OR_COL
                        t1
                     key
                  .
                     TOK_TABLE_OR_COL
                        t2
                     key
               =
                  .
                     TOK_TABLE_OR_COL
                        t1
                     ds
                  '2000-04-08'
            =
               .
                  TOK_TABLE_OR_COL
                     t2
                  ds
               '2000-04-08'
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            .
               TOK_TABLE_OR_COL
                  t1
               key


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Reducer 2 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                      tag: 0
                      value expressions: value (type: string)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [t1]
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                      tag: 1
                      value expressions: value (type: string)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [t2]
        Reducer 2 
            Needs Tagging: true
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 key (type: int)
                  1 key (type: int)
                outputColumnNames: _col0, _col1, _col6, _col7
                Statistics: Num rows: 11 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: string), _col6 (type: int), _col7 (type: string)
                  outputColumnNames: _col0, _col1, _col3, _col4
                  Statistics: Num rows: 11 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: int)
                    sort order: +
                    Statistics: Num rows: 11 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                    tag: -1
                    value expressions: _col1 (type: string), _col3 (type: int), _col4 (type: string)
                    auto parallelism: false
        Reducer 3 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string), '2000-04-08' (type: string), VALUE._col2 (type: int), VALUE._col3 (type: string), '2000-04-08' (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 11 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 11 Data size: 88 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2,_col3,_col4,_col5
                        columns.types int:string:string:int:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from pcr_t1 t1 join pcr_t1 t2 on t1.key=t2.key and t1.ds='2000-04-08' and t2.ds='2000-04-08' order by t1.key
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
#### A masked pattern was here ####
POSTHOOK: query: select * from pcr_t1 t1 join pcr_t1 t2 on t1.key=t2.key and t1.ds='2000-04-08' and t2.ds='2000-04-08' order by t1.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
#### A masked pattern was here ####
0	val_0	2000-04-08	0	val_0	2000-04-08
0	val_0	2000-04-08	0	val_0	2000-04-08
0	val_0	2000-04-08	0	val_0	2000-04-08
0	val_0	2000-04-08	0	val_0	2000-04-08
0	val_0	2000-04-08	0	val_0	2000-04-08
0	val_0	2000-04-08	0	val_0	2000-04-08
0	val_0	2000-04-08	0	val_0	2000-04-08
0	val_0	2000-04-08	0	val_0	2000-04-08
0	val_0	2000-04-08	0	val_0	2000-04-08
2	val_2	2000-04-08	2	val_2	2000-04-08
4	val_4	2000-04-08	4	val_4	2000-04-08
5	val_5	2000-04-08	5	val_5	2000-04-08
5	val_5	2000-04-08	5	val_5	2000-04-08
5	val_5	2000-04-08	5	val_5	2000-04-08
5	val_5	2000-04-08	5	val_5	2000-04-08
5	val_5	2000-04-08	5	val_5	2000-04-08
5	val_5	2000-04-08	5	val_5	2000-04-08
5	val_5	2000-04-08	5	val_5	2000-04-08
5	val_5	2000-04-08	5	val_5	2000-04-08
5	val_5	2000-04-08	5	val_5	2000-04-08
8	val_8	2000-04-08	8	val_8	2000-04-08
9	val_9	2000-04-08	9	val_9	2000-04-08
10	val_10	2000-04-08	10	val_10	2000-04-08
11	val_11	2000-04-08	11	val_11	2000-04-08
12	val_12	2000-04-08	12	val_12	2000-04-08
12	val_12	2000-04-08	12	val_12	2000-04-08
12	val_12	2000-04-08	12	val_12	2000-04-08
12	val_12	2000-04-08	12	val_12	2000-04-08
15	val_15	2000-04-08	15	val_15	2000-04-08
15	val_15	2000-04-08	15	val_15	2000-04-08
15	val_15	2000-04-08	15	val_15	2000-04-08
15	val_15	2000-04-08	15	val_15	2000-04-08
17	val_17	2000-04-08	17	val_17	2000-04-08
18	val_18	2000-04-08	18	val_18	2000-04-08
18	val_18	2000-04-08	18	val_18	2000-04-08
18	val_18	2000-04-08	18	val_18	2000-04-08
18	val_18	2000-04-08	18	val_18	2000-04-08
19	val_19	2000-04-08	19	val_19	2000-04-08
PREHOOK: query: explain extended select * from pcr_t1 t1 join pcr_t1 t2 on t1.key=t2.key and t1.ds='2000-04-08' and t2.ds='2000-04-09' order by t1.key
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select * from pcr_t1 t1 join pcr_t1 t2 on t1.key=t2.key and t1.ds='2000-04-08' and t2.ds='2000-04-09' order by t1.key
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_JOIN
         TOK_TABREF
            TOK_TABNAME
               pcr_t1
            t1
         TOK_TABREF
            TOK_TABNAME
               pcr_t1
            t2
         and
            and
               =
                  .
                     TOK_TABLE_OR_COL
                        t1
                     key
                  .
                     TOK_TABLE_OR_COL
                        t2
                     key
               =
                  .
                     TOK_TABLE_OR_COL
                        t1
                     ds
                  '2000-04-08'
            =
               .
                  TOK_TABLE_OR_COL
                     t2
                  ds
               '2000-04-09'
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            .
               TOK_TABLE_OR_COL
                  t1
               key


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)
        Reducer 3 <- Reducer 2 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: t1
                  Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                      tag: 0
                      value expressions: value (type: string)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [t1]
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: t2
                  Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                      tag: 1
                      value expressions: value (type: string)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-09 [t2]
        Reducer 2 
            Needs Tagging: true
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 key (type: int)
                  1 key (type: int)
                outputColumnNames: _col0, _col1, _col6, _col7
                Statistics: Num rows: 11 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: string), _col6 (type: int), _col7 (type: string)
                  outputColumnNames: _col0, _col1, _col3, _col4
                  Statistics: Num rows: 11 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: int)
                    sort order: +
                    Statistics: Num rows: 11 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                    tag: -1
                    value expressions: _col1 (type: string), _col3 (type: int), _col4 (type: string)
                    auto parallelism: false
        Reducer 3 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string), '2000-04-08' (type: string), VALUE._col2 (type: int), VALUE._col3 (type: string), '2000-04-09' (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                Statistics: Num rows: 11 Data size: 88 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 11 Data size: 88 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2,_col3,_col4,_col5
                        columns.types int:string:string:int:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from pcr_t1 t1 join pcr_t1 t2 on t1.key=t2.key and t1.ds='2000-04-08' and t2.ds='2000-04-09' order by t1.key
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
POSTHOOK: query: select * from pcr_t1 t1 join pcr_t1 t2 on t1.key=t2.key and t1.ds='2000-04-08' and t2.ds='2000-04-09' order by t1.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
#### A masked pattern was here ####
0	val_0	2000-04-08	0	val_0	2000-04-09
0	val_0	2000-04-08	0	val_0	2000-04-09
0	val_0	2000-04-08	0	val_0	2000-04-09
0	val_0	2000-04-08	0	val_0	2000-04-09
0	val_0	2000-04-08	0	val_0	2000-04-09
0	val_0	2000-04-08	0	val_0	2000-04-09
0	val_0	2000-04-08	0	val_0	2000-04-09
0	val_0	2000-04-08	0	val_0	2000-04-09
0	val_0	2000-04-08	0	val_0	2000-04-09
2	val_2	2000-04-08	2	val_2	2000-04-09
4	val_4	2000-04-08	4	val_4	2000-04-09
5	val_5	2000-04-08	5	val_5	2000-04-09
5	val_5	2000-04-08	5	val_5	2000-04-09
5	val_5	2000-04-08	5	val_5	2000-04-09
5	val_5	2000-04-08	5	val_5	2000-04-09
5	val_5	2000-04-08	5	val_5	2000-04-09
5	val_5	2000-04-08	5	val_5	2000-04-09
5	val_5	2000-04-08	5	val_5	2000-04-09
5	val_5	2000-04-08	5	val_5	2000-04-09
5	val_5	2000-04-08	5	val_5	2000-04-09
8	val_8	2000-04-08	8	val_8	2000-04-09
9	val_9	2000-04-08	9	val_9	2000-04-09
10	val_10	2000-04-08	10	val_10	2000-04-09
11	val_11	2000-04-08	11	val_11	2000-04-09
12	val_12	2000-04-08	12	val_12	2000-04-09
12	val_12	2000-04-08	12	val_12	2000-04-09
12	val_12	2000-04-08	12	val_12	2000-04-09
12	val_12	2000-04-08	12	val_12	2000-04-09
15	val_15	2000-04-08	15	val_15	2000-04-09
15	val_15	2000-04-08	15	val_15	2000-04-09
15	val_15	2000-04-08	15	val_15	2000-04-09
15	val_15	2000-04-08	15	val_15	2000-04-09
17	val_17	2000-04-08	17	val_17	2000-04-09
18	val_18	2000-04-08	18	val_18	2000-04-09
18	val_18	2000-04-08	18	val_18	2000-04-09
18	val_18	2000-04-08	18	val_18	2000-04-09
18	val_18	2000-04-08	18	val_18	2000-04-09
19	val_19	2000-04-08	19	val_19	2000-04-09
PREHOOK: query: insert overwrite table pcr_t1 partition (ds='2000-04-11') select * from src where key < 20 order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@pcr_t1@ds=2000-04-11
POSTHOOK: query: insert overwrite table pcr_t1 partition (ds='2000-04-11') select * from src where key < 20 order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@pcr_t1@ds=2000-04-11
POSTHOOK: Lineage: pcr_t1 PARTITION(ds=2000-04-11).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: pcr_t1 PARTITION(ds=2000-04-11).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain extended select key, value, ds from pcr_t1 where (ds>'2000-04-08' and ds<'2000-04-11') or (ds>='2000-04-08' and ds<='2000-04-11' and key=2) order by key, value, ds
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value, ds from pcr_t1 where (ds>'2000-04-08' and ds<'2000-04-11') or (ds>='2000-04-08' and ds<='2000-04-11' and key=2) order by key, value, ds
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               ds
      TOK_WHERE
         or
            and
               >
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-08'
               <
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-11'
            and
               and
                  >=
                     TOK_TABLE_OR_COL
                        ds
                     '2000-04-08'
                  <=
                     TOK_TABLE_OR_COL
                        ds
                     '2000-04-11'
               =
                  TOK_TABLE_OR_COL
                     key
                  2
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               value
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               ds


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 80 Data size: 640 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (((ds > '2000-04-08') and (ds < '2000-04-11')) or (key = 2)) (type: boolean)
                    Statistics: Num rows: 48 Data size: 384 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string), ds (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 48 Data size: 384 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
                        sort order: +++
                        Statistics: Num rows: 48 Data size: 384 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-10
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-11
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-11
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
              /pcr_t1/ds=2000-04-10 [pcr_t1]
              /pcr_t1/ds=2000-04-11 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 48 Data size: 384 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 48 Data size: 384 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types int:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value, ds from pcr_t1 where (ds>'2000-04-08' and ds<'2000-04-11') or (ds>='2000-04-08' and ds<='2000-04-11' and key=2) order by key, value, ds
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
PREHOOK: Input: default@pcr_t1@ds=2000-04-10
PREHOOK: Input: default@pcr_t1@ds=2000-04-11
#### A masked pattern was here ####
POSTHOOK: query: select key, value, ds from pcr_t1 where (ds>'2000-04-08' and ds<'2000-04-11') or (ds>='2000-04-08' and ds<='2000-04-11' and key=2) order by key, value, ds
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
POSTHOOK: Input: default@pcr_t1@ds=2000-04-10
POSTHOOK: Input: default@pcr_t1@ds=2000-04-11
#### A masked pattern was here ####
0	val_0	2000-04-09
0	val_0	2000-04-09
0	val_0	2000-04-09
0	val_0	2000-04-10
0	val_0	2000-04-10
0	val_0	2000-04-10
2	val_2	2000-04-08
2	val_2	2000-04-09
2	val_2	2000-04-10
2	val_2	2000-04-11
4	val_4	2000-04-09
4	val_4	2000-04-10
5	val_5	2000-04-09
5	val_5	2000-04-09
5	val_5	2000-04-09
5	val_5	2000-04-10
5	val_5	2000-04-10
5	val_5	2000-04-10
8	val_8	2000-04-09
8	val_8	2000-04-10
9	val_9	2000-04-09
9	val_9	2000-04-10
10	val_10	2000-04-09
10	val_10	2000-04-10
11	val_11	2000-04-09
11	val_11	2000-04-10
12	val_12	2000-04-09
12	val_12	2000-04-09
12	val_12	2000-04-10
12	val_12	2000-04-10
15	val_15	2000-04-09
15	val_15	2000-04-09
15	val_15	2000-04-10
15	val_15	2000-04-10
17	val_17	2000-04-09
17	val_17	2000-04-10
18	val_18	2000-04-09
18	val_18	2000-04-09
18	val_18	2000-04-10
18	val_18	2000-04-10
19	val_19	2000-04-09
19	val_19	2000-04-10
PREHOOK: query: explain extended select key, value, ds from pcr_t1 where (ds>'2000-04-08' and ds<'2000-04-11') or (ds<='2000-04-09' and key=2) order by key, value, ds
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value, ds from pcr_t1 where (ds>'2000-04-08' and ds<'2000-04-11') or (ds<='2000-04-09' and key=2) order by key, value, ds
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               ds
      TOK_WHERE
         or
            and
               >
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-08'
               <
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-11'
            and
               <=
                  TOK_TABLE_OR_COL
                     ds
                  '2000-04-09'
               =
                  TOK_TABLE_OR_COL
                     key
                  2
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               value
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               ds


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 60 Data size: 480 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((ds > '2000-04-08') or ((ds <= '2000-04-09') and (key = 2))) (type: boolean)
                    Statistics: Num rows: 30 Data size: 240 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: int), value (type: string), ds (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 30 Data size: 240 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
                        sort order: +++
                        Statistics: Num rows: 30 Data size: 240 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-09
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-09
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-10
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]
              /pcr_t1/ds=2000-04-09 [pcr_t1]
              /pcr_t1/ds=2000-04-10 [pcr_t1]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 30 Data size: 240 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 30 Data size: 240 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2
                        columns.types int:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value, ds from pcr_t1 where (ds>'2000-04-08' and ds<'2000-04-11') or (ds<='2000-04-09' and key=2) order by key, value, ds
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Input: default@pcr_t1@ds=2000-04-09
PREHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
POSTHOOK: query: select key, value, ds from pcr_t1 where (ds>'2000-04-08' and ds<'2000-04-11') or (ds<='2000-04-09' and key=2) order by key, value, ds
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Input: default@pcr_t1@ds=2000-04-09
POSTHOOK: Input: default@pcr_t1@ds=2000-04-10
#### A masked pattern was here ####
0	val_0	2000-04-09
0	val_0	2000-04-09
0	val_0	2000-04-09
0	val_0	2000-04-10
0	val_0	2000-04-10
0	val_0	2000-04-10
2	val_2	2000-04-08
2	val_2	2000-04-09
2	val_2	2000-04-10
4	val_4	2000-04-09
4	val_4	2000-04-10
5	val_5	2000-04-09
5	val_5	2000-04-09
5	val_5	2000-04-09
5	val_5	2000-04-10
5	val_5	2000-04-10
5	val_5	2000-04-10
8	val_8	2000-04-09
8	val_8	2000-04-10
9	val_9	2000-04-09
9	val_9	2000-04-10
10	val_10	2000-04-09
10	val_10	2000-04-10
11	val_11	2000-04-09
11	val_11	2000-04-10
12	val_12	2000-04-09
12	val_12	2000-04-09
12	val_12	2000-04-10
12	val_12	2000-04-10
15	val_15	2000-04-09
15	val_15	2000-04-09
15	val_15	2000-04-10
15	val_15	2000-04-10
17	val_17	2000-04-09
17	val_17	2000-04-10
18	val_18	2000-04-09
18	val_18	2000-04-09
18	val_18	2000-04-10
18	val_18	2000-04-10
19	val_19	2000-04-09
19	val_19	2000-04-10
PREHOOK: query: create table pcr_t2 (key int, value string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@pcr_t2
POSTHOOK: query: create table pcr_t2 (key int, value string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@pcr_t2
PREHOOK: query: create table pcr_t3 (key int, value string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@pcr_t3
POSTHOOK: query: create table pcr_t3 (key int, value string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@pcr_t3
PREHOOK: query: explain extended
from pcr_t1
insert overwrite table pcr_t2 select key, value where ds='2000-04-08'
insert overwrite table pcr_t3 select key, value where ds='2000-04-08'
PREHOOK: type: QUERY
POSTHOOK: query: explain extended
from pcr_t1
insert overwrite table pcr_t2 select key, value where ds='2000-04-08'
insert overwrite table pcr_t3 select key, value where ds='2000-04-08'
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_TAB
            TOK_TABNAME
               pcr_t2
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
      TOK_WHERE
         =
            TOK_TABLE_OR_COL
               ds
            '2000-04-08'
   TOK_INSERT
      TOK_DESTINATION
         TOK_TAB
            TOK_TABNAME
               pcr_t3
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
      TOK_WHERE
         =
            TOK_TABLE_OR_COL
               ds
            '2000-04-08'


STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-2
  Stage-4 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: key (type: int), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      GlobalTableId: 1
#### A masked pattern was here ####
                      NumFilesPerFileSink: 1
                      Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          properties:
                            bucket_count -1
                            columns key,value
                            columns.comments 
                            columns.types int:string
#### A masked pattern was here ####
                            name default.pcr_t2
                            serialization.ddl struct pcr_t2 { i32 key, string value}
                            serialization.format 1
                            serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.pcr_t2
                      TotalFiles: 1
                      GatherStats: true
                      MultiFileSpray: false
                  Select Operator
                    expressions: key (type: int), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      GlobalTableId: 2
#### A masked pattern was here ####
                      NumFilesPerFileSink: 1
                      Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          properties:
                            bucket_count -1
                            columns key,value
                            columns.comments 
                            columns.types int:string
#### A masked pattern was here ####
                            name default.pcr_t3
                            serialization.ddl struct pcr_t3 { i32 key, string value}
                            serialization.format 1
                            serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.pcr_t3
                      TotalFiles: 1
                      GatherStats: true
                      MultiFileSpray: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
#### A masked pattern was here ####
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 
                columns.types int:string
#### A masked pattern was here ####
                name default.pcr_t2
                serialization.ddl struct pcr_t2 { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.pcr_t2

  Stage: Stage-3
    Stats-Aggr Operator
#### A masked pattern was here ####

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
#### A masked pattern was here ####
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 
                columns.types int:string
#### A masked pattern was here ####
                name default.pcr_t3
                serialization.ddl struct pcr_t3 { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.pcr_t3

  Stage: Stage-4
    Stats-Aggr Operator
#### A masked pattern was here ####

PREHOOK: query: from pcr_t1
insert overwrite table pcr_t2 select key, value where ds='2000-04-08'
insert overwrite table pcr_t3 select key, value where ds='2000-04-08'
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Output: default@pcr_t2
PREHOOK: Output: default@pcr_t3
POSTHOOK: query: from pcr_t1
insert overwrite table pcr_t2 select key, value where ds='2000-04-08'
insert overwrite table pcr_t3 select key, value where ds='2000-04-08'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Output: default@pcr_t2
POSTHOOK: Output: default@pcr_t3
POSTHOOK: Lineage: pcr_t2.key SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: pcr_t2.value SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:value, type:string, comment:null), ]
POSTHOOK: Lineage: pcr_t3.key SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: pcr_t3.value SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: explain extended
from pcr_t1
insert overwrite table pcr_t2 select key, value where ds='2000-04-08' and key=2
insert overwrite table pcr_t3 select key, value where ds='2000-04-08' and key=3
PREHOOK: type: QUERY
POSTHOOK: query: explain extended
from pcr_t1
insert overwrite table pcr_t2 select key, value where ds='2000-04-08' and key=2
insert overwrite table pcr_t3 select key, value where ds='2000-04-08' and key=3
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            pcr_t1
   TOK_INSERT
      TOK_DESTINATION
         TOK_TAB
            TOK_TABNAME
               pcr_t2
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
      TOK_WHERE
         and
            =
               TOK_TABLE_OR_COL
                  ds
               '2000-04-08'
            =
               TOK_TABLE_OR_COL
                  key
               2
   TOK_INSERT
      TOK_DESTINATION
         TOK_TAB
            TOK_TABNAME
               pcr_t3
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
      TOK_WHERE
         and
            =
               TOK_TABLE_OR_COL
                  ds
               '2000-04-08'
            =
               TOK_TABLE_OR_COL
                  key
               3


STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-0 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-2
  Stage-4 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: pcr_t1
                  Statistics: Num rows: 20 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (key = 2) (type: boolean)
                    Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: 2 (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                      File Output Operator
                        compressed: false
                        GlobalTableId: 1
#### A masked pattern was here ####
                        NumFilesPerFileSink: 1
                        Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                        table:
                            input format: org.apache.hadoop.mapred.TextInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                            properties:
                              COLUMN_STATS_ACCURATE true
                              bucket_count -1
                              columns key,value
                              columns.comments 
                              columns.types int:string
#### A masked pattern was here ####
                              name default.pcr_t2
                              numFiles 1
                              numRows 0
                              rawDataSize 0
                              serialization.ddl struct pcr_t2 { i32 key, string value}
                              serialization.format 1
                              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                              totalSize 180
#### A masked pattern was here ####
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                            name: default.pcr_t2
                        TotalFiles: 1
                        GatherStats: true
                        MultiFileSpray: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (key = 3) (type: boolean)
                    Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: 3 (type: int), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
                      File Output Operator
                        compressed: false
                        GlobalTableId: 2
#### A masked pattern was here ####
                        NumFilesPerFileSink: 1
                        Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                        table:
                            input format: org.apache.hadoop.mapred.TextInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                            properties:
                              COLUMN_STATS_ACCURATE true
                              bucket_count -1
                              columns key,value
                              columns.comments 
                              columns.types int:string
#### A masked pattern was here ####
                              name default.pcr_t3
                              numFiles 1
                              numRows 0
                              rawDataSize 0
                              serialization.ddl struct pcr_t3 { i32 key, string value}
                              serialization.format 1
                              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                              totalSize 180
#### A masked pattern was here ####
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                            name: default.pcr_t3
                        TotalFiles: 1
                        GatherStats: true
                        MultiFileSpray: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: ds=2000-04-08
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2000-04-08
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:string
#### A masked pattern was here ####
                    name default.pcr_t1
                    numFiles 1
                    numRows 20
                    partition_columns ds
                    partition_columns.types string
                    rawDataSize 160
                    serialization.ddl struct pcr_t1 { i32 key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 180
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:string
#### A masked pattern was here ####
                      name default.pcr_t1
                      partition_columns ds
                      partition_columns.types string
                      serialization.ddl struct pcr_t1 { i32 key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.pcr_t1
                  name: default.pcr_t1
            Truncated Path -> Alias:
              /pcr_t1/ds=2000-04-08 [pcr_t1]

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
#### A masked pattern was here ####
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.comments 
                columns.types int:string
#### A masked pattern was here ####
                name default.pcr_t2
                numFiles 1
                numRows 0
                rawDataSize 0
                serialization.ddl struct pcr_t2 { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 180
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.pcr_t2

  Stage: Stage-3
    Stats-Aggr Operator
#### A masked pattern was here ####

  Stage: Stage-1
    Move Operator
      tables:
          replace: true
#### A masked pattern was here ####
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns key,value
                columns.comments 
                columns.types int:string
#### A masked pattern was here ####
                name default.pcr_t3
                numFiles 1
                numRows 0
                rawDataSize 0
                serialization.ddl struct pcr_t3 { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 180
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.pcr_t3

  Stage: Stage-4
    Stats-Aggr Operator
#### A masked pattern was here ####

PREHOOK: query: from pcr_t1
insert overwrite table pcr_t2 select key, value where ds='2000-04-08' and key=2
insert overwrite table pcr_t3 select key, value where ds='2000-04-08' and key=3
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_t1
PREHOOK: Input: default@pcr_t1@ds=2000-04-08
PREHOOK: Output: default@pcr_t2
PREHOOK: Output: default@pcr_t3
POSTHOOK: query: from pcr_t1
insert overwrite table pcr_t2 select key, value where ds='2000-04-08' and key=2
insert overwrite table pcr_t3 select key, value where ds='2000-04-08' and key=3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Input: default@pcr_t1@ds=2000-04-08
POSTHOOK: Output: default@pcr_t2
POSTHOOK: Output: default@pcr_t3
POSTHOOK: Lineage: pcr_t2.key SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: pcr_t2.value SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:value, type:string, comment:null), ]
POSTHOOK: Lineage: pcr_t3.key SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:key, type:int, comment:null), ]
POSTHOOK: Lineage: pcr_t3.value SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:value, type:string, comment:null), ]
PREHOOK: query: explain extended select key, value from srcpart where ds='2008-04-08' and hr=11 order by key limit 10
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value from srcpart where ds='2008-04-08' and hr=11 order by key limit 10
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            srcpart
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
      TOK_WHERE
         and
            =
               TOK_TABLE_OR_COL
                  ds
               '2008-04-08'
            =
               TOK_TABLE_OR_COL
                  hr
               11
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
      TOK_LIMIT
         10


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: key (type: string), value (type: string)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      tag: -1
                      value expressions: _col1 (type: string)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: hr=11
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2008-04-08
                    hr 11
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 'default','default'
                    columns.types string:string
#### A masked pattern was here ####
                    name default.srcpart
                    numFiles 1
                    numRows 500
                    partition_columns ds/hr
                    partition_columns.types string:string
                    rawDataSize 5312
                    serialization.ddl struct srcpart { string key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 5812
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 'default','default'
                      columns.types string:string
#### A masked pattern was here ####
                      name default.srcpart
                      partition_columns ds/hr
                      partition_columns.types string:string
                      serialization.ddl struct srcpart { string key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.srcpart
                  name: default.srcpart
            Truncated Path -> Alias:
              /srcpart/ds=2008-04-08/hr=11 [srcpart]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 10 Data size: 100 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          columns _col0,_col1
                          columns.types string:string
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink

PREHOOK: query: select key, value from srcpart where ds='2008-04-04' and hr=11 order by key limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@srcpart
#### A masked pattern was here ####
POSTHOOK: query: select key, value from srcpart where ds='2008-04-04' and hr=11 order by key limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcpart
#### A masked pattern was here ####
PREHOOK: query: explain extended select key, value, ds, hr from srcpart where ds='2008-04-08' and (hr='11' or hr='12') and key=11 order by key, ds, hr
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value, ds, hr from srcpart where ds='2008-04-08' and (hr='11' or hr='12') and key=11 order by key, ds, hr
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            srcpart
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               ds
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               hr
      TOK_WHERE
         and
            and
               =
                  TOK_TABLE_OR_COL
                     ds
                  '2008-04-08'
               or
                  =
                     TOK_TABLE_OR_COL
                        hr
                     '11'
                  =
                     TOK_TABLE_OR_COL
                        hr
                     '12'
            =
               TOK_TABLE_OR_COL
                  key
               11
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               ds
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               hr


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (key = 11) (type: boolean)
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: value (type: string), hr (type: string)
                      outputColumnNames: _col1, _col3
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: '11' (type: string), '2008-04-08' (type: string), _col3 (type: string)
                        sort order: +++
                        Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col1 (type: string)
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: hr=11
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2008-04-08
                    hr 11
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 'default','default'
                    columns.types string:string
#### A masked pattern was here ####
                    name default.srcpart
                    numFiles 1
                    numRows 500
                    partition_columns ds/hr
                    partition_columns.types string:string
                    rawDataSize 5312
                    serialization.ddl struct srcpart { string key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 5812
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 'default','default'
                      columns.types string:string
#### A masked pattern was here ####
                      name default.srcpart
                      partition_columns ds/hr
                      partition_columns.types string:string
                      serialization.ddl struct srcpart { string key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.srcpart
                  name: default.srcpart
#### A masked pattern was here ####
                Partition
                  base file name: hr=12
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2008-04-08
                    hr 12
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 'default','default'
                    columns.types string:string
#### A masked pattern was here ####
                    name default.srcpart
                    numFiles 1
                    numRows 500
                    partition_columns ds/hr
                    partition_columns.types string:string
                    rawDataSize 5312
                    serialization.ddl struct srcpart { string key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 5812
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 'default','default'
                      columns.types string:string
#### A masked pattern was here ####
                      name default.srcpart
                      partition_columns ds/hr
                      partition_columns.types string:string
                      serialization.ddl struct srcpart { string key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.srcpart
                  name: default.srcpart
            Truncated Path -> Alias:
              /srcpart/ds=2008-04-08/hr=11 [srcpart]
              /srcpart/ds=2008-04-08/hr=12 [srcpart]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: '11' (type: string), VALUE._col0 (type: string), '2008-04-08' (type: string), KEY.reducesinkkey2 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2,_col3
                        columns.types string:string:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value, ds, hr from srcpart where ds='2008-04-08' and (hr='11' or hr='12') and key=11 order by key, ds, hr
PREHOOK: type: QUERY
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
#### A masked pattern was here ####
POSTHOOK: query: select key, value, ds, hr from srcpart where ds='2008-04-08' and (hr='11' or hr='12') and key=11 order by key, ds, hr
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
#### A masked pattern was here ####
11	val_11	2008-04-08	11
11	val_11	2008-04-08	12
PREHOOK: query: explain extended select key, value, ds, hr from srcpart where hr='11' and key=11 order by key, ds, hr
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key, value, ds, hr from srcpart where hr='11' and key=11 order by key, ds, hr
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            srcpart
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               key
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               value
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               ds
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               hr
      TOK_WHERE
         and
            =
               TOK_TABLE_OR_COL
                  hr
               '11'
            =
               TOK_TABLE_OR_COL
                  key
               11
      TOK_ORDERBY
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               key
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               ds
         TOK_TABSORTCOLNAMEASC
            TOK_TABLE_OR_COL
               hr


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (key = 11) (type: boolean)
                    Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: value (type: string), ds (type: string)
                      outputColumnNames: _col1, _col2
                      Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: '11' (type: string), _col2 (type: string), '11' (type: string)
                        sort order: +++
                        Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col1 (type: string)
                        auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: hr=11
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2008-04-08
                    hr 11
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 'default','default'
                    columns.types string:string
#### A masked pattern was here ####
                    name default.srcpart
                    numFiles 1
                    numRows 500
                    partition_columns ds/hr
                    partition_columns.types string:string
                    rawDataSize 5312
                    serialization.ddl struct srcpart { string key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 5812
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 'default','default'
                      columns.types string:string
#### A masked pattern was here ####
                      name default.srcpart
                      partition_columns ds/hr
                      partition_columns.types string:string
                      serialization.ddl struct srcpart { string key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.srcpart
                  name: default.srcpart
#### A masked pattern was here ####
                Partition
                  base file name: hr=11
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    ds 2008-04-09
                    hr 11
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 'default','default'
                    columns.types string:string
#### A masked pattern was here ####
                    name default.srcpart
                    numFiles 1
                    numRows 500
                    partition_columns ds/hr
                    partition_columns.types string:string
                    rawDataSize 5312
                    serialization.ddl struct srcpart { string key, string value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 5812
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      columns key,value
                      columns.comments 'default','default'
                      columns.types string:string
#### A masked pattern was here ####
                      name default.srcpart
                      partition_columns ds/hr
                      partition_columns.types string:string
                      serialization.ddl struct srcpart { string key, string value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.srcpart
                  name: default.srcpart
            Truncated Path -> Alias:
              /srcpart/ds=2008-04-08/hr=11 [srcpart]
              /srcpart/ds=2008-04-09/hr=11 [srcpart]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: '11' (type: string), VALUE._col0 (type: string), KEY.reducesinkkey1 (type: string), '11' (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
#### A masked pattern was here ####
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        columns _col0,_col1,_col2,_col3
                        columns.types string:string:string:string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select key, value, ds, hr from srcpart where hr='11' and key=11 order by key, ds, hr
PREHOOK: type: QUERY
PREHOOK: Input: default@srcpart
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
#### A masked pattern was here ####
POSTHOOK: query: select key, value, ds, hr from srcpart where hr='11' and key=11 order by key, ds, hr
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcpart
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
#### A masked pattern was here ####
11	val_11	2008-04-08	11
11	val_11	2008-04-09	11
PREHOOK: query: drop table pcr_t1
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@pcr_t1
PREHOOK: Output: default@pcr_t1
POSTHOOK: query: drop table pcr_t1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@pcr_t1
POSTHOOK: Output: default@pcr_t1
PREHOOK: query: drop table pcr_t2
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@pcr_t2
PREHOOK: Output: default@pcr_t2
POSTHOOK: query: drop table pcr_t2
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@pcr_t2
POSTHOOK: Output: default@pcr_t2
PREHOOK: query: drop table pcr_t3
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@pcr_t3
PREHOOK: Output: default@pcr_t3
POSTHOOK: query: drop table pcr_t3
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@pcr_t3
POSTHOOK: Output: default@pcr_t3
PREHOOK: query: -- Test cases when a non-boolean ds expression has same and different values for all possible ds values: 
drop table pcr_foo
PREHOOK: type: DROPTABLE
POSTHOOK: query: -- Test cases when a non-boolean ds expression has same and different values for all possible ds values: 
drop table pcr_foo
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table pcr_foo (key int, value string) partitioned by (ds int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@pcr_foo
POSTHOOK: query: create table pcr_foo (key int, value string) partitioned by (ds int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@pcr_foo
PREHOOK: query: insert overwrite table pcr_foo partition (ds=3) select * from src where key < 10 order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@pcr_foo@ds=3
POSTHOOK: query: insert overwrite table pcr_foo partition (ds=3) select * from src where key < 10 order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@pcr_foo@ds=3
POSTHOOK: Lineage: pcr_foo PARTITION(ds=3).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: pcr_foo PARTITION(ds=3).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: insert overwrite table pcr_foo partition (ds=5) select * from src where key < 10 order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@pcr_foo@ds=5
POSTHOOK: query: insert overwrite table pcr_foo partition (ds=5) select * from src where key < 10 order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@pcr_foo@ds=5
POSTHOOK: Lineage: pcr_foo PARTITION(ds=5).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: pcr_foo PARTITION(ds=5).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: insert overwrite table pcr_foo partition (ds=7) select * from src where key < 10 order by key
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@pcr_foo@ds=7
POSTHOOK: query: insert overwrite table pcr_foo partition (ds=7) select * from src where key < 10 order by key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@pcr_foo@ds=7
POSTHOOK: Lineage: pcr_foo PARTITION(ds=7).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: pcr_foo PARTITION(ds=7).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: -- the condition is 'true' for all the 3 partitions (ds=3,5,7):
select key, value, ds from pcr_foo where (ds % 2 == 1)
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_foo
PREHOOK: Input: default@pcr_foo@ds=3
PREHOOK: Input: default@pcr_foo@ds=5
PREHOOK: Input: default@pcr_foo@ds=7
#### A masked pattern was here ####
POSTHOOK: query: -- the condition is 'true' for all the 3 partitions (ds=3,5,7):
select key, value, ds from pcr_foo where (ds % 2 == 1)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_foo
POSTHOOK: Input: default@pcr_foo@ds=3
POSTHOOK: Input: default@pcr_foo@ds=5
POSTHOOK: Input: default@pcr_foo@ds=7
#### A masked pattern was here ####
0	val_0	3
0	val_0	3
0	val_0	3
2	val_2	3
4	val_4	3
5	val_5	3
5	val_5	3
5	val_5	3
8	val_8	3
9	val_9	3
0	val_0	5
0	val_0	5
0	val_0	5
2	val_2	5
4	val_4	5
5	val_5	5
5	val_5	5
5	val_5	5
8	val_8	5
9	val_9	5
0	val_0	7
0	val_0	7
0	val_0	7
2	val_2	7
4	val_4	7
5	val_5	7
5	val_5	7
5	val_5	7
8	val_8	7
9	val_9	7
PREHOOK: query: -- the condition is 'true' for partitions (ds=3,5) but 'false' of partition ds=7:
select key, value, ds from pcr_foo where (ds / 3 < 2)
PREHOOK: type: QUERY
PREHOOK: Input: default@pcr_foo
PREHOOK: Input: default@pcr_foo@ds=3
PREHOOK: Input: default@pcr_foo@ds=5
#### A masked pattern was here ####
POSTHOOK: query: -- the condition is 'true' for partitions (ds=3,5) but 'false' of partition ds=7:
select key, value, ds from pcr_foo where (ds / 3 < 2)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@pcr_foo
POSTHOOK: Input: default@pcr_foo@ds=3
POSTHOOK: Input: default@pcr_foo@ds=5
#### A masked pattern was here ####
0	val_0	3
0	val_0	3
0	val_0	3
2	val_2	3
4	val_4	3
5	val_5	3
5	val_5	3
5	val_5	3
8	val_8	3
9	val_9	3
0	val_0	5
0	val_0	5
0	val_0	5
2	val_2	5
4	val_4	5
5	val_5	5
5	val_5	5
5	val_5	5
8	val_8	5
9	val_9	5
PREHOOK: query: drop table pcr_foo
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@pcr_foo
PREHOOK: Output: default@pcr_foo
POSTHOOK: query: drop table pcr_foo
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@pcr_foo
POSTHOOK: Output: default@pcr_foo
PREHOOK: query: -- Cover org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory.FieldExprProcessor.
-- Create a table with a struct data:
create table ab(strct struct<a:int, b:string>)
row format delimited
  fields terminated by '\t'
  collection items terminated by '\001'
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@ab
POSTHOOK: query: -- Cover org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory.FieldExprProcessor.
-- Create a table with a struct data:
create table ab(strct struct<a:int, b:string>)
row format delimited
  fields terminated by '\t'
  collection items terminated by '\001'
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@ab
PREHOOK: query: load data local inpath '../../data/files/kv1.txt'
overwrite into table ab
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@ab
POSTHOOK: query: load data local inpath '../../data/files/kv1.txt'
overwrite into table ab
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@ab
PREHOOK: query: -- Create partitioned table with struct data:
drop table foo_field
PREHOOK: type: DROPTABLE
POSTHOOK: query: -- Create partitioned table with struct data:
drop table foo_field
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table foo_field (s struct<a:int,b:string>) partitioned by (ds int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@foo_field
POSTHOOK: query: create table foo_field (s struct<a:int,b:string>) partitioned by (ds int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@foo_field
PREHOOK: query: insert overwrite table foo_field partition (ds=5) select strct from ab where strct.a < 10 limit 2
PREHOOK: type: QUERY
PREHOOK: Input: default@ab
PREHOOK: Output: default@foo_field@ds=5
POSTHOOK: query: insert overwrite table foo_field partition (ds=5) select strct from ab where strct.a < 10 limit 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ab
POSTHOOK: Output: default@foo_field@ds=5
POSTHOOK: Lineage: foo_field PARTITION(ds=5).s SIMPLE [(ab)ab.FieldSchema(name:strct, type:struct<a:int,b:string>, comment:null), ]
PREHOOK: query: insert overwrite table foo_field partition (ds=7) select strct from ab where strct.a > 190 limit 2
PREHOOK: type: QUERY
PREHOOK: Input: default@ab
PREHOOK: Output: default@foo_field@ds=7
POSTHOOK: query: insert overwrite table foo_field partition (ds=7) select strct from ab where strct.a > 190 limit 2
POSTHOOK: type: QUERY
POSTHOOK: Input: default@ab
POSTHOOK: Output: default@foo_field@ds=7
POSTHOOK: Lineage: foo_field PARTITION(ds=7).s SIMPLE [(ab)ab.FieldSchema(name:strct, type:struct<a:int,b:string>, comment:null), ]
PREHOOK: query: select s,ds from foo_field where ((ds + s.a) > 0) order by ds,s
PREHOOK: type: QUERY
PREHOOK: Input: default@foo_field
PREHOOK: Input: default@foo_field@ds=5
PREHOOK: Input: default@foo_field@ds=7
#### A masked pattern was here ####
POSTHOOK: query: select s,ds from foo_field where ((ds + s.a) > 0) order by ds,s
POSTHOOK: type: QUERY
POSTHOOK: Input: default@foo_field
POSTHOOK: Input: default@foo_field@ds=5
POSTHOOK: Input: default@foo_field@ds=7
#### A masked pattern was here ####
{"a":0,"b":"val_0"}	5
{"a":4,"b":"val_4"}	5
{"a":238,"b":"val_238"}	7
{"a":311,"b":"val_311"}	7
PREHOOK: query: drop table foo_field
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@foo_field
PREHOOK: Output: default@foo_field
POSTHOOK: query: drop table foo_field
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@foo_field
POSTHOOK: Output: default@foo_field
PREHOOK: query: explain select key,value from srcpart where cast(hr as double)  = cast(11 as double)
PREHOOK: type: QUERY
POSTHOOK: query: explain select key,value from srcpart where cast(hr as double)  = cast(11 as double)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: srcpart
          Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: key (type: string), value (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
            ListSink

PREHOOK: query: explain select key,value from srcpart where hr  = cast(11 as double)
PREHOOK: type: QUERY
POSTHOOK: query: explain select key,value from srcpart where hr  = cast(11 as double)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: srcpart
          Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: key (type: string), value (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
            ListSink

PREHOOK: query: explain select key,value from srcpart where cast(hr as double)  = 11
PREHOOK: type: QUERY
POSTHOOK: query: explain select key,value from srcpart where cast(hr as double)  = 11
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: srcpart
          Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: key (type: string), value (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
            ListSink

