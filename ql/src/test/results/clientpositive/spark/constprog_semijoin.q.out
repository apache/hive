PREHOOK: query: create table table1_n10 (id int, val string, val1 string, dimid int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@table1_n10
POSTHOOK: query: create table table1_n10 (id int, val string, val1 string, dimid int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@table1_n10
PREHOOK: query: insert into table1_n10 (id, val, val1, dimid) values (1, 't1val01', 'val101', 100), (2, 't1val02', 'val102', 200), (3, 't1val03', 'val103', 103), (3, 't1val01', 'val104', 100), (2, 't1val05', 'val105', 200), (3, 't1val01', 'val106', 103), (1, 't1val07', 'val107', 200), (2, 't1val01', 'val108', 200), (3, 't1val09', 'val109', 103), (4,'t1val01', 'val110', 200)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@table1_n10
POSTHOOK: query: insert into table1_n10 (id, val, val1, dimid) values (1, 't1val01', 'val101', 100), (2, 't1val02', 'val102', 200), (3, 't1val03', 'val103', 103), (3, 't1val01', 'val104', 100), (2, 't1val05', 'val105', 200), (3, 't1val01', 'val106', 103), (1, 't1val07', 'val107', 200), (2, 't1val01', 'val108', 200), (3, 't1val09', 'val109', 103), (4,'t1val01', 'val110', 200)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@table1_n10
POSTHOOK: Lineage: table1_n10.dimid SCRIPT []
POSTHOOK: Lineage: table1_n10.id SCRIPT []
POSTHOOK: Lineage: table1_n10.val SCRIPT []
POSTHOOK: Lineage: table1_n10.val1 SCRIPT []
PREHOOK: query: create table table2_n6 (id int, val2 string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@table2_n6
POSTHOOK: query: create table table2_n6 (id int, val2 string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@table2_n6
PREHOOK: query: insert into table2_n6 (id, val2) values (1, 't2val201'), (2, 't2val202'), (3, 't2val203')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@table2_n6
POSTHOOK: query: insert into table2_n6 (id, val2) values (1, 't2val201'), (2, 't2val202'), (3, 't2val203')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@table2_n6
POSTHOOK: Lineage: table2_n6.id SCRIPT []
POSTHOOK: Lineage: table2_n6.val2 SCRIPT []
PREHOOK: query: create table table3_n0 (id int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@table3_n0
POSTHOOK: query: create table table3_n0 (id int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@table3_n0
PREHOOK: query: insert into table3_n0 (id) values (100), (100), (101), (102), (103)
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@table3_n0
POSTHOOK: query: insert into table3_n0 (id) values (100), (100), (101), (102), (103)
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@table3_n0
POSTHOOK: Lineage: table3_n0.id SCRIPT []
PREHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id where table1_n10.val = 't1val01'
PREHOOK: type: QUERY
POSTHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id where table1_n10.val = 't1val01'
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 3 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: table1_n10
                  Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((val = 't1val01') and dimid is not null) (type: boolean)
                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int), val1 (type: string), dimid (type: int)
                      outputColumnNames: _col0, _col2, _col3
                      Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col3 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col3 (type: int)
                        Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: int), _col2 (type: string)
            Execution mode: vectorized
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: table3_n0
                  Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: id is not null (type: boolean)
                    Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                keys:
                  0 _col3 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col2
                Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), 't1val01' (type: string), _col2 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id where table1_n10.val = 't1val01'
PREHOOK: type: QUERY
PREHOOK: Input: default@table1_n10
PREHOOK: Input: default@table3_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id where table1_n10.val = 't1val01'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table1_n10
POSTHOOK: Input: default@table3_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	t1val01	val101
3	t1val01	val104
3	t1val01	val106
PREHOOK: query: explain select table1_n10.id, table1_n10.val, table2_n6.val2 from table1_n10 inner join table2_n6 on table1_n10.val = 't1val01' and table1_n10.id = table2_n6.id left semi join table3_n0 on table1_n10.dimid = table3_n0.id
PREHOOK: type: QUERY
POSTHOOK: query: explain select table1_n10.id, table1_n10.val, table2_n6.val2 from table1_n10 inner join table2_n6 on table1_n10.val = 't1val01' and table1_n10.id = table2_n6.id left semi join table3_n0 on table1_n10.dimid = table3_n0.id
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 4 (PARTITION-LEVEL SORT, 4)
        Reducer 3 <- Map 5 (PARTITION-LEVEL SORT, 4), Reducer 2 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: table1_n10
                  Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((val = 't1val01') and dimid is not null and id is not null) (type: boolean)
                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int), dimid (type: int)
                      outputColumnNames: _col0, _col2
                      Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col2 (type: int)
            Execution mode: vectorized
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: table2_n6
                  Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: id is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int), val2 (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: string)
            Execution mode: vectorized
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: table3_n0
                  Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: id is not null (type: boolean)
                    Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col2, _col4
                Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col2 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col2 (type: int)
                  Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: int), _col4 (type: string)
        Reducer 3 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                keys:
                  0 _col2 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col4
                Statistics: Num rows: 5 Data size: 121 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), 't1val01' (type: string), _col4 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 5 Data size: 121 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 5 Data size: 121 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select table1_n10.id, table1_n10.val, table2_n6.val2 from table1_n10 inner join table2_n6 on table1_n10.val = 't1val01' and table1_n10.id = table2_n6.id left semi join table3_n0 on table1_n10.dimid = table3_n0.id
PREHOOK: type: QUERY
PREHOOK: Input: default@table1_n10
PREHOOK: Input: default@table2_n6
PREHOOK: Input: default@table3_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select table1_n10.id, table1_n10.val, table2_n6.val2 from table1_n10 inner join table2_n6 on table1_n10.val = 't1val01' and table1_n10.id = table2_n6.id left semi join table3_n0 on table1_n10.dimid = table3_n0.id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table1_n10
POSTHOOK: Input: default@table2_n6
POSTHOOK: Input: default@table3_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	t1val01	t2val201
3	t1val01	t2val203
3	t1val01	t2val203
PREHOOK: query: explain select table1_n10.id, table1_n10.val, table2_n6.val2 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id inner join table2_n6 on table1_n10.val = 't1val01' and table1_n10.id = table2_n6.id
PREHOOK: type: QUERY
POSTHOOK: query: explain select table1_n10.id, table1_n10.val, table2_n6.val2 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id inner join table2_n6 on table1_n10.val = 't1val01' and table1_n10.id = table2_n6.id
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 4 (PARTITION-LEVEL SORT, 4)
        Reducer 3 <- Map 5 (PARTITION-LEVEL SORT, 4), Reducer 2 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: table1_n10
                  Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: ((val = 't1val01') and dimid is not null and id is not null) (type: boolean)
                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int), dimid (type: int)
                      outputColumnNames: _col0, _col2
                      Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col2 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col2 (type: int)
                        Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: int)
            Execution mode: vectorized
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: table3_n0
                  Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: id is not null (type: boolean)
                    Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: table2_n6
                  Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: id is not null (type: boolean)
                    Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int), val2 (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 3 Data size: 30 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: string)
            Execution mode: vectorized
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                keys:
                  0 _col2 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col4
                Statistics: Num rows: 5 Data size: 121 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), 't1val01' (type: string), _col4 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 5 Data size: 121 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 5 Data size: 121 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select table1_n10.id, table1_n10.val, table2_n6.val2 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id inner join table2_n6 on table1_n10.val = 't1val01' and table1_n10.id = table2_n6.id
PREHOOK: type: QUERY
PREHOOK: Input: default@table1_n10
PREHOOK: Input: default@table2_n6
PREHOOK: Input: default@table3_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select table1_n10.id, table1_n10.val, table2_n6.val2 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id inner join table2_n6 on table1_n10.val = 't1val01' and table1_n10.id = table2_n6.id
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table1_n10
POSTHOOK: Input: default@table2_n6
POSTHOOK: Input: default@table3_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	t1val01	t2val201
3	t1val01	t2val203
3	t1val01	t2val203
PREHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid <> 100
PREHOOK: type: QUERY
POSTHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid <> 100
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 3 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: table1_n10
                  Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: false (type: boolean)
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int), val (type: string), val1 (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: 100 (type: int), true (type: boolean)
                        sort order: ++
                        Map-reduce partition columns: 100 (type: int), true (type: boolean)
                        Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
            Execution mode: vectorized
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: table3_n0
                  Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (id = 100) (type: boolean)
                    Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: 100 (type: int), true (type: boolean)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int), _col1 (type: boolean)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: boolean)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: int), _col1 (type: boolean)
                          Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                keys:
                  0 100 (type: int), true (type: boolean)
                  1 _col0 (type: int), _col1 (type: boolean)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid <> 100
PREHOOK: type: QUERY
PREHOOK: Input: default@table1_n10
PREHOOK: Input: default@table3_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid <> 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table1_n10
POSTHOOK: Input: default@table3_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
PREHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  IN (100,200)
PREHOOK: type: QUERY
POSTHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  IN (100,200)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 3 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: table1_n10
                  Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (dimid = 100) (type: boolean)
                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int), val (type: string), val1 (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: 100 (type: int), true (type: boolean)
                        sort order: ++
                        Map-reduce partition columns: 100 (type: int), true (type: boolean)
                        Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
            Execution mode: vectorized
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: table3_n0
                  Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (id = 100) (type: boolean)
                    Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: 100 (type: int), true (type: boolean)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int), _col1 (type: boolean)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: boolean)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: int), _col1 (type: boolean)
                          Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                keys:
                  0 100 (type: int), true (type: boolean)
                  1 _col0 (type: int), _col1 (type: boolean)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  IN (100,200)
PREHOOK: type: QUERY
PREHOOK: Input: default@table1_n10
PREHOOK: Input: default@table3_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  IN (100,200)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table1_n10
POSTHOOK: Input: default@table3_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	t1val01	val101
3	t1val01	val104
PREHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  = 200
PREHOOK: type: QUERY
POSTHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  = 200
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 3 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: table1_n10
                  Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: false (type: boolean)
                    Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int), val (type: string), val1 (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: 100 (type: int), true (type: boolean)
                        sort order: ++
                        Map-reduce partition columns: 100 (type: int), true (type: boolean)
                        Statistics: Num rows: 1 Data size: 20 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
            Execution mode: vectorized
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: table3_n0
                  Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (id = 100) (type: boolean)
                    Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: 100 (type: int), true (type: boolean)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int), _col1 (type: boolean)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: boolean)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: int), _col1 (type: boolean)
                          Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                keys:
                  0 100 (type: int), true (type: boolean)
                  1 _col0 (type: int), _col1 (type: boolean)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  = 200
PREHOOK: type: QUERY
PREHOOK: Input: default@table1_n10
PREHOOK: Input: default@table3_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  = 200
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table1_n10
POSTHOOK: Input: default@table3_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
PREHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  = 100
PREHOOK: type: QUERY
POSTHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  = 100
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 3 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: table1_n10
                  Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (dimid = 100) (type: boolean)
                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int), val (type: string), val1 (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: 100 (type: int), true (type: boolean)
                        sort order: ++
                        Map-reduce partition columns: 100 (type: int), true (type: boolean)
                        Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
            Execution mode: vectorized
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: table3_n0
                  Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (id = 100) (type: boolean)
                    Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: 100 (type: int), true (type: boolean)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int), _col1 (type: boolean)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: boolean)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: int), _col1 (type: boolean)
                          Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                keys:
                  0 100 (type: int), true (type: boolean)
                  1 _col0 (type: int), _col1 (type: boolean)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  = 100
PREHOOK: type: QUERY
PREHOOK: Input: default@table1_n10
PREHOOK: Input: default@table3_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100 where table1_n10.dimid  = 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table1_n10
POSTHOOK: Input: default@table3_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	t1val01	val101
3	t1val01	val104
PREHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100
PREHOOK: type: QUERY
POSTHOOK: query: explain select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 4), Map 3 (PARTITION-LEVEL SORT, 4)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: table1_n10
                  Statistics: Num rows: 10 Data size: 200 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (dimid = 100) (type: boolean)
                    Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: id (type: int), val (type: string), val1 (type: string)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: 100 (type: int), true (type: boolean)
                        sort order: ++
                        Map-reduce partition columns: 100 (type: int), true (type: boolean)
                        Statistics: Num rows: 5 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
            Execution mode: vectorized
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: table3_n0
                  Statistics: Num rows: 5 Data size: 15 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (id = 100) (type: boolean)
                    Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: 100 (type: int), true (type: boolean)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: int), _col1 (type: boolean)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int), _col1 (type: boolean)
                          sort order: ++
                          Map-reduce partition columns: _col0 (type: int), _col1 (type: boolean)
                          Statistics: Num rows: 2 Data size: 6 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Reducer 2 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                keys:
                  0 100 (type: int), true (type: boolean)
                  1 _col0 (type: int), _col1 (type: boolean)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 5 Data size: 110 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100
PREHOOK: type: QUERY
PREHOOK: Input: default@table1_n10
PREHOOK: Input: default@table3_n0
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: select table1_n10.id, table1_n10.val, table1_n10.val1 from table1_n10 left semi join table3_n0 on table1_n10.dimid = table3_n0.id and table3_n0.id = 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@table1_n10
POSTHOOK: Input: default@table3_n0
POSTHOOK: Output: hdfs://### HDFS PATH ###
1	t1val01	val101
3	t1val01	val104
