PREHOOK: query: -- SORT_QUERY_RESULTS
-- HIVE-3411 Filter predicates on outer join overlapped on single alias is not handled properly

create table a as SELECT 100 as key, a.value as value FROM src LATERAL VIEW explode(array(40, 50, 60)) a as value limit 3
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@a
POSTHOOK: query: -- SORT_QUERY_RESULTS
-- HIVE-3411 Filter predicates on outer join overlapped on single alias is not handled properly

create table a as SELECT 100 as key, a.value as value FROM src LATERAL VIEW explode(array(40, 50, 60)) a as value limit 3
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@a
PREHOOK: query: -- overlap on a
explain extended select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60)
PREHOOK: type: QUERY
POSTHOOK: query: -- overlap on a
explain extended select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_LEFTOUTERJOIN
         TOK_LEFTOUTERJOIN
            TOK_TABREF
               TOK_TABNAME
                  a
            TOK_TABREF
               TOK_TABNAME
                  a
               b
            AND
               AND
                  =
                     .
                        TOK_TABLE_OR_COL
                           a
                        key
                     .
                        TOK_TABLE_OR_COL
                           b
                        key
                  =
                     .
                        TOK_TABLE_OR_COL
                           a
                        value
                     50
               =
                  .
                     TOK_TABLE_OR_COL
                        b
                     value
                  50
         TOK_TABREF
            TOK_TABNAME
               a
            c
         AND
            AND
               =
                  .
                     TOK_TABLE_OR_COL
                        a
                     key
                  .
                     TOK_TABLE_OR_COL
                        c
                     key
               =
                  .
                     TOK_TABLE_OR_COL
                        a
                     value
                  60
            =
               .
                  TOK_TABLE_OR_COL
                     c
                  value
               60
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 3 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                    tag: 0
                    value expressions: value (type: int)
                    auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [a]
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 50) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 1
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [b]
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 60) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 2
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [c]
        Reducer 2 
            Needs Tagging: true
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Outer Join0 to 1
                     Left Outer Join0 to 2
                filter mappings:
                  0 [1, 1, 2, 1]
                filter predicates:
                  0 {(VALUE._col0 = 50)} {(VALUE._col0 = 60)}
                  1 
                  2 
                keys:
                  0 key (type: int)
                  1 key (type: int)
                  2 key (type: int)
                outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5
                          columns.types int:int:int:int:int:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL
100	50	100	50	NULL	NULL
100	60	NULL	NULL	100	60
PREHOOK: query: select /*+ MAPJOIN(b,c)*/ * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(b,c)*/ * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL
100	50	100	50	NULL	NULL
100	60	NULL	NULL	100	60
PREHOOK: query: -- overlap on b
explain extended select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
POSTHOOK: query: -- overlap on b
explain extended select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_LEFTOUTERJOIN
         TOK_RIGHTOUTERJOIN
            TOK_TABREF
               TOK_TABNAME
                  a
            TOK_TABREF
               TOK_TABNAME
                  a
               b
            AND
               AND
                  =
                     .
                        TOK_TABLE_OR_COL
                           a
                        key
                     .
                        TOK_TABLE_OR_COL
                           b
                        key
                  =
                     .
                        TOK_TABLE_OR_COL
                           a
                        value
                     50
               =
                  .
                     TOK_TABLE_OR_COL
                        b
                     value
                  50
         TOK_TABREF
            TOK_TABNAME
               a
            c
         AND
            AND
               =
                  .
                     TOK_TABLE_OR_COL
                        b
                     key
                  .
                     TOK_TABLE_OR_COL
                        c
                     key
               =
                  .
                     TOK_TABLE_OR_COL
                        b
                     value
                  60
            =
               .
                  TOK_TABLE_OR_COL
                     c
                  value
               60
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 3 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 50) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 0
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [a]
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                    tag: 1
                    value expressions: value (type: int)
                    auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [b]
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 60) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 2
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [c]
        Reducer 2 
            Needs Tagging: true
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Right Outer Join0 to 1
                     Left Outer Join1 to 2
                filter mappings:
                  1 [0, 1, 2, 1]
                filter predicates:
                  0 
                  1 {(VALUE._col0 = 50)} {(VALUE._col0 = 60)}
                  2 
                keys:
                  0 key (type: int)
                  1 key (type: int)
                  2 key (type: int)
                outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5
                          columns.types int:int:int:int:int:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: select /*+ MAPJOIN(a,c)*/ * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(a,c)*/ * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: -- overlap on b with two filters for each
explain extended select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
POSTHOOK: query: -- overlap on b with two filters for each
explain extended select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_LEFTOUTERJOIN
         TOK_RIGHTOUTERJOIN
            TOK_TABREF
               TOK_TABNAME
                  a
            TOK_TABREF
               TOK_TABNAME
                  a
               b
            AND
               AND
                  AND
                     =
                        .
                           TOK_TABLE_OR_COL
                              a
                           key
                        .
                           TOK_TABLE_OR_COL
                              b
                           key
                     =
                        .
                           TOK_TABLE_OR_COL
                              a
                           value
                        50
                  =
                     .
                        TOK_TABLE_OR_COL
                           b
                        value
                     50
               >
                  .
                     TOK_TABLE_OR_COL
                        b
                     value
                  10
         TOK_TABREF
            TOK_TABNAME
               a
            c
         AND
            AND
               AND
                  =
                     .
                        TOK_TABLE_OR_COL
                           b
                        key
                     .
                        TOK_TABLE_OR_COL
                           c
                        key
                  =
                     .
                        TOK_TABLE_OR_COL
                           b
                        value
                     60
               >
                  .
                     TOK_TABLE_OR_COL
                        b
                     value
                  20
            =
               .
                  TOK_TABLE_OR_COL
                     c
                  value
               60
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 3 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 50) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 0
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [a]
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                    tag: 1
                    value expressions: value (type: int)
                    auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [b]
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 60) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 2
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [c]
        Reducer 2 
            Needs Tagging: true
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Right Outer Join0 to 1
                     Left Outer Join1 to 2
                filter mappings:
                  1 [0, 2, 2, 2]
                filter predicates:
                  0 
                  1 {(VALUE._col0 = 50)} {(VALUE._col0 > 10)} {(VALUE._col0 = 60)} {(VALUE._col0 > 20)}
                  2 
                keys:
                  0 key (type: int)
                  1 key (type: int)
                  2 key (type: int)
                outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11
                Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                  Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 6 Data size: 39 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5
                          columns.types int:int:int:int:int:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: select /*+ MAPJOIN(a,c)*/ * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(a,c)*/ * from a right outer join a b on (a.key=b.key AND a.value=50 AND b.value=50 AND b.value>10) left outer join a c on (b.key=c.key AND b.value=60 AND b.value>20 AND c.value=60)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	50	100	50	NULL	NULL
NULL	NULL	100	40	NULL	NULL
NULL	NULL	100	60	100	60
PREHOOK: query: -- overlap on a, b
explain extended select * from a full outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
PREHOOK: type: QUERY
POSTHOOK: query: -- overlap on a, b
explain extended select * from a full outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_LEFTOUTERJOIN
         TOK_LEFTOUTERJOIN
            TOK_FULLOUTERJOIN
               TOK_TABREF
                  TOK_TABNAME
                     a
               TOK_TABREF
                  TOK_TABNAME
                     a
                  b
               AND
                  AND
                     =
                        .
                           TOK_TABLE_OR_COL
                              a
                           key
                        .
                           TOK_TABLE_OR_COL
                              b
                           key
                     =
                        .
                           TOK_TABLE_OR_COL
                              a
                           value
                        50
                  =
                     .
                        TOK_TABLE_OR_COL
                           b
                        value
                     50
            TOK_TABREF
               TOK_TABNAME
                  a
               c
            AND
               AND
                  =
                     .
                        TOK_TABLE_OR_COL
                           b
                        key
                     .
                        TOK_TABLE_OR_COL
                           c
                        key
                  =
                     .
                        TOK_TABLE_OR_COL
                           b
                        value
                     60
               =
                  .
                     TOK_TABLE_OR_COL
                        c
                     value
                  60
         TOK_TABREF
            TOK_TABNAME
               a
            d
         AND
            AND
               =
                  .
                     TOK_TABLE_OR_COL
                        a
                     key
                  .
                     TOK_TABLE_OR_COL
                        d
                     key
               =
                  .
                     TOK_TABLE_OR_COL
                        a
                     value
                  40
            =
               .
                  TOK_TABLE_OR_COL
                     d
                  value
               40
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 3 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2), Map 5 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                    tag: 0
                    value expressions: value (type: int)
                    auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [a]
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                    tag: 1
                    value expressions: value (type: int)
                    auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [b]
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 60) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 2
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [c]
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: d
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 40) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 3
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [d]
        Reducer 2 
            Needs Tagging: true
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Outer Join 0 to 1
                     Left Outer Join1 to 2
                     Left Outer Join0 to 3
                filter mappings:
                  0 [1, 1, 3, 1]
                  1 [0, 1, 2, 1]
                filter predicates:
                  0 {(VALUE._col0 = 50)} {(VALUE._col0 = 40)}
                  1 {(VALUE._col0 = 50)} {(VALUE._col0 = 60)}
                  2 
                  3 
                keys:
                  0 key (type: int)
                  1 key (type: int)
                  2 key (type: int)
                  3 key (type: int)
                outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11, _col15, _col16
                Statistics: Num rows: 9 Data size: 59 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int), _col15 (type: int), _col16 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                  Statistics: Num rows: 9 Data size: 59 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 9 Data size: 59 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
                          columns.types int:int:int:int:int:int:int:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a full outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select * from a full outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (b.key=c.key AND b.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	NULL	NULL	NULL	NULL
NULL	NULL	100	40	NULL	NULL	NULL	NULL
NULL	NULL	100	60	100	60	NULL	NULL
PREHOOK: query: -- triple overlap on a
explain extended select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
PREHOOK: type: QUERY
POSTHOOK: query: -- triple overlap on a
explain extended select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_LEFTOUTERJOIN
         TOK_LEFTOUTERJOIN
            TOK_LEFTOUTERJOIN
               TOK_TABREF
                  TOK_TABNAME
                     a
               TOK_TABREF
                  TOK_TABNAME
                     a
                  b
               AND
                  AND
                     =
                        .
                           TOK_TABLE_OR_COL
                              a
                           key
                        .
                           TOK_TABLE_OR_COL
                              b
                           key
                     =
                        .
                           TOK_TABLE_OR_COL
                              a
                           value
                        50
                  =
                     .
                        TOK_TABLE_OR_COL
                           b
                        value
                     50
            TOK_TABREF
               TOK_TABNAME
                  a
               c
            AND
               AND
                  =
                     .
                        TOK_TABLE_OR_COL
                           a
                        key
                     .
                        TOK_TABLE_OR_COL
                           c
                        key
                  =
                     .
                        TOK_TABLE_OR_COL
                           a
                        value
                     60
               =
                  .
                     TOK_TABLE_OR_COL
                        c
                     value
                  60
         TOK_TABREF
            TOK_TABNAME
               a
            d
         AND
            AND
               =
                  .
                     TOK_TABLE_OR_COL
                        a
                     key
                  .
                     TOK_TABLE_OR_COL
                        d
                     key
               =
                  .
                     TOK_TABLE_OR_COL
                        a
                     value
                  40
            =
               .
                  TOK_TABLE_OR_COL
                     d
                  value
               40
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 3 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2), Map 5 (PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: a
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Reduce Output Operator
                    key expressions: key (type: int)
                    sort order: +
                    Map-reduce partition columns: key (type: int)
                    Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                    tag: 0
                    value expressions: value (type: int)
                    auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [a]
        Map 3 
            Map Operator Tree:
                TableScan
                  alias: b
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 50) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 1
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [b]
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: c
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 60) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 2
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [c]
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: d
                  Statistics: Num rows: 3 Data size: 18 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (value = 40) (type: boolean)
                    Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: int)
                      sort order: +
                      Map-reduce partition columns: key (type: int)
                      Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE
                      tag: 3
                      value expressions: value (type: int)
                      auto parallelism: false
            Path -> Alias:
#### A masked pattern was here ####
            Path -> Partition:
#### A masked pattern was here ####
                Partition
                  base file name: a
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE true
                    bucket_count -1
                    columns key,value
                    columns.comments 
                    columns.types int:int
#### A masked pattern was here ####
                    name default.a
                    numFiles 1
                    numRows 3
                    rawDataSize 18
                    serialization.ddl struct a { i32 key, i32 value}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 21
#### A masked pattern was here ####
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE true
                      bucket_count -1
                      columns key,value
                      columns.comments 
                      columns.types int:int
#### A masked pattern was here ####
                      name default.a
                      numFiles 1
                      numRows 3
                      rawDataSize 18
                      serialization.ddl struct a { i32 key, i32 value}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 21
#### A masked pattern was here ####
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.a
                  name: default.a
            Truncated Path -> Alias:
              /a [d]
        Reducer 2 
            Needs Tagging: true
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Outer Join0 to 1
                     Left Outer Join0 to 2
                     Left Outer Join0 to 3
                filter mappings:
                  0 [1, 1, 2, 1, 3, 1]
                filter predicates:
                  0 {(VALUE._col0 = 50)} {(VALUE._col0 = 60)} {(VALUE._col0 = 40)}
                  1 
                  2 
                  3 
                keys:
                  0 key (type: int)
                  1 key (type: int)
                  2 key (type: int)
                  3 key (type: int)
                outputColumnNames: _col0, _col1, _col5, _col6, _col10, _col11, _col15, _col16
                Statistics: Num rows: 9 Data size: 59 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col5 (type: int), _col6 (type: int), _col10 (type: int), _col11 (type: int), _col15 (type: int), _col16 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                  Statistics: Num rows: 9 Data size: 59 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
#### A masked pattern was here ####
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 9 Data size: 59 Basic stats: COMPLETE Column stats: NONE
#### A masked pattern was here ####
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
                          columns.types int:int:int:int:int:int:int:int
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	100	60	NULL	NULL
PREHOOK: query: select /*+ MAPJOIN(b,c, d)*/ * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
PREHOOK: type: QUERY
PREHOOK: Input: default@a
#### A masked pattern was here ####
POSTHOOK: query: select /*+ MAPJOIN(b,c, d)*/ * from a left outer join a b on (a.key=b.key AND a.value=50 AND b.value=50) left outer join a c on (a.key=c.key AND a.value=60 AND c.value=60) left outer join a d on (a.key=d.key AND a.value=40 AND d.value=40)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@a
#### A masked pattern was here ####
100	40	NULL	NULL	NULL	NULL	100	40
100	50	100	50	NULL	NULL	NULL	NULL
100	60	NULL	NULL	100	60	NULL	NULL
