PREHOOK: query: create table abcd (a int, b int, c int, d int)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@abcd
POSTHOOK: query: create table abcd (a int, b int, c int, d int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@abcd
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/in4.txt' INTO TABLE abcd
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@abcd
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/in4.txt' INTO TABLE abcd
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@abcd
PREHOOK: query: select * from abcd
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select * from abcd
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
10	100	45	4
10	100	NULL	5
10	1000	50	1
100	100	10	3
12	100	75	7
12	NULL	80	2
NULL	35	23	6
PREHOOK: query: explain select a, count(distinct b), count(distinct c), sum(d) from abcd group by a
PREHOOK: type: QUERY
POSTHOOK: query: explain select a, count(distinct b), count(distinct c), sum(d) from abcd group by a
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: a (type: int), b (type: int), c (type: int), d (type: int)
                    outputColumnNames: a, b, c, d
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count(DISTINCT b), count(DISTINCT c), sum(d)
                      keys: a (type: int), b (type: int), c (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col5 (type: bigint)
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col1:0._col0), count(DISTINCT KEY._col1:1._col0), sum(VALUE._col2)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a, count(distinct b), count(distinct c), sum(d) from abcd group by a
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select a, count(distinct b), count(distinct c), sum(d) from abcd group by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
10	2	2	10
100	1	1	3
12	1	2	9
NULL	1	1	6
PREHOOK: query: explain select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
PREHOOK: type: QUERY
POSTHOOK: query: explain select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP PARTITION-LEVEL SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: a (type: int), b (type: int), c (type: int), d (type: int)
                    outputColumnNames: a, b, c, d
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count(), count(a), count(b), count(c), count(d), count(DISTINCT a), count(DISTINCT b), count(DISTINCT c), count(DISTINCT d), count(DISTINCT a, b), count(DISTINCT b, c), count(DISTINCT c, d), count(DISTINCT a, d), count(DISTINCT a, c), count(DISTINCT b, d), count(DISTINCT a, b, c), count(DISTINCT b, c, d), count(DISTINCT a, c, d), count(DISTINCT a, b, d), count(DISTINCT a, b, c, d)
                      keys: a (type: int), b (type: int), c (type: int), d (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: int)
                        sort order: ++++
                        Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col4 (type: bigint), _col5 (type: bigint), _col6 (type: bigint), _col7 (type: bigint), _col8 (type: bigint)
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0), count(VALUE._col1), count(VALUE._col2), count(VALUE._col3), count(VALUE._col4), count(DISTINCT KEY._col0:0._col0), count(DISTINCT KEY._col0:1._col0), count(DISTINCT KEY._col0:2._col0), count(DISTINCT KEY._col0:3._col0), count(DISTINCT KEY._col0:4._col0, KEY._col0:4._col1), count(DISTINCT KEY._col0:5._col0, KEY._col0:5._col1), count(DISTINCT KEY._col0:6._col0, KEY._col0:6._col1), count(DISTINCT KEY._col0:7._col0, KEY._col0:7._col1), count(DISTINCT KEY._col0:8._col0, KEY._col0:8._col1), count(DISTINCT KEY._col0:9._col0, KEY._col0:9._col1), count(DISTINCT KEY._col0:10._col0, KEY._col0:10._col1, KEY._col0:10._col2), count(DISTINCT KEY._col0:11._col0, KEY._col0:11._col1, KEY._col0:11._col2), count(DISTINCT KEY._col0:12._col0, KEY._col0:12._col1, KEY._col0:12._col2), count(DISTINCT KEY._col0:13._col0, KEY._col0:13._col1, KEY._col0:13._col2), count(DISTINCT KEY._col0:14._col0, KEY._col0:14._col1, KEY._col0:14._col2, KEY._col0:14._col3)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19
                Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: bigint), _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: bigint), _col7 (type: bigint), _col8 (type: bigint), _col9 (type: bigint), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: bigint), _col15 (type: bigint), _col16 (type: bigint), _col17 (type: bigint), _col18 (type: bigint), _col19 (type: bigint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20
                  Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
7	7	6	6	6	7	3	3	6	7	4	5	6	6	5	6	4	5	5	5	4
PREHOOK: query: explain select a, count(distinct b), count(distinct c), sum(d) from abcd group by a
PREHOOK: type: QUERY
POSTHOOK: query: explain select a, count(distinct b), count(distinct c), sum(d) from abcd group by a
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: a (type: int), b (type: int), c (type: int), d (type: int)
                    outputColumnNames: a, b, c, d
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: a (type: int), b (type: int), c (type: int)
                      sort order: +++
                      Map-reduce partition columns: a (type: int)
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                      value expressions: d (type: int)
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col1:0._col0), count(DISTINCT KEY._col1:1._col0), sum(VALUE._col0)
                keys: KEY._col0 (type: int)
                mode: complete
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a, count(distinct b), count(distinct c), sum(d) from abcd group by a
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select a, count(distinct b), count(distinct c), sum(d) from abcd group by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
10	2	2	10
100	1	1	3
12	1	2	9
NULL	1	1	6
PREHOOK: query: explain select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
PREHOOK: type: QUERY
POSTHOOK: query: explain select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP PARTITION-LEVEL SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: a (type: int), b (type: int), c (type: int), d (type: int)
                    outputColumnNames: a, b, c, d
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: a (type: int), b (type: int), c (type: int), d (type: int)
                      sort order: ++++
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(), count(KEY._col0:0._col0), count(KEY._col0:1._col0), count(KEY._col0:2._col0), count(KEY._col0:3._col0), count(DISTINCT KEY._col0:0._col0), count(DISTINCT KEY._col0:1._col0), count(DISTINCT KEY._col0:2._col0), count(DISTINCT KEY._col0:3._col0), count(DISTINCT KEY._col0:4._col0, KEY._col0:4._col1), count(DISTINCT KEY._col0:5._col0, KEY._col0:5._col1), count(DISTINCT KEY._col0:6._col0, KEY._col0:6._col1), count(DISTINCT KEY._col0:7._col0, KEY._col0:7._col1), count(DISTINCT KEY._col0:8._col0, KEY._col0:8._col1), count(DISTINCT KEY._col0:9._col0, KEY._col0:9._col1), count(DISTINCT KEY._col0:10._col0, KEY._col0:10._col1, KEY._col0:10._col2), count(DISTINCT KEY._col0:11._col0, KEY._col0:11._col1, KEY._col0:11._col2), count(DISTINCT KEY._col0:12._col0, KEY._col0:12._col1, KEY._col0:12._col2), count(DISTINCT KEY._col0:13._col0, KEY._col0:13._col1, KEY._col0:13._col2), count(DISTINCT KEY._col0:14._col0, KEY._col0:14._col1, KEY._col0:14._col2, KEY._col0:14._col3)
                mode: complete
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19
                Statistics: Num rows: 1 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: bigint), _col0 (type: bigint), _col1 (type: bigint), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: bigint), _col6 (type: bigint), _col7 (type: bigint), _col8 (type: bigint), _col9 (type: bigint), _col10 (type: bigint), _col11 (type: bigint), _col12 (type: bigint), _col13 (type: bigint), _col14 (type: bigint), _col15 (type: bigint), _col16 (type: bigint), _col17 (type: bigint), _col18 (type: bigint), _col19 (type: bigint)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20
                  Statistics: Num rows: 1 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
7	7	6	6	6	7	3	3	6	7	4	5	6	6	5	6	4	5	5	5	4
PREHOOK: query: explain select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
PREHOOK: type: QUERY
POSTHOOK: query: explain select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP PARTITION-LEVEL SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: a (type: int), b (type: int), c (type: int), d (type: int)
                    outputColumnNames: a, b, c, d
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count(), count(a), count(b), count(c), count(d), count(DISTINCT a), count(DISTINCT b), count(DISTINCT c), count(DISTINCT d), count(DISTINCT a, b), count(DISTINCT b, c), count(DISTINCT c, d), count(DISTINCT a, d), count(DISTINCT a, c), count(DISTINCT b, d), count(DISTINCT a, b, c), count(DISTINCT b, c, d), count(DISTINCT a, c, d), count(DISTINCT a, b, d), count(DISTINCT a, b, c, d)
                      keys: a (type: int), b (type: int), c (type: int), d (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22, _col23
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col3 (type: int)
                        sort order: ++++
                        Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col4 (type: bigint), _col5 (type: bigint), _col6 (type: bigint), _col7 (type: bigint), _col8 (type: bigint)
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0), count(VALUE._col1), count(VALUE._col2), count(VALUE._col3), count(VALUE._col4), count(DISTINCT KEY._col0:0._col0), count(DISTINCT KEY._col0:1._col0), count(DISTINCT KEY._col0:2._col0), count(DISTINCT KEY._col0:3._col0), count(DISTINCT KEY._col0:4._col0, KEY._col0:4._col1), count(DISTINCT KEY._col0:5._col0, KEY._col0:5._col1), count(DISTINCT KEY._col0:6._col0, KEY._col0:6._col1), count(DISTINCT KEY._col0:7._col0, KEY._col0:7._col1), count(DISTINCT KEY._col0:8._col0, KEY._col0:8._col1), count(DISTINCT KEY._col0:9._col0, KEY._col0:9._col1), count(DISTINCT KEY._col0:10._col0, KEY._col0:10._col1, KEY._col0:10._col2), count(DISTINCT KEY._col0:11._col0, KEY._col0:11._col1, KEY._col0:11._col2), count(DISTINCT KEY._col0:12._col0, KEY._col0:12._col1, KEY._col0:12._col2), count(DISTINCT KEY._col0:13._col0, KEY._col0:13._col1, KEY._col0:13._col2), count(DISTINCT KEY._col0:14._col0, KEY._col0:14._col1, KEY._col0:14._col2, KEY._col0:14._col3)
                mode: mergepartial
                outputColumnNames: $f0, $f1, $f2, $f3, $f4, $f5, $f6, $f7, $f8, $f9, $f10, $f11, $f12, $f13, $f14, $f15, $f16, $f17, $f18, $f19
                Statistics: Num rows: 1 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: $f0 (type: bigint), $f0 (type: bigint), $f1 (type: bigint), $f2 (type: bigint), $f3 (type: bigint), $f4 (type: bigint), $f5 (type: bigint), $f6 (type: bigint), $f7 (type: bigint), $f8 (type: bigint), $f9 (type: bigint), $f10 (type: bigint), $f11 (type: bigint), $f12 (type: bigint), $f13 (type: bigint), $f14 (type: bigint), $f15 (type: bigint), $f16 (type: bigint), $f17 (type: bigint), $f18 (type: bigint), $f19 (type: bigint)
                  outputColumnNames: $f0, $f00, $f1, $f2, $f3, $f4, $f5, $f6, $f7, $f8, $f9, $f10, $f11, $f12, $f13, $f14, $f15, $f16, $f17, $f18, $f19
                  Statistics: Num rows: 1 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 320 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
7	7	6	6	6	7	3	3	6	7	4	5	6	6	5	6	4	5	5	5	4
PREHOOK: query: explain select count(distinct b) from abcd group by a
PREHOOK: type: QUERY
POSTHOOK: query: explain select count(distinct b) from abcd group by a
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP, 2)
        Reducer 3 <- Reducer 2 (GROUP, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: a (type: int), b (type: int)
                    outputColumnNames: a, b
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: a (type: int), b (type: int)
                      sort order: ++
                      Map-reduce partition columns: a (type: int), b (type: int)
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int)
                mode: complete
                outputColumnNames: a, b
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: a (type: int)
                  sort order: +
                  Map-reduce partition columns: a (type: int)
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  value expressions: b (type: int)
        Reducer 3 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: int)
                mode: complete
                outputColumnNames: a, $f1
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: $f1 (type: bigint)
                  outputColumnNames: _o__c0
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(distinct b) from abcd group by a
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select count(distinct b) from abcd group by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
1
1
1
2
PREHOOK: query: explain select count(distinct b) from abcd group by b
PREHOOK: type: QUERY
POSTHOOK: query: explain select count(distinct b) from abcd group by b
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP, 2)
        Reducer 3 <- Reducer 2 (GROUP, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: b (type: int)
                    outputColumnNames: b
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: b (type: int)
                      sort order: +
                      Map-reduce partition columns: b (type: int)
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int)
                mode: complete
                outputColumnNames: b
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: b (type: int)
                  sort order: +
                  Map-reduce partition columns: b (type: int)
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(KEY._col0)
                keys: KEY._col0 (type: int)
                mode: complete
                outputColumnNames: b, $f1
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: $f1 (type: bigint)
                  outputColumnNames: _o__c0
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(distinct b) from abcd group by b
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select count(distinct b) from abcd group by b
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
0
1
1
1
PREHOOK: query: explain select count(distinct b) from abcd group by c
PREHOOK: type: QUERY
POSTHOOK: query: explain select count(distinct b) from abcd group by c
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP, 2)
        Reducer 3 <- Reducer 2 (GROUP, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: b (type: int), c (type: int)
                    outputColumnNames: b, c
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: b (type: int), c (type: int)
                      sort order: ++
                      Map-reduce partition columns: b (type: int), c (type: int)
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: int), KEY._col1 (type: int)
                mode: complete
                outputColumnNames: b, c
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: c (type: int)
                  sort order: +
                  Map-reduce partition columns: c (type: int)
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  value expressions: b (type: int)
        Reducer 3 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: int)
                mode: complete
                outputColumnNames: c, $f1
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: $f1 (type: bigint)
                  outputColumnNames: _o__c0
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(distinct b) from abcd group by c
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select count(distinct b) from abcd group by c
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
0
1
1
1
1
1
1
PREHOOK: query: explain select count(b), count(distinct c) from abcd group by d
PREHOOK: type: QUERY
POSTHOOK: query: explain select count(b), count(distinct c) from abcd group by d
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: b (type: int), c (type: int), d (type: int)
                    outputColumnNames: b, c, d
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: d (type: int), c (type: int)
                      sort order: ++
                      Map-reduce partition columns: d (type: int)
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                      value expressions: b (type: int)
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0), count(DISTINCT KEY._col1:0._col0)
                keys: KEY._col0 (type: int)
                mode: complete
                outputColumnNames: d, $f1, $f2
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: $f1 (type: bigint), $f2 (type: bigint)
                  outputColumnNames: _o__c0, _o__c1
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(b), count(distinct c) from abcd group by d
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select count(b), count(distinct c) from abcd group by d
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
0	1
1	0
1	1
1	1
1	1
1	1
1	1
PREHOOK: query: explain select a, count(distinct b), count(distinct c), sum(d), sum(d+d), sum(d*3), sum(b), sum(c), sum(a), sum(distinct a), sum(distinct b) from abcd group by a
PREHOOK: type: QUERY
POSTHOOK: query: explain select a, count(distinct b), count(distinct c), sum(d), sum(d+d), sum(d*3), sum(b), sum(c), sum(a), sum(distinct a), sum(distinct b) from abcd group by a
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: a (type: int), b (type: int), c (type: int), d (type: int), (d + d) (type: int), (d * 3) (type: int)
                    outputColumnNames: $f0, $f1, $f2, $f3, $f4, $f5
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: $f0 (type: int), $f1 (type: int), $f2 (type: int)
                      sort order: +++
                      Map-reduce partition columns: $f0 (type: int)
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                      value expressions: $f3 (type: int), $f4 (type: int), $f5 (type: int)
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col1:0._col0), count(DISTINCT KEY._col1:1._col0), sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2), sum(KEY._col1:0._col0), sum(KEY._col1:1._col0), sum(KEY._col0), sum(DISTINCT KEY._col1:2._col0), sum(DISTINCT KEY._col1:3._col0)
                keys: KEY._col0 (type: int)
                mode: complete
                outputColumnNames: $f0, $f1, $f2, $f3, $f4, $f5, $f6, $f7, $f8, $f9, $f10
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a, count(distinct b), count(distinct c), sum(d), sum(d+d), sum(d*3), sum(b), sum(c), sum(a), sum(distinct a), sum(distinct b) from abcd group by a
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select a, count(distinct b), count(distinct c), sum(d), sum(d+d), sum(d*3), sum(b), sum(c), sum(a), sum(distinct a), sum(distinct b) from abcd group by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
10	2	2	10	20	30	1200	95	30	10	1100
100	1	1	3	6	9	100	10	100	100	100
12	1	2	9	18	27	100	155	24	12	100
NULL	1	1	6	12	18	35	23	NULL	NULL	35
PREHOOK: query: explain select a, count(distinct b), count(distinct c), sum(d), sum(c) from abcd group by a
PREHOOK: type: QUERY
POSTHOOK: query: explain select a, count(distinct b), count(distinct c), sum(d), sum(c) from abcd group by a
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP PARTITION-LEVEL SORT, 2)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: a (type: int), b (type: int), c (type: int), d (type: int)
                    outputColumnNames: a, b, c, d
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: a (type: int), b (type: int), c (type: int)
                      sort order: +++
                      Map-reduce partition columns: a (type: int)
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                      value expressions: d (type: int)
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(DISTINCT KEY._col1:0._col0), count(DISTINCT KEY._col1:1._col0), sum(VALUE._col0), sum(KEY._col1:1._col0)
                keys: KEY._col0 (type: int)
                mode: complete
                outputColumnNames: a, $f1, $f2, $f3, $f4
                Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select a, count(distinct b), count(distinct c), sum(d), sum(c) from abcd group by a
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select a, count(distinct b), count(distinct c), sum(d), sum(c) from abcd group by a
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
10	2	2	10	95
100	1	1	3	10
12	1	2	9	155
NULL	1	1	6	23
PREHOOK: query: explain select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
PREHOOK: type: QUERY
POSTHOOK: query: explain select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (GROUP PARTITION-LEVEL SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: abcd
                  Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: a (type: int), b (type: int), c (type: int), d (type: int)
                    outputColumnNames: a, b, c, d
                    Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: a (type: int), b (type: int), c (type: int), d (type: int)
                      sort order: ++++
                      Statistics: Num rows: 1 Data size: 780 Basic stats: COMPLETE Column stats: NONE
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(), count(KEY._col0:0._col0), count(KEY._col0:1._col0), count(KEY._col0:2._col0), count(KEY._col0:3._col0), count(DISTINCT KEY._col0:0._col0), count(DISTINCT KEY._col0:1._col0), count(DISTINCT KEY._col0:2._col0), count(DISTINCT KEY._col0:3._col0), count(DISTINCT KEY._col0:4._col0, KEY._col0:4._col1), count(DISTINCT KEY._col0:5._col0, KEY._col0:5._col1), count(DISTINCT KEY._col0:6._col0, KEY._col0:6._col1), count(DISTINCT KEY._col0:7._col0, KEY._col0:7._col1), count(DISTINCT KEY._col0:8._col0, KEY._col0:8._col1), count(DISTINCT KEY._col0:9._col0, KEY._col0:9._col1), count(DISTINCT KEY._col0:10._col0, KEY._col0:10._col1, KEY._col0:10._col2), count(DISTINCT KEY._col0:11._col0, KEY._col0:11._col1, KEY._col0:11._col2), count(DISTINCT KEY._col0:12._col0, KEY._col0:12._col1, KEY._col0:12._col2), count(DISTINCT KEY._col0:13._col0, KEY._col0:13._col1, KEY._col0:13._col2), count(DISTINCT KEY._col0:14._col0, KEY._col0:14._col1, KEY._col0:14._col2, KEY._col0:14._col3)
                mode: complete
                outputColumnNames: $f0, $f1, $f2, $f3, $f4, $f5, $f6, $f7, $f8, $f9, $f10, $f11, $f12, $f13, $f14, $f15, $f16, $f17, $f18, $f19
                Statistics: Num rows: 1 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: $f0 (type: bigint), $f0 (type: bigint), $f1 (type: bigint), $f2 (type: bigint), $f3 (type: bigint), $f4 (type: bigint), $f5 (type: bigint), $f6 (type: bigint), $f7 (type: bigint), $f8 (type: bigint), $f9 (type: bigint), $f10 (type: bigint), $f11 (type: bigint), $f12 (type: bigint), $f13 (type: bigint), $f14 (type: bigint), $f15 (type: bigint), $f16 (type: bigint), $f17 (type: bigint), $f18 (type: bigint), $f19 (type: bigint)
                  outputColumnNames: $f0, $f00, $f1, $f2, $f3, $f4, $f5, $f6, $f7, $f8, $f9, $f10, $f11, $f12, $f13, $f14, $f15, $f16, $f17, $f18, $f19
                  Statistics: Num rows: 1 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 160 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
PREHOOK: type: QUERY
PREHOOK: Input: default@abcd
#### A masked pattern was here ####
POSTHOOK: query: select count(1), count(*), count(a), count(b), count(c), count(d), count(distinct a), count(distinct b), count(distinct c), count(distinct d), count(distinct a,b), count(distinct b,c), count(distinct c,d), count(distinct a,d), count(distinct a,c), count(distinct b,d), count(distinct a,b,c), count(distinct b,c,d), count(distinct a,c,d), count(distinct a,b,d), count(distinct a,b,c,d) from abcd
POSTHOOK: type: QUERY
POSTHOOK: Input: default@abcd
#### A masked pattern was here ####
7	7	6	6	6	7	3	3	6	7	4	5	6	6	5	6	4	5	5	5	4
