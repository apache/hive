PREHOOK: query: explain
select concat(*),array(*) from src where key < 100 limit 10
PREHOOK: type: QUERY
POSTHOOK: query: explain
select concat(*),array(*) from src where key < 100 limit 10
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONSTAR concat)) (TOK_SELEXPR (TOK_FUNCTIONSTAR array))) (TOK_WHERE (< (TOK_TABLE_OR_COL key) 100)) (TOK_LIMIT 10)))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Filter Operator
              predicate:
                  expr: (key < 100)
                  type: boolean
              Select Operator
                expressions:
                      expr: concat(key, value)
                      type: string
                      expr: array(key,value)
                      type: array<string>
                outputColumnNames: _col0, _col1
                Limit
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 10


PREHOOK: query: select concat(*),array(*) from src where key < 100 limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select concat(*),array(*) from src where key < 100 limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
86val_86	["86","val_86"]
27val_27	["27","val_27"]
98val_98	["98","val_98"]
66val_66	["66","val_66"]
37val_37	["37","val_37"]
15val_15	["15","val_15"]
82val_82	["82","val_82"]
17val_17	["17","val_17"]
0val_0	["0","val_0"]
57val_57	["57","val_57"]
PREHOOK: query: -- The order of columns is decided by row schema of prev operator
-- Like join which has two or more aliases, it's from left most aias to right aliases.

explain
select stack(2, *) as (e1,e2,e3) from (
  select concat(*), concat(a.*), concat(b.*), concat(a.*, b.key), concat(a.key, b.*)
  from src a join src b on a.key+1=b.key where a.key < 100) x limit 10
PREHOOK: type: QUERY
POSTHOOK: query: -- The order of columns is decided by row schema of prev operator
-- Like join which has two or more aliases, it's from left most aias to right aliases.

explain
select stack(2, *) as (e1,e2,e3) from (
  select concat(*), concat(a.*), concat(b.*), concat(a.*, b.key), concat(a.key, b.*)
  from src a join src b on a.key+1=b.key where a.key < 100) x limit 10
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME src) a) (TOK_TABREF (TOK_TABNAME src) b) (= (+ (. (TOK_TABLE_OR_COL a) key) 1) (. (TOK_TABLE_OR_COL b) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONSTAR concat)) (TOK_SELEXPR (TOK_FUNCTION concat (TOK_ALLCOLREF (TOK_TABNAME a)))) (TOK_SELEXPR (TOK_FUNCTION concat (TOK_ALLCOLREF (TOK_TABNAME b)))) (TOK_SELEXPR (TOK_FUNCTION concat (TOK_ALLCOLREF (TOK_TABNAME a)) (. (TOK_TABLE_OR_COL b) key))) (TOK_SELEXPR (TOK_FUNCTION concat (. (TOK_TABLE_OR_COL a) key) (TOK_ALLCOLREF (TOK_TABNAME b))))) (TOK_WHERE (< (. (TOK_TABLE_OR_COL a) key) 100)))) x)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION stack 2 TOK_ALLCOLREF) e1 e2 e3)) (TOK_LIMIT 10)))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        x:a 
          TableScan
            alias: a
            Filter Operator
              predicate:
                  expr: (key < 100)
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: (key + 1)
                      type: double
                sort order: +
                Map-reduce partition columns:
                      expr: (key + 1)
                      type: double
                tag: 0
                value expressions:
                      expr: key
                      type: string
                      expr: value
                      type: string
        x:b 
          TableScan
            alias: b
            Reduce Output Operator
              key expressions:
                    expr: UDFToDouble(key)
                    type: double
              sort order: +
              Map-reduce partition columns:
                    expr: UDFToDouble(key)
                    type: double
              tag: 1
              value expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 {VALUE._col0} {VALUE._col1}
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col4, _col5
          Select Operator
            expressions:
                  expr: 2
                  type: int
                  expr: concat(_col0, _col1, _col4, _col5)
                  type: string
                  expr: concat(_col0, _col1)
                  type: string
                  expr: concat(_col4, _col5)
                  type: string
                  expr: concat(_col0, _col1, _col4)
                  type: string
                  expr: concat(_col0, _col4, _col5)
                  type: string
            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
            UDTF Operator
              function name: stack
              Limit
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 10


PREHOOK: query: select stack(2, *) as (e1,e2,e3) from (
  select concat(*), concat(a.*), concat(b.*), concat(a.*, b.key), concat(a.key, b.*)
  from src a join src b on a.key+1=b.key where a.key < 100) x limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select stack(2, *) as (e1,e2,e3) from (
  select concat(*), concat(a.*), concat(b.*), concat(a.*, b.key), concat(a.key, b.*)
  from src a join src b on a.key+1=b.key where a.key < 100) x limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
4val_45val_5	4val_4	5val_5
4val_45	NULL	5val_5
4val_45val_5	4val_4	5val_5
4val_45	NULL	5val_5
4val_45val_5	4val_4	5val_5
4val_45	NULL	5val_5
8val_89val_9	8val_8	9val_9
8val_89	NULL	9val_9
9val_910val_10	9val_9	10val_10
9val_910	NULL	10val_10
PREHOOK: query: -- HIVE-4181 TOK_FUNCTIONSTAR for UDTF
create table allcolref as select array(key, value) from src
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
POSTHOOK: query: -- HIVE-4181 TOK_FUNCTIONSTAR for UDTF
create table allcolref as select array(key, value) from src
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: default@allcolref
PREHOOK: query: explain select explode(*) as x from allcolref limit 10
PREHOOK: type: QUERY
POSTHOOK: query: explain select explode(*) as x from allcolref limit 10
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME allcolref))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONSTAR explode) x)) (TOK_LIMIT 10)))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        allcolref 
          TableScan
            alias: allcolref
            Select Operator
              expressions:
                    expr: _c0
                    type: array<string>
              outputColumnNames: _col0
              UDTF Operator
                function name: explode
                Limit
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 10


PREHOOK: query: select explode(*) as x from allcolref limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@allcolref
#### A masked pattern was here ####
POSTHOOK: query: select explode(*) as x from allcolref limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@allcolref
#### A masked pattern was here ####
238
val_238
86
val_86
311
val_311
27
val_27
165
val_165
