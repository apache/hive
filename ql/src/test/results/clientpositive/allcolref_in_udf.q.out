PREHOOK: query: explain
select concat(*),array(*) from src where key < 100 limit 10
PREHOOK: type: QUERY
POSTHOOK: query: explain
select concat(*),array(*) from src where key < 100 limit 10
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (UDFToDouble(key) < 100.0) (type: boolean)
              Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: concat(key, value) (type: string), array(key,value) (type: array<string>)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 10 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink

PREHOOK: query: select concat(*),array(*) from src where key < 100 limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select concat(*),array(*) from src where key < 100 limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
86val_86	["86","val_86"]
27val_27	["27","val_27"]
98val_98	["98","val_98"]
66val_66	["66","val_66"]
37val_37	["37","val_37"]
15val_15	["15","val_15"]
82val_82	["82","val_82"]
17val_17	["17","val_17"]
0val_0	["0","val_0"]
57val_57	["57","val_57"]
PREHOOK: query: explain
select stack(2, *) as (e1,e2,e3) from (
  select concat(*), concat(a.*), concat(b.*), concat(a.*, b.key), concat(a.key, b.*)
  from src a join src b on a.key+1=b.key where a.key < 100) x limit 10
PREHOOK: type: QUERY
POSTHOOK: query: explain
select stack(2, *) as (e1,e2,e3) from (
  select concat(*), concat(a.*), concat(b.*), concat(a.*, b.key), concat(a.key, b.*)
  from src a join src b on a.key+1=b.key where a.key < 100) x limit 10
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: a
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (UDFToDouble(key) < 100.0) (type: boolean)
              Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: (UDFToDouble(_col0) + 1.0) (type: double)
                  sort order: +
                  Map-reduce partition columns: (UDFToDouble(_col0) + 1.0) (type: double)
                  Statistics: Num rows: 166 Data size: 1763 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: string), _col1 (type: string)
          TableScan
            alias: b
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: UDFToDouble(_col0) (type: double)
                  sort order: +
                  Map-reduce partition columns: UDFToDouble(_col0) (type: double)
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: string), _col1 (type: string)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 (UDFToDouble(_col0) + 1.0) (type: double)
            1 UDFToDouble(_col0) (type: double)
          outputColumnNames: _col0, _col1, _col5, _col6
          Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: 2 (type: int), concat(_col0, _col1, _col5, _col6) (type: string), concat(_col0, _col1) (type: string), concat(_col5, _col6) (type: string), concat(_col0, _col1, _col5) (type: string), concat(_col0, _col5, _col6) (type: string)
            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
            Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
            UDTF Operator
              Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
              function name: stack
              Select Operator
                expressions: col0 (type: string), col1 (type: string), col2 (type: string)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 10 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink

PREHOOK: query: select stack(2, *) as (e1,e2,e3) from (
  select concat(*), concat(a.*), concat(b.*), concat(a.*, b.key), concat(a.key, b.*)
  from src a join src b on a.key+1=b.key where a.key < 100) x limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select stack(2, *) as (e1,e2,e3) from (
  select concat(*), concat(a.*), concat(b.*), concat(a.*, b.key), concat(a.key, b.*)
  from src a join src b on a.key+1=b.key where a.key < 100) x limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
#### A masked pattern was here ####
4val_45val_5	4val_4	5val_5
4val_45	NULL	5val_5
4val_45val_5	4val_4	5val_5
4val_45	NULL	5val_5
4val_45val_5	4val_4	5val_5
4val_45	NULL	5val_5
8val_89val_9	8val_8	9val_9
8val_89	NULL	9val_9
9val_910val_10	9val_9	10val_10
9val_910	NULL	10val_10
PREHOOK: query: create table allcolref as select array(key, value) from src
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
PREHOOK: Output: database:default
PREHOOK: Output: default@allcolref
POSTHOOK: query: create table allcolref as select array(key, value) from src
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: database:default
POSTHOOK: Output: default@allcolref
POSTHOOK: Lineage: allcolref._c0 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: explain select explode(*) as x from allcolref limit 10
PREHOOK: type: QUERY
POSTHOOK: query: explain select explode(*) as x from allcolref limit 10
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: allcolref
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: _c0 (type: array<string>)
              outputColumnNames: _col0
              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
              UDTF Operator
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                function name: explode
                Select Operator
                  expressions: col (type: string)
                  outputColumnNames: _col0
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  Limit
                    Number of rows: 10
                    Statistics: Num rows: 10 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 10 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                      table:
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink

PREHOOK: query: select explode(*) as x from allcolref limit 10
PREHOOK: type: QUERY
PREHOOK: Input: default@allcolref
#### A masked pattern was here ####
POSTHOOK: query: select explode(*) as x from allcolref limit 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@allcolref
#### A masked pattern was here ####
238
val_238
86
val_86
311
val_311
27
val_27
165
val_165
