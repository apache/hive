Warning: Map Join MAPJOIN[94][bigTable=?] in task 'Reducer 3' is a cross product
PREHOOK: query: explain vectorization expression
select  *
from (select avg(ss_list_price) B1_LP
            ,count(ss_list_price) B1_CNT
            ,count(distinct ss_list_price) B1_CNTD
      from store_sales
      where ss_quantity between 0 and 5
        and (ss_list_price between 11 and 11+10 
             or ss_coupon_amt between 460 and 460+1000
             or ss_wholesale_cost between 14 and 14+20)) B1,
     (select avg(ss_list_price) B2_LP
            ,count(ss_list_price) B2_CNT
            ,count(distinct ss_list_price) B2_CNTD
      from store_sales
      where ss_quantity between 6 and 10
        and (ss_list_price between 91 and 91+10
          or ss_coupon_amt between 1430 and 1430+1000
          or ss_wholesale_cost between 32 and 32+20)) B2,
     (select avg(ss_list_price) B3_LP
            ,count(ss_list_price) B3_CNT
            ,count(distinct ss_list_price) B3_CNTD
      from store_sales
      where ss_quantity between 11 and 15
        and (ss_list_price between 66 and 66+10
          or ss_coupon_amt between 920 and 920+1000
          or ss_wholesale_cost between 4 and 4+20)) B3,
     (select avg(ss_list_price) B4_LP
            ,count(ss_list_price) B4_CNT
            ,count(distinct ss_list_price) B4_CNTD
      from store_sales
      where ss_quantity between 16 and 20
        and (ss_list_price between 142 and 142+10
          or ss_coupon_amt between 3054 and 3054+1000
          or ss_wholesale_cost between 80 and 80+20)) B4,
     (select avg(ss_list_price) B5_LP
            ,count(ss_list_price) B5_CNT
            ,count(distinct ss_list_price) B5_CNTD
      from store_sales
      where ss_quantity between 21 and 25
        and (ss_list_price between 135 and 135+10
          or ss_coupon_amt between 14180 and 14180+1000
          or ss_wholesale_cost between 38 and 38+20)) B5,
     (select avg(ss_list_price) B6_LP
            ,count(ss_list_price) B6_CNT
            ,count(distinct ss_list_price) B6_CNTD
      from store_sales
      where ss_quantity between 26 and 30
        and (ss_list_price between 28 and 28+10
          or ss_coupon_amt between 2513 and 2513+1000
          or ss_wholesale_cost between 42 and 42+20)) B6
limit 100
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
select  *
from (select avg(ss_list_price) B1_LP
            ,count(ss_list_price) B1_CNT
            ,count(distinct ss_list_price) B1_CNTD
      from store_sales
      where ss_quantity between 0 and 5
        and (ss_list_price between 11 and 11+10 
             or ss_coupon_amt between 460 and 460+1000
             or ss_wholesale_cost between 14 and 14+20)) B1,
     (select avg(ss_list_price) B2_LP
            ,count(ss_list_price) B2_CNT
            ,count(distinct ss_list_price) B2_CNTD
      from store_sales
      where ss_quantity between 6 and 10
        and (ss_list_price between 91 and 91+10
          or ss_coupon_amt between 1430 and 1430+1000
          or ss_wholesale_cost between 32 and 32+20)) B2,
     (select avg(ss_list_price) B3_LP
            ,count(ss_list_price) B3_CNT
            ,count(distinct ss_list_price) B3_CNTD
      from store_sales
      where ss_quantity between 11 and 15
        and (ss_list_price between 66 and 66+10
          or ss_coupon_amt between 920 and 920+1000
          or ss_wholesale_cost between 4 and 4+20)) B3,
     (select avg(ss_list_price) B4_LP
            ,count(ss_list_price) B4_CNT
            ,count(distinct ss_list_price) B4_CNTD
      from store_sales
      where ss_quantity between 16 and 20
        and (ss_list_price between 142 and 142+10
          or ss_coupon_amt between 3054 and 3054+1000
          or ss_wholesale_cost between 80 and 80+20)) B4,
     (select avg(ss_list_price) B5_LP
            ,count(ss_list_price) B5_CNT
            ,count(distinct ss_list_price) B5_CNTD
      from store_sales
      where ss_quantity between 21 and 25
        and (ss_list_price between 135 and 135+10
          or ss_coupon_amt between 14180 and 14180+1000
          or ss_wholesale_cost between 38 and 38+20)) B5,
     (select avg(ss_list_price) B6_LP
            ,count(ss_list_price) B6_CNT
            ,count(distinct ss_list_price) B6_CNTD
      from store_sales
      where ss_quantity between 26 and 30
        and (ss_list_price between 28 and 28+10
          or ss_coupon_amt between 2513 and 2513+1000
          or ss_wholesale_cost between 42 and 42+20)) B6
limit 100
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 10 <- Map 1 (SIMPLE_EDGE)
        Reducer 11 <- Reducer 10 (CUSTOM_SIMPLE_EDGE)
        Reducer 12 <- Map 1 (SIMPLE_EDGE)
        Reducer 13 <- Reducer 12 (CUSTOM_SIMPLE_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 11 (BROADCAST_EDGE), Reducer 13 (BROADCAST_EDGE), Reducer 2 (CUSTOM_SIMPLE_EDGE), Reducer 5 (BROADCAST_EDGE), Reducer 7 (BROADCAST_EDGE), Reducer 9 (BROADCAST_EDGE)
        Reducer 4 <- Map 1 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 4 (CUSTOM_SIMPLE_EDGE)
        Reducer 6 <- Map 1 (SIMPLE_EDGE)
        Reducer 7 <- Reducer 6 (CUSTOM_SIMPLE_EDGE)
        Reducer 8 <- Map 1 (SIMPLE_EDGE)
        Reducer 9 <- Reducer 8 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: store_sales
                  filterExpr: ((ss_quantity BETWEEN 0 AND 5 and (ss_list_price BETWEEN 11 AND 21 or ss_coupon_amt BETWEEN 460 AND 1460 or ss_wholesale_cost BETWEEN 14 AND 34)) or (ss_quantity BETWEEN 26 AND 30 and (ss_list_price BETWEEN 28 AND 38 or ss_coupon_amt BETWEEN 2513 AND 3513 or ss_wholesale_cost BETWEEN 42 AND 62)) or (ss_quantity BETWEEN 21 AND 25 and (ss_list_price BETWEEN 135 AND 145 or ss_coupon_amt BETWEEN 14180 AND 15180 or ss_wholesale_cost BETWEEN 38 AND 58)) or (ss_quantity BETWEEN 16 AND 20 and (ss_list_price BETWEEN 142 AND 152 or ss_coupon_amt BETWEEN 3054 AND 4054 or ss_wholesale_cost BETWEEN 80 AND 100)) or (ss_quantity BETWEEN 11 AND 15 and (ss_list_price BETWEEN 66 AND 76 or ss_coupon_amt BETWEEN 920 AND 1920 or ss_wholesale_cost BETWEEN 4 AND 24)) or (ss_quantity BETWEEN 6 AND 10 and (ss_list_price BETWEEN 91 AND 101 or ss_coupon_amt BETWEEN 1430 AND 2430 or ss_wholesale_cost BETWEEN 32 AND 52))) (type: boolean)
                  Statistics: Num rows: 575995635 Data size: 50814502088 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColumnBetween(col 10:int, left 0, right 5), FilterExprOrExpr(children: FilterDecimal64ColumnBetween(col 12:decimal(7,2)/DECIMAL_64, decimal64LeftVal 1100, decimalLeftVal 1100, decimal64RightVal 2100, decimalRightVal 2100), FilterDecimal64ColumnBetween(col 19:decimal(7,2)/DECIMAL_64, decimal64LeftVal 46000, decimalLeftVal 46000, decimal64RightVal 146000, decimalRightVal 146000), FilterDecimal64ColumnBetween(col 11:decimal(7,2)/DECIMAL_64, decimal64LeftVal 1400, decimalLeftVal 1400, decimal64RightVal 3400, decimalRightVal 3400)))
                    predicate: ((ss_list_price BETWEEN 11 AND 21 or ss_coupon_amt BETWEEN 460 AND 1460 or ss_wholesale_cost BETWEEN 14 AND 34) and ss_quantity BETWEEN 0 AND 5) (type: boolean)
                    Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ss_list_price (type: decimal(7,2))
                      outputColumnNames: ss_list_price
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [12]
                      Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(ss_list_price), count(ss_list_price)
                        Group By Vectorization:
                            aggregators: VectorUDAFSumDecimal64(col 12:decimal(7,2)/DECIMAL_64) -> decimal(17,2)/DECIMAL_64, VectorUDAFCount(col 12:decimal(7,2)/DECIMAL_64) -> bigint
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 12:decimal(7,2)/DECIMAL_64
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: [0, 1]
                        keys: ss_list_price (type: decimal(7,2))
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: decimal(7,2))
                          sort order: +
                          Map-reduce partition columns: _col0 (type: decimal(7,2))
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkMultiKeyOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: decimal(17,2)), _col2 (type: bigint)
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColumnBetween(col 10:int, left 26, right 30), FilterExprOrExpr(children: FilterDecimal64ColumnBetween(col 12:decimal(7,2)/DECIMAL_64, decimal64LeftVal 2800, decimalLeftVal 2800, decimal64RightVal 3800, decimalRightVal 3800), FilterDecimal64ColumnBetween(col 19:decimal(7,2)/DECIMAL_64, decimal64LeftVal 251300, decimalLeftVal 251300, decimal64RightVal 351300, decimalRightVal 351300), FilterDecimal64ColumnBetween(col 11:decimal(7,2)/DECIMAL_64, decimal64LeftVal 4200, decimalLeftVal 4200, decimal64RightVal 6200, decimalRightVal 6200)))
                    predicate: ((ss_list_price BETWEEN 28 AND 38 or ss_coupon_amt BETWEEN 2513 AND 3513 or ss_wholesale_cost BETWEEN 42 AND 62) and ss_quantity BETWEEN 26 AND 30) (type: boolean)
                    Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ss_list_price (type: decimal(7,2))
                      outputColumnNames: ss_list_price
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [12]
                      Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(ss_list_price), count(ss_list_price)
                        Group By Vectorization:
                            aggregators: VectorUDAFSumDecimal64(col 12:decimal(7,2)/DECIMAL_64) -> decimal(17,2)/DECIMAL_64, VectorUDAFCount(col 12:decimal(7,2)/DECIMAL_64) -> bigint
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 12:decimal(7,2)/DECIMAL_64
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: [0, 1]
                        keys: ss_list_price (type: decimal(7,2))
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: decimal(7,2))
                          sort order: +
                          Map-reduce partition columns: _col0 (type: decimal(7,2))
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkMultiKeyOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: decimal(17,2)), _col2 (type: bigint)
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColumnBetween(col 10:int, left 21, right 25), FilterExprOrExpr(children: FilterDecimal64ColumnBetween(col 12:decimal(7,2)/DECIMAL_64, decimal64LeftVal 13500, decimalLeftVal 13500, decimal64RightVal 14500, decimalRightVal 14500), FilterDecimal64ColumnBetween(col 19:decimal(7,2)/DECIMAL_64, decimal64LeftVal 1418000, decimalLeftVal 1418000, decimal64RightVal 1518000, decimalRightVal 1518000), FilterDecimal64ColumnBetween(col 11:decimal(7,2)/DECIMAL_64, decimal64LeftVal 3800, decimalLeftVal 3800, decimal64RightVal 5800, decimalRightVal 5800)))
                    predicate: ((ss_list_price BETWEEN 135 AND 145 or ss_coupon_amt BETWEEN 14180 AND 15180 or ss_wholesale_cost BETWEEN 38 AND 58) and ss_quantity BETWEEN 21 AND 25) (type: boolean)
                    Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ss_list_price (type: decimal(7,2))
                      outputColumnNames: ss_list_price
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [12]
                      Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(ss_list_price), count(ss_list_price)
                        Group By Vectorization:
                            aggregators: VectorUDAFSumDecimal64(col 12:decimal(7,2)/DECIMAL_64) -> decimal(17,2)/DECIMAL_64, VectorUDAFCount(col 12:decimal(7,2)/DECIMAL_64) -> bigint
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 12:decimal(7,2)/DECIMAL_64
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: [0, 1]
                        keys: ss_list_price (type: decimal(7,2))
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: decimal(7,2))
                          sort order: +
                          Map-reduce partition columns: _col0 (type: decimal(7,2))
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkMultiKeyOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: decimal(17,2)), _col2 (type: bigint)
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColumnBetween(col 10:int, left 16, right 20), FilterExprOrExpr(children: FilterDecimal64ColumnBetween(col 12:decimal(7,2)/DECIMAL_64, decimal64LeftVal 14200, decimalLeftVal 14200, decimal64RightVal 15200, decimalRightVal 15200), FilterDecimal64ColumnBetween(col 19:decimal(7,2)/DECIMAL_64, decimal64LeftVal 305400, decimalLeftVal 305400, decimal64RightVal 405400, decimalRightVal 405400), FilterDecimal64ColumnBetween(col 11:decimal(7,2)/DECIMAL_64, decimal64LeftVal 8000, decimalLeftVal 8000, decimal64RightVal 10000, decimalRightVal 10000)))
                    predicate: ((ss_list_price BETWEEN 142 AND 152 or ss_coupon_amt BETWEEN 3054 AND 4054 or ss_wholesale_cost BETWEEN 80 AND 100) and ss_quantity BETWEEN 16 AND 20) (type: boolean)
                    Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ss_list_price (type: decimal(7,2))
                      outputColumnNames: ss_list_price
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [12]
                      Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(ss_list_price), count(ss_list_price)
                        Group By Vectorization:
                            aggregators: VectorUDAFSumDecimal64(col 12:decimal(7,2)/DECIMAL_64) -> decimal(17,2)/DECIMAL_64, VectorUDAFCount(col 12:decimal(7,2)/DECIMAL_64) -> bigint
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 12:decimal(7,2)/DECIMAL_64
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: [0, 1]
                        keys: ss_list_price (type: decimal(7,2))
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: decimal(7,2))
                          sort order: +
                          Map-reduce partition columns: _col0 (type: decimal(7,2))
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkMultiKeyOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: decimal(17,2)), _col2 (type: bigint)
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColumnBetween(col 10:int, left 11, right 15), FilterExprOrExpr(children: FilterDecimal64ColumnBetween(col 12:decimal(7,2)/DECIMAL_64, decimal64LeftVal 6600, decimalLeftVal 6600, decimal64RightVal 7600, decimalRightVal 7600), FilterDecimal64ColumnBetween(col 19:decimal(7,2)/DECIMAL_64, decimal64LeftVal 92000, decimalLeftVal 92000, decimal64RightVal 192000, decimalRightVal 192000), FilterDecimal64ColumnBetween(col 11:decimal(7,2)/DECIMAL_64, decimal64LeftVal 400, decimalLeftVal 400, decimal64RightVal 2400, decimalRightVal 2400)))
                    predicate: ((ss_list_price BETWEEN 66 AND 76 or ss_coupon_amt BETWEEN 920 AND 1920 or ss_wholesale_cost BETWEEN 4 AND 24) and ss_quantity BETWEEN 11 AND 15) (type: boolean)
                    Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ss_list_price (type: decimal(7,2))
                      outputColumnNames: ss_list_price
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [12]
                      Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(ss_list_price), count(ss_list_price)
                        Group By Vectorization:
                            aggregators: VectorUDAFSumDecimal64(col 12:decimal(7,2)/DECIMAL_64) -> decimal(17,2)/DECIMAL_64, VectorUDAFCount(col 12:decimal(7,2)/DECIMAL_64) -> bigint
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 12:decimal(7,2)/DECIMAL_64
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: [0, 1]
                        keys: ss_list_price (type: decimal(7,2))
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: decimal(7,2))
                          sort order: +
                          Map-reduce partition columns: _col0 (type: decimal(7,2))
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkMultiKeyOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: decimal(17,2)), _col2 (type: bigint)
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColumnBetween(col 10:int, left 6, right 10), FilterExprOrExpr(children: FilterDecimal64ColumnBetween(col 12:decimal(7,2)/DECIMAL_64, decimal64LeftVal 9100, decimalLeftVal 9100, decimal64RightVal 10100, decimalRightVal 10100), FilterDecimal64ColumnBetween(col 19:decimal(7,2)/DECIMAL_64, decimal64LeftVal 143000, decimalLeftVal 143000, decimal64RightVal 243000, decimalRightVal 243000), FilterDecimal64ColumnBetween(col 11:decimal(7,2)/DECIMAL_64, decimal64LeftVal 3200, decimalLeftVal 3200, decimal64RightVal 5200, decimalRightVal 5200)))
                    predicate: ((ss_list_price BETWEEN 91 AND 101 or ss_coupon_amt BETWEEN 1430 AND 2430 or ss_wholesale_cost BETWEEN 32 AND 52) and ss_quantity BETWEEN 6 AND 10) (type: boolean)
                    Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ss_list_price (type: decimal(7,2))
                      outputColumnNames: ss_list_price
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [12]
                      Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(ss_list_price), count(ss_list_price)
                        Group By Vectorization:
                            aggregators: VectorUDAFSumDecimal64(col 12:decimal(7,2)/DECIMAL_64) -> decimal(17,2)/DECIMAL_64, VectorUDAFCount(col 12:decimal(7,2)/DECIMAL_64) -> bigint
                            className: VectorGroupByOperator
                            groupByMode: HASH
                            keyExpressions: col 12:decimal(7,2)/DECIMAL_64
                            native: false
                            vectorProcessingMode: HASH
                            projectedOutputColumnNums: [0, 1]
                        keys: ss_list_price (type: decimal(7,2))
                        mode: hash
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: decimal(7,2))
                          sort order: +
                          Map-reduce partition columns: _col0 (type: decimal(7,2))
                          Reduce Sink Vectorization:
                              className: VectorReduceSinkMultiKeyOperator
                              native: true
                              nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: decimal(17,2)), _col2 (type: bigint)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 10 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: PARTIAL2
                    keyExpressions: col 0:decimal(7,2)
                    native: false
                    vectorProcessingMode: STREAMING
                    projectedOutputColumnNums: [0, 1]
                keys: KEY._col0 (type: decimal(7,2))
                mode: partial2
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: sum(_col1), count(_col2), count(_col0)
                  Group By Vectorization:
                      aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint, VectorUDAFCount(col 0:decimal(7,2)) -> bigint
                      className: VectorGroupByOperator
                      groupByMode: PARTIAL2
                      native: false
                      vectorProcessingMode: STREAMING
                      projectedOutputColumnNums: [0, 1, 2]
                  mode: partial2
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(17,2)), _col1 (type: bigint), _col2 (type: bigint)
        Reducer 11 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), count(VALUE._col2)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 0:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 1:bigint) -> bigint, VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    native: false
                    vectorProcessingMode: GLOBAL
                    projectedOutputColumnNums: [0, 1, 2]
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: (_col0 / _col1) (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)
                  outputColumnNames: _col0, _col1, _col2
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumnNums: [4, 1, 2]
                      selectExpressions: DecimalColDivideDecimalColumn(col 0:decimal(17,2), col 3:decimal(19,0))(children: CastLongToDecimal(col 1:bigint) -> 3:decimal(19,0)) -> 4:decimal(37,22)
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)
        Reducer 12 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: PARTIAL2
                    keyExpressions: col 0:decimal(7,2)
                    native: false
                    vectorProcessingMode: STREAMING
                    projectedOutputColumnNums: [0, 1]
                keys: KEY._col0 (type: decimal(7,2))
                mode: partial2
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: sum(_col1), count(_col2), count(_col0)
                  Group By Vectorization:
                      aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint, VectorUDAFCount(col 0:decimal(7,2)) -> bigint
                      className: VectorGroupByOperator
                      groupByMode: PARTIAL2
                      native: false
                      vectorProcessingMode: STREAMING
                      projectedOutputColumnNums: [0, 1, 2]
                  mode: partial2
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(17,2)), _col1 (type: bigint), _col2 (type: bigint)
        Reducer 13 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), count(VALUE._col2)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 0:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 1:bigint) -> bigint, VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    native: false
                    vectorProcessingMode: GLOBAL
                    projectedOutputColumnNums: [0, 1, 2]
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: (_col0 / _col1) (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)
                  outputColumnNames: _col0, _col1, _col2
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumnNums: [4, 1, 2]
                      selectExpressions: DecimalColDivideDecimalColumn(col 0:decimal(17,2), col 3:decimal(19,0))(children: CastLongToDecimal(col 1:bigint) -> 3:decimal(19,0)) -> 4:decimal(37,22)
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)
        Reducer 2 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: PARTIAL2
                    keyExpressions: col 0:decimal(7,2)
                    native: false
                    vectorProcessingMode: STREAMING
                    projectedOutputColumnNums: [0, 1]
                keys: KEY._col0 (type: decimal(7,2))
                mode: partial2
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: sum(_col1), count(_col2), count(_col0)
                  Group By Vectorization:
                      aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint, VectorUDAFCount(col 0:decimal(7,2)) -> bigint
                      className: VectorGroupByOperator
                      groupByMode: PARTIAL2
                      native: false
                      vectorProcessingMode: STREAMING
                      projectedOutputColumnNums: [0, 1, 2]
                  mode: partial2
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(17,2)), _col1 (type: bigint), _col2 (type: bigint)
        Reducer 3 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), count(VALUE._col2)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 0:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 1:bigint) -> bigint, VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    native: false
                    vectorProcessingMode: GLOBAL
                    projectedOutputColumnNums: [0, 1, 2]
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: (_col0 / _col1) (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)
                  outputColumnNames: _col0, _col1, _col2
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumnNums: [4, 1, 2]
                      selectExpressions: DecimalColDivideDecimalColumn(col 0:decimal(17,2), col 3:decimal(19,0))(children: CastLongToDecimal(col 1:bigint) -> 3:decimal(19,0)) -> 4:decimal(37,22)
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Map Join Operator
                    condition map:
                         Inner Join 0 to 1
                         Inner Join 0 to 2
                         Inner Join 0 to 3
                         Inner Join 0 to 4
                         Inner Join 0 to 5
                    keys:
                      0 
                      1 
                      2 
                      3 
                      4 
                      5 
                    Map Join Vectorization:
                        bigTableValueExpressions: col 4:decimal(37,22), col 1:bigint, col 2:bigint
                        className: VectorMapJoinOperator
                        native: false
                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                        nativeConditionsNotMet: One MapJoin Condition IS false
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                    input vertices:
                      1 Reducer 5
                      2 Reducer 7
                      3 Reducer 9
                      4 Reducer 11
                      5 Reducer 13
                    Statistics: Num rows: 1 Data size: 1393 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint), _col15 (type: decimal(37,22)), _col16 (type: bigint), _col17 (type: bigint), _col12 (type: decimal(37,22)), _col13 (type: bigint), _col14 (type: bigint), _col9 (type: decimal(37,22)), _col10 (type: bigint), _col11 (type: bigint), _col6 (type: decimal(37,22)), _col7 (type: bigint), _col8 (type: bigint), _col3 (type: decimal(37,22)), _col4 (type: bigint), _col5 (type: bigint)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1, 2, 15, 16, 17, 12, 13, 14, 9, 10, 11, 6, 7, 8, 3, 4, 5]
                      Statistics: Num rows: 1 Data size: 1393 Basic stats: COMPLETE Column stats: NONE
                      Limit
                        Number of rows: 100
                        Limit Vectorization:
                            className: VectorLimitOperator
                            native: true
                        Statistics: Num rows: 1 Data size: 1393 Basic stats: COMPLETE Column stats: NONE
                        File Output Operator
                          compressed: false
                          File Sink Vectorization:
                              className: VectorFileSinkOperator
                              native: false
                          Statistics: Num rows: 1 Data size: 1393 Basic stats: COMPLETE Column stats: NONE
                          table:
                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 4 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: PARTIAL2
                    keyExpressions: col 0:decimal(7,2)
                    native: false
                    vectorProcessingMode: STREAMING
                    projectedOutputColumnNums: [0, 1]
                keys: KEY._col0 (type: decimal(7,2))
                mode: partial2
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: sum(_col1), count(_col2), count(_col0)
                  Group By Vectorization:
                      aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint, VectorUDAFCount(col 0:decimal(7,2)) -> bigint
                      className: VectorGroupByOperator
                      groupByMode: PARTIAL2
                      native: false
                      vectorProcessingMode: STREAMING
                      projectedOutputColumnNums: [0, 1, 2]
                  mode: partial2
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(17,2)), _col1 (type: bigint), _col2 (type: bigint)
        Reducer 5 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), count(VALUE._col2)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 0:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 1:bigint) -> bigint, VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    native: false
                    vectorProcessingMode: GLOBAL
                    projectedOutputColumnNums: [0, 1, 2]
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: (_col0 / _col1) (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)
                  outputColumnNames: _col0, _col1, _col2
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumnNums: [4, 1, 2]
                      selectExpressions: DecimalColDivideDecimalColumn(col 0:decimal(17,2), col 3:decimal(19,0))(children: CastLongToDecimal(col 1:bigint) -> 3:decimal(19,0)) -> 4:decimal(37,22)
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)
        Reducer 6 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: PARTIAL2
                    keyExpressions: col 0:decimal(7,2)
                    native: false
                    vectorProcessingMode: STREAMING
                    projectedOutputColumnNums: [0, 1]
                keys: KEY._col0 (type: decimal(7,2))
                mode: partial2
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: sum(_col1), count(_col2), count(_col0)
                  Group By Vectorization:
                      aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint, VectorUDAFCount(col 0:decimal(7,2)) -> bigint
                      className: VectorGroupByOperator
                      groupByMode: PARTIAL2
                      native: false
                      vectorProcessingMode: STREAMING
                      projectedOutputColumnNums: [0, 1, 2]
                  mode: partial2
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(17,2)), _col1 (type: bigint), _col2 (type: bigint)
        Reducer 7 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), count(VALUE._col2)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 0:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 1:bigint) -> bigint, VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    native: false
                    vectorProcessingMode: GLOBAL
                    projectedOutputColumnNums: [0, 1, 2]
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: (_col0 / _col1) (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)
                  outputColumnNames: _col0, _col1, _col2
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumnNums: [4, 1, 2]
                      selectExpressions: DecimalColDivideDecimalColumn(col 0:decimal(17,2), col 3:decimal(19,0))(children: CastLongToDecimal(col 1:bigint) -> 3:decimal(19,0)) -> 4:decimal(37,22)
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)
        Reducer 8 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: PARTIAL2
                    keyExpressions: col 0:decimal(7,2)
                    native: false
                    vectorProcessingMode: STREAMING
                    projectedOutputColumnNums: [0, 1]
                keys: KEY._col0 (type: decimal(7,2))
                mode: partial2
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 21333171 Data size: 1882018537 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: sum(_col1), count(_col2), count(_col0)
                  Group By Vectorization:
                      aggregators: VectorUDAFSumDecimal(col 1:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 2:bigint) -> bigint, VectorUDAFCount(col 0:decimal(7,2)) -> bigint
                      className: VectorGroupByOperator
                      groupByMode: PARTIAL2
                      native: false
                      vectorProcessingMode: STREAMING
                      projectedOutputColumnNums: [0, 1, 2]
                  mode: partial2
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(17,2)), _col1 (type: bigint), _col2 (type: bigint)
        Reducer 9 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), count(VALUE._col2)
                Group By Vectorization:
                    aggregators: VectorUDAFSumDecimal(col 0:decimal(17,2)) -> decimal(17,2), VectorUDAFCountMerge(col 1:bigint) -> bigint, VectorUDAFCountMerge(col 2:bigint) -> bigint
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    native: false
                    vectorProcessingMode: GLOBAL
                    projectedOutputColumnNums: [0, 1, 2]
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: (_col0 / _col1) (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)
                  outputColumnNames: _col0, _col1, _col2
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumnNums: [4, 1, 2]
                      selectExpressions: DecimalColDivideDecimalColumn(col 0:decimal(17,2), col 3:decimal(19,0))(children: CastLongToDecimal(col 1:bigint) -> 3:decimal(19,0)) -> 4:decimal(37,22)
                  Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Reduce Sink Vectorization:
                        className: VectorReduceSinkEmptyKeyOperator
                        native: true
                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                    Statistics: Num rows: 1 Data size: 232 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: decimal(37,22)), _col1 (type: bigint), _col2 (type: bigint)

  Stage: Stage-0
    Fetch Operator
      limit: 100
      Processor Tree:
        ListSink

