PREHOOK: query: explain vectorization expression
with inv as
(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
       ,stdev,mean, case mean when 0 then null else stdev/mean end cov
 from(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
            ,stddev_samp(inv_quantity_on_hand) stdev,avg(inv_quantity_on_hand) mean
      from inventory
          ,item
          ,warehouse
          ,date_dim
      where inv_item_sk = i_item_sk
        and inv_warehouse_sk = w_warehouse_sk
        and inv_date_sk = d_date_sk
        and d_year =1999
      group by w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy) foo
 where case mean when 0 then 0 else stdev/mean end > 1)
select inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean, inv1.cov
        ,inv2.w_warehouse_sk,inv2.i_item_sk,inv2.d_moy,inv2.mean, inv2.cov
from inv inv1,inv inv2
where inv1.i_item_sk = inv2.i_item_sk
  and inv1.w_warehouse_sk =  inv2.w_warehouse_sk
  and inv1.d_moy=4
  and inv2.d_moy=4+1
order by inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean,inv1.cov
        ,inv2.d_moy,inv2.mean, inv2.cov
PREHOOK: type: QUERY
POSTHOOK: query: explain vectorization expression
with inv as
(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
       ,stdev,mean, case mean when 0 then null else stdev/mean end cov
 from(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
            ,stddev_samp(inv_quantity_on_hand) stdev,avg(inv_quantity_on_hand) mean
      from inventory
          ,item
          ,warehouse
          ,date_dim
      where inv_item_sk = i_item_sk
        and inv_warehouse_sk = w_warehouse_sk
        and inv_date_sk = d_date_sk
        and d_year =1999
      group by w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy) foo
 where case mean when 0 then 0 else stdev/mean end > 1)
select inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean, inv1.cov
        ,inv2.w_warehouse_sk,inv2.i_item_sk,inv2.d_moy,inv2.mean, inv2.cov
from inv inv1,inv inv2
where inv1.i_item_sk = inv2.i_item_sk
  and inv1.w_warehouse_sk =  inv2.w_warehouse_sk
  and inv1.d_moy=4
  and inv2.d_moy=4+1
order by inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean,inv1.cov
        ,inv2.d_moy,inv2.mean, inv2.cov
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-3 depends on stages: Stage-2
  Stage-1 depends on stages: Stage-3
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 9 
            Map Operator Tree:
                TableScan
                  alias: warehouse
                  filterExpr: w_warehouse_sk is not null (type: boolean)
                  Statistics: Num rows: 27 Data size: 27802 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: w_warehouse_sk is not null (type: boolean)
                    Statistics: Num rows: 27 Data size: 27802 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: w_warehouse_sk (type: int), w_warehouse_name (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 2]
                      Statistics: Num rows: 27 Data size: 27802 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        Spark Hash Table Sink Vectorization:
                            className: VectorSparkHashTableSinkOperator
                            native: true
                        keys:
                          0 _col2 (type: int)
                          1 _col0 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
            Local Work:
              Map Reduce Local Work

  Stage: Stage-3
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 16 
            Map Operator Tree:
                TableScan
                  alias: warehouse
                  filterExpr: w_warehouse_sk is not null (type: boolean)
                  Statistics: Num rows: 27 Data size: 27802 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: w_warehouse_sk is not null (type: boolean)
                    Statistics: Num rows: 27 Data size: 27802 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: w_warehouse_sk (type: int), w_warehouse_name (type: string)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 2]
                      Statistics: Num rows: 27 Data size: 27802 Basic stats: COMPLETE Column stats: NONE
                      Spark HashTable Sink Operator
                        Spark Hash Table Sink Vectorization:
                            className: VectorSparkHashTableSinkOperator
                            native: true
                        keys:
                          0 _col2 (type: int)
                          1 _col0 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
      Edges:
        Reducer 11 <- Map 10 (PARTITION-LEVEL SORT, 5), Map 14 (PARTITION-LEVEL SORT, 5)
        Reducer 12 <- Map 15 (PARTITION-LEVEL SORT, 11), Reducer 11 (PARTITION-LEVEL SORT, 11)
        Reducer 13 <- Reducer 12 (GROUP, 7)
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 5), Map 7 (PARTITION-LEVEL SORT, 5)
        Reducer 3 <- Map 8 (PARTITION-LEVEL SORT, 11), Reducer 2 (PARTITION-LEVEL SORT, 11)
        Reducer 4 <- Reducer 3 (GROUP, 7)
        Reducer 5 <- Reducer 13 (PARTITION-LEVEL SORT, 4), Reducer 4 (PARTITION-LEVEL SORT, 4)
        Reducer 6 <- Reducer 5 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: inventory
                  filterExpr: (inv_item_sk is not null and inv_warehouse_sk is not null and inv_date_sk is not null) (type: boolean)
                  Statistics: Num rows: 37584000 Data size: 593821104 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: SelectColumnIsNotNull(col 1:int), SelectColumnIsNotNull(col 2:int), SelectColumnIsNotNull(col 0:int))
                    predicate: (inv_date_sk is not null and inv_item_sk is not null and inv_warehouse_sk is not null) (type: boolean)
                    Statistics: Num rows: 37584000 Data size: 593821104 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: inv_date_sk (type: int), inv_item_sk (type: int), inv_warehouse_sk (type: int), inv_quantity_on_hand (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1, 2, 3]
                      Statistics: Num rows: 37584000 Data size: 593821104 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        Statistics: Num rows: 37584000 Data size: 593821104 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 10 
            Map Operator Tree:
                TableScan
                  alias: inventory
                  filterExpr: (inv_item_sk is not null and inv_warehouse_sk is not null and inv_date_sk is not null) (type: boolean)
                  Statistics: Num rows: 37584000 Data size: 593821104 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: SelectColumnIsNotNull(col 1:int), SelectColumnIsNotNull(col 2:int), SelectColumnIsNotNull(col 0:int))
                    predicate: (inv_date_sk is not null and inv_item_sk is not null and inv_warehouse_sk is not null) (type: boolean)
                    Statistics: Num rows: 37584000 Data size: 593821104 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: inv_date_sk (type: int), inv_item_sk (type: int), inv_warehouse_sk (type: int), inv_quantity_on_hand (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1, 2, 3]
                      Statistics: Num rows: 37584000 Data size: 593821104 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        Statistics: Num rows: 37584000 Data size: 593821104 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int)
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 14 
            Map Operator Tree:
                TableScan
                  alias: date_dim
                  filterExpr: ((d_year = 1999) and (d_moy = 5) and d_date_sk is not null) (type: boolean)
                  Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColEqualLongScalar(col 6:int, val 1999), FilterLongColEqualLongScalar(col 8:int, val 5), SelectColumnIsNotNull(col 0:int))
                    predicate: ((d_moy = 5) and (d_year = 1999) and d_date_sk is not null) (type: boolean)
                    Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: d_date_sk (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 15 
            Map Operator Tree:
                TableScan
                  alias: item
                  filterExpr: i_item_sk is not null (type: boolean)
                  Statistics: Num rows: 462000 Data size: 663560457 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: i_item_sk is not null (type: boolean)
                    Statistics: Num rows: 462000 Data size: 663560457 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: i_item_sk (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 462000 Data size: 663560457 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        Statistics: Num rows: 462000 Data size: 663560457 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 7 
            Map Operator Tree:
                TableScan
                  alias: date_dim
                  filterExpr: ((d_year = 1999) and (d_moy = 4) and d_date_sk is not null) (type: boolean)
                  Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterExprAndExpr(children: FilterLongColEqualLongScalar(col 6:int, val 1999), FilterLongColEqualLongScalar(col 8:int, val 4), SelectColumnIsNotNull(col 0:int))
                    predicate: ((d_moy = 4) and (d_year = 1999) and d_date_sk is not null) (type: boolean)
                    Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: d_date_sk (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Map 8 
            Map Operator Tree:
                TableScan
                  alias: item
                  filterExpr: i_item_sk is not null (type: boolean)
                  Statistics: Num rows: 462000 Data size: 663560457 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsNotNull(col 0:int)
                    predicate: i_item_sk is not null (type: boolean)
                    Statistics: Num rows: 462000 Data size: 663560457 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: i_item_sk (type: int)
                      outputColumnNames: _col0
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0]
                      Statistics: Num rows: 462000 Data size: 663560457 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkLongOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        Statistics: Num rows: 462000 Data size: 663560457 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 11 
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true
                notVectorizedReason: Tagging not supported
                vectorized: false
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col1, _col2, _col3
                Statistics: Num rows: 41342400 Data size: 653203228 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col1 (type: int)
                  Statistics: Num rows: 41342400 Data size: 653203228 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col2 (type: int), _col3 (type: int)
        Reducer 12 
            Local Work:
              Map Reduce Local Work
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true
                notVectorizedReason: Tagging not supported
                vectorized: false
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col2, _col3, _col7
                Statistics: Num rows: 45476640 Data size: 718523566 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  keys:
                    0 _col2 (type: int)
                    1 _col0 (type: int)
                  outputColumnNames: _col3, _col7, _col8, _col9
                  input vertices:
                    1 Map 16
                  Statistics: Num rows: 50024305 Data size: 790375939 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col9 (type: string), _col8 (type: int), _col7 (type: int), _col3 (type: int), UDFToDouble(_col3) (type: double), (UDFToDouble(_col3) * UDFToDouble(_col3)) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 50024305 Data size: 790375939 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(_col3), count(_col3), sum(_col5), sum(_col4)
                      keys: _col1 (type: int), _col2 (type: int), _col0 (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                      Statistics: Num rows: 50024305 Data size: 790375939 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: string)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: string)
                        Statistics: Num rows: 50024305 Data size: 790375939 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col3 (type: bigint), _col4 (type: bigint), _col5 (type: double), _col6 (type: double)
        Reducer 13 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), sum(VALUE._col2), sum(VALUE._col3)
                Group By Vectorization:
                    aggregators: VectorUDAFSumLong(col 3:bigint) -> bigint, VectorUDAFCountMerge(col 4:bigint) -> bigint, VectorUDAFSumDouble(col 5:double) -> double, VectorUDAFSumDouble(col 6:double) -> double
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    keyExpressions: col 0:int, col 1:int, col 2:string
                    native: false
                    vectorProcessingMode: MERGE_PARTIAL
                    projectedOutputColumnNums: [0, 1, 2, 3]
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Statistics: Num rows: 25012152 Data size: 395187961 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: double), _col6 (type: double)
                  outputColumnNames: _col0, _col1, _col3, _col4, _col5, _col6
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumnNums: [0, 1, 3, 4, 5, 6]
                  Statistics: Num rows: 25012152 Data size: 395187961 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsTrue(col 15:boolean)(children: IfExprColumnCondExpr(col 8:boolean, col 9:booleancol 13:boolean)(children: DoubleColEqualLongScalar(col 7:double, val 0)(children: LongColDivideLongColumn(col 3:bigint, col 4:bigint) -> 7:double) -> 8:boolean, ConstantVectorExpression(val 0) -> 9:boolean, DoubleColGreaterDoubleScalar(col 14:double, val 1.0)(children: DoubleColDivideDoubleColumn(col 7:double, col 10:double)(children: FuncPowerDoubleToDouble(col 10:double)(children: DoubleColDivideLongColumn(col 7:double, col 13:bigint)(children: DoubleColSubtractDoubleColumn(col 5:double, col 10:double)(children: DoubleColDivideLongColumn(col 7:double, col 4:bigint)(children: DoubleColMultiplyDoubleColumn(col 6:double, col 6:double) -> 7:double) -> 10:double) -> 7:double, IfExprNullCondExpr(col 11:boolean, null, col 12:bigint)(children: LongColEqualLongScalar(col 4:bigint, val 1) -> 11:boolean, LongColSubtractLongScalar(col 4:bigint, val 1) -> 12:bigint) -> 13:bigint) -> 10:double) -> 7:double, LongColDivideLongColumn(col 3:bigint, col 4:bigint) -> 10:double) -> 14:double) -> 13:boolean) -> 15:boolean)
                    predicate: CASE WHEN (((_col3 / _col4) = 0)) THEN (false) ELSE (((power(((_col5 - ((_col6 * _col6) / _col4)) / CASE WHEN ((_col4 = 1L)) THEN (null) ELSE ((_col4 - 1)) END), 0.5) / (_col3 / _col4)) > 1.0D)) END (type: boolean)
                    Statistics: Num rows: 12506076 Data size: 197593980 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: int), (_col3 / _col4) (type: double), CASE WHEN (((_col3 / _col4) = 0)) THEN (null) ELSE ((power(((_col5 - ((_col6 * _col6) / _col4)) / CASE WHEN ((_col4 = 1L)) THEN (null) ELSE ((_col4 - 1)) END), 0.5) / (_col3 / _col4))) END (type: double)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1, 7, 10]
                          selectExpressions: LongColDivideLongColumn(col 3:bigint, col 4:bigint) -> 7:double, IfExprNullCondExpr(col 16:boolean, null, col 20:double)(children: DoubleColEqualLongScalar(col 10:double, val 0)(children: LongColDivideLongColumn(col 3:bigint, col 4:bigint) -> 10:double) -> 16:boolean, DoubleColDivideDoubleColumn(col 10:double, col 14:double)(children: FuncPowerDoubleToDouble(col 14:double)(children: DoubleColDivideLongColumn(col 10:double, col 19:bigint)(children: DoubleColSubtractDoubleColumn(col 5:double, col 14:double)(children: DoubleColDivideLongColumn(col 10:double, col 4:bigint)(children: DoubleColMultiplyDoubleColumn(col 6:double, col 6:double) -> 10:double) -> 14:double) -> 10:double, IfExprNullCondExpr(col 17:boolean, null, col 18:bigint)(children: LongColEqualLongScalar(col 4:bigint, val 1) -> 17:boolean, LongColSubtractLongScalar(col 4:bigint, val 1) -> 18:bigint) -> 19:bigint) -> 14:double) -> 10:double, LongColDivideLongColumn(col 3:bigint, col 4:bigint) -> 14:double) -> 20:double) -> 10:double
                      Statistics: Num rows: 12506076 Data size: 197593980 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int)
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkMultiKeyOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        Statistics: Num rows: 12506076 Data size: 197593980 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col2 (type: double), _col3 (type: double)
        Reducer 2 
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true
                notVectorizedReason: Tagging not supported
                vectorized: false
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col1, _col2, _col3
                Statistics: Num rows: 41342400 Data size: 653203228 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col1 (type: int)
                  Statistics: Num rows: 41342400 Data size: 653203228 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col2 (type: int), _col3 (type: int)
        Reducer 3 
            Local Work:
              Map Reduce Local Work
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true
                notVectorizedReason: Tagging not supported
                vectorized: false
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col2, _col3, _col7
                Statistics: Num rows: 45476640 Data size: 718523566 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  keys:
                    0 _col2 (type: int)
                    1 _col0 (type: int)
                  outputColumnNames: _col3, _col7, _col8, _col9
                  input vertices:
                    1 Map 9
                  Statistics: Num rows: 50024305 Data size: 790375939 Basic stats: COMPLETE Column stats: NONE
                  Select Operator
                    expressions: _col9 (type: string), _col8 (type: int), _col7 (type: int), _col3 (type: int), UDFToDouble(_col3) (type: double), (UDFToDouble(_col3) * UDFToDouble(_col3)) (type: double)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                    Statistics: Num rows: 50024305 Data size: 790375939 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(_col3), count(_col3), sum(_col5), sum(_col4)
                      keys: _col1 (type: int), _col2 (type: int), _col0 (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                      Statistics: Num rows: 50024305 Data size: 790375939 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: string)
                        sort order: +++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: string)
                        Statistics: Num rows: 50024305 Data size: 790375939 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col3 (type: bigint), _col4 (type: bigint), _col5 (type: double), _col6 (type: double)
        Reducer 4 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), count(VALUE._col1), sum(VALUE._col2), sum(VALUE._col3)
                Group By Vectorization:
                    aggregators: VectorUDAFSumLong(col 3:bigint) -> bigint, VectorUDAFCountMerge(col 4:bigint) -> bigint, VectorUDAFSumDouble(col 5:double) -> double, VectorUDAFSumDouble(col 6:double) -> double
                    className: VectorGroupByOperator
                    groupByMode: MERGEPARTIAL
                    keyExpressions: col 0:int, col 1:int, col 2:string
                    native: false
                    vectorProcessingMode: MERGE_PARTIAL
                    projectedOutputColumnNums: [0, 1, 2, 3]
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Statistics: Num rows: 25012152 Data size: 395187961 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int), _col3 (type: bigint), _col4 (type: bigint), _col5 (type: double), _col6 (type: double)
                  outputColumnNames: _col0, _col1, _col3, _col4, _col5, _col6
                  Select Vectorization:
                      className: VectorSelectOperator
                      native: true
                      projectedOutputColumnNums: [0, 1, 3, 4, 5, 6]
                  Statistics: Num rows: 25012152 Data size: 395187961 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: SelectColumnIsTrue(col 15:boolean)(children: IfExprColumnCondExpr(col 8:boolean, col 9:booleancol 13:boolean)(children: DoubleColEqualLongScalar(col 7:double, val 0)(children: LongColDivideLongColumn(col 3:bigint, col 4:bigint) -> 7:double) -> 8:boolean, ConstantVectorExpression(val 0) -> 9:boolean, DoubleColGreaterDoubleScalar(col 14:double, val 1.0)(children: DoubleColDivideDoubleColumn(col 7:double, col 10:double)(children: FuncPowerDoubleToDouble(col 10:double)(children: DoubleColDivideLongColumn(col 7:double, col 13:bigint)(children: DoubleColSubtractDoubleColumn(col 5:double, col 10:double)(children: DoubleColDivideLongColumn(col 7:double, col 4:bigint)(children: DoubleColMultiplyDoubleColumn(col 6:double, col 6:double) -> 7:double) -> 10:double) -> 7:double, IfExprNullCondExpr(col 11:boolean, null, col 12:bigint)(children: LongColEqualLongScalar(col 4:bigint, val 1) -> 11:boolean, LongColSubtractLongScalar(col 4:bigint, val 1) -> 12:bigint) -> 13:bigint) -> 10:double) -> 7:double, LongColDivideLongColumn(col 3:bigint, col 4:bigint) -> 10:double) -> 14:double) -> 13:boolean) -> 15:boolean)
                    predicate: CASE WHEN (((_col3 / _col4) = 0)) THEN (false) ELSE (((power(((_col5 - ((_col6 * _col6) / _col4)) / CASE WHEN ((_col4 = 1L)) THEN (null) ELSE ((_col4 - 1)) END), 0.5) / (_col3 / _col4)) > 1.0D)) END (type: boolean)
                    Statistics: Num rows: 12506076 Data size: 197593980 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: int), _col1 (type: int), (_col3 / _col4) (type: double), CASE WHEN (((_col3 / _col4) = 0)) THEN (null) ELSE ((power(((_col5 - ((_col6 * _col6) / _col4)) / CASE WHEN ((_col4 = 1L)) THEN (null) ELSE ((_col4 - 1)) END), 0.5) / (_col3 / _col4))) END (type: double)
                      outputColumnNames: _col0, _col1, _col2, _col3
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1, 7, 10]
                          selectExpressions: LongColDivideLongColumn(col 3:bigint, col 4:bigint) -> 7:double, IfExprNullCondExpr(col 16:boolean, null, col 20:double)(children: DoubleColEqualLongScalar(col 10:double, val 0)(children: LongColDivideLongColumn(col 3:bigint, col 4:bigint) -> 10:double) -> 16:boolean, DoubleColDivideDoubleColumn(col 10:double, col 14:double)(children: FuncPowerDoubleToDouble(col 14:double)(children: DoubleColDivideLongColumn(col 10:double, col 19:bigint)(children: DoubleColSubtractDoubleColumn(col 5:double, col 14:double)(children: DoubleColDivideLongColumn(col 10:double, col 4:bigint)(children: DoubleColMultiplyDoubleColumn(col 6:double, col 6:double) -> 10:double) -> 14:double) -> 10:double, IfExprNullCondExpr(col 17:boolean, null, col 18:bigint)(children: LongColEqualLongScalar(col 4:bigint, val 1) -> 17:boolean, LongColSubtractLongScalar(col 4:bigint, val 1) -> 18:bigint) -> 19:bigint) -> 14:double) -> 10:double, LongColDivideLongColumn(col 3:bigint, col 4:bigint) -> 14:double) -> 20:double) -> 10:double
                      Statistics: Num rows: 12506076 Data size: 197593980 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: int)
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkMultiKeyOperator
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                        Statistics: Num rows: 12506076 Data size: 197593980 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col2 (type: double), _col3 (type: double)
        Reducer 5 
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true
                notVectorizedReason: Tagging not supported
                vectorized: false
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: int), _col1 (type: int)
                  1 _col0 (type: int), _col1 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                Statistics: Num rows: 13756683 Data size: 217353382 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: double), _col3 (type: double), _col6 (type: double), _col7 (type: double)
                  sort order: ++++++
                  Statistics: Num rows: 13756683 Data size: 217353382 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col4 (type: int), _col5 (type: int)
        Reducer 6 
            Execution mode: vectorized
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine spark IN [tez, spark] IS true
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int), 4 (type: int), KEY.reducesinkkey2 (type: double), KEY.reducesinkkey3 (type: double), VALUE._col0 (type: int), VALUE._col1 (type: int), 5 (type: int), KEY.reducesinkkey4 (type: double), KEY.reducesinkkey5 (type: double)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 8, 2, 3, 6, 7, 9, 4, 5]
                    selectExpressions: ConstantVectorExpression(val 4) -> 8:int, ConstantVectorExpression(val 5) -> 9:int
                Statistics: Num rows: 13756683 Data size: 217353382 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 13756683 Data size: 217353382 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: with inv as
(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
       ,stdev,mean, case mean when 0 then null else stdev/mean end cov
 from(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
            ,stddev_samp(inv_quantity_on_hand) stdev,avg(inv_quantity_on_hand) mean
      from inventory
          ,item
          ,warehouse
          ,date_dim
      where inv_item_sk = i_item_sk
        and inv_warehouse_sk = w_warehouse_sk
        and inv_date_sk = d_date_sk
        and d_year =1999
      group by w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy) foo
 where case mean when 0 then 0 else stdev/mean end > 1)
select inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean, inv1.cov
        ,inv2.w_warehouse_sk,inv2.i_item_sk,inv2.d_moy,inv2.mean, inv2.cov
from inv inv1,inv inv2
where inv1.i_item_sk = inv2.i_item_sk
  and inv1.w_warehouse_sk =  inv2.w_warehouse_sk
  and inv1.d_moy=4
  and inv2.d_moy=4+1
  and inv1.cov > 1.5
order by inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean,inv1.cov
        ,inv2.d_moy,inv2.mean, inv2.cov
PREHOOK: type: QUERY
PREHOOK: Input: default@date_dim
PREHOOK: Input: default@inventory
PREHOOK: Input: default@item
PREHOOK: Input: default@warehouse
#### A masked pattern was here ####
POSTHOOK: query: with inv as
(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
       ,stdev,mean, case mean when 0 then null else stdev/mean end cov
 from(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy
            ,stddev_samp(inv_quantity_on_hand) stdev,avg(inv_quantity_on_hand) mean
      from inventory
          ,item
          ,warehouse
          ,date_dim
      where inv_item_sk = i_item_sk
        and inv_warehouse_sk = w_warehouse_sk
        and inv_date_sk = d_date_sk
        and d_year =1999
      group by w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy) foo
 where case mean when 0 then 0 else stdev/mean end > 1)
select inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean, inv1.cov
        ,inv2.w_warehouse_sk,inv2.i_item_sk,inv2.d_moy,inv2.mean, inv2.cov
from inv inv1,inv inv2
where inv1.i_item_sk = inv2.i_item_sk
  and inv1.w_warehouse_sk =  inv2.w_warehouse_sk
  and inv1.d_moy=4
  and inv2.d_moy=4+1
  and inv1.cov > 1.5
order by inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean,inv1.cov
        ,inv2.d_moy,inv2.mean, inv2.cov
POSTHOOK: type: QUERY
POSTHOOK: Input: default@date_dim
POSTHOOK: Input: default@inventory
POSTHOOK: Input: default@item
POSTHOOK: Input: default@warehouse
#### A masked pattern was here ####
