Saving all output to "!!{outputDirectory}!!/partition_wise_fileformat2.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/partition_wise_fileformat2.q
>>>  
>>>  
>>>  create table partition_test_partitioned(key string, value string) partitioned by (dt string);
No rows affected 
>>>  
>>>  insert overwrite table partition_test_partitioned partition(dt=100) select * from src1;
'key','value'
No rows selected 
>>>  alter table partition_test_partitioned set fileformat rcfile;
No rows affected 
>>>  insert overwrite table partition_test_partitioned partition(dt=101) select * from src1;
'key','value'
No rows selected 
>>>  alter table partition_test_partitioned set fileformat Sequencefile;
No rows affected 
>>>  insert overwrite table partition_test_partitioned partition(dt=102) select * from src1;
'key','value'
No rows selected 
>>>  
>>>  set hive.fetch.task.conversion=minimal;
No rows affected 
>>>  explain select *, BLOCK__OFFSET__INSIDE__FILE from partition_test_partitioned where dt >=100 and dt <= 102;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME partition_test_partitioned))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF) (TOK_SELEXPR (TOK_TABLE_OR_COL BLOCK__OFFSET__INSIDE__FILE))) (TOK_WHERE (and (>= (TOK_TABLE_OR_COL dt) 100) (<= (TOK_TABLE_OR_COL dt) 102)))))'
''
'STAGE DEPENDENCIES:'
'  Stage-1 is a root stage'
'  Stage-0 is a root stage'
''
'STAGE PLANS:'
'  Stage: Stage-1'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        partition_test_partitioned '
'          TableScan'
'            alias: partition_test_partitioned'
'            Select Operator'
'              expressions:'
'                    expr: key'
'                    type: string'
'                    expr: value'
'                    type: string'
'                    expr: dt'
'                    type: string'
'                    expr: BLOCK__OFFSET__INSIDE__FILE'
'                    type: bigint'
'              outputColumnNames: _col0, _col1, _col2, _col3'
'              File Output Operator'
'                compressed: false'
'                GlobalTableId: 0'
'                table:'
'                    input format: org.apache.hadoop.mapred.TextInputFormat'
'                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
''
'  Stage: Stage-0'
'    Fetch Operator'
'      limit: -1'
''
''
37 rows selected 
>>>  select * from partition_test_partitioned where dt >=100 and dt <= 102;
'key','value','dt'
'238','val_238','100'
'','','100'
'311','val_311','100'
'','val_27','100'
'','val_165','100'
'','val_409','100'
'255','val_255','100'
'278','val_278','100'
'98','val_98','100'
'','val_484','100'
'','val_265','100'
'','val_193','100'
'401','val_401','100'
'150','val_150','100'
'273','val_273','100'
'224','','100'
'369','','100'
'66','val_66','100'
'128','','100'
'213','val_213','100'
'146','val_146','100'
'406','val_406','100'
'','','100'
'','','100'
'','','100'
'238','val_238','101'
'','','101'
'311','val_311','101'
'','val_27','101'
'','val_165','101'
'','val_409','101'
'255','val_255','101'
'278','val_278','101'
'98','val_98','101'
'','val_484','101'
'','val_265','101'
'','val_193','101'
'401','val_401','101'
'150','val_150','101'
'273','val_273','101'
'224','','101'
'369','','101'
'66','val_66','101'
'128','','101'
'213','val_213','101'
'146','val_146','101'
'406','val_406','101'
'','','101'
'','','101'
'','','101'
'238','val_238','102'
'','','102'
'311','val_311','102'
'','val_27','102'
'','val_165','102'
'','val_409','102'
'255','val_255','102'
'278','val_278','102'
'98','val_98','102'
'','val_484','102'
'','val_265','102'
'','val_193','102'
'401','val_401','102'
'150','val_150','102'
'273','val_273','102'
'224','','102'
'369','','102'
'66','val_66','102'
'128','','102'
'213','val_213','102'
'146','val_146','102'
'406','val_406','102'
'','','102'
'','','102'
'','','102'
75 rows selected 
>>>  
>>>  set hive.fetch.task.conversion=more;
No rows affected 
>>>  explain select *, BLOCK__OFFSET__INSIDE__FILE from partition_test_partitioned where dt >=100 and dt <= 102;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME partition_test_partitioned))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF) (TOK_SELEXPR (TOK_TABLE_OR_COL BLOCK__OFFSET__INSIDE__FILE))) (TOK_WHERE (and (>= (TOK_TABLE_OR_COL dt) 100) (<= (TOK_TABLE_OR_COL dt) 102)))))'
''
'STAGE DEPENDENCIES:'
'  Stage-0 is a root stage'
''
'STAGE PLANS:'
'  Stage: Stage-0'
'    Fetch Operator'
'      limit: -1'
'      Processor Tree:'
'        TableScan'
'          alias: partition_test_partitioned'
'          Select Operator'
'            expressions:'
'                  expr: key'
'                  type: string'
'                  expr: value'
'                  type: string'
'                  expr: dt'
'                  type: string'
'                  expr: BLOCK__OFFSET__INSIDE__FILE'
'                  type: bigint'
'            outputColumnNames: _col0, _col1, _col2, _col3'
'            ListSink'
''
''
27 rows selected 
>>>  select * from partition_test_partitioned where dt >=100 and dt <= 102;
'key','value','dt'
'238','val_238','100'
'','','100'
'311','val_311','100'
'','val_27','100'
'','val_165','100'
'','val_409','100'
'255','val_255','100'
'278','val_278','100'
'98','val_98','100'
'','val_484','100'
'','val_265','100'
'','val_193','100'
'401','val_401','100'
'150','val_150','100'
'273','val_273','100'
'224','','100'
'369','','100'
'66','val_66','100'
'128','','100'
'213','val_213','100'
'146','val_146','100'
'406','val_406','100'
'','','100'
'','','100'
'','','100'
'238','val_238','101'
'','','101'
'311','val_311','101'
'','val_27','101'
'','val_165','101'
'','val_409','101'
'255','val_255','101'
'278','val_278','101'
'98','val_98','101'
'','val_484','101'
'','val_265','101'
'','val_193','101'
'401','val_401','101'
'150','val_150','101'
'273','val_273','101'
'224','','101'
'369','','101'
'66','val_66','101'
'128','','101'
'213','val_213','101'
'146','val_146','101'
'406','val_406','101'
'','','101'
'','','101'
'','','101'
'238','val_238','102'
'','','102'
'311','val_311','102'
'','val_27','102'
'','val_165','102'
'','val_409','102'
'255','val_255','102'
'278','val_278','102'
'98','val_98','102'
'','val_484','102'
'','val_265','102'
'','val_193','102'
'401','val_401','102'
'150','val_150','102'
'273','val_273','102'
'224','','102'
'369','','102'
'66','val_66','102'
'128','','102'
'213','val_213','102'
'146','val_146','102'
'406','val_406','102'
'','','102'
'','','102'
'','','102'
75 rows selected 
>>>  
>>>  !record
