Saving all output to "!!{outputDirectory}!!/stats15.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/stats15.q
>>>  set datanucleus.cache.collections=false;
No rows affected 
>>>  set hive.stats.collect.uncompressedsize=false;
No rows affected 
>>>  
>>>  create table stats_src like src;
No rows affected 
>>>  insert overwrite table stats_src select * from src;
'key','value'
No rows selected 
>>>  analyze table stats_src compute statistics;
'key','value'
No rows selected 
>>>  desc formatted stats_src;
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'key                 ','string              ','None                '
'value               ','string              ','None                '
'','',''
'# Detailed Table Information','',''
'Database:           ','stats15             ',''
'Owner:              ','!!{user.name}!!                ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Retention:          ','0                   ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats15.db/stats_src',''
'Table Type:         ','MANAGED_TABLE       ',''
'Table Parameters:','',''
'','numFiles            ','1                   '
'','numPartitions       ','0                   '
'','numRows             ','500                 '
'','rawDataSize         ','5312                '
'','totalSize           ','5812                '
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
32 rows selected 
>>>  
>>>  create table stats_part like srcpart;
No rows affected 
>>>  
>>>  insert overwrite table stats_part partition (ds='2010-04-08', hr = '11') select key, value from src;
'key','value'
No rows selected 
>>>  insert overwrite table stats_part partition (ds='2010-04-08', hr = '12') select key, value from src;
'key','value'
No rows selected 
>>>  
>>>  analyze table stats_part partition(ds='2010-04-08', hr='11') compute statistics;
'key','value','ds','hr'
No rows selected 
>>>  analyze table stats_part partition(ds='2010-04-08', hr='12') compute statistics;
'key','value','ds','hr'
No rows selected 
>>>  
>>>  insert overwrite table stats_part partition (ds='2010-04-08', hr = '13') select key, value from src;
'key','value'
No rows selected 
>>>  
>>>  desc formatted stats_part;
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'key                 ','string              ','None                '
'value               ','string              ','None                '
'','',''
'# Partition Information','',''
'# col_name            ','data_type           ','comment             '
'','',''
'ds                  ','string              ','None                '
'hr                  ','string              ','None                '
'','',''
'# Detailed Table Information','',''
'Database:           ','stats15             ',''
'Owner:              ','!!{user.name}!!                ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Retention:          ','0                   ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats15.db/stats_part',''
'Table Type:         ','MANAGED_TABLE       ',''
'Table Parameters:','',''
'','numFiles            ','3                   '
'','numPartitions       ','3                   '
'','numRows             ','1500                '
'','rawDataSize         ','15936               '
'','totalSize           ','17436               '
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
38 rows selected 
>>>  desc formatted stats_part partition (ds='2010-04-08', hr = '11');
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'key                 ','string              ','None                '
'value               ','string              ','None                '
'','',''
'# Partition Information','',''
'# col_name            ','data_type           ','comment             '
'','',''
'ds                  ','string              ','None                '
'hr                  ','string              ','None                '
'','',''
'# Detailed Partition Information','',''
'Partition Value:    ','[2010-04-08, 11]    ',''
'Database:           ','stats15             ',''
'Table:              ','stats_part          ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats15.db/stats_part/ds=2010-04-08/hr=11',''
'Partition Parameters:','',''
'','numFiles            ','1                   '
'','numRows             ','500                 '
'','rawDataSize         ','5312                '
'','totalSize           ','5812                '
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
36 rows selected 
>>>  desc formatted stats_part partition (ds='2010-04-08', hr = '12');
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'key                 ','string              ','None                '
'value               ','string              ','None                '
'','',''
'# Partition Information','',''
'# col_name            ','data_type           ','comment             '
'','',''
'ds                  ','string              ','None                '
'hr                  ','string              ','None                '
'','',''
'# Detailed Partition Information','',''
'Partition Value:    ','[2010-04-08, 12]    ',''
'Database:           ','stats15             ',''
'Table:              ','stats_part          ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats15.db/stats_part/ds=2010-04-08/hr=12',''
'Partition Parameters:','',''
'','numFiles            ','1                   '
'','numRows             ','500                 '
'','rawDataSize         ','5312                '
'','totalSize           ','5812                '
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
36 rows selected 
>>>  
>>>  analyze table stats_part partition(ds, hr) compute statistics;
'key','value','ds','hr'
No rows selected 
>>>  desc formatted stats_part;
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'key                 ','string              ','None                '
'value               ','string              ','None                '
'','',''
'# Partition Information','',''
'# col_name            ','data_type           ','comment             '
'','',''
'ds                  ','string              ','None                '
'hr                  ','string              ','None                '
'','',''
'# Detailed Table Information','',''
'Database:           ','stats15             ',''
'Owner:              ','!!{user.name}!!                ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Retention:          ','0                   ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats15.db/stats_part',''
'Table Type:         ','MANAGED_TABLE       ',''
'Table Parameters:','',''
'','numFiles            ','3                   '
'','numPartitions       ','3                   '
'','numRows             ','1500                '
'','rawDataSize         ','15936               '
'','totalSize           ','17436               '
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
38 rows selected 
>>>  
>>>  drop table stats_src;
No rows affected 
>>>  drop table stats_part;
No rows affected 
>>>  !record
