Saving all output to "!!{outputDirectory}!!/inputddl4.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/inputddl4.q
>>>  -- a simple test to test sorted/clustered syntax
>>>  
>>>  CREATE TABLE INPUTDDL4(viewTime STRING, userid INT, 
page_url STRING, referrer_url STRING, 
friends ARRAY<BIGINT>, properties MAP<STRING, STRING>, 
ip STRING COMMENT 'IP Address of the User') 
COMMENT 'This is the page view table' 
PARTITIONED BY(ds STRING, country STRING) 
CLUSTERED BY(userid) SORTED BY(viewTime) INTO 32 BUCKETS;
No rows affected 
>>>  DESCRIBE INPUTDDL4;
'col_name','data_type','comment'
'viewtime','string',''
'userid','int',''
'page_url','string',''
'referrer_url','string',''
'friends','array<bigint>',''
'properties','map<string,string>',''
'ip','string','IP Address of the User'
'ds','string',''
'country','string',''
9 rows selected 
>>>  DESCRIBE EXTENDED INPUTDDL4;
'col_name','data_type','comment'
'viewtime','string',''
'userid','int',''
'page_url','string',''
'referrer_url','string',''
'friends','array<bigint>',''
'properties','map<string,string>',''
'ip','string','IP Address of the User'
'ds','string',''
'country','string',''
'','',''
'Detailed Table Information','Table(tableName:inputddl4, dbName:inputddl4, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:viewtime, type:string, comment:null), FieldSchema(name:userid, type:int, comment:null), FieldSchema(name:page_url, type:string, comment:null), FieldSchema(name:referrer_url, type:string, comment:null), FieldSchema(name:friends, type:array<bigint>, comment:null), FieldSchema(name:properties, type:map<string,string>, comment:null), FieldSchema(name:ip, type:string, comment:IP Address of the User), FieldSchema(name:ds, type:string, comment:null), FieldSchema(name:country, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/inputddl4.db/inputddl4, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:32, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[userid], sortCols:[Order(col:viewtime, order:1)], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:ds, type:string, comment:null), FieldSchema(name:country, type:string, comment:null)], parameters:{transient_lastDdlTime=!!UNIXTIME!!, comment=This is the page view table}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)',''
11 rows selected 
>>>  
>>>  !record
