Saving all output to "!!{outputDirectory}!!/stats3.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/stats3.q
>>>  set datanucleus.cache.collections=false;
No rows affected 
>>>  set hive.stats.autogather=true;
No rows affected 
>>>  drop table hive_test_src;
No rows affected 
>>>  drop table hive_test_dst;
No rows affected 
>>>  
>>>  create table hive_test_src ( col1 string ) stored as textfile ;
No rows affected 
>>>  explain extended 
load data local inpath '../data/files/test.dat' overwrite into table hive_test_src ;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_LOAD '../data/files/test.dat' (TOK_TAB (TOK_TABNAME hive_test_src)) local overwrite)'
''
'STAGE DEPENDENCIES:'
'  Stage-0 is a root stage'
'  Stage-1 depends on stages: Stage-0'
'  Stage-2 depends on stages: Stage-1'
''
'STAGE PLANS:'
'  Stage: Stage-0'
'    Copy'
'      source: file:!!{hive.root}!!/data/files/test.dat'
'      destination: pfile:!!{hive.exec.scratchdir}!!'
''
'  Stage: Stage-1'
'    Move Operator'
'      tables:'
'          replace: true'
'          source: pfile:!!{hive.exec.scratchdir}!!'
'          table:'
'              input format: org.apache.hadoop.mapred.TextInputFormat'
'              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'              properties:'
'                bucket_count -1'
'                columns col1'
'                columns.types string'
'                file.inputformat org.apache.hadoop.mapred.TextInputFormat'
'                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'                location !!{hive.metastore.warehouse.dir}!!/stats3.db/hive_test_src'
'                name stats3.hive_test_src'
'                serialization.ddl struct hive_test_src { string col1}'
'                serialization.format 1'
'                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'                transient_lastDdlTime !!UNIXTIME!!'
'              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'              name: stats3.hive_test_src'
'          tmp directory: pfile:!!{hive.exec.scratchdir}!!'
''
'  Stage: Stage-2'
'    Stats-Aggr Operator'
''
''
42 rows selected 
>>>  
>>>  load data local inpath '../data/files/test.dat' overwrite into table hive_test_src ;
No rows affected 
>>>  
>>>  desc formatted hive_test_src;
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'col1                ','string              ','None                '
'','',''
'# Detailed Table Information','',''
'Database:           ','stats3              ',''
'Owner:              ','!!{user.name}!!                ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Retention:          ','0                   ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats3.db/hive_test_src',''
'Table Type:         ','MANAGED_TABLE       ',''
'Table Parameters:','',''
'','numFiles            ','1                   '
'','numPartitions       ','0                   '
'','numRows             ','0                   '
'','rawDataSize         ','0                   '
'','totalSize           ','11                  '
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
31 rows selected 
>>>  
>>>  create table hive_test_dst ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as sequencefile;
No rows affected 
>>>  insert overwrite table hive_test_dst partition ( pcol1='test_part', pCol2='test_Part') select col1 from hive_test_src ;
'col1'
No rows selected 
>>>  select * from hive_test_dst where pcol1='test_part' and pcol2='test_Part';
'col1','pcol1','pcol2'
'1','test_part','test_Part'
'2','test_part','test_Part'
'3','test_part','test_Part'
'4','test_part','test_Part'
'5','test_part','test_Part'
'6','test_part','test_Part'
6 rows selected 
>>>  
>>>  select count(1) from hive_test_dst;
'_c0'
'6'
1 row selected 
>>>  
>>>  insert overwrite table hive_test_dst partition ( pCol1='test_part', pcol2='test_Part') select col1 from hive_test_src ;
'col1'
No rows selected 
>>>  select * from hive_test_dst where pcol1='test_part' and pcol2='test_part';
'col1','pcol1','pcol2'
No rows selected 
>>>  
>>>  select count(1) from hive_test_dst;
'_c0'
'6'
1 row selected 
>>>  
>>>  select * from hive_test_dst where pcol1='test_part';
'col1','pcol1','pcol2'
'1','test_part','test_Part'
'2','test_part','test_Part'
'3','test_part','test_Part'
'4','test_part','test_Part'
'5','test_part','test_Part'
'6','test_part','test_Part'
6 rows selected 
>>>  select * from hive_test_dst where pcol1='test_part' and pcol2='test_part';
'col1','pcol1','pcol2'
No rows selected 
>>>  select * from hive_test_dst where pcol1='test_Part';
'col1','pcol1','pcol2'
No rows selected 
>>>  
>>>  describe formatted hive_test_dst;
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'col1                ','string              ','None                '
'','',''
'# Partition Information','',''
'# col_name            ','data_type           ','comment             '
'','',''
'pcol1               ','string              ','None                '
'pcol2               ','string              ','None                '
'','',''
'# Detailed Table Information','',''
'Database:           ','stats3              ',''
'Owner:              ','!!{user.name}!!                ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Retention:          ','0                   ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats3.db/hive_test_dst',''
'Table Type:         ','MANAGED_TABLE       ',''
'Table Parameters:','',''
'','numFiles            ','1                   '
'','numPartitions       ','1                   '
'','numRows             ','6                   '
'','rawDataSize         ','6                   '
'','totalSize           ','171                 '
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.SequenceFileInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
37 rows selected 
>>>  
>>>  drop table hive_test_src;
No rows affected 
>>>  drop table hive_test_dst;
No rows affected 
>>>  !record
