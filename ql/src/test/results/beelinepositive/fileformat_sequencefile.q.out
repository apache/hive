Saving all output to "!!{outputDirectory}!!/fileformat_sequencefile.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/fileformat_sequencefile.q
>>>  EXPLAIN 
CREATE TABLE dest1(key INT, value STRING) STORED AS 
INPUTFORMAT 'org.apache.hadoop.mapred.SequenceFileInputFormat' 
OUTPUTFORMAT 'org.apache.hadoop.mapred.SequenceFileOutputFormat';
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_CREATETABLE (TOK_TABNAME dest1) TOK_LIKETABLE (TOK_TABCOLLIST (TOK_TABCOL key TOK_INT) (TOK_TABCOL value TOK_STRING)) (TOK_TABLEFILEFORMAT 'org.apache.hadoop.mapred.SequenceFileInputFormat' 'org.apache.hadoop.mapred.SequenceFileOutputFormat'))'
''
'STAGE DEPENDENCIES:'
'  Stage-0 is a root stage'
''
'STAGE PLANS:'
'  Stage: Stage-0'
'      Create Table Operator:'
'        Create Table'
'          columns: key int, value string'
'          if not exists: false'
'          input format: org.apache.hadoop.mapred.SequenceFileInputFormat'
'          # buckets: -1'
'          output format: org.apache.hadoop.mapred.SequenceFileOutputFormat'
'          name: dest1'
'          isExternal: false'
''
''
19 rows selected 
>>>  
>>>  CREATE TABLE dest1(key INT, value STRING) STORED AS 
INPUTFORMAT 'org.apache.hadoop.mapred.SequenceFileInputFormat' 
OUTPUTFORMAT 'org.apache.hadoop.mapred.SequenceFileOutputFormat';
No rows affected 
>>>  
>>>  DESCRIBE EXTENDED dest1;
'col_name','data_type','comment'
'key','int',''
'value','string',''
'','',''
'Detailed Table Information','Table(tableName:dest1, dbName:fileformat_sequencefile, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:int, comment:null), FieldSchema(name:value, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/fileformat_sequencefile.db/dest1, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{transient_lastDdlTime=!!UNIXTIME!!}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)',''
4 rows selected 
>>>  
>>>  FROM src 
INSERT OVERWRITE TABLE dest1 SELECT src.key, src.value WHERE src.key < 10;
'_col0','_col1'
No rows selected 
>>>  
>>>  SELECT dest1.* FROM dest1;
'key','value'
'0','val_0'
'4','val_4'
'8','val_8'
'0','val_0'
'0','val_0'
'5','val_5'
'5','val_5'
'2','val_2'
'5','val_5'
'9','val_9'
10 rows selected 
>>>  
>>>  
>>>  !record
