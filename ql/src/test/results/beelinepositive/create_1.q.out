Saving all output to "!!{outputDirectory}!!/create_1.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/create_1.q
>>>  set fs.default.name=invalidscheme:///;
No rows affected 
>>>  
>>>  CREATE TABLE table1 (a STRING, b STRING) STORED AS TEXTFILE;
No rows affected 
>>>  DESCRIBE table1;
'col_name','data_type','comment'
'a','string',''
'b','string',''
2 rows selected 
>>>  DESCRIBE EXTENDED table1;
'col_name','data_type','comment'
'a','string',''
'b','string',''
'','',''
'Detailed Table Information','Table(tableName:table1, dbName:create_1, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:string, comment:null), FieldSchema(name:b, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/create_1.db/table1, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{transient_lastDdlTime=!!UNIXTIME!!}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)',''
4 rows selected 
>>>  
>>>  CREATE TABLE IF NOT EXISTS table1 (a STRING, b STRING) STORED AS TEXTFILE;
No rows affected 
>>>  
>>>  CREATE TABLE IF NOT EXISTS table2 (a STRING, b INT) STORED AS TEXTFILE;
No rows affected 
>>>  DESCRIBE table2;
'col_name','data_type','comment'
'a','string',''
'b','int',''
2 rows selected 
>>>  DESCRIBE EXTENDED table2;
'col_name','data_type','comment'
'a','string',''
'b','int',''
'','',''
'Detailed Table Information','Table(tableName:table2, dbName:create_1, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:string, comment:null), FieldSchema(name:b, type:int, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/create_1.db/table2, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{transient_lastDdlTime=!!UNIXTIME!!}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)',''
4 rows selected 
>>>  
>>>  CREATE TABLE table3 (a STRING, b STRING) 
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' 
STORED AS TEXTFILE;
No rows affected 
>>>  DESCRIBE table3;
'col_name','data_type','comment'
'a','string',''
'b','string',''
2 rows selected 
>>>  DESCRIBE EXTENDED table3;
'col_name','data_type','comment'
'a','string',''
'b','string',''
'','',''
'Detailed Table Information','Table(tableName:table3, dbName:create_1, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:string, comment:null), FieldSchema(name:b, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/create_1.db/table3, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=',', field.delim='
4 rows selected 
>>>  
>>>  CREATE TABLE table4 (a STRING, b STRING) 
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' 
STORED AS SEQUENCEFILE;
No rows affected 
>>>  DESCRIBE table4;
'col_name','data_type','comment'
'a','string',''
'b','string',''
2 rows selected 
>>>  DESCRIBE EXTENDED table4;
'col_name','data_type','comment'
'a','string',''
'b','string',''
'','',''
'Detailed Table Information','Table(tableName:table4, dbName:create_1, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:string, comment:null), FieldSchema(name:b, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/create_1.db/table4, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=',', field.delim='
4 rows selected 
>>>  
>>>  CREATE TABLE table5 (a STRING, b STRING) 
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' 
STORED AS RCFILE;
No rows affected 
>>>  DESCRIBE table5;
'col_name','data_type','comment'
'a','string',''
'b','string',''
2 rows selected 
>>>  DESCRIBE EXTENDED table5;
'col_name','data_type','comment'
'a','string',''
'b','string',''
'','',''
'Detailed Table Information','Table(tableName:table5, dbName:create_1, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:string, comment:null), FieldSchema(name:b, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/create_1.db/table5, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=',', field.delim='
4 rows selected 
>>>  !record
