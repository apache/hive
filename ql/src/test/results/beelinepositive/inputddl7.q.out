Saving all output to "!!{outputDirectory}!!/inputddl7.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/inputddl7.q
>>>  -- test for loading into tables with the correct file format
>>>  -- test for loading into partitions with the correct file format
>>>  
>>>  
>>>  CREATE TABLE T1(name STRING) STORED AS TEXTFILE;
No rows affected 
>>>  LOAD DATA LOCAL INPATH '../data/files/kv1.txt' INTO TABLE T1;
No rows affected 
>>>  SELECT COUNT(1) FROM T1;
'_c0'
'500'
1 row selected 
>>>  
>>>  
>>>  CREATE TABLE T2(name STRING) STORED AS SEQUENCEFILE;
No rows affected 
>>>  LOAD DATA LOCAL INPATH '../data/files/kv1.seq' INTO TABLE T2;
No rows affected 
>>>  SELECT COUNT(1) FROM T2;
'_c0'
'500'
1 row selected 
>>>  
>>>  
>>>  CREATE TABLE T3(name STRING) PARTITIONED BY(ds STRING) STORED AS TEXTFILE;
No rows affected 
>>>  LOAD DATA LOCAL INPATH '../data/files/kv1.txt' INTO TABLE T3 PARTITION (ds='2008-04-09');
No rows affected 
>>>  SELECT COUNT(1) FROM T3 where T3.ds='2008-04-09';
'_c0'
'500'
1 row selected 
>>>  
>>>  
>>>  CREATE TABLE T4(name STRING) PARTITIONED BY(ds STRING) STORED AS SEQUENCEFILE;
No rows affected 
>>>  LOAD DATA LOCAL INPATH '../data/files/kv1.seq' INTO TABLE T4 PARTITION (ds='2008-04-09');
No rows affected 
>>>  SELECT COUNT(1) FROM T4 where T4.ds='2008-04-09';
'_c0'
'500'
1 row selected 
>>>  
>>>  DESCRIBE EXTENDED T1;
'col_name','data_type','comment'
'name','string',''
'','',''
'Detailed Table Information','Table(tableName:t1, dbName:inputddl7, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:name, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/inputddl7.db/t1, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{numPartitions=0, numFiles=1, transient_lastDdlTime=!!UNIXTIME!!, totalSize=5812, numRows=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)',''
3 rows selected 
>>>  DESCRIBE EXTENDED T2;
'col_name','data_type','comment'
'name','string',''
'','',''
'Detailed Table Information','Table(tableName:t2, dbName:inputddl7, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:name, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/inputddl7.db/t2, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{numPartitions=0, numFiles=1, transient_lastDdlTime=!!UNIXTIME!!, totalSize=10508, numRows=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)',''
3 rows selected 
>>>  DESCRIBE EXTENDED T3 PARTITION (ds='2008-04-09');
'col_name','data_type','comment'
'name','string',''
'ds','string',''
'','',''
'Detailed Partition Information','Partition(values:[2008-04-09], dbName:inputddl7, tableName:t3, createTime:!!UNIXTIME!!, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:name, type:string, comment:null), FieldSchema(name:ds, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/inputddl7.db/t3/ds=2008-04-09, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), parameters:{numFiles=1, transient_lastDdlTime=!!UNIXTIME!!, totalSize=5812, numRows=0, rawDataSize=0})',''
4 rows selected 
>>>  DESCRIBE EXTENDED T4 PARTITION (ds='2008-04-09');
'col_name','data_type','comment'
'name','string',''
'ds','string',''
'','',''
'Detailed Partition Information','Partition(values:[2008-04-09], dbName:inputddl7, tableName:t4, createTime:!!UNIXTIME!!, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:name, type:string, comment:null), FieldSchema(name:ds, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/inputddl7.db/t4/ds=2008-04-09, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), parameters:{numFiles=1, transient_lastDdlTime=!!UNIXTIME!!, totalSize=10508, numRows=0, rawDataSize=0})',''
4 rows selected 
>>>  
>>>  
>>>  
>>>  
>>>  
>>>  
>>>  !record
