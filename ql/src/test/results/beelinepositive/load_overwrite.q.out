Saving all output to "!!{outputDirectory}!!/load_overwrite.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/load_overwrite.q
>>>  create table load_overwrite like src;
No rows affected 
>>>  
>>>  insert overwrite table load_overwrite select * from src;
'key','value'
No rows selected 
>>>  show table extended like load_overwrite;
'tab_name'
'tableName:load_overwrite'
'owner:!!{user.name}!!'
'location:!!{hive.metastore.warehouse.dir}!!/load_overwrite.db/load_overwrite'
'inputformat:org.apache.hadoop.mapred.TextInputFormat'
'outputformat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'columns:struct columns { string key, string value}'
'partitioned:false'
'partitionColumns:'
'totalNumberFiles:1'
'totalFileSize:5812'
'maxFileSize:5812'
'minFileSize:5812'
'lastAccessTime:0'
'lastUpdateTime:!!UNIXTIMEMILLIS!!'
''
15 rows selected 
>>>  select count(*) from load_overwrite;
'_c0'
'500'
1 row selected 
>>>  
>>>  
>>>  load data local inpath '../data/files/kv1.txt' into table load_overwrite;
No rows affected 
>>>  show table extended like load_overwrite;
'tab_name'
'tableName:load_overwrite'
'owner:!!{user.name}!!'
'location:!!{hive.metastore.warehouse.dir}!!/load_overwrite.db/load_overwrite'
'inputformat:org.apache.hadoop.mapred.TextInputFormat'
'outputformat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'columns:struct columns { string key, string value}'
'partitioned:false'
'partitionColumns:'
'totalNumberFiles:2'
'totalFileSize:11624'
'maxFileSize:5812'
'minFileSize:5812'
'lastAccessTime:0'
'lastUpdateTime:!!UNIXTIMEMILLIS!!'
''
15 rows selected 
>>>  select count(*) from load_overwrite;
'_c0'
'1000'
1 row selected 
>>>  
>>>  
>>>  load data local inpath '../data/files/kv1.txt' overwrite into table load_overwrite;
No rows affected 
>>>  show table extended like load_overwrite;
'tab_name'
'tableName:load_overwrite'
'owner:!!{user.name}!!'
'location:!!{hive.metastore.warehouse.dir}!!/load_overwrite.db/load_overwrite'
'inputformat:org.apache.hadoop.mapred.TextInputFormat'
'outputformat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'columns:struct columns { string key, string value}'
'partitioned:false'
'partitionColumns:'
'totalNumberFiles:1'
'totalFileSize:5812'
'maxFileSize:5812'
'minFileSize:5812'
'lastAccessTime:0'
'lastUpdateTime:!!UNIXTIMEMILLIS!!'
''
15 rows selected 
>>>  select count(*) from load_overwrite;
'_c0'
'500'
1 row selected 
>>>  !record
