Saving all output to "!!{outputDirectory}!!/udf_java_method.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/udf_java_method.q
>>>  DESCRIBE FUNCTION java_method;
'tab_name'
'java_method(class,method[,arg1[,arg2..]]) calls method with reflection'
1 row selected 
>>>  DESCRIBE FUNCTION EXTENDED java_method;
'tab_name'
'java_method(class,method[,arg1[,arg2..]]) calls method with reflection'
'Synonyms: reflect'
'Use this UDF to call Java methods by matching the argument signature'
''
4 rows selected 
>>>  
>>>  -- java_method() is a synonym for reflect()
>>>  
>>>  EXPLAIN EXTENDED 
SELECT java_method("java.lang.String", "valueOf", 1), 
java_method("java.lang.String", "isEmpty"), 
java_method("java.lang.Math", "max", 2, 3), 
java_method("java.lang.Math", "min", 2, 3), 
java_method("java.lang.Math", "round", 2.5), 
java_method("java.lang.Math", "exp", 1.0), 
java_method("java.lang.Math", "floor", 1.9) 
FROM src LIMIT 1;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION java_method "java.lang.String" "valueOf" 1)) (TOK_SELEXPR (TOK_FUNCTION java_method "java.lang.String" "isEmpty")) (TOK_SELEXPR (TOK_FUNCTION java_method "java.lang.Math" "max" 2 3)) (TOK_SELEXPR (TOK_FUNCTION java_method "java.lang.Math" "min" 2 3)) (TOK_SELEXPR (TOK_FUNCTION java_method "java.lang.Math" "round" 2.5)) (TOK_SELEXPR (TOK_FUNCTION java_method "java.lang.Math" "exp" 1.0)) (TOK_SELEXPR (TOK_FUNCTION java_method "java.lang.Math" "floor" 1.9))) (TOK_LIMIT 1)))'
''
'STAGE DEPENDENCIES:'
'  Stage-1 is a root stage'
'  Stage-0 is a root stage'
''
'STAGE PLANS:'
'  Stage: Stage-1'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        src '
'          TableScan'
'            alias: src'
'            GatherStats: false'
'            Select Operator'
'              expressions:'
'                    expr: reflect('java.lang.String','valueOf',1)'
'                    type: string'
'                    expr: reflect('java.lang.String','isEmpty')'
'                    type: string'
'                    expr: reflect('java.lang.Math','max',2,3)'
'                    type: string'
'                    expr: reflect('java.lang.Math','min',2,3)'
'                    type: string'
'                    expr: reflect('java.lang.Math','round',2.5)'
'                    type: string'
'                    expr: reflect('java.lang.Math','exp',1.0)'
'                    type: string'
'                    expr: reflect('java.lang.Math','floor',1.9)'
'                    type: string'
'              outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6'
'              Limit'
'                File Output Operator'
'                  compressed: false'
'                  GlobalTableId: 0'
'                  directory: file:!!{hive.exec.scratchdir}!!'
'                  NumFilesPerFileSink: 1'
'                  Stats Publishing Key Prefix: file:!!{hive.exec.scratchdir}!!'
'                  table:'
'                      input format: org.apache.hadoop.mapred.TextInputFormat'
'                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'                      properties:'
'                        columns _col0,_col1,_col2,_col3,_col4,_col5,_col6'
'                        columns.types string:string:string:string:string:string:string'
'                        escape.delim \'
'                        serialization.format 1'
'                  TotalFiles: 1'
'                  GatherStats: false'
'                  MultiFileSpray: false'
'      Needs Tagging: false'
'      Path -> Alias:'
'        !!{hive.metastore.warehouse.dir}!!/udf_java_method.db/src [src]'
'      Path -> Partition:'
'        !!{hive.metastore.warehouse.dir}!!/udf_java_method.db/src '
'          Partition'
'            base file name: src'
'            input format: org.apache.hadoop.mapred.TextInputFormat'
'            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'            properties:'
'              bucket_count -1'
'              columns key,value'
'              columns.types string:string'
'              file.inputformat org.apache.hadoop.mapred.TextInputFormat'
'              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'              location !!{hive.metastore.warehouse.dir}!!/udf_java_method.db/src'
'              name udf_java_method.src'
'              numFiles 1'
'              numPartitions 0'
'              numRows 0'
'              rawDataSize 0'
'              serialization.ddl struct src { string key, string value}'
'              serialization.format 1'
'              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'              totalSize 5812'
'              transient_lastDdlTime !!UNIXTIME!!'
'            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'          '
'              input format: org.apache.hadoop.mapred.TextInputFormat'
'              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'              properties:'
'                bucket_count -1'
'                columns key,value'
'                columns.types string:string'
'                file.inputformat org.apache.hadoop.mapred.TextInputFormat'
'                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'                location !!{hive.metastore.warehouse.dir}!!/udf_java_method.db/src'
'                name udf_java_method.src'
'                numFiles 1'
'                numPartitions 0'
'                numRows 0'
'                rawDataSize 0'
'                serialization.ddl struct src { string key, string value}'
'                serialization.format 1'
'                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'                totalSize 5812'
'                transient_lastDdlTime !!UNIXTIME!!'
'              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'              name: udf_java_method.src'
'            name: udf_java_method.src'
''
'  Stage: Stage-0'
'    Fetch Operator'
'      limit: 1'
''
''
106 rows selected 
>>>  
>>>  
>>>  SELECT java_method("java.lang.String", "valueOf", 1), 
java_method("java.lang.String", "isEmpty"), 
java_method("java.lang.Math", "max", 2, 3), 
java_method("java.lang.Math", "min", 2, 3), 
java_method("java.lang.Math", "round", 2.5), 
java_method("java.lang.Math", "exp", 1.0), 
java_method("java.lang.Math", "floor", 1.9) 
FROM src LIMIT 1;
'_c0','_c1','_c2','_c3','_c4','_c5','_c6'
'1','true','3','2','3','2.7182818284590455','1.0'
1 row selected 
>>>  
>>>  !record
