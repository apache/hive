Saving all output to "!!{outputDirectory}!!/stats12.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/stats12.q
>>>  set datanucleus.cache.collections=false;
No rows affected 
>>>  set hive.stats.autogather=false;
No rows affected 
>>>  set hive.exec.dynamic.partition=true;
No rows affected 
>>>  set hive.exec.dynamic.partition.mode=nonstrict;
No rows affected 
>>>  
>>>  create table analyze_srcpart like srcpart;
No rows affected 
>>>  insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart where ds is not null;
'key','value','ds','hr'
No rows selected 
>>>  
>>>  explain extended 
analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr) compute statistics;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_ANALYZE (TOK_TAB (TOK_TABNAME analyze_srcpart) (TOK_PARTSPEC (TOK_PARTVAL ds '2008-04-08') (TOK_PARTVAL hr))))'
''
'STAGE DEPENDENCIES:'
'  Stage-0 is a root stage'
'  Stage-1 depends on stages: Stage-0'
''
'STAGE PLANS:'
'  Stage: Stage-0'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        analyze_srcpart '
'          TableScan'
'            alias: analyze_srcpart'
'            Statistics Aggregation Key Prefix: analyze_srcpart/'
'            GatherStats: true'
'      Needs Tagging: false'
'      Path -> Alias:'
'        !!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart/ds=2008-04-08/hr=11 [analyze_srcpart]'
'        !!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart/ds=2008-04-08/hr=12 [analyze_srcpart]'
'      Path -> Partition:'
'        !!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart/ds=2008-04-08/hr=11 '
'          Partition'
'            base file name: hr=11'
'            input format: org.apache.hadoop.mapred.TextInputFormat'
'            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'            partition values:'
'              ds 2008-04-08'
'              hr 11'
'            properties:'
'              bucket_count -1'
'              columns key,value'
'              columns.types string:string'
'              file.inputformat org.apache.hadoop.mapred.TextInputFormat'
'              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'              location !!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart/ds=2008-04-08/hr=11'
'              name stats12.analyze_srcpart'
'              partition_columns ds/hr'
'              serialization.ddl struct analyze_srcpart { string key, string value}'
'              serialization.format 1'
'              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'              transient_lastDdlTime !!UNIXTIME!!'
'            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'          '
'              input format: org.apache.hadoop.mapred.TextInputFormat'
'              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'              properties:'
'                bucket_count -1'
'                columns key,value'
'                columns.types string:string'
'                file.inputformat org.apache.hadoop.mapred.TextInputFormat'
'                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'                location !!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart'
'                name stats12.analyze_srcpart'
'                partition_columns ds/hr'
'                serialization.ddl struct analyze_srcpart { string key, string value}'
'                serialization.format 1'
'                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'                transient_lastDdlTime !!UNIXTIME!!'
'              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'              name: stats12.analyze_srcpart'
'            name: stats12.analyze_srcpart'
'        !!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart/ds=2008-04-08/hr=12 '
'          Partition'
'            base file name: hr=12'
'            input format: org.apache.hadoop.mapred.TextInputFormat'
'            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'            partition values:'
'              ds 2008-04-08'
'              hr 12'
'            properties:'
'              bucket_count -1'
'              columns key,value'
'              columns.types string:string'
'              file.inputformat org.apache.hadoop.mapred.TextInputFormat'
'              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'              location !!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart/ds=2008-04-08/hr=12'
'              name stats12.analyze_srcpart'
'              partition_columns ds/hr'
'              serialization.ddl struct analyze_srcpart { string key, string value}'
'              serialization.format 1'
'              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'              transient_lastDdlTime !!UNIXTIME!!'
'            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'          '
'              input format: org.apache.hadoop.mapred.TextInputFormat'
'              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'              properties:'
'                bucket_count -1'
'                columns key,value'
'                columns.types string:string'
'                file.inputformat org.apache.hadoop.mapred.TextInputFormat'
'                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'                location !!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart'
'                name stats12.analyze_srcpart'
'                partition_columns ds/hr'
'                serialization.ddl struct analyze_srcpart { string key, string value}'
'                serialization.format 1'
'                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'                transient_lastDdlTime !!UNIXTIME!!'
'              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'              name: stats12.analyze_srcpart'
'            name: stats12.analyze_srcpart'
''
'  Stage: Stage-1'
'    Stats-Aggr Operator'
'      Stats Aggregation Key Prefix: analyze_srcpart/'
''
''
109 rows selected 
>>>  
>>>  analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr) compute statistics;
'key','value','ds','hr'
No rows selected 
>>>  
>>>  desc formatted analyze_srcpart;
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'key                 ','string              ','None                '
'value               ','string              ','None                '
'','',''
'# Partition Information','',''
'# col_name            ','data_type           ','comment             '
'','',''
'ds                  ','string              ','None                '
'hr                  ','string              ','None                '
'','',''
'# Detailed Table Information','',''
'Database:           ','stats12             ',''
'Owner:              ','!!{user.name}!!                ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Retention:          ','0                   ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart',''
'Table Type:         ','MANAGED_TABLE       ',''
'Table Parameters:','',''
'','numFiles            ','2                   '
'','numPartitions       ','2                   '
'','numRows             ','1000                '
'','rawDataSize         ','10624               '
'','totalSize           ','11624               '
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
38 rows selected 
>>>  desc formatted analyze_srcpart partition (ds='2008-04-08', hr=11);
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'key                 ','string              ','None                '
'value               ','string              ','None                '
'','',''
'# Partition Information','',''
'# col_name            ','data_type           ','comment             '
'','',''
'ds                  ','string              ','None                '
'hr                  ','string              ','None                '
'','',''
'# Detailed Partition Information','',''
'Partition Value:    ','[2008-04-08, 11]    ',''
'Database:           ','stats12             ',''
'Table:              ','analyze_srcpart     ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart/ds=2008-04-08/hr=11',''
'Partition Parameters:','',''
'','numFiles            ','1                   '
'','numRows             ','500                 '
'','rawDataSize         ','5312                '
'','totalSize           ','5812                '
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
36 rows selected 
>>>  desc formatted analyze_srcpart partition (ds='2008-04-08', hr=12);
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'key                 ','string              ','None                '
'value               ','string              ','None                '
'','',''
'# Partition Information','',''
'# col_name            ','data_type           ','comment             '
'','',''
'ds                  ','string              ','None                '
'hr                  ','string              ','None                '
'','',''
'# Detailed Partition Information','',''
'Partition Value:    ','[2008-04-08, 12]    ',''
'Database:           ','stats12             ',''
'Table:              ','analyze_srcpart     ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart/ds=2008-04-08/hr=12',''
'Partition Parameters:','',''
'','numFiles            ','1                   '
'','numRows             ','500                 '
'','rawDataSize         ','5312                '
'','totalSize           ','5812                '
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
36 rows selected 
>>>  desc formatted analyze_srcpart partition (ds='2008-04-09', hr=11);
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'key                 ','string              ','None                '
'value               ','string              ','None                '
'','',''
'# Partition Information','',''
'# col_name            ','data_type           ','comment             '
'','',''
'ds                  ','string              ','None                '
'hr                  ','string              ','None                '
'','',''
'# Detailed Partition Information','',''
'Partition Value:    ','[2008-04-09, 11]    ',''
'Database:           ','stats12             ',''
'Table:              ','analyze_srcpart     ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart/ds=2008-04-09/hr=11',''
'Partition Parameters:','',''
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
32 rows selected 
>>>  desc formatted analyze_srcpart partition (ds='2008-04-09', hr=12);
'col_name','data_type','comment'
'# col_name            ','data_type           ','comment             '
'','',''
'key                 ','string              ','None                '
'value               ','string              ','None                '
'','',''
'# Partition Information','',''
'# col_name            ','data_type           ','comment             '
'','',''
'ds                  ','string              ','None                '
'hr                  ','string              ','None                '
'','',''
'# Detailed Partition Information','',''
'Partition Value:    ','[2008-04-09, 12]    ',''
'Database:           ','stats12             ',''
'Table:              ','analyze_srcpart     ',''
'CreateTime:         ','!!TIMESTAMP!!',''
'LastAccessTime:     ','UNKNOWN             ',''
'Protect Mode:       ','None                ',''
'Location:           ','!!{hive.metastore.warehouse.dir}!!/stats12.db/analyze_srcpart/ds=2008-04-09/hr=12',''
'Partition Parameters:','',''
'','transient_lastDdlTime','!!UNIXTIME!!          '
'','',''
'# Storage Information','',''
'SerDe Library:      ','org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',''
'InputFormat:        ','org.apache.hadoop.mapred.TextInputFormat',''
'OutputFormat:       ','org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',''
'Compressed:         ','No                  ',''
'Num Buckets:        ','-1                  ',''
'Bucket Columns:     ','[]                  ',''
'Sort Columns:       ','[]                  ',''
'Storage Desc Params:','',''
'','serialization.format','1                   '
32 rows selected 
>>>  
>>>  !record
