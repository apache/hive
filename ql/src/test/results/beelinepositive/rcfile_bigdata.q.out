Saving all output to "!!{outputDirectory}!!/rcfile_bigdata.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/rcfile_bigdata.q
>>>  set hive.map.aggr.hash.percentmemory = 0.3;
No rows affected 
>>>  set hive.mapred.local.mem = 256;
No rows affected 
>>>  
>>>  add file ../data/scripts/dumpdata_script.py;
No rows affected 
>>>  
>>>  CREATE table columnTable_Bigdata (key STRING, value STRING) 
ROW FORMAT SERDE 
'org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe' 
STORED AS 
INPUTFORMAT 'org.apache.hadoop.hive.ql.io.RCFileInputFormat' 
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.RCFileOutputFormat';
No rows affected 
>>>  
>>>  FROM (FROM src MAP src.key,src.value USING 'python dumpdata_script.py' AS (key,value) WHERE src.key = 10) subq 
INSERT OVERWRITE TABLE columnTable_Bigdata SELECT subq.key, subq.value;
'key','value'
No rows selected 
>>>  
>>>  describe columnTable_Bigdata;
'col_name','data_type','comment'
'key','string',''
'value','string',''
2 rows selected 
>>>  select count(columnTable_Bigdata.key) from columnTable_Bigdata;
'_c0'
'5005500'
1 row selected 
>>>  
>>>  
>>>  !record
