Saving all output to "!!{outputDirectory}!!/alter_table_serde.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/alter_table_serde.q
>>>  -- test table
>>>  create table test_table (id int, query string, name string);
No rows affected 
>>>  describe extended test_table;
'col_name','data_type','comment'
'id','int',''
'query','string',''
'name','string',''
'','',''
'Detailed Table Information','Table(tableName:test_table, dbName:alter_table_serde, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:query, type:string, comment:null), FieldSchema(name:name, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/alter_table_serde.db/test_table, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{transient_lastDdlTime=!!UNIXTIME!!}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)',''
5 rows selected 
>>>  
>>>  alter table test_table set serde 'org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe';
No rows affected 
>>>  describe extended test_table;
'col_name','data_type','comment'
'id','int','from deserializer'
'query','string','from deserializer'
'name','string','from deserializer'
'','',''
'Detailed Table Information','Table(tableName:test_table, dbName:alter_table_serde, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:from deserializer), FieldSchema(name:query, type:string, comment:from deserializer), FieldSchema(name:name, type:string, comment:from deserializer)], location:!!{hive.metastore.warehouse.dir}!!/alter_table_serde.db/test_table, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{last_modified_by=!!ELIDED!!, last_modified_time=!!UNIXTIME!!, transient_lastDdlTime=!!UNIXTIME!!}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)',''
5 rows selected 
>>>  
>>>  alter table test_table set serdeproperties ('field.delim' = ',');
No rows affected 
>>>  describe extended test_table;
'col_name','data_type','comment'
'id','int','from deserializer'
'query','string','from deserializer'
'name','string','from deserializer'
'','',''
'Detailed Table Information','Table(tableName:test_table, dbName:alter_table_serde, owner:!!{user.name}!!, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:from deserializer), FieldSchema(name:query, type:string, comment:from deserializer), FieldSchema(name:name, type:string, comment:from deserializer)], location:!!{hive.metastore.warehouse.dir}!!/alter_table_serde.db/test_table, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1, field.delim=,}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{last_modified_by=!!ELIDED!!, last_modified_time=!!UNIXTIME!!, transient_lastDdlTime=!!UNIXTIME!!}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)',''
5 rows selected 
>>>  
>>>  drop table test_table;
No rows affected 
>>>  
>>>  --- test partitioned table
>>>  create table test_table (id int, query string, name string) partitioned by (dt string);
No rows affected 
>>>  
>>>  alter table test_table add partition (dt = '2011');
No rows affected 
>>>  describe extended test_table partition (dt='2011');
'col_name','data_type','comment'
'id','int',''
'query','string',''
'name','string',''
'dt','string',''
'','',''
'Detailed Partition Information','Partition(values:[2011], dbName:alter_table_serde, tableName:test_table, createTime:!!UNIXTIME!!, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:query, type:string, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:dt, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/alter_table_serde.db/test_table/dt=2011, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), parameters:{transient_lastDdlTime=!!UNIXTIME!!})',''
6 rows selected 
>>>  
>>>  alter table test_table set serde 'org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe';
No rows affected 
>>>  describe extended test_table partition (dt='2011');
'col_name','data_type','comment'
'id','int',''
'query','string',''
'name','string',''
'dt','string',''
'','',''
'Detailed Partition Information','Partition(values:[2011], dbName:alter_table_serde, tableName:test_table, createTime:!!UNIXTIME!!, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:query, type:string, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:dt, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/alter_table_serde.db/test_table/dt=2011, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), parameters:{transient_lastDdlTime=!!UNIXTIME!!})',''
6 rows selected 
>>>  
>>>  alter table test_table set serdeproperties ('field.delim' = ',');
No rows affected 
>>>  describe extended test_table partition (dt='2011');
'col_name','data_type','comment'
'id','int',''
'query','string',''
'name','string',''
'dt','string',''
'','',''
'Detailed Partition Information','Partition(values:[2011], dbName:alter_table_serde, tableName:test_table, createTime:!!UNIXTIME!!, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:query, type:string, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:dt, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/alter_table_serde.db/test_table/dt=2011, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), parameters:{transient_lastDdlTime=!!UNIXTIME!!})',''
6 rows selected 
>>>  
>>>  -- test partitions
>>>  
>>>  alter table test_table partition(dt='2011') set serde 'org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe';
No rows affected 
>>>  describe extended test_table partition (dt='2011');
'col_name','data_type','comment'
'id','int',''
'query','string',''
'name','string',''
'dt','string',''
'','',''
'Detailed Partition Information','Partition(values:[2011], dbName:alter_table_serde, tableName:test_table, createTime:!!UNIXTIME!!, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:query, type:string, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:dt, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/alter_table_serde.db/test_table/dt=2011, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), parameters:{last_modified_by=!!ELIDED!!, last_modified_time=!!UNIXTIME!!, transient_lastDdlTime=!!UNIXTIME!!})',''
6 rows selected 
>>>  
>>>  alter table test_table partition(dt='2011') set serdeproperties ('field.delim' = ',');
No rows affected 
>>>  describe extended test_table partition (dt='2011');
'col_name','data_type','comment'
'id','int',''
'query','string',''
'name','string',''
'dt','string',''
'','',''
'Detailed Partition Information','Partition(values:[2011], dbName:alter_table_serde, tableName:test_table, createTime:!!UNIXTIME!!, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:query, type:string, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:dt, type:string, comment:null)], location:!!{hive.metastore.warehouse.dir}!!/alter_table_serde.db/test_table/dt=2011, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1, field.delim=,}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), parameters:{last_modified_by=!!ELIDED!!, last_modified_time=!!UNIXTIME!!, transient_lastDdlTime=!!UNIXTIME!!})',''
6 rows selected 
>>>  
>>>  drop table test_table;
No rows affected 
>>>  !record
