Saving all output to "!!{outputDirectory}!!/udf1.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/udf1.q
>>>  CREATE TABLE dest1(c1 STRING, c2 STRING, c3 STRING, c4 STRING, 
c5 STRING, c6 STRING, c7 STRING, c8 STRING, 
c9 STRING, c10 STRING, c11 STRING, c12 STRING, c13 STRING, 
c14 STRING, c15 STRING, c16 STRING, c17 STRING, 
c18 STRING, c19 STRING, c20 STRING) STORED AS TEXTFILE;
No rows affected 
>>>  
>>>  EXPLAIN 
FROM src INSERT OVERWRITE TABLE dest1 SELECT 'a' LIKE '%a%', 'b' LIKE '%a%', 'ab' LIKE '%a%', 'ab' LIKE '%a_', 
'%_' LIKE '\%\_', 'ab' LIKE '\%\_', 'ab' LIKE '_a%', 'ab' LIKE 'a', 
'' RLIKE '.*', 'a' RLIKE '[ab]', '' RLIKE '[ab]', 'hadoop' RLIKE '[a-z]*', 'hadoop' RLIKE 'o*', 
REGEXP_REPLACE('abc', 'b', 'c'), REGEXP_REPLACE('abc', 'z', 'a'), REGEXP_REPLACE('abbbb', 'bb', 'b'), 
REGEXP_REPLACE('hadoop', '(.)[a-z]*', '$1ive'), REGEXP_REPLACE('hadoopAAA','A.*',''), 
REGEXP_REPLACE('abc', '', 'A'), 'abc' RLIKE '' 
WHERE src.key = 86;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME dest1))) (TOK_SELECT (TOK_SELEXPR (LIKE 'a' '%a%')) (TOK_SELEXPR (LIKE 'b' '%a%')) (TOK_SELEXPR (LIKE 'ab' '%a%')) (TOK_SELEXPR (LIKE 'ab' '%a_')) (TOK_SELEXPR (LIKE '%_' '\%\_')) (TOK_SELEXPR (LIKE 'ab' '\%\_')) (TOK_SELEXPR (LIKE 'ab' '_a%')) (TOK_SELEXPR (LIKE 'ab' 'a')) (TOK_SELEXPR (RLIKE '' '.*')) (TOK_SELEXPR (RLIKE 'a' '[ab]')) (TOK_SELEXPR (RLIKE '' '[ab]')) (TOK_SELEXPR (RLIKE 'hadoop' '[a-z]*')) (TOK_SELEXPR (RLIKE 'hadoop' 'o*')) (TOK_SELEXPR (TOK_FUNCTION REGEXP_REPLACE 'abc' 'b' 'c')) (TOK_SELEXPR (TOK_FUNCTION REGEXP_REPLACE 'abc' 'z' 'a')) (TOK_SELEXPR (TOK_FUNCTION REGEXP_REPLACE 'abbbb' 'bb' 'b')) (TOK_SELEXPR (TOK_FUNCTION REGEXP_REPLACE 'hadoop' '(.)[a-z]*' '$1ive')) (TOK_SELEXPR (TOK_FUNCTION REGEXP_REPLACE 'hadoopAAA' 'A.*' '')) (TOK_SELEXPR (TOK_FUNCTION REGEXP_REPLACE 'abc' '' 'A')) (TOK_SELEXPR (RLIKE 'abc' ''))) (TOK_WHERE (= (. (TOK_TABLE_OR_COL src) key) 86))))'
''
'STAGE DEPENDENCIES:'
'  Stage-1 is a root stage'
'  Stage-7 depends on stages: Stage-1 , consists of Stage-4, Stage-3, Stage-5'
'  Stage-4'
'  Stage-0 depends on stages: Stage-4, Stage-3, Stage-6'
'  Stage-2 depends on stages: Stage-0'
'  Stage-3'
'  Stage-5'
'  Stage-6 depends on stages: Stage-5'
''
'STAGE PLANS:'
'  Stage: Stage-1'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        src '
'          TableScan'
'            alias: src'
'            Filter Operator'
'              predicate:'
'                  expr: (key = 86.0)'
'                  type: boolean'
'              Select Operator'
'                expressions:'
'                      expr: ('a' like '%a%')'
'                      type: boolean'
'                      expr: ('b' like '%a%')'
'                      type: boolean'
'                      expr: ('ab' like '%a%')'
'                      type: boolean'
'                      expr: ('ab' like '%a_')'
'                      type: boolean'
'                      expr: ('%_' like '\%\_')'
'                      type: boolean'
'                      expr: ('ab' like '\%\_')'
'                      type: boolean'
'                      expr: ('ab' like '_a%')'
'                      type: boolean'
'                      expr: ('ab' like 'a')'
'                      type: boolean'
'                      expr: ('' rlike '.*')'
'                      type: boolean'
'                      expr: ('a' rlike '[ab]')'
'                      type: boolean'
'                      expr: ('' rlike '[ab]')'
'                      type: boolean'
'                      expr: ('hadoop' rlike '[a-z]*')'
'                      type: boolean'
'                      expr: ('hadoop' rlike 'o*')'
'                      type: boolean'
'                      expr: regexp_replace('abc', 'b', 'c')'
'                      type: string'
'                      expr: regexp_replace('abc', 'z', 'a')'
'                      type: string'
'                      expr: regexp_replace('abbbb', 'bb', 'b')'
'                      type: string'
'                      expr: regexp_replace('hadoop', '(.)[a-z]*', '$1ive')'
'                      type: string'
'                      expr: regexp_replace('hadoopAAA', 'A.*', '')'
'                      type: string'
'                      expr: regexp_replace('abc', '', 'A')'
'                      type: string'
'                      expr: ('abc' rlike '')'
'                      type: boolean'
'                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19'
'                File Output Operator'
'                  compressed: false'
'                  GlobalTableId: 1'
'                  table:'
'                      input format: org.apache.hadoop.mapred.TextInputFormat'
'                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'                      name: udf1.dest1'
''
'  Stage: Stage-7'
'    Conditional Operator'
''
'  Stage: Stage-4'
'    Move Operator'
'      files:'
'          hdfs directory: true'
'          destination: pfile:!!{hive.exec.scratchdir}!!'
''
'  Stage: Stage-0'
'    Move Operator'
'      tables:'
'          replace: true'
'          table:'
'              input format: org.apache.hadoop.mapred.TextInputFormat'
'              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'              name: udf1.dest1'
''
'  Stage: Stage-2'
'    Stats-Aggr Operator'
''
'  Stage: Stage-3'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        pfile:!!{hive.exec.scratchdir}!! '
'            File Output Operator'
'              compressed: false'
'              GlobalTableId: 0'
'              table:'
'                  input format: org.apache.hadoop.mapred.TextInputFormat'
'                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'                  name: udf1.dest1'
''
'  Stage: Stage-5'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        pfile:!!{hive.exec.scratchdir}!! '
'            File Output Operator'
'              compressed: false'
'              GlobalTableId: 0'
'              table:'
'                  input format: org.apache.hadoop.mapred.TextInputFormat'
'                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
'                  name: udf1.dest1'
''
'  Stage: Stage-6'
'    Move Operator'
'      files:'
'          hdfs directory: true'
'          destination: pfile:!!{hive.exec.scratchdir}!!'
''
''
131 rows selected 
>>>  
>>>  FROM src INSERT OVERWRITE TABLE dest1 SELECT 'a' LIKE '%a%', 'b' LIKE '%a%', 'ab' LIKE '%a%', 'ab' LIKE '%a_', 
'%_' LIKE '\%\_', 'ab' LIKE '\%\_', 'ab' LIKE '_a%', 'ab' LIKE 'a', 
'' RLIKE '.*', 'a' RLIKE '[ab]', '' RLIKE '[ab]', 'hadoop' RLIKE '[a-z]*', 'hadoop' RLIKE 'o*', 
REGEXP_REPLACE('abc', 'b', 'c'), REGEXP_REPLACE('abc', 'z', 'a'), REGEXP_REPLACE('abbbb', 'bb', 'b'), 
REGEXP_REPLACE('hadoop', '(.)[a-z]*', '$1ive'), REGEXP_REPLACE('hadoopAAA','A.*',''), 
REGEXP_REPLACE('abc', '', 'A'), 'abc' RLIKE '' 
WHERE src.key = 86;
'_c0','_c1','_c2','_c3','_c4','_c5','_c6','_c7','_c8','_c9','_c10','_c11','_c12','_c13','_c14','_c15','_c16','_c17','_c18','_c19'
No rows selected 
>>>  
>>>  SELECT dest1.* FROM dest1;
'c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','c13','c14','c15','c16','c17','c18','c19','c20'
'true','false','true','true','true','false','false','false','true','true','false','true','true','acc','abc','abb','hive','hadoop','AaAbAcA','false'
1 row selected 
>>>  !record
