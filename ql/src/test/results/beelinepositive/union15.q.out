Saving all output to "!!{outputDirectory}!!/union15.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/union15.q
>>>  set hive.map.aggr = true;
No rows affected 
>>>  
>>>  -- union case: 1 subquery is a map-reduce job, different inputs for sub-queries, followed by reducesink
>>>  
>>>  explain 
select unionsrc.key, count(1) FROM (select 'tst1' as key, cast(count(1) as string) as value from src s1 
UNION  ALL 
select s2.key as key, s2.value as value from src1 s2 
UNION  ALL 
select s3.key as key, s3.value as value from src1 s3) unionsrc group by unionsrc.key;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_UNION (TOK_UNION (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) s1)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR 'tst1' key) (TOK_SELEXPR (TOK_FUNCTION TOK_STRING (TOK_FUNCTION count 1)) value)))) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src1) s2)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL s2) key) key) (TOK_SELEXPR (. (TOK_TABLE_OR_COL s2) value) value))))) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src1) s3)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL s3) key) key) (TOK_SELEXPR (. (TOK_TABLE_OR_COL s3) value) value))))) unionsrc)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL unionsrc) key)) (TOK_SELEXPR (TOK_FUNCTION count 1))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL unionsrc) key))))'
''
'STAGE DEPENDENCIES:'
'  Stage-1 is a root stage'
'  Stage-2 depends on stages: Stage-1'
'  Stage-0 is a root stage'
''
'STAGE PLANS:'
'  Stage: Stage-1'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        null-subquery1-subquery1:unionsrc-subquery1-subquery1:s1 '
'          TableScan'
'            alias: s1'
'            Select Operator'
'              Group By Operator'
'                aggregations:'
'                      expr: count(1)'
'                bucketGroup: false'
'                mode: hash'
'                outputColumnNames: _col0'
'                Reduce Output Operator'
'                  sort order: '
'                  tag: -1'
'                  value expressions:'
'                        expr: _col0'
'                        type: bigint'
'      Reduce Operator Tree:'
'        Group By Operator'
'          aggregations:'
'                expr: count(VALUE._col0)'
'          bucketGroup: false'
'          mode: mergepartial'
'          outputColumnNames: _col0'
'          Select Operator'
'            expressions:'
'                  expr: 'tst1''
'                  type: string'
'                  expr: UDFToString(_col0)'
'                  type: string'
'            outputColumnNames: _col0, _col1'
'            File Output Operator'
'              compressed: false'
'              GlobalTableId: 0'
'              table:'
'                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat'
'                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat'
''
'  Stage: Stage-2'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        file:!!{hive.exec.scratchdir}!! '
'          TableScan'
'            Union'
'              Select Operator'
'                expressions:'
'                      expr: _col0'
'                      type: string'
'                outputColumnNames: _col0'
'                Group By Operator'
'                  aggregations:'
'                        expr: count(1)'
'                  bucketGroup: false'
'                  keys:'
'                        expr: _col0'
'                        type: string'
'                  mode: hash'
'                  outputColumnNames: _col0, _col1'
'                  Reduce Output Operator'
'                    key expressions:'
'                          expr: _col0'
'                          type: string'
'                    sort order: +'
'                    Map-reduce partition columns:'
'                          expr: _col0'
'                          type: string'
'                    tag: -1'
'                    value expressions:'
'                          expr: _col1'
'                          type: bigint'
'        null-subquery1-subquery2:unionsrc-subquery1-subquery2:s2 '
'          TableScan'
'            alias: s2'
'            Select Operator'
'              expressions:'
'                    expr: key'
'                    type: string'
'                    expr: value'
'                    type: string'
'              outputColumnNames: _col0, _col1'
'              Union'
'                Select Operator'
'                  expressions:'
'                        expr: _col0'
'                        type: string'
'                  outputColumnNames: _col0'
'                  Group By Operator'
'                    aggregations:'
'                          expr: count(1)'
'                    bucketGroup: false'
'                    keys:'
'                          expr: _col0'
'                          type: string'
'                    mode: hash'
'                    outputColumnNames: _col0, _col1'
'                    Reduce Output Operator'
'                      key expressions:'
'                            expr: _col0'
'                            type: string'
'                      sort order: +'
'                      Map-reduce partition columns:'
'                            expr: _col0'
'                            type: string'
'                      tag: -1'
'                      value expressions:'
'                            expr: _col1'
'                            type: bigint'
'        null-subquery2:unionsrc-subquery2:s3 '
'          TableScan'
'            alias: s3'
'            Select Operator'
'              expressions:'
'                    expr: key'
'                    type: string'
'                    expr: value'
'                    type: string'
'              outputColumnNames: _col0, _col1'
'              Union'
'                Select Operator'
'                  expressions:'
'                        expr: _col0'
'                        type: string'
'                  outputColumnNames: _col0'
'                  Group By Operator'
'                    aggregations:'
'                          expr: count(1)'
'                    bucketGroup: false'
'                    keys:'
'                          expr: _col0'
'                          type: string'
'                    mode: hash'
'                    outputColumnNames: _col0, _col1'
'                    Reduce Output Operator'
'                      key expressions:'
'                            expr: _col0'
'                            type: string'
'                      sort order: +'
'                      Map-reduce partition columns:'
'                            expr: _col0'
'                            type: string'
'                      tag: -1'
'                      value expressions:'
'                            expr: _col1'
'                            type: bigint'
'      Reduce Operator Tree:'
'        Group By Operator'
'          aggregations:'
'                expr: count(VALUE._col0)'
'          bucketGroup: false'
'          keys:'
'                expr: KEY._col0'
'                type: string'
'          mode: mergepartial'
'          outputColumnNames: _col0, _col1'
'          Select Operator'
'            expressions:'
'                  expr: _col0'
'                  type: string'
'                  expr: _col1'
'                  type: bigint'
'            outputColumnNames: _col0, _col1'
'            File Output Operator'
'              compressed: false'
'              GlobalTableId: 0'
'              table:'
'                  input format: org.apache.hadoop.mapred.TextInputFormat'
'                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
''
'  Stage: Stage-0'
'    Fetch Operator'
'      limit: -1'
''
''
184 rows selected 
>>>  
>>>  select unionsrc.key, count(1) FROM (select 'tst1' as key, cast(count(1) as string) as value from src s1 
UNION  ALL 
select s2.key as key, s2.value as value from src1 s2 
UNION  ALL 
select s3.key as key, s3.value as value from src1 s3) unionsrc group by unionsrc.key;
'key','_c1'
'','20'
'128','2'
'146','2'
'150','2'
'213','2'
'224','2'
'238','2'
'255','2'
'273','2'
'278','2'
'311','2'
'369','2'
'401','2'
'406','2'
'66','2'
'98','2'
'tst1','1'
17 rows selected 
>>>  
>>>  
>>>  !record
