// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: orc_proto.proto

package org.apache.hadoop.hive.ql.io.orc;

public final class OrcProto {
  private OrcProto() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public enum CompressionKind
      implements com.google.protobuf.ProtocolMessageEnum {
    NONE(0, 0),
    ZLIB(1, 1),
    SNAPPY(2, 2),
    LZO(3, 3),
    ;
    
    public static final int NONE_VALUE = 0;
    public static final int ZLIB_VALUE = 1;
    public static final int SNAPPY_VALUE = 2;
    public static final int LZO_VALUE = 3;
    
    
    public final int getNumber() { return value; }
    
    public static CompressionKind valueOf(int value) {
      switch (value) {
        case 0: return NONE;
        case 1: return ZLIB;
        case 2: return SNAPPY;
        case 3: return LZO;
        default: return null;
      }
    }
    
    public static com.google.protobuf.Internal.EnumLiteMap<CompressionKind>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<CompressionKind>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<CompressionKind>() {
            public CompressionKind findValueByNumber(int number) {
              return CompressionKind.valueOf(number);
            }
          };
    
    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.getDescriptor().getEnumTypes().get(0);
    }
    
    private static final CompressionKind[] VALUES = {
      NONE, ZLIB, SNAPPY, LZO, 
    };
    
    public static CompressionKind valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }
    
    private final int index;
    private final int value;
    
    private CompressionKind(int index, int value) {
      this.index = index;
      this.value = value;
    }
    
    // @@protoc_insertion_point(enum_scope:org.apache.hadoop.hive.ql.io.orc.CompressionKind)
  }
  
  public interface IntegerStatisticsOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional sint64 minimum = 1;
    boolean hasMinimum();
    long getMinimum();
    
    // optional sint64 maximum = 2;
    boolean hasMaximum();
    long getMaximum();
    
    // optional sint64 sum = 3;
    boolean hasSum();
    long getSum();
  }
  public static final class IntegerStatistics extends
      com.google.protobuf.GeneratedMessage
      implements IntegerStatisticsOrBuilder {
    // Use IntegerStatistics.newBuilder() to construct.
    private IntegerStatistics(Builder builder) {
      super(builder);
    }
    private IntegerStatistics(boolean noInit) {}
    
    private static final IntegerStatistics defaultInstance;
    public static IntegerStatistics getDefaultInstance() {
      return defaultInstance;
    }
    
    public IntegerStatistics getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional sint64 minimum = 1;
    public static final int MINIMUM_FIELD_NUMBER = 1;
    private long minimum_;
    public boolean hasMinimum() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public long getMinimum() {
      return minimum_;
    }
    
    // optional sint64 maximum = 2;
    public static final int MAXIMUM_FIELD_NUMBER = 2;
    private long maximum_;
    public boolean hasMaximum() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public long getMaximum() {
      return maximum_;
    }
    
    // optional sint64 sum = 3;
    public static final int SUM_FIELD_NUMBER = 3;
    private long sum_;
    public boolean hasSum() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public long getSum() {
      return sum_;
    }
    
    private void initFields() {
      minimum_ = 0L;
      maximum_ = 0L;
      sum_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeSInt64(1, minimum_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeSInt64(2, maximum_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeSInt64(3, sum_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeSInt64Size(1, minimum_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeSInt64Size(2, maximum_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeSInt64Size(3, sum_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatisticsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        minimum_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        maximum_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        sum_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.minimum_ = minimum_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.maximum_ = maximum_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.sum_ = sum_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.getDefaultInstance()) return this;
        if (other.hasMinimum()) {
          setMinimum(other.getMinimum());
        }
        if (other.hasMaximum()) {
          setMaximum(other.getMaximum());
        }
        if (other.hasSum()) {
          setSum(other.getSum());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              minimum_ = input.readSInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              maximum_ = input.readSInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              sum_ = input.readSInt64();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional sint64 minimum = 1;
      private long minimum_ ;
      public boolean hasMinimum() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public long getMinimum() {
        return minimum_;
      }
      public Builder setMinimum(long value) {
        bitField0_ |= 0x00000001;
        minimum_ = value;
        onChanged();
        return this;
      }
      public Builder clearMinimum() {
        bitField0_ = (bitField0_ & ~0x00000001);
        minimum_ = 0L;
        onChanged();
        return this;
      }
      
      // optional sint64 maximum = 2;
      private long maximum_ ;
      public boolean hasMaximum() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public long getMaximum() {
        return maximum_;
      }
      public Builder setMaximum(long value) {
        bitField0_ |= 0x00000002;
        maximum_ = value;
        onChanged();
        return this;
      }
      public Builder clearMaximum() {
        bitField0_ = (bitField0_ & ~0x00000002);
        maximum_ = 0L;
        onChanged();
        return this;
      }
      
      // optional sint64 sum = 3;
      private long sum_ ;
      public boolean hasSum() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public long getSum() {
        return sum_;
      }
      public Builder setSum(long value) {
        bitField0_ |= 0x00000004;
        sum_ = value;
        onChanged();
        return this;
      }
      public Builder clearSum() {
        bitField0_ = (bitField0_ & ~0x00000004);
        sum_ = 0L;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.IntegerStatistics)
    }
    
    static {
      defaultInstance = new IntegerStatistics(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.IntegerStatistics)
  }
  
  public interface DoubleStatisticsOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional double minimum = 1;
    boolean hasMinimum();
    double getMinimum();
    
    // optional double maximum = 2;
    boolean hasMaximum();
    double getMaximum();
    
    // optional double sum = 3;
    boolean hasSum();
    double getSum();
  }
  public static final class DoubleStatistics extends
      com.google.protobuf.GeneratedMessage
      implements DoubleStatisticsOrBuilder {
    // Use DoubleStatistics.newBuilder() to construct.
    private DoubleStatistics(Builder builder) {
      super(builder);
    }
    private DoubleStatistics(boolean noInit) {}
    
    private static final DoubleStatistics defaultInstance;
    public static DoubleStatistics getDefaultInstance() {
      return defaultInstance;
    }
    
    public DoubleStatistics getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional double minimum = 1;
    public static final int MINIMUM_FIELD_NUMBER = 1;
    private double minimum_;
    public boolean hasMinimum() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public double getMinimum() {
      return minimum_;
    }
    
    // optional double maximum = 2;
    public static final int MAXIMUM_FIELD_NUMBER = 2;
    private double maximum_;
    public boolean hasMaximum() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public double getMaximum() {
      return maximum_;
    }
    
    // optional double sum = 3;
    public static final int SUM_FIELD_NUMBER = 3;
    private double sum_;
    public boolean hasSum() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public double getSum() {
      return sum_;
    }
    
    private void initFields() {
      minimum_ = 0D;
      maximum_ = 0D;
      sum_ = 0D;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeDouble(1, minimum_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeDouble(2, maximum_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeDouble(3, sum_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeDoubleSize(1, minimum_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeDoubleSize(2, maximum_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeDoubleSize(3, sum_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatisticsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        minimum_ = 0D;
        bitField0_ = (bitField0_ & ~0x00000001);
        maximum_ = 0D;
        bitField0_ = (bitField0_ & ~0x00000002);
        sum_ = 0D;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.minimum_ = minimum_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.maximum_ = maximum_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.sum_ = sum_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.getDefaultInstance()) return this;
        if (other.hasMinimum()) {
          setMinimum(other.getMinimum());
        }
        if (other.hasMaximum()) {
          setMaximum(other.getMaximum());
        }
        if (other.hasSum()) {
          setSum(other.getSum());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 9: {
              bitField0_ |= 0x00000001;
              minimum_ = input.readDouble();
              break;
            }
            case 17: {
              bitField0_ |= 0x00000002;
              maximum_ = input.readDouble();
              break;
            }
            case 25: {
              bitField0_ |= 0x00000004;
              sum_ = input.readDouble();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional double minimum = 1;
      private double minimum_ ;
      public boolean hasMinimum() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public double getMinimum() {
        return minimum_;
      }
      public Builder setMinimum(double value) {
        bitField0_ |= 0x00000001;
        minimum_ = value;
        onChanged();
        return this;
      }
      public Builder clearMinimum() {
        bitField0_ = (bitField0_ & ~0x00000001);
        minimum_ = 0D;
        onChanged();
        return this;
      }
      
      // optional double maximum = 2;
      private double maximum_ ;
      public boolean hasMaximum() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public double getMaximum() {
        return maximum_;
      }
      public Builder setMaximum(double value) {
        bitField0_ |= 0x00000002;
        maximum_ = value;
        onChanged();
        return this;
      }
      public Builder clearMaximum() {
        bitField0_ = (bitField0_ & ~0x00000002);
        maximum_ = 0D;
        onChanged();
        return this;
      }
      
      // optional double sum = 3;
      private double sum_ ;
      public boolean hasSum() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public double getSum() {
        return sum_;
      }
      public Builder setSum(double value) {
        bitField0_ |= 0x00000004;
        sum_ = value;
        onChanged();
        return this;
      }
      public Builder clearSum() {
        bitField0_ = (bitField0_ & ~0x00000004);
        sum_ = 0D;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.DoubleStatistics)
    }
    
    static {
      defaultInstance = new DoubleStatistics(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.DoubleStatistics)
  }
  
  public interface StringStatisticsOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional string minimum = 1;
    boolean hasMinimum();
    String getMinimum();
    
    // optional string maximum = 2;
    boolean hasMaximum();
    String getMaximum();
  }
  public static final class StringStatistics extends
      com.google.protobuf.GeneratedMessage
      implements StringStatisticsOrBuilder {
    // Use StringStatistics.newBuilder() to construct.
    private StringStatistics(Builder builder) {
      super(builder);
    }
    private StringStatistics(boolean noInit) {}
    
    private static final StringStatistics defaultInstance;
    public static StringStatistics getDefaultInstance() {
      return defaultInstance;
    }
    
    public StringStatistics getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional string minimum = 1;
    public static final int MINIMUM_FIELD_NUMBER = 1;
    private java.lang.Object minimum_;
    public boolean hasMinimum() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public String getMinimum() {
      java.lang.Object ref = minimum_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          minimum_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getMinimumBytes() {
      java.lang.Object ref = minimum_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        minimum_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    // optional string maximum = 2;
    public static final int MAXIMUM_FIELD_NUMBER = 2;
    private java.lang.Object maximum_;
    public boolean hasMaximum() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public String getMaximum() {
      java.lang.Object ref = maximum_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          maximum_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getMaximumBytes() {
      java.lang.Object ref = maximum_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        maximum_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    private void initFields() {
      minimum_ = "";
      maximum_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getMinimumBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getMaximumBytes());
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getMinimumBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getMaximumBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatisticsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        minimum_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        maximum_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.minimum_ = minimum_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.maximum_ = maximum_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.getDefaultInstance()) return this;
        if (other.hasMinimum()) {
          setMinimum(other.getMinimum());
        }
        if (other.hasMaximum()) {
          setMaximum(other.getMaximum());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              minimum_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              maximum_ = input.readBytes();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional string minimum = 1;
      private java.lang.Object minimum_ = "";
      public boolean hasMinimum() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public String getMinimum() {
        java.lang.Object ref = minimum_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          minimum_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setMinimum(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        minimum_ = value;
        onChanged();
        return this;
      }
      public Builder clearMinimum() {
        bitField0_ = (bitField0_ & ~0x00000001);
        minimum_ = getDefaultInstance().getMinimum();
        onChanged();
        return this;
      }
      void setMinimum(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000001;
        minimum_ = value;
        onChanged();
      }
      
      // optional string maximum = 2;
      private java.lang.Object maximum_ = "";
      public boolean hasMaximum() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public String getMaximum() {
        java.lang.Object ref = maximum_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          maximum_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setMaximum(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        maximum_ = value;
        onChanged();
        return this;
      }
      public Builder clearMaximum() {
        bitField0_ = (bitField0_ & ~0x00000002);
        maximum_ = getDefaultInstance().getMaximum();
        onChanged();
        return this;
      }
      void setMaximum(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000002;
        maximum_ = value;
        onChanged();
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.StringStatistics)
    }
    
    static {
      defaultInstance = new StringStatistics(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.StringStatistics)
  }
  
  public interface BucketStatisticsOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated uint64 count = 1 [packed = true];
    java.util.List<java.lang.Long> getCountList();
    int getCountCount();
    long getCount(int index);
  }
  public static final class BucketStatistics extends
      com.google.protobuf.GeneratedMessage
      implements BucketStatisticsOrBuilder {
    // Use BucketStatistics.newBuilder() to construct.
    private BucketStatistics(Builder builder) {
      super(builder);
    }
    private BucketStatistics(boolean noInit) {}
    
    private static final BucketStatistics defaultInstance;
    public static BucketStatistics getDefaultInstance() {
      return defaultInstance;
    }
    
    public BucketStatistics getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_fieldAccessorTable;
    }
    
    // repeated uint64 count = 1 [packed = true];
    public static final int COUNT_FIELD_NUMBER = 1;
    private java.util.List<java.lang.Long> count_;
    public java.util.List<java.lang.Long>
        getCountList() {
      return count_;
    }
    public int getCountCount() {
      return count_.size();
    }
    public long getCount(int index) {
      return count_.get(index);
    }
    private int countMemoizedSerializedSize = -1;
    
    private void initFields() {
      count_ = java.util.Collections.emptyList();;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (getCountList().size() > 0) {
        output.writeRawVarint32(10);
        output.writeRawVarint32(countMemoizedSerializedSize);
      }
      for (int i = 0; i < count_.size(); i++) {
        output.writeUInt64NoTag(count_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < count_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeUInt64SizeNoTag(count_.get(i));
        }
        size += dataSize;
        if (!getCountList().isEmpty()) {
          size += 1;
          size += com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(dataSize);
        }
        countMemoizedSerializedSize = dataSize;
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatisticsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        count_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          count_ = java.util.Collections.unmodifiableList(count_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.count_ = count_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.getDefaultInstance()) return this;
        if (!other.count_.isEmpty()) {
          if (count_.isEmpty()) {
            count_ = other.count_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureCountIsMutable();
            count_.addAll(other.count_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              ensureCountIsMutable();
              count_.add(input.readUInt64());
              break;
            }
            case 10: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              while (input.getBytesUntilLimit() > 0) {
                addCount(input.readUInt64());
              }
              input.popLimit(limit);
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated uint64 count = 1 [packed = true];
      private java.util.List<java.lang.Long> count_ = java.util.Collections.emptyList();;
      private void ensureCountIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          count_ = new java.util.ArrayList<java.lang.Long>(count_);
          bitField0_ |= 0x00000001;
         }
      }
      public java.util.List<java.lang.Long>
          getCountList() {
        return java.util.Collections.unmodifiableList(count_);
      }
      public int getCountCount() {
        return count_.size();
      }
      public long getCount(int index) {
        return count_.get(index);
      }
      public Builder setCount(
          int index, long value) {
        ensureCountIsMutable();
        count_.set(index, value);
        onChanged();
        return this;
      }
      public Builder addCount(long value) {
        ensureCountIsMutable();
        count_.add(value);
        onChanged();
        return this;
      }
      public Builder addAllCount(
          java.lang.Iterable<? extends java.lang.Long> values) {
        ensureCountIsMutable();
        super.addAll(values, count_);
        onChanged();
        return this;
      }
      public Builder clearCount() {
        count_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.BucketStatistics)
    }
    
    static {
      defaultInstance = new BucketStatistics(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.BucketStatistics)
  }
  
  public interface ColumnStatisticsOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional uint64 numberOfValues = 1;
    boolean hasNumberOfValues();
    long getNumberOfValues();
    
    // optional .org.apache.hadoop.hive.ql.io.orc.IntegerStatistics intStatistics = 2;
    boolean hasIntStatistics();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics getIntStatistics();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatisticsOrBuilder getIntStatisticsOrBuilder();
    
    // optional .org.apache.hadoop.hive.ql.io.orc.DoubleStatistics doubleStatistics = 3;
    boolean hasDoubleStatistics();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics getDoubleStatistics();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatisticsOrBuilder getDoubleStatisticsOrBuilder();
    
    // optional .org.apache.hadoop.hive.ql.io.orc.StringStatistics stringStatistics = 4;
    boolean hasStringStatistics();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics getStringStatistics();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatisticsOrBuilder getStringStatisticsOrBuilder();
    
    // optional .org.apache.hadoop.hive.ql.io.orc.BucketStatistics bucketStatistics = 5;
    boolean hasBucketStatistics();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics getBucketStatistics();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatisticsOrBuilder getBucketStatisticsOrBuilder();
  }
  public static final class ColumnStatistics extends
      com.google.protobuf.GeneratedMessage
      implements ColumnStatisticsOrBuilder {
    // Use ColumnStatistics.newBuilder() to construct.
    private ColumnStatistics(Builder builder) {
      super(builder);
    }
    private ColumnStatistics(boolean noInit) {}
    
    private static final ColumnStatistics defaultInstance;
    public static ColumnStatistics getDefaultInstance() {
      return defaultInstance;
    }
    
    public ColumnStatistics getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional uint64 numberOfValues = 1;
    public static final int NUMBEROFVALUES_FIELD_NUMBER = 1;
    private long numberOfValues_;
    public boolean hasNumberOfValues() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public long getNumberOfValues() {
      return numberOfValues_;
    }
    
    // optional .org.apache.hadoop.hive.ql.io.orc.IntegerStatistics intStatistics = 2;
    public static final int INTSTATISTICS_FIELD_NUMBER = 2;
    private org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics intStatistics_;
    public boolean hasIntStatistics() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics getIntStatistics() {
      return intStatistics_;
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatisticsOrBuilder getIntStatisticsOrBuilder() {
      return intStatistics_;
    }
    
    // optional .org.apache.hadoop.hive.ql.io.orc.DoubleStatistics doubleStatistics = 3;
    public static final int DOUBLESTATISTICS_FIELD_NUMBER = 3;
    private org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics doubleStatistics_;
    public boolean hasDoubleStatistics() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics getDoubleStatistics() {
      return doubleStatistics_;
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatisticsOrBuilder getDoubleStatisticsOrBuilder() {
      return doubleStatistics_;
    }
    
    // optional .org.apache.hadoop.hive.ql.io.orc.StringStatistics stringStatistics = 4;
    public static final int STRINGSTATISTICS_FIELD_NUMBER = 4;
    private org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics stringStatistics_;
    public boolean hasStringStatistics() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics getStringStatistics() {
      return stringStatistics_;
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatisticsOrBuilder getStringStatisticsOrBuilder() {
      return stringStatistics_;
    }
    
    // optional .org.apache.hadoop.hive.ql.io.orc.BucketStatistics bucketStatistics = 5;
    public static final int BUCKETSTATISTICS_FIELD_NUMBER = 5;
    private org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics bucketStatistics_;
    public boolean hasBucketStatistics() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics getBucketStatistics() {
      return bucketStatistics_;
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatisticsOrBuilder getBucketStatisticsOrBuilder() {
      return bucketStatistics_;
    }
    
    private void initFields() {
      numberOfValues_ = 0L;
      intStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.getDefaultInstance();
      doubleStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.getDefaultInstance();
      stringStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.getDefaultInstance();
      bucketStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt64(1, numberOfValues_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, intStatistics_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, doubleStatistics_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, stringStatistics_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, bucketStatistics_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, numberOfValues_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, intStatistics_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, doubleStatistics_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, stringStatistics_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, bucketStatistics_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getIntStatisticsFieldBuilder();
          getDoubleStatisticsFieldBuilder();
          getStringStatisticsFieldBuilder();
          getBucketStatisticsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        numberOfValues_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (intStatisticsBuilder_ == null) {
          intStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.getDefaultInstance();
        } else {
          intStatisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (doubleStatisticsBuilder_ == null) {
          doubleStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.getDefaultInstance();
        } else {
          doubleStatisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (stringStatisticsBuilder_ == null) {
          stringStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.getDefaultInstance();
        } else {
          stringStatisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (bucketStatisticsBuilder_ == null) {
          bucketStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.getDefaultInstance();
        } else {
          bucketStatisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.numberOfValues_ = numberOfValues_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (intStatisticsBuilder_ == null) {
          result.intStatistics_ = intStatistics_;
        } else {
          result.intStatistics_ = intStatisticsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (doubleStatisticsBuilder_ == null) {
          result.doubleStatistics_ = doubleStatistics_;
        } else {
          result.doubleStatistics_ = doubleStatisticsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (stringStatisticsBuilder_ == null) {
          result.stringStatistics_ = stringStatistics_;
        } else {
          result.stringStatistics_ = stringStatisticsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (bucketStatisticsBuilder_ == null) {
          result.bucketStatistics_ = bucketStatistics_;
        } else {
          result.bucketStatistics_ = bucketStatisticsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.getDefaultInstance()) return this;
        if (other.hasNumberOfValues()) {
          setNumberOfValues(other.getNumberOfValues());
        }
        if (other.hasIntStatistics()) {
          mergeIntStatistics(other.getIntStatistics());
        }
        if (other.hasDoubleStatistics()) {
          mergeDoubleStatistics(other.getDoubleStatistics());
        }
        if (other.hasStringStatistics()) {
          mergeStringStatistics(other.getStringStatistics());
        }
        if (other.hasBucketStatistics()) {
          mergeBucketStatistics(other.getBucketStatistics());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              numberOfValues_ = input.readUInt64();
              break;
            }
            case 18: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.newBuilder();
              if (hasIntStatistics()) {
                subBuilder.mergeFrom(getIntStatistics());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setIntStatistics(subBuilder.buildPartial());
              break;
            }
            case 26: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.newBuilder();
              if (hasDoubleStatistics()) {
                subBuilder.mergeFrom(getDoubleStatistics());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setDoubleStatistics(subBuilder.buildPartial());
              break;
            }
            case 34: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.newBuilder();
              if (hasStringStatistics()) {
                subBuilder.mergeFrom(getStringStatistics());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setStringStatistics(subBuilder.buildPartial());
              break;
            }
            case 42: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.newBuilder();
              if (hasBucketStatistics()) {
                subBuilder.mergeFrom(getBucketStatistics());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setBucketStatistics(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional uint64 numberOfValues = 1;
      private long numberOfValues_ ;
      public boolean hasNumberOfValues() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public long getNumberOfValues() {
        return numberOfValues_;
      }
      public Builder setNumberOfValues(long value) {
        bitField0_ |= 0x00000001;
        numberOfValues_ = value;
        onChanged();
        return this;
      }
      public Builder clearNumberOfValues() {
        bitField0_ = (bitField0_ & ~0x00000001);
        numberOfValues_ = 0L;
        onChanged();
        return this;
      }
      
      // optional .org.apache.hadoop.hive.ql.io.orc.IntegerStatistics intStatistics = 2;
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics intStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatisticsOrBuilder> intStatisticsBuilder_;
      public boolean hasIntStatistics() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics getIntStatistics() {
        if (intStatisticsBuilder_ == null) {
          return intStatistics_;
        } else {
          return intStatisticsBuilder_.getMessage();
        }
      }
      public Builder setIntStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics value) {
        if (intStatisticsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          intStatistics_ = value;
          onChanged();
        } else {
          intStatisticsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setIntStatistics(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.Builder builderForValue) {
        if (intStatisticsBuilder_ == null) {
          intStatistics_ = builderForValue.build();
          onChanged();
        } else {
          intStatisticsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeIntStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics value) {
        if (intStatisticsBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              intStatistics_ != org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.getDefaultInstance()) {
            intStatistics_ =
              org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.newBuilder(intStatistics_).mergeFrom(value).buildPartial();
          } else {
            intStatistics_ = value;
          }
          onChanged();
        } else {
          intStatisticsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearIntStatistics() {
        if (intStatisticsBuilder_ == null) {
          intStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.getDefaultInstance();
          onChanged();
        } else {
          intStatisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.Builder getIntStatisticsBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getIntStatisticsFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatisticsOrBuilder getIntStatisticsOrBuilder() {
        if (intStatisticsBuilder_ != null) {
          return intStatisticsBuilder_.getMessageOrBuilder();
        } else {
          return intStatistics_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatisticsOrBuilder> 
          getIntStatisticsFieldBuilder() {
        if (intStatisticsBuilder_ == null) {
          intStatisticsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatisticsOrBuilder>(
                  intStatistics_,
                  getParentForChildren(),
                  isClean());
          intStatistics_ = null;
        }
        return intStatisticsBuilder_;
      }
      
      // optional .org.apache.hadoop.hive.ql.io.orc.DoubleStatistics doubleStatistics = 3;
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics doubleStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatisticsOrBuilder> doubleStatisticsBuilder_;
      public boolean hasDoubleStatistics() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics getDoubleStatistics() {
        if (doubleStatisticsBuilder_ == null) {
          return doubleStatistics_;
        } else {
          return doubleStatisticsBuilder_.getMessage();
        }
      }
      public Builder setDoubleStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics value) {
        if (doubleStatisticsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          doubleStatistics_ = value;
          onChanged();
        } else {
          doubleStatisticsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder setDoubleStatistics(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.Builder builderForValue) {
        if (doubleStatisticsBuilder_ == null) {
          doubleStatistics_ = builderForValue.build();
          onChanged();
        } else {
          doubleStatisticsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder mergeDoubleStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics value) {
        if (doubleStatisticsBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              doubleStatistics_ != org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.getDefaultInstance()) {
            doubleStatistics_ =
              org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.newBuilder(doubleStatistics_).mergeFrom(value).buildPartial();
          } else {
            doubleStatistics_ = value;
          }
          onChanged();
        } else {
          doubleStatisticsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder clearDoubleStatistics() {
        if (doubleStatisticsBuilder_ == null) {
          doubleStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.getDefaultInstance();
          onChanged();
        } else {
          doubleStatisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.Builder getDoubleStatisticsBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getDoubleStatisticsFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatisticsOrBuilder getDoubleStatisticsOrBuilder() {
        if (doubleStatisticsBuilder_ != null) {
          return doubleStatisticsBuilder_.getMessageOrBuilder();
        } else {
          return doubleStatistics_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatisticsOrBuilder> 
          getDoubleStatisticsFieldBuilder() {
        if (doubleStatisticsBuilder_ == null) {
          doubleStatisticsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatisticsOrBuilder>(
                  doubleStatistics_,
                  getParentForChildren(),
                  isClean());
          doubleStatistics_ = null;
        }
        return doubleStatisticsBuilder_;
      }
      
      // optional .org.apache.hadoop.hive.ql.io.orc.StringStatistics stringStatistics = 4;
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics stringStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatisticsOrBuilder> stringStatisticsBuilder_;
      public boolean hasStringStatistics() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics getStringStatistics() {
        if (stringStatisticsBuilder_ == null) {
          return stringStatistics_;
        } else {
          return stringStatisticsBuilder_.getMessage();
        }
      }
      public Builder setStringStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics value) {
        if (stringStatisticsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          stringStatistics_ = value;
          onChanged();
        } else {
          stringStatisticsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      public Builder setStringStatistics(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.Builder builderForValue) {
        if (stringStatisticsBuilder_ == null) {
          stringStatistics_ = builderForValue.build();
          onChanged();
        } else {
          stringStatisticsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      public Builder mergeStringStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics value) {
        if (stringStatisticsBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              stringStatistics_ != org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.getDefaultInstance()) {
            stringStatistics_ =
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.newBuilder(stringStatistics_).mergeFrom(value).buildPartial();
          } else {
            stringStatistics_ = value;
          }
          onChanged();
        } else {
          stringStatisticsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      public Builder clearStringStatistics() {
        if (stringStatisticsBuilder_ == null) {
          stringStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.getDefaultInstance();
          onChanged();
        } else {
          stringStatisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.Builder getStringStatisticsBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getStringStatisticsFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatisticsOrBuilder getStringStatisticsOrBuilder() {
        if (stringStatisticsBuilder_ != null) {
          return stringStatisticsBuilder_.getMessageOrBuilder();
        } else {
          return stringStatistics_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatisticsOrBuilder> 
          getStringStatisticsFieldBuilder() {
        if (stringStatisticsBuilder_ == null) {
          stringStatisticsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatisticsOrBuilder>(
                  stringStatistics_,
                  getParentForChildren(),
                  isClean());
          stringStatistics_ = null;
        }
        return stringStatisticsBuilder_;
      }
      
      // optional .org.apache.hadoop.hive.ql.io.orc.BucketStatistics bucketStatistics = 5;
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics bucketStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatisticsOrBuilder> bucketStatisticsBuilder_;
      public boolean hasBucketStatistics() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics getBucketStatistics() {
        if (bucketStatisticsBuilder_ == null) {
          return bucketStatistics_;
        } else {
          return bucketStatisticsBuilder_.getMessage();
        }
      }
      public Builder setBucketStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics value) {
        if (bucketStatisticsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          bucketStatistics_ = value;
          onChanged();
        } else {
          bucketStatisticsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder setBucketStatistics(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.Builder builderForValue) {
        if (bucketStatisticsBuilder_ == null) {
          bucketStatistics_ = builderForValue.build();
          onChanged();
        } else {
          bucketStatisticsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder mergeBucketStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics value) {
        if (bucketStatisticsBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              bucketStatistics_ != org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.getDefaultInstance()) {
            bucketStatistics_ =
              org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.newBuilder(bucketStatistics_).mergeFrom(value).buildPartial();
          } else {
            bucketStatistics_ = value;
          }
          onChanged();
        } else {
          bucketStatisticsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder clearBucketStatistics() {
        if (bucketStatisticsBuilder_ == null) {
          bucketStatistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.getDefaultInstance();
          onChanged();
        } else {
          bucketStatisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.Builder getBucketStatisticsBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getBucketStatisticsFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatisticsOrBuilder getBucketStatisticsOrBuilder() {
        if (bucketStatisticsBuilder_ != null) {
          return bucketStatisticsBuilder_.getMessageOrBuilder();
        } else {
          return bucketStatistics_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatisticsOrBuilder> 
          getBucketStatisticsFieldBuilder() {
        if (bucketStatisticsBuilder_ == null) {
          bucketStatisticsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatisticsOrBuilder>(
                  bucketStatistics_,
                  getParentForChildren(),
                  isClean());
          bucketStatistics_ = null;
        }
        return bucketStatisticsBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.ColumnStatistics)
    }
    
    static {
      defaultInstance = new ColumnStatistics(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.ColumnStatistics)
  }
  
  public interface RowIndexEntryOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated uint64 positions = 1 [packed = true];
    java.util.List<java.lang.Long> getPositionsList();
    int getPositionsCount();
    long getPositions(int index);
    
    // optional .org.apache.hadoop.hive.ql.io.orc.ColumnStatistics statistics = 2;
    boolean hasStatistics();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics getStatistics();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder getStatisticsOrBuilder();
  }
  public static final class RowIndexEntry extends
      com.google.protobuf.GeneratedMessage
      implements RowIndexEntryOrBuilder {
    // Use RowIndexEntry.newBuilder() to construct.
    private RowIndexEntry(Builder builder) {
      super(builder);
    }
    private RowIndexEntry(boolean noInit) {}
    
    private static final RowIndexEntry defaultInstance;
    public static RowIndexEntry getDefaultInstance() {
      return defaultInstance;
    }
    
    public RowIndexEntry getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_fieldAccessorTable;
    }
    
    private int bitField0_;
    // repeated uint64 positions = 1 [packed = true];
    public static final int POSITIONS_FIELD_NUMBER = 1;
    private java.util.List<java.lang.Long> positions_;
    public java.util.List<java.lang.Long>
        getPositionsList() {
      return positions_;
    }
    public int getPositionsCount() {
      return positions_.size();
    }
    public long getPositions(int index) {
      return positions_.get(index);
    }
    private int positionsMemoizedSerializedSize = -1;
    
    // optional .org.apache.hadoop.hive.ql.io.orc.ColumnStatistics statistics = 2;
    public static final int STATISTICS_FIELD_NUMBER = 2;
    private org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics statistics_;
    public boolean hasStatistics() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics getStatistics() {
      return statistics_;
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder getStatisticsOrBuilder() {
      return statistics_;
    }
    
    private void initFields() {
      positions_ = java.util.Collections.emptyList();;
      statistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (getPositionsList().size() > 0) {
        output.writeRawVarint32(10);
        output.writeRawVarint32(positionsMemoizedSerializedSize);
      }
      for (int i = 0; i < positions_.size(); i++) {
        output.writeUInt64NoTag(positions_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(2, statistics_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < positions_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeUInt64SizeNoTag(positions_.get(i));
        }
        size += dataSize;
        if (!getPositionsList().isEmpty()) {
          size += 1;
          size += com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(dataSize);
        }
        positionsMemoizedSerializedSize = dataSize;
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, statistics_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntryOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getStatisticsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        positions_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (statisticsBuilder_ == null) {
          statistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.getDefaultInstance();
        } else {
          statisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          positions_ = java.util.Collections.unmodifiableList(positions_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.positions_ = positions_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        if (statisticsBuilder_ == null) {
          result.statistics_ = statistics_;
        } else {
          result.statistics_ = statisticsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.getDefaultInstance()) return this;
        if (!other.positions_.isEmpty()) {
          if (positions_.isEmpty()) {
            positions_ = other.positions_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensurePositionsIsMutable();
            positions_.addAll(other.positions_);
          }
          onChanged();
        }
        if (other.hasStatistics()) {
          mergeStatistics(other.getStatistics());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              ensurePositionsIsMutable();
              positions_.add(input.readUInt64());
              break;
            }
            case 10: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              while (input.getBytesUntilLimit() > 0) {
                addPositions(input.readUInt64());
              }
              input.popLimit(limit);
              break;
            }
            case 18: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.newBuilder();
              if (hasStatistics()) {
                subBuilder.mergeFrom(getStatistics());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setStatistics(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated uint64 positions = 1 [packed = true];
      private java.util.List<java.lang.Long> positions_ = java.util.Collections.emptyList();;
      private void ensurePositionsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          positions_ = new java.util.ArrayList<java.lang.Long>(positions_);
          bitField0_ |= 0x00000001;
         }
      }
      public java.util.List<java.lang.Long>
          getPositionsList() {
        return java.util.Collections.unmodifiableList(positions_);
      }
      public int getPositionsCount() {
        return positions_.size();
      }
      public long getPositions(int index) {
        return positions_.get(index);
      }
      public Builder setPositions(
          int index, long value) {
        ensurePositionsIsMutable();
        positions_.set(index, value);
        onChanged();
        return this;
      }
      public Builder addPositions(long value) {
        ensurePositionsIsMutable();
        positions_.add(value);
        onChanged();
        return this;
      }
      public Builder addAllPositions(
          java.lang.Iterable<? extends java.lang.Long> values) {
        ensurePositionsIsMutable();
        super.addAll(values, positions_);
        onChanged();
        return this;
      }
      public Builder clearPositions() {
        positions_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      
      // optional .org.apache.hadoop.hive.ql.io.orc.ColumnStatistics statistics = 2;
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics statistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder> statisticsBuilder_;
      public boolean hasStatistics() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics getStatistics() {
        if (statisticsBuilder_ == null) {
          return statistics_;
        } else {
          return statisticsBuilder_.getMessage();
        }
      }
      public Builder setStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics value) {
        if (statisticsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          statistics_ = value;
          onChanged();
        } else {
          statisticsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setStatistics(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder builderForValue) {
        if (statisticsBuilder_ == null) {
          statistics_ = builderForValue.build();
          onChanged();
        } else {
          statisticsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics value) {
        if (statisticsBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              statistics_ != org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.getDefaultInstance()) {
            statistics_ =
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.newBuilder(statistics_).mergeFrom(value).buildPartial();
          } else {
            statistics_ = value;
          }
          onChanged();
        } else {
          statisticsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearStatistics() {
        if (statisticsBuilder_ == null) {
          statistics_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.getDefaultInstance();
          onChanged();
        } else {
          statisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder getStatisticsBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getStatisticsFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder getStatisticsOrBuilder() {
        if (statisticsBuilder_ != null) {
          return statisticsBuilder_.getMessageOrBuilder();
        } else {
          return statistics_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder> 
          getStatisticsFieldBuilder() {
        if (statisticsBuilder_ == null) {
          statisticsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder>(
                  statistics_,
                  getParentForChildren(),
                  isClean());
          statistics_ = null;
        }
        return statisticsBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.RowIndexEntry)
    }
    
    static {
      defaultInstance = new RowIndexEntry(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.RowIndexEntry)
  }
  
  public interface RowIndexOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.RowIndexEntry entry = 1;
    java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry> 
        getEntryList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry getEntry(int index);
    int getEntryCount();
    java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntryOrBuilder> 
        getEntryOrBuilderList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntryOrBuilder getEntryOrBuilder(
        int index);
  }
  public static final class RowIndex extends
      com.google.protobuf.GeneratedMessage
      implements RowIndexOrBuilder {
    // Use RowIndex.newBuilder() to construct.
    private RowIndex(Builder builder) {
      super(builder);
    }
    private RowIndex(boolean noInit) {}
    
    private static final RowIndex defaultInstance;
    public static RowIndex getDefaultInstance() {
      return defaultInstance;
    }
    
    public RowIndex getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_fieldAccessorTable;
    }
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.RowIndexEntry entry = 1;
    public static final int ENTRY_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry> entry_;
    public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry> getEntryList() {
      return entry_;
    }
    public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntryOrBuilder> 
        getEntryOrBuilderList() {
      return entry_;
    }
    public int getEntryCount() {
      return entry_.size();
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry getEntry(int index) {
      return entry_.get(index);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntryOrBuilder getEntryOrBuilder(
        int index) {
      return entry_.get(index);
    }
    
    private void initFields() {
      entry_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < entry_.size(); i++) {
        output.writeMessage(1, entry_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      for (int i = 0; i < entry_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, entry_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getEntryFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (entryBuilder_ == null) {
          entry_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          entryBuilder_.clear();
        }
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex(this);
        int from_bitField0_ = bitField0_;
        if (entryBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            entry_ = java.util.Collections.unmodifiableList(entry_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.entry_ = entry_;
        } else {
          result.entry_ = entryBuilder_.build();
        }
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex.getDefaultInstance()) return this;
        if (entryBuilder_ == null) {
          if (!other.entry_.isEmpty()) {
            if (entry_.isEmpty()) {
              entry_ = other.entry_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureEntryIsMutable();
              entry_.addAll(other.entry_);
            }
            onChanged();
          }
        } else {
          if (!other.entry_.isEmpty()) {
            if (entryBuilder_.isEmpty()) {
              entryBuilder_.dispose();
              entryBuilder_ = null;
              entry_ = other.entry_;
              bitField0_ = (bitField0_ & ~0x00000001);
              entryBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getEntryFieldBuilder() : null;
            } else {
              entryBuilder_.addAllMessages(other.entry_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addEntry(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated .org.apache.hadoop.hive.ql.io.orc.RowIndexEntry entry = 1;
      private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry> entry_ =
        java.util.Collections.emptyList();
      private void ensureEntryIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          entry_ = new java.util.ArrayList<org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry>(entry_);
          bitField0_ |= 0x00000001;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntryOrBuilder> entryBuilder_;
      
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry> getEntryList() {
        if (entryBuilder_ == null) {
          return java.util.Collections.unmodifiableList(entry_);
        } else {
          return entryBuilder_.getMessageList();
        }
      }
      public int getEntryCount() {
        if (entryBuilder_ == null) {
          return entry_.size();
        } else {
          return entryBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry getEntry(int index) {
        if (entryBuilder_ == null) {
          return entry_.get(index);
        } else {
          return entryBuilder_.getMessage(index);
        }
      }
      public Builder setEntry(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry value) {
        if (entryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryIsMutable();
          entry_.set(index, value);
          onChanged();
        } else {
          entryBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setEntry(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder builderForValue) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.set(index, builderForValue.build());
          onChanged();
        } else {
          entryBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addEntry(org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry value) {
        if (entryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryIsMutable();
          entry_.add(value);
          onChanged();
        } else {
          entryBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addEntry(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry value) {
        if (entryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryIsMutable();
          entry_.add(index, value);
          onChanged();
        } else {
          entryBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addEntry(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder builderForValue) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.add(builderForValue.build());
          onChanged();
        } else {
          entryBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addEntry(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder builderForValue) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.add(index, builderForValue.build());
          onChanged();
        } else {
          entryBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllEntry(
          java.lang.Iterable<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry> values) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          super.addAll(values, entry_);
          onChanged();
        } else {
          entryBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearEntry() {
        if (entryBuilder_ == null) {
          entry_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          entryBuilder_.clear();
        }
        return this;
      }
      public Builder removeEntry(int index) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.remove(index);
          onChanged();
        } else {
          entryBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder getEntryBuilder(
          int index) {
        return getEntryFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntryOrBuilder getEntryOrBuilder(
          int index) {
        if (entryBuilder_ == null) {
          return entry_.get(index);  } else {
          return entryBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntryOrBuilder> 
           getEntryOrBuilderList() {
        if (entryBuilder_ != null) {
          return entryBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(entry_);
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder addEntryBuilder() {
        return getEntryFieldBuilder().addBuilder(
            org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.getDefaultInstance());
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder addEntryBuilder(
          int index) {
        return getEntryFieldBuilder().addBuilder(
            index, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder> 
           getEntryBuilderList() {
        return getEntryFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntryOrBuilder> 
          getEntryFieldBuilder() {
        if (entryBuilder_ == null) {
          entryBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntryOrBuilder>(
                  entry_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          entry_ = null;
        }
        return entryBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.RowIndex)
    }
    
    static {
      defaultInstance = new RowIndex(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.RowIndex)
  }
  
  public interface StreamOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .org.apache.hadoop.hive.ql.io.orc.Stream.Kind kind = 1;
    boolean hasKind();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind getKind();
    
    // optional uint32 column = 2;
    boolean hasColumn();
    int getColumn();
    
    // optional uint64 length = 3;
    boolean hasLength();
    long getLength();
  }
  public static final class Stream extends
      com.google.protobuf.GeneratedMessage
      implements StreamOrBuilder {
    // Use Stream.newBuilder() to construct.
    private Stream(Builder builder) {
      super(builder);
    }
    private Stream(boolean noInit) {}
    
    private static final Stream defaultInstance;
    public static Stream getDefaultInstance() {
      return defaultInstance;
    }
    
    public Stream getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_fieldAccessorTable;
    }
    
    public enum Kind
        implements com.google.protobuf.ProtocolMessageEnum {
      PRESENT(0, 0),
      DATA(1, 1),
      LENGTH(2, 2),
      DICTIONARY_DATA(3, 3),
      DICTIONARY_COUNT(4, 4),
      NANO_DATA(5, 5),
      ROW_INDEX(6, 6),
      ;
      
      public static final int PRESENT_VALUE = 0;
      public static final int DATA_VALUE = 1;
      public static final int LENGTH_VALUE = 2;
      public static final int DICTIONARY_DATA_VALUE = 3;
      public static final int DICTIONARY_COUNT_VALUE = 4;
      public static final int NANO_DATA_VALUE = 5;
      public static final int ROW_INDEX_VALUE = 6;
      
      
      public final int getNumber() { return value; }
      
      public static Kind valueOf(int value) {
        switch (value) {
          case 0: return PRESENT;
          case 1: return DATA;
          case 2: return LENGTH;
          case 3: return DICTIONARY_DATA;
          case 4: return DICTIONARY_COUNT;
          case 5: return NANO_DATA;
          case 6: return ROW_INDEX;
          default: return null;
        }
      }
      
      public static com.google.protobuf.Internal.EnumLiteMap<Kind>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<Kind>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Kind>() {
              public Kind findValueByNumber(int number) {
                return Kind.valueOf(number);
              }
            };
      
      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.getDescriptor().getEnumTypes().get(0);
      }
      
      private static final Kind[] VALUES = {
        PRESENT, DATA, LENGTH, DICTIONARY_DATA, DICTIONARY_COUNT, NANO_DATA, ROW_INDEX, 
      };
      
      public static Kind valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }
      
      private final int index;
      private final int value;
      
      private Kind(int index, int value) {
        this.index = index;
        this.value = value;
      }
      
      // @@protoc_insertion_point(enum_scope:org.apache.hadoop.hive.ql.io.orc.Stream.Kind)
    }
    
    private int bitField0_;
    // required .org.apache.hadoop.hive.ql.io.orc.Stream.Kind kind = 1;
    public static final int KIND_FIELD_NUMBER = 1;
    private org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind kind_;
    public boolean hasKind() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind getKind() {
      return kind_;
    }
    
    // optional uint32 column = 2;
    public static final int COLUMN_FIELD_NUMBER = 2;
    private int column_;
    public boolean hasColumn() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public int getColumn() {
      return column_;
    }
    
    // optional uint64 length = 3;
    public static final int LENGTH_FIELD_NUMBER = 3;
    private long length_;
    public boolean hasLength() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public long getLength() {
      return length_;
    }
    
    private void initFields() {
      kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind.PRESENT;
      column_ = 0;
      length_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasKind()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, kind_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt32(2, column_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(3, length_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, kind_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, column_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, length_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.StreamOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind.PRESENT;
        bitField0_ = (bitField0_ & ~0x00000001);
        column_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        length_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.kind_ = kind_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.column_ = column_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.length_ = length_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.getDefaultInstance()) return this;
        if (other.hasKind()) {
          setKind(other.getKind());
        }
        if (other.hasColumn()) {
          setColumn(other.getColumn());
        }
        if (other.hasLength()) {
          setLength(other.getLength());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasKind()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind value = org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                kind_ = value;
              }
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              column_ = input.readUInt32();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              length_ = input.readUInt64();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .org.apache.hadoop.hive.ql.io.orc.Stream.Kind kind = 1;
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind.PRESENT;
      public boolean hasKind() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind getKind() {
        return kind_;
      }
      public Builder setKind(org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        kind_ = value;
        onChanged();
        return this;
      }
      public Builder clearKind() {
        bitField0_ = (bitField0_ & ~0x00000001);
        kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Kind.PRESENT;
        onChanged();
        return this;
      }
      
      // optional uint32 column = 2;
      private int column_ ;
      public boolean hasColumn() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public int getColumn() {
        return column_;
      }
      public Builder setColumn(int value) {
        bitField0_ |= 0x00000002;
        column_ = value;
        onChanged();
        return this;
      }
      public Builder clearColumn() {
        bitField0_ = (bitField0_ & ~0x00000002);
        column_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint64 length = 3;
      private long length_ ;
      public boolean hasLength() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public long getLength() {
        return length_;
      }
      public Builder setLength(long value) {
        bitField0_ |= 0x00000004;
        length_ = value;
        onChanged();
        return this;
      }
      public Builder clearLength() {
        bitField0_ = (bitField0_ & ~0x00000004);
        length_ = 0L;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.Stream)
    }
    
    static {
      defaultInstance = new Stream(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.Stream)
  }
  
  public interface ColumnEncodingOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .org.apache.hadoop.hive.ql.io.orc.ColumnEncoding.Kind kind = 1;
    boolean hasKind();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind getKind();
    
    // optional uint32 dictionarySize = 2;
    boolean hasDictionarySize();
    int getDictionarySize();
  }
  public static final class ColumnEncoding extends
      com.google.protobuf.GeneratedMessage
      implements ColumnEncodingOrBuilder {
    // Use ColumnEncoding.newBuilder() to construct.
    private ColumnEncoding(Builder builder) {
      super(builder);
    }
    private ColumnEncoding(boolean noInit) {}
    
    private static final ColumnEncoding defaultInstance;
    public static ColumnEncoding getDefaultInstance() {
      return defaultInstance;
    }
    
    public ColumnEncoding getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_fieldAccessorTable;
    }
    
    public enum Kind
        implements com.google.protobuf.ProtocolMessageEnum {
      DIRECT(0, 0),
      DICTIONARY(1, 1),
      ;
      
      public static final int DIRECT_VALUE = 0;
      public static final int DICTIONARY_VALUE = 1;
      
      
      public final int getNumber() { return value; }
      
      public static Kind valueOf(int value) {
        switch (value) {
          case 0: return DIRECT;
          case 1: return DICTIONARY;
          default: return null;
        }
      }
      
      public static com.google.protobuf.Internal.EnumLiteMap<Kind>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<Kind>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Kind>() {
              public Kind findValueByNumber(int number) {
                return Kind.valueOf(number);
              }
            };
      
      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.getDescriptor().getEnumTypes().get(0);
      }
      
      private static final Kind[] VALUES = {
        DIRECT, DICTIONARY, 
      };
      
      public static Kind valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }
      
      private final int index;
      private final int value;
      
      private Kind(int index, int value) {
        this.index = index;
        this.value = value;
      }
      
      // @@protoc_insertion_point(enum_scope:org.apache.hadoop.hive.ql.io.orc.ColumnEncoding.Kind)
    }
    
    private int bitField0_;
    // required .org.apache.hadoop.hive.ql.io.orc.ColumnEncoding.Kind kind = 1;
    public static final int KIND_FIELD_NUMBER = 1;
    private org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind kind_;
    public boolean hasKind() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind getKind() {
      return kind_;
    }
    
    // optional uint32 dictionarySize = 2;
    public static final int DICTIONARYSIZE_FIELD_NUMBER = 2;
    private int dictionarySize_;
    public boolean hasDictionarySize() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public int getDictionarySize() {
      return dictionarySize_;
    }
    
    private void initFields() {
      kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind.DIRECT;
      dictionarySize_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasKind()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, kind_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt32(2, dictionarySize_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, kind_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, dictionarySize_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncodingOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind.DIRECT;
        bitField0_ = (bitField0_ & ~0x00000001);
        dictionarySize_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.kind_ = kind_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.dictionarySize_ = dictionarySize_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.getDefaultInstance()) return this;
        if (other.hasKind()) {
          setKind(other.getKind());
        }
        if (other.hasDictionarySize()) {
          setDictionarySize(other.getDictionarySize());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasKind()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind value = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                kind_ = value;
              }
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              dictionarySize_ = input.readUInt32();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .org.apache.hadoop.hive.ql.io.orc.ColumnEncoding.Kind kind = 1;
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind.DIRECT;
      public boolean hasKind() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind getKind() {
        return kind_;
      }
      public Builder setKind(org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        kind_ = value;
        onChanged();
        return this;
      }
      public Builder clearKind() {
        bitField0_ = (bitField0_ & ~0x00000001);
        kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Kind.DIRECT;
        onChanged();
        return this;
      }
      
      // optional uint32 dictionarySize = 2;
      private int dictionarySize_ ;
      public boolean hasDictionarySize() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public int getDictionarySize() {
        return dictionarySize_;
      }
      public Builder setDictionarySize(int value) {
        bitField0_ |= 0x00000002;
        dictionarySize_ = value;
        onChanged();
        return this;
      }
      public Builder clearDictionarySize() {
        bitField0_ = (bitField0_ & ~0x00000002);
        dictionarySize_ = 0;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.ColumnEncoding)
    }
    
    static {
      defaultInstance = new ColumnEncoding(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.ColumnEncoding)
  }
  
  public interface StripeFooterOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.Stream streams = 1;
    java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream> 
        getStreamsList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream getStreams(int index);
    int getStreamsCount();
    java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.StreamOrBuilder> 
        getStreamsOrBuilderList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.StreamOrBuilder getStreamsOrBuilder(
        int index);
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.ColumnEncoding columns = 2;
    java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding> 
        getColumnsList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding getColumns(int index);
    int getColumnsCount();
    java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncodingOrBuilder> 
        getColumnsOrBuilderList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncodingOrBuilder getColumnsOrBuilder(
        int index);
  }
  public static final class StripeFooter extends
      com.google.protobuf.GeneratedMessage
      implements StripeFooterOrBuilder {
    // Use StripeFooter.newBuilder() to construct.
    private StripeFooter(Builder builder) {
      super(builder);
    }
    private StripeFooter(boolean noInit) {}
    
    private static final StripeFooter defaultInstance;
    public static StripeFooter getDefaultInstance() {
      return defaultInstance;
    }
    
    public StripeFooter getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_fieldAccessorTable;
    }
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.Stream streams = 1;
    public static final int STREAMS_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream> streams_;
    public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream> getStreamsList() {
      return streams_;
    }
    public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.StreamOrBuilder> 
        getStreamsOrBuilderList() {
      return streams_;
    }
    public int getStreamsCount() {
      return streams_.size();
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream getStreams(int index) {
      return streams_.get(index);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.StreamOrBuilder getStreamsOrBuilder(
        int index) {
      return streams_.get(index);
    }
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.ColumnEncoding columns = 2;
    public static final int COLUMNS_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding> columns_;
    public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding> getColumnsList() {
      return columns_;
    }
    public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncodingOrBuilder> 
        getColumnsOrBuilderList() {
      return columns_;
    }
    public int getColumnsCount() {
      return columns_.size();
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding getColumns(int index) {
      return columns_.get(index);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncodingOrBuilder getColumnsOrBuilder(
        int index) {
      return columns_.get(index);
    }
    
    private void initFields() {
      streams_ = java.util.Collections.emptyList();
      columns_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      for (int i = 0; i < getStreamsCount(); i++) {
        if (!getStreams(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getColumnsCount(); i++) {
        if (!getColumns(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < streams_.size(); i++) {
        output.writeMessage(1, streams_.get(i));
      }
      for (int i = 0; i < columns_.size(); i++) {
        output.writeMessage(2, columns_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      for (int i = 0; i < streams_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, streams_.get(i));
      }
      for (int i = 0; i < columns_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, columns_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooterOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getStreamsFieldBuilder();
          getColumnsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (streamsBuilder_ == null) {
          streams_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          streamsBuilder_.clear();
        }
        if (columnsBuilder_ == null) {
          columns_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          columnsBuilder_.clear();
        }
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter(this);
        int from_bitField0_ = bitField0_;
        if (streamsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            streams_ = java.util.Collections.unmodifiableList(streams_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.streams_ = streams_;
        } else {
          result.streams_ = streamsBuilder_.build();
        }
        if (columnsBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            columns_ = java.util.Collections.unmodifiableList(columns_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.columns_ = columns_;
        } else {
          result.columns_ = columnsBuilder_.build();
        }
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter.getDefaultInstance()) return this;
        if (streamsBuilder_ == null) {
          if (!other.streams_.isEmpty()) {
            if (streams_.isEmpty()) {
              streams_ = other.streams_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureStreamsIsMutable();
              streams_.addAll(other.streams_);
            }
            onChanged();
          }
        } else {
          if (!other.streams_.isEmpty()) {
            if (streamsBuilder_.isEmpty()) {
              streamsBuilder_.dispose();
              streamsBuilder_ = null;
              streams_ = other.streams_;
              bitField0_ = (bitField0_ & ~0x00000001);
              streamsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getStreamsFieldBuilder() : null;
            } else {
              streamsBuilder_.addAllMessages(other.streams_);
            }
          }
        }
        if (columnsBuilder_ == null) {
          if (!other.columns_.isEmpty()) {
            if (columns_.isEmpty()) {
              columns_ = other.columns_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureColumnsIsMutable();
              columns_.addAll(other.columns_);
            }
            onChanged();
          }
        } else {
          if (!other.columns_.isEmpty()) {
            if (columnsBuilder_.isEmpty()) {
              columnsBuilder_.dispose();
              columnsBuilder_ = null;
              columns_ = other.columns_;
              bitField0_ = (bitField0_ & ~0x00000002);
              columnsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getColumnsFieldBuilder() : null;
            } else {
              columnsBuilder_.addAllMessages(other.columns_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        for (int i = 0; i < getStreamsCount(); i++) {
          if (!getStreams(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getColumnsCount(); i++) {
          if (!getColumns(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addStreams(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addColumns(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated .org.apache.hadoop.hive.ql.io.orc.Stream streams = 1;
      private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream> streams_ =
        java.util.Collections.emptyList();
      private void ensureStreamsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          streams_ = new java.util.ArrayList<org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream>(streams_);
          bitField0_ |= 0x00000001;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream, org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.StreamOrBuilder> streamsBuilder_;
      
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream> getStreamsList() {
        if (streamsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(streams_);
        } else {
          return streamsBuilder_.getMessageList();
        }
      }
      public int getStreamsCount() {
        if (streamsBuilder_ == null) {
          return streams_.size();
        } else {
          return streamsBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream getStreams(int index) {
        if (streamsBuilder_ == null) {
          return streams_.get(index);
        } else {
          return streamsBuilder_.getMessage(index);
        }
      }
      public Builder setStreams(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream value) {
        if (streamsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStreamsIsMutable();
          streams_.set(index, value);
          onChanged();
        } else {
          streamsBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setStreams(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder builderForValue) {
        if (streamsBuilder_ == null) {
          ensureStreamsIsMutable();
          streams_.set(index, builderForValue.build());
          onChanged();
        } else {
          streamsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addStreams(org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream value) {
        if (streamsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStreamsIsMutable();
          streams_.add(value);
          onChanged();
        } else {
          streamsBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addStreams(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream value) {
        if (streamsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStreamsIsMutable();
          streams_.add(index, value);
          onChanged();
        } else {
          streamsBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addStreams(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder builderForValue) {
        if (streamsBuilder_ == null) {
          ensureStreamsIsMutable();
          streams_.add(builderForValue.build());
          onChanged();
        } else {
          streamsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addStreams(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder builderForValue) {
        if (streamsBuilder_ == null) {
          ensureStreamsIsMutable();
          streams_.add(index, builderForValue.build());
          onChanged();
        } else {
          streamsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllStreams(
          java.lang.Iterable<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream> values) {
        if (streamsBuilder_ == null) {
          ensureStreamsIsMutable();
          super.addAll(values, streams_);
          onChanged();
        } else {
          streamsBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearStreams() {
        if (streamsBuilder_ == null) {
          streams_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          streamsBuilder_.clear();
        }
        return this;
      }
      public Builder removeStreams(int index) {
        if (streamsBuilder_ == null) {
          ensureStreamsIsMutable();
          streams_.remove(index);
          onChanged();
        } else {
          streamsBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder getStreamsBuilder(
          int index) {
        return getStreamsFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StreamOrBuilder getStreamsOrBuilder(
          int index) {
        if (streamsBuilder_ == null) {
          return streams_.get(index);  } else {
          return streamsBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.StreamOrBuilder> 
           getStreamsOrBuilderList() {
        if (streamsBuilder_ != null) {
          return streamsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(streams_);
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder addStreamsBuilder() {
        return getStreamsFieldBuilder().addBuilder(
            org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.getDefaultInstance());
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder addStreamsBuilder(
          int index) {
        return getStreamsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder> 
           getStreamsBuilderList() {
        return getStreamsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream, org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.StreamOrBuilder> 
          getStreamsFieldBuilder() {
        if (streamsBuilder_ == null) {
          streamsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream, org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.StreamOrBuilder>(
                  streams_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          streams_ = null;
        }
        return streamsBuilder_;
      }
      
      // repeated .org.apache.hadoop.hive.ql.io.orc.ColumnEncoding columns = 2;
      private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding> columns_ =
        java.util.Collections.emptyList();
      private void ensureColumnsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          columns_ = new java.util.ArrayList<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding>(columns_);
          bitField0_ |= 0x00000002;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncodingOrBuilder> columnsBuilder_;
      
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding> getColumnsList() {
        if (columnsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(columns_);
        } else {
          return columnsBuilder_.getMessageList();
        }
      }
      public int getColumnsCount() {
        if (columnsBuilder_ == null) {
          return columns_.size();
        } else {
          return columnsBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding getColumns(int index) {
        if (columnsBuilder_ == null) {
          return columns_.get(index);
        } else {
          return columnsBuilder_.getMessage(index);
        }
      }
      public Builder setColumns(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding value) {
        if (columnsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnsIsMutable();
          columns_.set(index, value);
          onChanged();
        } else {
          columnsBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setColumns(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder builderForValue) {
        if (columnsBuilder_ == null) {
          ensureColumnsIsMutable();
          columns_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addColumns(org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding value) {
        if (columnsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnsIsMutable();
          columns_.add(value);
          onChanged();
        } else {
          columnsBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addColumns(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding value) {
        if (columnsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnsIsMutable();
          columns_.add(index, value);
          onChanged();
        } else {
          columnsBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addColumns(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder builderForValue) {
        if (columnsBuilder_ == null) {
          ensureColumnsIsMutable();
          columns_.add(builderForValue.build());
          onChanged();
        } else {
          columnsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addColumns(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder builderForValue) {
        if (columnsBuilder_ == null) {
          ensureColumnsIsMutable();
          columns_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllColumns(
          java.lang.Iterable<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding> values) {
        if (columnsBuilder_ == null) {
          ensureColumnsIsMutable();
          super.addAll(values, columns_);
          onChanged();
        } else {
          columnsBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearColumns() {
        if (columnsBuilder_ == null) {
          columns_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          columnsBuilder_.clear();
        }
        return this;
      }
      public Builder removeColumns(int index) {
        if (columnsBuilder_ == null) {
          ensureColumnsIsMutable();
          columns_.remove(index);
          onChanged();
        } else {
          columnsBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder getColumnsBuilder(
          int index) {
        return getColumnsFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncodingOrBuilder getColumnsOrBuilder(
          int index) {
        if (columnsBuilder_ == null) {
          return columns_.get(index);  } else {
          return columnsBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncodingOrBuilder> 
           getColumnsOrBuilderList() {
        if (columnsBuilder_ != null) {
          return columnsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(columns_);
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder addColumnsBuilder() {
        return getColumnsFieldBuilder().addBuilder(
            org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.getDefaultInstance());
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder addColumnsBuilder(
          int index) {
        return getColumnsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder> 
           getColumnsBuilderList() {
        return getColumnsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncodingOrBuilder> 
          getColumnsFieldBuilder() {
        if (columnsBuilder_ == null) {
          columnsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncodingOrBuilder>(
                  columns_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          columns_ = null;
        }
        return columnsBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.StripeFooter)
    }
    
    static {
      defaultInstance = new StripeFooter(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.StripeFooter)
  }
  
  public interface TypeOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .org.apache.hadoop.hive.ql.io.orc.Type.Kind kind = 1;
    boolean hasKind();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind getKind();
    
    // repeated uint32 subtypes = 2 [packed = true];
    java.util.List<java.lang.Integer> getSubtypesList();
    int getSubtypesCount();
    int getSubtypes(int index);
    
    // repeated string fieldNames = 3;
    java.util.List<String> getFieldNamesList();
    int getFieldNamesCount();
    String getFieldNames(int index);
  }
  public static final class Type extends
      com.google.protobuf.GeneratedMessage
      implements TypeOrBuilder {
    // Use Type.newBuilder() to construct.
    private Type(Builder builder) {
      super(builder);
    }
    private Type(boolean noInit) {}
    
    private static final Type defaultInstance;
    public static Type getDefaultInstance() {
      return defaultInstance;
    }
    
    public Type getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Type_fieldAccessorTable;
    }
    
    public enum Kind
        implements com.google.protobuf.ProtocolMessageEnum {
      BOOLEAN(0, 0),
      BYTE(1, 1),
      SHORT(2, 2),
      INT(3, 3),
      LONG(4, 4),
      FLOAT(5, 5),
      DOUBLE(6, 6),
      STRING(7, 7),
      BINARY(8, 8),
      TIMESTAMP(9, 9),
      LIST(10, 10),
      MAP(11, 11),
      STRUCT(12, 12),
      UNION(13, 13),
      ;
      
      public static final int BOOLEAN_VALUE = 0;
      public static final int BYTE_VALUE = 1;
      public static final int SHORT_VALUE = 2;
      public static final int INT_VALUE = 3;
      public static final int LONG_VALUE = 4;
      public static final int FLOAT_VALUE = 5;
      public static final int DOUBLE_VALUE = 6;
      public static final int STRING_VALUE = 7;
      public static final int BINARY_VALUE = 8;
      public static final int TIMESTAMP_VALUE = 9;
      public static final int LIST_VALUE = 10;
      public static final int MAP_VALUE = 11;
      public static final int STRUCT_VALUE = 12;
      public static final int UNION_VALUE = 13;
      
      
      public final int getNumber() { return value; }
      
      public static Kind valueOf(int value) {
        switch (value) {
          case 0: return BOOLEAN;
          case 1: return BYTE;
          case 2: return SHORT;
          case 3: return INT;
          case 4: return LONG;
          case 5: return FLOAT;
          case 6: return DOUBLE;
          case 7: return STRING;
          case 8: return BINARY;
          case 9: return TIMESTAMP;
          case 10: return LIST;
          case 11: return MAP;
          case 12: return STRUCT;
          case 13: return UNION;
          default: return null;
        }
      }
      
      public static com.google.protobuf.Internal.EnumLiteMap<Kind>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<Kind>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Kind>() {
              public Kind findValueByNumber(int number) {
                return Kind.valueOf(number);
              }
            };
      
      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.getDescriptor().getEnumTypes().get(0);
      }
      
      private static final Kind[] VALUES = {
        BOOLEAN, BYTE, SHORT, INT, LONG, FLOAT, DOUBLE, STRING, BINARY, TIMESTAMP, LIST, MAP, STRUCT, UNION, 
      };
      
      public static Kind valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }
      
      private final int index;
      private final int value;
      
      private Kind(int index, int value) {
        this.index = index;
        this.value = value;
      }
      
      // @@protoc_insertion_point(enum_scope:org.apache.hadoop.hive.ql.io.orc.Type.Kind)
    }
    
    private int bitField0_;
    // required .org.apache.hadoop.hive.ql.io.orc.Type.Kind kind = 1;
    public static final int KIND_FIELD_NUMBER = 1;
    private org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind kind_;
    public boolean hasKind() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind getKind() {
      return kind_;
    }
    
    // repeated uint32 subtypes = 2 [packed = true];
    public static final int SUBTYPES_FIELD_NUMBER = 2;
    private java.util.List<java.lang.Integer> subtypes_;
    public java.util.List<java.lang.Integer>
        getSubtypesList() {
      return subtypes_;
    }
    public int getSubtypesCount() {
      return subtypes_.size();
    }
    public int getSubtypes(int index) {
      return subtypes_.get(index);
    }
    private int subtypesMemoizedSerializedSize = -1;
    
    // repeated string fieldNames = 3;
    public static final int FIELDNAMES_FIELD_NUMBER = 3;
    private com.google.protobuf.LazyStringList fieldNames_;
    public java.util.List<String>
        getFieldNamesList() {
      return fieldNames_;
    }
    public int getFieldNamesCount() {
      return fieldNames_.size();
    }
    public String getFieldNames(int index) {
      return fieldNames_.get(index);
    }
    
    private void initFields() {
      kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind.BOOLEAN;
      subtypes_ = java.util.Collections.emptyList();;
      fieldNames_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasKind()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, kind_.getNumber());
      }
      if (getSubtypesList().size() > 0) {
        output.writeRawVarint32(18);
        output.writeRawVarint32(subtypesMemoizedSerializedSize);
      }
      for (int i = 0; i < subtypes_.size(); i++) {
        output.writeUInt32NoTag(subtypes_.get(i));
      }
      for (int i = 0; i < fieldNames_.size(); i++) {
        output.writeBytes(3, fieldNames_.getByteString(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, kind_.getNumber());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < subtypes_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeUInt32SizeNoTag(subtypes_.get(i));
        }
        size += dataSize;
        if (!getSubtypesList().isEmpty()) {
          size += 1;
          size += com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(dataSize);
        }
        subtypesMemoizedSerializedSize = dataSize;
      }
      {
        int dataSize = 0;
        for (int i = 0; i < fieldNames_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(fieldNames_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getFieldNamesList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Type parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Type parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Type parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Type parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Type parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Type parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Type parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Type parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Type parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Type parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.Type prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.TypeOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Type_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind.BOOLEAN;
        bitField0_ = (bitField0_ & ~0x00000001);
        subtypes_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000002);
        fieldNames_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Type getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Type build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.Type result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.Type buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.Type result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Type buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.Type result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.Type(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.kind_ = kind_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          subtypes_ = java.util.Collections.unmodifiableList(subtypes_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.subtypes_ = subtypes_;
        if (((bitField0_ & 0x00000004) == 0x00000004)) {
          fieldNames_ = new com.google.protobuf.UnmodifiableLazyStringList(
              fieldNames_);
          bitField0_ = (bitField0_ & ~0x00000004);
        }
        result.fieldNames_ = fieldNames_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.Type) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.Type)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.Type other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.getDefaultInstance()) return this;
        if (other.hasKind()) {
          setKind(other.getKind());
        }
        if (!other.subtypes_.isEmpty()) {
          if (subtypes_.isEmpty()) {
            subtypes_ = other.subtypes_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureSubtypesIsMutable();
            subtypes_.addAll(other.subtypes_);
          }
          onChanged();
        }
        if (!other.fieldNames_.isEmpty()) {
          if (fieldNames_.isEmpty()) {
            fieldNames_ = other.fieldNames_;
            bitField0_ = (bitField0_ & ~0x00000004);
          } else {
            ensureFieldNamesIsMutable();
            fieldNames_.addAll(other.fieldNames_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasKind()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind value = org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                kind_ = value;
              }
              break;
            }
            case 16: {
              ensureSubtypesIsMutable();
              subtypes_.add(input.readUInt32());
              break;
            }
            case 18: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              while (input.getBytesUntilLimit() > 0) {
                addSubtypes(input.readUInt32());
              }
              input.popLimit(limit);
              break;
            }
            case 26: {
              ensureFieldNamesIsMutable();
              fieldNames_.add(input.readBytes());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .org.apache.hadoop.hive.ql.io.orc.Type.Kind kind = 1;
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind.BOOLEAN;
      public boolean hasKind() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind getKind() {
        return kind_;
      }
      public Builder setKind(org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        kind_ = value;
        onChanged();
        return this;
      }
      public Builder clearKind() {
        bitField0_ = (bitField0_ & ~0x00000001);
        kind_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Kind.BOOLEAN;
        onChanged();
        return this;
      }
      
      // repeated uint32 subtypes = 2 [packed = true];
      private java.util.List<java.lang.Integer> subtypes_ = java.util.Collections.emptyList();;
      private void ensureSubtypesIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          subtypes_ = new java.util.ArrayList<java.lang.Integer>(subtypes_);
          bitField0_ |= 0x00000002;
         }
      }
      public java.util.List<java.lang.Integer>
          getSubtypesList() {
        return java.util.Collections.unmodifiableList(subtypes_);
      }
      public int getSubtypesCount() {
        return subtypes_.size();
      }
      public int getSubtypes(int index) {
        return subtypes_.get(index);
      }
      public Builder setSubtypes(
          int index, int value) {
        ensureSubtypesIsMutable();
        subtypes_.set(index, value);
        onChanged();
        return this;
      }
      public Builder addSubtypes(int value) {
        ensureSubtypesIsMutable();
        subtypes_.add(value);
        onChanged();
        return this;
      }
      public Builder addAllSubtypes(
          java.lang.Iterable<? extends java.lang.Integer> values) {
        ensureSubtypesIsMutable();
        super.addAll(values, subtypes_);
        onChanged();
        return this;
      }
      public Builder clearSubtypes() {
        subtypes_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      
      // repeated string fieldNames = 3;
      private com.google.protobuf.LazyStringList fieldNames_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureFieldNamesIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          fieldNames_ = new com.google.protobuf.LazyStringArrayList(fieldNames_);
          bitField0_ |= 0x00000004;
         }
      }
      public java.util.List<String>
          getFieldNamesList() {
        return java.util.Collections.unmodifiableList(fieldNames_);
      }
      public int getFieldNamesCount() {
        return fieldNames_.size();
      }
      public String getFieldNames(int index) {
        return fieldNames_.get(index);
      }
      public Builder setFieldNames(
          int index, String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFieldNamesIsMutable();
        fieldNames_.set(index, value);
        onChanged();
        return this;
      }
      public Builder addFieldNames(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFieldNamesIsMutable();
        fieldNames_.add(value);
        onChanged();
        return this;
      }
      public Builder addAllFieldNames(
          java.lang.Iterable<String> values) {
        ensureFieldNamesIsMutable();
        super.addAll(values, fieldNames_);
        onChanged();
        return this;
      }
      public Builder clearFieldNames() {
        fieldNames_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      void addFieldNames(com.google.protobuf.ByteString value) {
        ensureFieldNamesIsMutable();
        fieldNames_.add(value);
        onChanged();
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.Type)
    }
    
    static {
      defaultInstance = new Type(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.Type)
  }
  
  public interface StripeInformationOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional uint64 offset = 1;
    boolean hasOffset();
    long getOffset();
    
    // optional uint64 indexLength = 2;
    boolean hasIndexLength();
    long getIndexLength();
    
    // optional uint64 dataLength = 3;
    boolean hasDataLength();
    long getDataLength();
    
    // optional uint64 footerLength = 4;
    boolean hasFooterLength();
    long getFooterLength();
    
    // optional uint64 numberOfRows = 5;
    boolean hasNumberOfRows();
    long getNumberOfRows();
  }
  public static final class StripeInformation extends
      com.google.protobuf.GeneratedMessage
      implements StripeInformationOrBuilder {
    // Use StripeInformation.newBuilder() to construct.
    private StripeInformation(Builder builder) {
      super(builder);
    }
    private StripeInformation(boolean noInit) {}
    
    private static final StripeInformation defaultInstance;
    public static StripeInformation getDefaultInstance() {
      return defaultInstance;
    }
    
    public StripeInformation getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional uint64 offset = 1;
    public static final int OFFSET_FIELD_NUMBER = 1;
    private long offset_;
    public boolean hasOffset() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public long getOffset() {
      return offset_;
    }
    
    // optional uint64 indexLength = 2;
    public static final int INDEXLENGTH_FIELD_NUMBER = 2;
    private long indexLength_;
    public boolean hasIndexLength() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public long getIndexLength() {
      return indexLength_;
    }
    
    // optional uint64 dataLength = 3;
    public static final int DATALENGTH_FIELD_NUMBER = 3;
    private long dataLength_;
    public boolean hasDataLength() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public long getDataLength() {
      return dataLength_;
    }
    
    // optional uint64 footerLength = 4;
    public static final int FOOTERLENGTH_FIELD_NUMBER = 4;
    private long footerLength_;
    public boolean hasFooterLength() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public long getFooterLength() {
      return footerLength_;
    }
    
    // optional uint64 numberOfRows = 5;
    public static final int NUMBEROFROWS_FIELD_NUMBER = 5;
    private long numberOfRows_;
    public boolean hasNumberOfRows() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    public long getNumberOfRows() {
      return numberOfRows_;
    }
    
    private void initFields() {
      offset_ = 0L;
      indexLength_ = 0L;
      dataLength_ = 0L;
      footerLength_ = 0L;
      numberOfRows_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt64(1, offset_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt64(2, indexLength_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(3, dataLength_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt64(4, footerLength_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeUInt64(5, numberOfRows_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, offset_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, indexLength_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, dataLength_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, footerLength_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(5, numberOfRows_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformationOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        offset_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        indexLength_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        dataLength_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        footerLength_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        numberOfRows_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.offset_ = offset_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.indexLength_ = indexLength_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.dataLength_ = dataLength_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.footerLength_ = footerLength_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.numberOfRows_ = numberOfRows_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.getDefaultInstance()) return this;
        if (other.hasOffset()) {
          setOffset(other.getOffset());
        }
        if (other.hasIndexLength()) {
          setIndexLength(other.getIndexLength());
        }
        if (other.hasDataLength()) {
          setDataLength(other.getDataLength());
        }
        if (other.hasFooterLength()) {
          setFooterLength(other.getFooterLength());
        }
        if (other.hasNumberOfRows()) {
          setNumberOfRows(other.getNumberOfRows());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              offset_ = input.readUInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              indexLength_ = input.readUInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              dataLength_ = input.readUInt64();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              footerLength_ = input.readUInt64();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              numberOfRows_ = input.readUInt64();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional uint64 offset = 1;
      private long offset_ ;
      public boolean hasOffset() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public long getOffset() {
        return offset_;
      }
      public Builder setOffset(long value) {
        bitField0_ |= 0x00000001;
        offset_ = value;
        onChanged();
        return this;
      }
      public Builder clearOffset() {
        bitField0_ = (bitField0_ & ~0x00000001);
        offset_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint64 indexLength = 2;
      private long indexLength_ ;
      public boolean hasIndexLength() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public long getIndexLength() {
        return indexLength_;
      }
      public Builder setIndexLength(long value) {
        bitField0_ |= 0x00000002;
        indexLength_ = value;
        onChanged();
        return this;
      }
      public Builder clearIndexLength() {
        bitField0_ = (bitField0_ & ~0x00000002);
        indexLength_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint64 dataLength = 3;
      private long dataLength_ ;
      public boolean hasDataLength() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public long getDataLength() {
        return dataLength_;
      }
      public Builder setDataLength(long value) {
        bitField0_ |= 0x00000004;
        dataLength_ = value;
        onChanged();
        return this;
      }
      public Builder clearDataLength() {
        bitField0_ = (bitField0_ & ~0x00000004);
        dataLength_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint64 footerLength = 4;
      private long footerLength_ ;
      public boolean hasFooterLength() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public long getFooterLength() {
        return footerLength_;
      }
      public Builder setFooterLength(long value) {
        bitField0_ |= 0x00000008;
        footerLength_ = value;
        onChanged();
        return this;
      }
      public Builder clearFooterLength() {
        bitField0_ = (bitField0_ & ~0x00000008);
        footerLength_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint64 numberOfRows = 5;
      private long numberOfRows_ ;
      public boolean hasNumberOfRows() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      public long getNumberOfRows() {
        return numberOfRows_;
      }
      public Builder setNumberOfRows(long value) {
        bitField0_ |= 0x00000010;
        numberOfRows_ = value;
        onChanged();
        return this;
      }
      public Builder clearNumberOfRows() {
        bitField0_ = (bitField0_ & ~0x00000010);
        numberOfRows_ = 0L;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.StripeInformation)
    }
    
    static {
      defaultInstance = new StripeInformation(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.StripeInformation)
  }
  
  public interface UserMetadataItemOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required string name = 1;
    boolean hasName();
    String getName();
    
    // required bytes value = 2;
    boolean hasValue();
    com.google.protobuf.ByteString getValue();
  }
  public static final class UserMetadataItem extends
      com.google.protobuf.GeneratedMessage
      implements UserMetadataItemOrBuilder {
    // Use UserMetadataItem.newBuilder() to construct.
    private UserMetadataItem(Builder builder) {
      super(builder);
    }
    private UserMetadataItem(boolean noInit) {}
    
    private static final UserMetadataItem defaultInstance;
    public static UserMetadataItem getDefaultInstance() {
      return defaultInstance;
    }
    
    public UserMetadataItem getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required string name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private java.lang.Object name_;
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          name_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    // required bytes value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString value_;
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public com.google.protobuf.ByteString getValue() {
      return value_;
    }
    
    private void initFields() {
      name_ = "";
      value_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasValue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, value_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItemOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.getDefaultInstance()) return this;
        if (other.hasName()) {
          setName(other.getName());
        }
        if (other.hasValue()) {
          setValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasName()) {
          
          return false;
        }
        if (!hasValue()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              name_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              value_ = input.readBytes();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required string name = 1;
      private java.lang.Object name_ = "";
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setName(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      void setName(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
      }
      
      // required bytes value = 2;
      private com.google.protobuf.ByteString value_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public com.google.protobuf.ByteString getValue() {
        return value_;
      }
      public Builder setValue(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.UserMetadataItem)
    }
    
    static {
      defaultInstance = new UserMetadataItem(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.UserMetadataItem)
  }
  
  public interface FooterOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional uint64 headerLength = 1;
    boolean hasHeaderLength();
    long getHeaderLength();
    
    // optional uint64 contentLength = 2;
    boolean hasContentLength();
    long getContentLength();
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.StripeInformation stripes = 3;
    java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation> 
        getStripesList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation getStripes(int index);
    int getStripesCount();
    java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformationOrBuilder> 
        getStripesOrBuilderList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformationOrBuilder getStripesOrBuilder(
        int index);
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.Type types = 4;
    java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Type> 
        getTypesList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.Type getTypes(int index);
    int getTypesCount();
    java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.TypeOrBuilder> 
        getTypesOrBuilderList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.TypeOrBuilder getTypesOrBuilder(
        int index);
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.UserMetadataItem metadata = 5;
    java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem> 
        getMetadataList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem getMetadata(int index);
    int getMetadataCount();
    java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItemOrBuilder> 
        getMetadataOrBuilderList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItemOrBuilder getMetadataOrBuilder(
        int index);
    
    // optional uint64 numberOfRows = 6;
    boolean hasNumberOfRows();
    long getNumberOfRows();
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.ColumnStatistics statistics = 7;
    java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics> 
        getStatisticsList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics getStatistics(int index);
    int getStatisticsCount();
    java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder> 
        getStatisticsOrBuilderList();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder getStatisticsOrBuilder(
        int index);
    
    // optional uint32 rowIndexStride = 8;
    boolean hasRowIndexStride();
    int getRowIndexStride();
  }
  public static final class Footer extends
      com.google.protobuf.GeneratedMessage
      implements FooterOrBuilder {
    // Use Footer.newBuilder() to construct.
    private Footer(Builder builder) {
      super(builder);
    }
    private Footer(boolean noInit) {}
    
    private static final Footer defaultInstance;
    public static Footer getDefaultInstance() {
      return defaultInstance;
    }
    
    public Footer getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional uint64 headerLength = 1;
    public static final int HEADERLENGTH_FIELD_NUMBER = 1;
    private long headerLength_;
    public boolean hasHeaderLength() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public long getHeaderLength() {
      return headerLength_;
    }
    
    // optional uint64 contentLength = 2;
    public static final int CONTENTLENGTH_FIELD_NUMBER = 2;
    private long contentLength_;
    public boolean hasContentLength() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public long getContentLength() {
      return contentLength_;
    }
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.StripeInformation stripes = 3;
    public static final int STRIPES_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation> stripes_;
    public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation> getStripesList() {
      return stripes_;
    }
    public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformationOrBuilder> 
        getStripesOrBuilderList() {
      return stripes_;
    }
    public int getStripesCount() {
      return stripes_.size();
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation getStripes(int index) {
      return stripes_.get(index);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformationOrBuilder getStripesOrBuilder(
        int index) {
      return stripes_.get(index);
    }
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.Type types = 4;
    public static final int TYPES_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Type> types_;
    public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Type> getTypesList() {
      return types_;
    }
    public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.TypeOrBuilder> 
        getTypesOrBuilderList() {
      return types_;
    }
    public int getTypesCount() {
      return types_.size();
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.Type getTypes(int index) {
      return types_.get(index);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.TypeOrBuilder getTypesOrBuilder(
        int index) {
      return types_.get(index);
    }
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.UserMetadataItem metadata = 5;
    public static final int METADATA_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem> metadata_;
    public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem> getMetadataList() {
      return metadata_;
    }
    public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItemOrBuilder> 
        getMetadataOrBuilderList() {
      return metadata_;
    }
    public int getMetadataCount() {
      return metadata_.size();
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem getMetadata(int index) {
      return metadata_.get(index);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItemOrBuilder getMetadataOrBuilder(
        int index) {
      return metadata_.get(index);
    }
    
    // optional uint64 numberOfRows = 6;
    public static final int NUMBEROFROWS_FIELD_NUMBER = 6;
    private long numberOfRows_;
    public boolean hasNumberOfRows() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public long getNumberOfRows() {
      return numberOfRows_;
    }
    
    // repeated .org.apache.hadoop.hive.ql.io.orc.ColumnStatistics statistics = 7;
    public static final int STATISTICS_FIELD_NUMBER = 7;
    private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics> statistics_;
    public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics> getStatisticsList() {
      return statistics_;
    }
    public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder> 
        getStatisticsOrBuilderList() {
      return statistics_;
    }
    public int getStatisticsCount() {
      return statistics_.size();
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics getStatistics(int index) {
      return statistics_.get(index);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder getStatisticsOrBuilder(
        int index) {
      return statistics_.get(index);
    }
    
    // optional uint32 rowIndexStride = 8;
    public static final int ROWINDEXSTRIDE_FIELD_NUMBER = 8;
    private int rowIndexStride_;
    public boolean hasRowIndexStride() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public int getRowIndexStride() {
      return rowIndexStride_;
    }
    
    private void initFields() {
      headerLength_ = 0L;
      contentLength_ = 0L;
      stripes_ = java.util.Collections.emptyList();
      types_ = java.util.Collections.emptyList();
      metadata_ = java.util.Collections.emptyList();
      numberOfRows_ = 0L;
      statistics_ = java.util.Collections.emptyList();
      rowIndexStride_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      for (int i = 0; i < getTypesCount(); i++) {
        if (!getTypes(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getMetadataCount(); i++) {
        if (!getMetadata(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt64(1, headerLength_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt64(2, contentLength_);
      }
      for (int i = 0; i < stripes_.size(); i++) {
        output.writeMessage(3, stripes_.get(i));
      }
      for (int i = 0; i < types_.size(); i++) {
        output.writeMessage(4, types_.get(i));
      }
      for (int i = 0; i < metadata_.size(); i++) {
        output.writeMessage(5, metadata_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(6, numberOfRows_);
      }
      for (int i = 0; i < statistics_.size(); i++) {
        output.writeMessage(7, statistics_.get(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt32(8, rowIndexStride_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, headerLength_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, contentLength_);
      }
      for (int i = 0; i < stripes_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, stripes_.get(i));
      }
      for (int i = 0; i < types_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, types_.get(i));
      }
      for (int i = 0; i < metadata_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, metadata_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(6, numberOfRows_);
      }
      for (int i = 0; i < statistics_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, statistics_.get(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(8, rowIndexStride_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.FooterOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getStripesFieldBuilder();
          getTypesFieldBuilder();
          getMetadataFieldBuilder();
          getStatisticsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        headerLength_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        contentLength_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (stripesBuilder_ == null) {
          stripes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          stripesBuilder_.clear();
        }
        if (typesBuilder_ == null) {
          types_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          typesBuilder_.clear();
        }
        if (metadataBuilder_ == null) {
          metadata_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          metadataBuilder_.clear();
        }
        numberOfRows_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000020);
        if (statisticsBuilder_ == null) {
          statistics_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
        } else {
          statisticsBuilder_.clear();
        }
        rowIndexStride_ = 0;
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.headerLength_ = headerLength_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.contentLength_ = contentLength_;
        if (stripesBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            stripes_ = java.util.Collections.unmodifiableList(stripes_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.stripes_ = stripes_;
        } else {
          result.stripes_ = stripesBuilder_.build();
        }
        if (typesBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            types_ = java.util.Collections.unmodifiableList(types_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.types_ = types_;
        } else {
          result.types_ = typesBuilder_.build();
        }
        if (metadataBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            metadata_ = java.util.Collections.unmodifiableList(metadata_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.metadata_ = metadata_;
        } else {
          result.metadata_ = metadataBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000004;
        }
        result.numberOfRows_ = numberOfRows_;
        if (statisticsBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040)) {
            statistics_ = java.util.Collections.unmodifiableList(statistics_);
            bitField0_ = (bitField0_ & ~0x00000040);
          }
          result.statistics_ = statistics_;
        } else {
          result.statistics_ = statisticsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000008;
        }
        result.rowIndexStride_ = rowIndexStride_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer.getDefaultInstance()) return this;
        if (other.hasHeaderLength()) {
          setHeaderLength(other.getHeaderLength());
        }
        if (other.hasContentLength()) {
          setContentLength(other.getContentLength());
        }
        if (stripesBuilder_ == null) {
          if (!other.stripes_.isEmpty()) {
            if (stripes_.isEmpty()) {
              stripes_ = other.stripes_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureStripesIsMutable();
              stripes_.addAll(other.stripes_);
            }
            onChanged();
          }
        } else {
          if (!other.stripes_.isEmpty()) {
            if (stripesBuilder_.isEmpty()) {
              stripesBuilder_.dispose();
              stripesBuilder_ = null;
              stripes_ = other.stripes_;
              bitField0_ = (bitField0_ & ~0x00000004);
              stripesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getStripesFieldBuilder() : null;
            } else {
              stripesBuilder_.addAllMessages(other.stripes_);
            }
          }
        }
        if (typesBuilder_ == null) {
          if (!other.types_.isEmpty()) {
            if (types_.isEmpty()) {
              types_ = other.types_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureTypesIsMutable();
              types_.addAll(other.types_);
            }
            onChanged();
          }
        } else {
          if (!other.types_.isEmpty()) {
            if (typesBuilder_.isEmpty()) {
              typesBuilder_.dispose();
              typesBuilder_ = null;
              types_ = other.types_;
              bitField0_ = (bitField0_ & ~0x00000008);
              typesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getTypesFieldBuilder() : null;
            } else {
              typesBuilder_.addAllMessages(other.types_);
            }
          }
        }
        if (metadataBuilder_ == null) {
          if (!other.metadata_.isEmpty()) {
            if (metadata_.isEmpty()) {
              metadata_ = other.metadata_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureMetadataIsMutable();
              metadata_.addAll(other.metadata_);
            }
            onChanged();
          }
        } else {
          if (!other.metadata_.isEmpty()) {
            if (metadataBuilder_.isEmpty()) {
              metadataBuilder_.dispose();
              metadataBuilder_ = null;
              metadata_ = other.metadata_;
              bitField0_ = (bitField0_ & ~0x00000010);
              metadataBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getMetadataFieldBuilder() : null;
            } else {
              metadataBuilder_.addAllMessages(other.metadata_);
            }
          }
        }
        if (other.hasNumberOfRows()) {
          setNumberOfRows(other.getNumberOfRows());
        }
        if (statisticsBuilder_ == null) {
          if (!other.statistics_.isEmpty()) {
            if (statistics_.isEmpty()) {
              statistics_ = other.statistics_;
              bitField0_ = (bitField0_ & ~0x00000040);
            } else {
              ensureStatisticsIsMutable();
              statistics_.addAll(other.statistics_);
            }
            onChanged();
          }
        } else {
          if (!other.statistics_.isEmpty()) {
            if (statisticsBuilder_.isEmpty()) {
              statisticsBuilder_.dispose();
              statisticsBuilder_ = null;
              statistics_ = other.statistics_;
              bitField0_ = (bitField0_ & ~0x00000040);
              statisticsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getStatisticsFieldBuilder() : null;
            } else {
              statisticsBuilder_.addAllMessages(other.statistics_);
            }
          }
        }
        if (other.hasRowIndexStride()) {
          setRowIndexStride(other.getRowIndexStride());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        for (int i = 0; i < getTypesCount(); i++) {
          if (!getTypes(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getMetadataCount(); i++) {
          if (!getMetadata(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              headerLength_ = input.readUInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              contentLength_ = input.readUInt64();
              break;
            }
            case 26: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addStripes(subBuilder.buildPartial());
              break;
            }
            case 34: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addTypes(subBuilder.buildPartial());
              break;
            }
            case 42: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addMetadata(subBuilder.buildPartial());
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              numberOfRows_ = input.readUInt64();
              break;
            }
            case 58: {
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder subBuilder = org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addStatistics(subBuilder.buildPartial());
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              rowIndexStride_ = input.readUInt32();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional uint64 headerLength = 1;
      private long headerLength_ ;
      public boolean hasHeaderLength() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public long getHeaderLength() {
        return headerLength_;
      }
      public Builder setHeaderLength(long value) {
        bitField0_ |= 0x00000001;
        headerLength_ = value;
        onChanged();
        return this;
      }
      public Builder clearHeaderLength() {
        bitField0_ = (bitField0_ & ~0x00000001);
        headerLength_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint64 contentLength = 2;
      private long contentLength_ ;
      public boolean hasContentLength() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public long getContentLength() {
        return contentLength_;
      }
      public Builder setContentLength(long value) {
        bitField0_ |= 0x00000002;
        contentLength_ = value;
        onChanged();
        return this;
      }
      public Builder clearContentLength() {
        bitField0_ = (bitField0_ & ~0x00000002);
        contentLength_ = 0L;
        onChanged();
        return this;
      }
      
      // repeated .org.apache.hadoop.hive.ql.io.orc.StripeInformation stripes = 3;
      private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation> stripes_ =
        java.util.Collections.emptyList();
      private void ensureStripesIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          stripes_ = new java.util.ArrayList<org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation>(stripes_);
          bitField0_ |= 0x00000004;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformationOrBuilder> stripesBuilder_;
      
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation> getStripesList() {
        if (stripesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(stripes_);
        } else {
          return stripesBuilder_.getMessageList();
        }
      }
      public int getStripesCount() {
        if (stripesBuilder_ == null) {
          return stripes_.size();
        } else {
          return stripesBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation getStripes(int index) {
        if (stripesBuilder_ == null) {
          return stripes_.get(index);
        } else {
          return stripesBuilder_.getMessage(index);
        }
      }
      public Builder setStripes(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation value) {
        if (stripesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStripesIsMutable();
          stripes_.set(index, value);
          onChanged();
        } else {
          stripesBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setStripes(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder builderForValue) {
        if (stripesBuilder_ == null) {
          ensureStripesIsMutable();
          stripes_.set(index, builderForValue.build());
          onChanged();
        } else {
          stripesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addStripes(org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation value) {
        if (stripesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStripesIsMutable();
          stripes_.add(value);
          onChanged();
        } else {
          stripesBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addStripes(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation value) {
        if (stripesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStripesIsMutable();
          stripes_.add(index, value);
          onChanged();
        } else {
          stripesBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addStripes(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder builderForValue) {
        if (stripesBuilder_ == null) {
          ensureStripesIsMutable();
          stripes_.add(builderForValue.build());
          onChanged();
        } else {
          stripesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addStripes(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder builderForValue) {
        if (stripesBuilder_ == null) {
          ensureStripesIsMutable();
          stripes_.add(index, builderForValue.build());
          onChanged();
        } else {
          stripesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllStripes(
          java.lang.Iterable<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation> values) {
        if (stripesBuilder_ == null) {
          ensureStripesIsMutable();
          super.addAll(values, stripes_);
          onChanged();
        } else {
          stripesBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearStripes() {
        if (stripesBuilder_ == null) {
          stripes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          stripesBuilder_.clear();
        }
        return this;
      }
      public Builder removeStripes(int index) {
        if (stripesBuilder_ == null) {
          ensureStripesIsMutable();
          stripes_.remove(index);
          onChanged();
        } else {
          stripesBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder getStripesBuilder(
          int index) {
        return getStripesFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformationOrBuilder getStripesOrBuilder(
          int index) {
        if (stripesBuilder_ == null) {
          return stripes_.get(index);  } else {
          return stripesBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformationOrBuilder> 
           getStripesOrBuilderList() {
        if (stripesBuilder_ != null) {
          return stripesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(stripes_);
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder addStripesBuilder() {
        return getStripesFieldBuilder().addBuilder(
            org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.getDefaultInstance());
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder addStripesBuilder(
          int index) {
        return getStripesFieldBuilder().addBuilder(
            index, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder> 
           getStripesBuilderList() {
        return getStripesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformationOrBuilder> 
          getStripesFieldBuilder() {
        if (stripesBuilder_ == null) {
          stripesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformationOrBuilder>(
                  stripes_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          stripes_ = null;
        }
        return stripesBuilder_;
      }
      
      // repeated .org.apache.hadoop.hive.ql.io.orc.Type types = 4;
      private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Type> types_ =
        java.util.Collections.emptyList();
      private void ensureTypesIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          types_ = new java.util.ArrayList<org.apache.hadoop.hive.ql.io.orc.OrcProto.Type>(types_);
          bitField0_ |= 0x00000008;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.Type, org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.TypeOrBuilder> typesBuilder_;
      
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Type> getTypesList() {
        if (typesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(types_);
        } else {
          return typesBuilder_.getMessageList();
        }
      }
      public int getTypesCount() {
        if (typesBuilder_ == null) {
          return types_.size();
        } else {
          return typesBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Type getTypes(int index) {
        if (typesBuilder_ == null) {
          return types_.get(index);
        } else {
          return typesBuilder_.getMessage(index);
        }
      }
      public Builder setTypes(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.Type value) {
        if (typesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureTypesIsMutable();
          types_.set(index, value);
          onChanged();
        } else {
          typesBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setTypes(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder builderForValue) {
        if (typesBuilder_ == null) {
          ensureTypesIsMutable();
          types_.set(index, builderForValue.build());
          onChanged();
        } else {
          typesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addTypes(org.apache.hadoop.hive.ql.io.orc.OrcProto.Type value) {
        if (typesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureTypesIsMutable();
          types_.add(value);
          onChanged();
        } else {
          typesBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addTypes(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.Type value) {
        if (typesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureTypesIsMutable();
          types_.add(index, value);
          onChanged();
        } else {
          typesBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addTypes(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder builderForValue) {
        if (typesBuilder_ == null) {
          ensureTypesIsMutable();
          types_.add(builderForValue.build());
          onChanged();
        } else {
          typesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addTypes(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder builderForValue) {
        if (typesBuilder_ == null) {
          ensureTypesIsMutable();
          types_.add(index, builderForValue.build());
          onChanged();
        } else {
          typesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllTypes(
          java.lang.Iterable<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.Type> values) {
        if (typesBuilder_ == null) {
          ensureTypesIsMutable();
          super.addAll(values, types_);
          onChanged();
        } else {
          typesBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearTypes() {
        if (typesBuilder_ == null) {
          types_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          typesBuilder_.clear();
        }
        return this;
      }
      public Builder removeTypes(int index) {
        if (typesBuilder_ == null) {
          ensureTypesIsMutable();
          types_.remove(index);
          onChanged();
        } else {
          typesBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder getTypesBuilder(
          int index) {
        return getTypesFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.TypeOrBuilder getTypesOrBuilder(
          int index) {
        if (typesBuilder_ == null) {
          return types_.get(index);  } else {
          return typesBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.TypeOrBuilder> 
           getTypesOrBuilderList() {
        if (typesBuilder_ != null) {
          return typesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(types_);
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder addTypesBuilder() {
        return getTypesFieldBuilder().addBuilder(
            org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.getDefaultInstance());
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder addTypesBuilder(
          int index) {
        return getTypesFieldBuilder().addBuilder(
            index, org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder> 
           getTypesBuilderList() {
        return getTypesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.Type, org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.TypeOrBuilder> 
          getTypesFieldBuilder() {
        if (typesBuilder_ == null) {
          typesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Type, org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.TypeOrBuilder>(
                  types_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          types_ = null;
        }
        return typesBuilder_;
      }
      
      // repeated .org.apache.hadoop.hive.ql.io.orc.UserMetadataItem metadata = 5;
      private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem> metadata_ =
        java.util.Collections.emptyList();
      private void ensureMetadataIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          metadata_ = new java.util.ArrayList<org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem>(metadata_);
          bitField0_ |= 0x00000010;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItemOrBuilder> metadataBuilder_;
      
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem> getMetadataList() {
        if (metadataBuilder_ == null) {
          return java.util.Collections.unmodifiableList(metadata_);
        } else {
          return metadataBuilder_.getMessageList();
        }
      }
      public int getMetadataCount() {
        if (metadataBuilder_ == null) {
          return metadata_.size();
        } else {
          return metadataBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem getMetadata(int index) {
        if (metadataBuilder_ == null) {
          return metadata_.get(index);
        } else {
          return metadataBuilder_.getMessage(index);
        }
      }
      public Builder setMetadata(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem value) {
        if (metadataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMetadataIsMutable();
          metadata_.set(index, value);
          onChanged();
        } else {
          metadataBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setMetadata(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder builderForValue) {
        if (metadataBuilder_ == null) {
          ensureMetadataIsMutable();
          metadata_.set(index, builderForValue.build());
          onChanged();
        } else {
          metadataBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addMetadata(org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem value) {
        if (metadataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMetadataIsMutable();
          metadata_.add(value);
          onChanged();
        } else {
          metadataBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addMetadata(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem value) {
        if (metadataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMetadataIsMutable();
          metadata_.add(index, value);
          onChanged();
        } else {
          metadataBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addMetadata(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder builderForValue) {
        if (metadataBuilder_ == null) {
          ensureMetadataIsMutable();
          metadata_.add(builderForValue.build());
          onChanged();
        } else {
          metadataBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addMetadata(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder builderForValue) {
        if (metadataBuilder_ == null) {
          ensureMetadataIsMutable();
          metadata_.add(index, builderForValue.build());
          onChanged();
        } else {
          metadataBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllMetadata(
          java.lang.Iterable<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem> values) {
        if (metadataBuilder_ == null) {
          ensureMetadataIsMutable();
          super.addAll(values, metadata_);
          onChanged();
        } else {
          metadataBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearMetadata() {
        if (metadataBuilder_ == null) {
          metadata_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          metadataBuilder_.clear();
        }
        return this;
      }
      public Builder removeMetadata(int index) {
        if (metadataBuilder_ == null) {
          ensureMetadataIsMutable();
          metadata_.remove(index);
          onChanged();
        } else {
          metadataBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder getMetadataBuilder(
          int index) {
        return getMetadataFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItemOrBuilder getMetadataOrBuilder(
          int index) {
        if (metadataBuilder_ == null) {
          return metadata_.get(index);  } else {
          return metadataBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItemOrBuilder> 
           getMetadataOrBuilderList() {
        if (metadataBuilder_ != null) {
          return metadataBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(metadata_);
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder addMetadataBuilder() {
        return getMetadataFieldBuilder().addBuilder(
            org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.getDefaultInstance());
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder addMetadataBuilder(
          int index) {
        return getMetadataFieldBuilder().addBuilder(
            index, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder> 
           getMetadataBuilderList() {
        return getMetadataFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItemOrBuilder> 
          getMetadataFieldBuilder() {
        if (metadataBuilder_ == null) {
          metadataBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItemOrBuilder>(
                  metadata_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          metadata_ = null;
        }
        return metadataBuilder_;
      }
      
      // optional uint64 numberOfRows = 6;
      private long numberOfRows_ ;
      public boolean hasNumberOfRows() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      public long getNumberOfRows() {
        return numberOfRows_;
      }
      public Builder setNumberOfRows(long value) {
        bitField0_ |= 0x00000020;
        numberOfRows_ = value;
        onChanged();
        return this;
      }
      public Builder clearNumberOfRows() {
        bitField0_ = (bitField0_ & ~0x00000020);
        numberOfRows_ = 0L;
        onChanged();
        return this;
      }
      
      // repeated .org.apache.hadoop.hive.ql.io.orc.ColumnStatistics statistics = 7;
      private java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics> statistics_ =
        java.util.Collections.emptyList();
      private void ensureStatisticsIsMutable() {
        if (!((bitField0_ & 0x00000040) == 0x00000040)) {
          statistics_ = new java.util.ArrayList<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics>(statistics_);
          bitField0_ |= 0x00000040;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder> statisticsBuilder_;
      
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics> getStatisticsList() {
        if (statisticsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(statistics_);
        } else {
          return statisticsBuilder_.getMessageList();
        }
      }
      public int getStatisticsCount() {
        if (statisticsBuilder_ == null) {
          return statistics_.size();
        } else {
          return statisticsBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics getStatistics(int index) {
        if (statisticsBuilder_ == null) {
          return statistics_.get(index);
        } else {
          return statisticsBuilder_.getMessage(index);
        }
      }
      public Builder setStatistics(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics value) {
        if (statisticsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStatisticsIsMutable();
          statistics_.set(index, value);
          onChanged();
        } else {
          statisticsBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setStatistics(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder builderForValue) {
        if (statisticsBuilder_ == null) {
          ensureStatisticsIsMutable();
          statistics_.set(index, builderForValue.build());
          onChanged();
        } else {
          statisticsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addStatistics(org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics value) {
        if (statisticsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStatisticsIsMutable();
          statistics_.add(value);
          onChanged();
        } else {
          statisticsBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addStatistics(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics value) {
        if (statisticsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStatisticsIsMutable();
          statistics_.add(index, value);
          onChanged();
        } else {
          statisticsBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addStatistics(
          org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder builderForValue) {
        if (statisticsBuilder_ == null) {
          ensureStatisticsIsMutable();
          statistics_.add(builderForValue.build());
          onChanged();
        } else {
          statisticsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addStatistics(
          int index, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder builderForValue) {
        if (statisticsBuilder_ == null) {
          ensureStatisticsIsMutable();
          statistics_.add(index, builderForValue.build());
          onChanged();
        } else {
          statisticsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllStatistics(
          java.lang.Iterable<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics> values) {
        if (statisticsBuilder_ == null) {
          ensureStatisticsIsMutable();
          super.addAll(values, statistics_);
          onChanged();
        } else {
          statisticsBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearStatistics() {
        if (statisticsBuilder_ == null) {
          statistics_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
          onChanged();
        } else {
          statisticsBuilder_.clear();
        }
        return this;
      }
      public Builder removeStatistics(int index) {
        if (statisticsBuilder_ == null) {
          ensureStatisticsIsMutable();
          statistics_.remove(index);
          onChanged();
        } else {
          statisticsBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder getStatisticsBuilder(
          int index) {
        return getStatisticsFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder getStatisticsOrBuilder(
          int index) {
        if (statisticsBuilder_ == null) {
          return statistics_.get(index);  } else {
          return statisticsBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder> 
           getStatisticsOrBuilderList() {
        if (statisticsBuilder_ != null) {
          return statisticsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(statistics_);
        }
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder addStatisticsBuilder() {
        return getStatisticsFieldBuilder().addBuilder(
            org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.getDefaultInstance());
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder addStatisticsBuilder(
          int index) {
        return getStatisticsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder> 
           getStatisticsBuilderList() {
        return getStatisticsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder> 
          getStatisticsFieldBuilder() {
        if (statisticsBuilder_ == null) {
          statisticsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder, org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatisticsOrBuilder>(
                  statistics_,
                  ((bitField0_ & 0x00000040) == 0x00000040),
                  getParentForChildren(),
                  isClean());
          statistics_ = null;
        }
        return statisticsBuilder_;
      }
      
      // optional uint32 rowIndexStride = 8;
      private int rowIndexStride_ ;
      public boolean hasRowIndexStride() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      public int getRowIndexStride() {
        return rowIndexStride_;
      }
      public Builder setRowIndexStride(int value) {
        bitField0_ |= 0x00000080;
        rowIndexStride_ = value;
        onChanged();
        return this;
      }
      public Builder clearRowIndexStride() {
        bitField0_ = (bitField0_ & ~0x00000080);
        rowIndexStride_ = 0;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.Footer)
    }
    
    static {
      defaultInstance = new Footer(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.Footer)
  }
  
  public interface PostScriptOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional uint64 footerLength = 1;
    boolean hasFooterLength();
    long getFooterLength();
    
    // optional .org.apache.hadoop.hive.ql.io.orc.CompressionKind compression = 2;
    boolean hasCompression();
    org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind getCompression();
    
    // optional uint64 compressionBlockSize = 3;
    boolean hasCompressionBlockSize();
    long getCompressionBlockSize();
  }
  public static final class PostScript extends
      com.google.protobuf.GeneratedMessage
      implements PostScriptOrBuilder {
    // Use PostScript.newBuilder() to construct.
    private PostScript(Builder builder) {
      super(builder);
    }
    private PostScript(boolean noInit) {}
    
    private static final PostScript defaultInstance;
    public static PostScript getDefaultInstance() {
      return defaultInstance;
    }
    
    public PostScript getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional uint64 footerLength = 1;
    public static final int FOOTERLENGTH_FIELD_NUMBER = 1;
    private long footerLength_;
    public boolean hasFooterLength() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public long getFooterLength() {
      return footerLength_;
    }
    
    // optional .org.apache.hadoop.hive.ql.io.orc.CompressionKind compression = 2;
    public static final int COMPRESSION_FIELD_NUMBER = 2;
    private org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind compression_;
    public boolean hasCompression() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind getCompression() {
      return compression_;
    }
    
    // optional uint64 compressionBlockSize = 3;
    public static final int COMPRESSIONBLOCKSIZE_FIELD_NUMBER = 3;
    private long compressionBlockSize_;
    public boolean hasCompressionBlockSize() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public long getCompressionBlockSize() {
      return compressionBlockSize_;
    }
    
    private void initFields() {
      footerLength_ = 0L;
      compression_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind.NONE;
      compressionBlockSize_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt64(1, footerLength_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, compression_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(3, compressionBlockSize_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, footerLength_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, compression_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, compressionBlockSize_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScriptOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        footerLength_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        compression_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind.NONE;
        bitField0_ = (bitField0_ & ~0x00000002);
        compressionBlockSize_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript.getDescriptor();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript getDefaultInstanceForType() {
        return org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript.getDefaultInstance();
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript build() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript buildPartial() {
        org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript result = new org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.footerLength_ = footerLength_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.compression_ = compression_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.compressionBlockSize_ = compressionBlockSize_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript) {
          return mergeFrom((org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript other) {
        if (other == org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript.getDefaultInstance()) return this;
        if (other.hasFooterLength()) {
          setFooterLength(other.getFooterLength());
        }
        if (other.hasCompression()) {
          setCompression(other.getCompression());
        }
        if (other.hasCompressionBlockSize()) {
          setCompressionBlockSize(other.getCompressionBlockSize());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              footerLength_ = input.readUInt64();
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind value = org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                compression_ = value;
              }
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              compressionBlockSize_ = input.readUInt64();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional uint64 footerLength = 1;
      private long footerLength_ ;
      public boolean hasFooterLength() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public long getFooterLength() {
        return footerLength_;
      }
      public Builder setFooterLength(long value) {
        bitField0_ |= 0x00000001;
        footerLength_ = value;
        onChanged();
        return this;
      }
      public Builder clearFooterLength() {
        bitField0_ = (bitField0_ & ~0x00000001);
        footerLength_ = 0L;
        onChanged();
        return this;
      }
      
      // optional .org.apache.hadoop.hive.ql.io.orc.CompressionKind compression = 2;
      private org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind compression_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind.NONE;
      public boolean hasCompression() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind getCompression() {
        return compression_;
      }
      public Builder setCompression(org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        compression_ = value;
        onChanged();
        return this;
      }
      public Builder clearCompression() {
        bitField0_ = (bitField0_ & ~0x00000002);
        compression_ = org.apache.hadoop.hive.ql.io.orc.OrcProto.CompressionKind.NONE;
        onChanged();
        return this;
      }
      
      // optional uint64 compressionBlockSize = 3;
      private long compressionBlockSize_ ;
      public boolean hasCompressionBlockSize() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public long getCompressionBlockSize() {
        return compressionBlockSize_;
      }
      public Builder setCompressionBlockSize(long value) {
        bitField0_ |= 0x00000004;
        compressionBlockSize_ = value;
        onChanged();
        return this;
      }
      public Builder clearCompressionBlockSize() {
        bitField0_ = (bitField0_ & ~0x00000004);
        compressionBlockSize_ = 0L;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hive.ql.io.orc.PostScript)
    }
    
    static {
      defaultInstance = new PostScript(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hive.ql.io.orc.PostScript)
  }
  
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_Type_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_fieldAccessorTable;
  
  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\017orc_proto.proto\022 org.apache.hadoop.hiv" +
      "e.ql.io.orc\"B\n\021IntegerStatistics\022\017\n\007mini" +
      "mum\030\001 \001(\022\022\017\n\007maximum\030\002 \001(\022\022\013\n\003sum\030\003 \001(\022\"" +
      "A\n\020DoubleStatistics\022\017\n\007minimum\030\001 \001(\001\022\017\n\007" +
      "maximum\030\002 \001(\001\022\013\n\003sum\030\003 \001(\001\"4\n\020StringStat" +
      "istics\022\017\n\007minimum\030\001 \001(\t\022\017\n\007maximum\030\002 \001(\t" +
      "\"%\n\020BucketStatistics\022\021\n\005count\030\001 \003(\004B\002\020\001\"" +
      "\340\002\n\020ColumnStatistics\022\026\n\016numberOfValues\030\001" +
      " \001(\004\022J\n\rintStatistics\030\002 \001(\01323.org.apache" +
      ".hadoop.hive.ql.io.orc.IntegerStatistics",
      "\022L\n\020doubleStatistics\030\003 \001(\01322.org.apache." +
      "hadoop.hive.ql.io.orc.DoubleStatistics\022L" +
      "\n\020stringStatistics\030\004 \001(\01322.org.apache.ha" +
      "doop.hive.ql.io.orc.StringStatistics\022L\n\020" +
      "bucketStatistics\030\005 \001(\01322.org.apache.hado" +
      "op.hive.ql.io.orc.BucketStatistics\"n\n\rRo" +
      "wIndexEntry\022\025\n\tpositions\030\001 \003(\004B\002\020\001\022F\n\nst" +
      "atistics\030\002 \001(\01322.org.apache.hadoop.hive." +
      "ql.io.orc.ColumnStatistics\"J\n\010RowIndex\022>" +
      "\n\005entry\030\001 \003(\0132/.org.apache.hadoop.hive.q",
      "l.io.orc.RowIndexEntry\"\331\001\n\006Stream\022;\n\004kin" +
      "d\030\001 \002(\0162-.org.apache.hadoop.hive.ql.io.o" +
      "rc.Stream.Kind\022\016\n\006column\030\002 \001(\r\022\016\n\006length" +
      "\030\003 \001(\004\"r\n\004Kind\022\013\n\007PRESENT\020\000\022\010\n\004DATA\020\001\022\n\n" +
      "\006LENGTH\020\002\022\023\n\017DICTIONARY_DATA\020\003\022\024\n\020DICTIO" +
      "NARY_COUNT\020\004\022\r\n\tNANO_DATA\020\005\022\r\n\tROW_INDEX" +
      "\020\006\"\221\001\n\016ColumnEncoding\022C\n\004kind\030\001 \002(\01625.or" +
      "g.apache.hadoop.hive.ql.io.orc.ColumnEnc" +
      "oding.Kind\022\026\n\016dictionarySize\030\002 \001(\r\"\"\n\004Ki" +
      "nd\022\n\n\006DIRECT\020\000\022\016\n\nDICTIONARY\020\001\"\214\001\n\014Strip",
      "eFooter\0229\n\007streams\030\001 \003(\0132(.org.apache.ha" +
      "doop.hive.ql.io.orc.Stream\022A\n\007columns\030\002 " +
      "\003(\01320.org.apache.hadoop.hive.ql.io.orc.C" +
      "olumnEncoding\"\221\002\n\004Type\0229\n\004kind\030\001 \002(\0162+.o" +
      "rg.apache.hadoop.hive.ql.io.orc.Type.Kin" +
      "d\022\024\n\010subtypes\030\002 \003(\rB\002\020\001\022\022\n\nfieldNames\030\003 " +
      "\003(\t\"\243\001\n\004Kind\022\013\n\007BOOLEAN\020\000\022\010\n\004BYTE\020\001\022\t\n\005S" +
      "HORT\020\002\022\007\n\003INT\020\003\022\010\n\004LONG\020\004\022\t\n\005FLOAT\020\005\022\n\n\006" +
      "DOUBLE\020\006\022\n\n\006STRING\020\007\022\n\n\006BINARY\020\010\022\r\n\tTIME" +
      "STAMP\020\t\022\010\n\004LIST\020\n\022\007\n\003MAP\020\013\022\n\n\006STRUCT\020\014\022\t",
      "\n\005UNION\020\r\"x\n\021StripeInformation\022\016\n\006offset" +
      "\030\001 \001(\004\022\023\n\013indexLength\030\002 \001(\004\022\022\n\ndataLengt" +
      "h\030\003 \001(\004\022\024\n\014footerLength\030\004 \001(\004\022\024\n\014numberO" +
      "fRows\030\005 \001(\004\"/\n\020UserMetadataItem\022\014\n\004name\030" +
      "\001 \002(\t\022\r\n\005value\030\002 \002(\014\"\356\002\n\006Footer\022\024\n\014heade" +
      "rLength\030\001 \001(\004\022\025\n\rcontentLength\030\002 \001(\004\022D\n\007" +
      "stripes\030\003 \003(\01323.org.apache.hadoop.hive.q" +
      "l.io.orc.StripeInformation\0225\n\005types\030\004 \003(" +
      "\0132&.org.apache.hadoop.hive.ql.io.orc.Typ" +
      "e\022D\n\010metadata\030\005 \003(\01322.org.apache.hadoop.",
      "hive.ql.io.orc.UserMetadataItem\022\024\n\014numbe" +
      "rOfRows\030\006 \001(\004\022F\n\nstatistics\030\007 \003(\01322.org." +
      "apache.hadoop.hive.ql.io.orc.ColumnStati" +
      "stics\022\026\n\016rowIndexStride\030\010 \001(\r\"\210\001\n\nPostSc" +
      "ript\022\024\n\014footerLength\030\001 \001(\004\022F\n\013compressio" +
      "n\030\002 \001(\01621.org.apache.hadoop.hive.ql.io.o" +
      "rc.CompressionKind\022\034\n\024compressionBlockSi" +
      "ze\030\003 \001(\004*:\n\017CompressionKind\022\010\n\004NONE\020\000\022\010\n" +
      "\004ZLIB\020\001\022\n\n\006SNAPPY\020\002\022\007\n\003LZO\020\003"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor,
              new java.lang.String[] { "Minimum", "Maximum", "Sum", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.IntegerStatistics.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor,
              new java.lang.String[] { "Minimum", "Maximum", "Sum", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.DoubleStatistics.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor,
              new java.lang.String[] { "Minimum", "Maximum", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StringStatistics.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor,
              new java.lang.String[] { "Count", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.BucketStatistics.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor,
              new java.lang.String[] { "NumberOfValues", "IntStatistics", "DoubleStatistics", "StringStatistics", "BucketStatistics", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnStatistics.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor,
              new java.lang.String[] { "Positions", "Statistics", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndexEntry.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor,
              new java.lang.String[] { "Entry", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.RowIndex.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor,
              new java.lang.String[] { "Kind", "Column", "Length", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Stream.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor,
              new java.lang.String[] { "Kind", "DictionarySize", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.ColumnEncoding.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor =
            getDescriptor().getMessageTypes().get(9);
          internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor,
              new java.lang.String[] { "Streams", "Columns", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeFooter.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor =
            getDescriptor().getMessageTypes().get(10);
          internal_static_org_apache_hadoop_hive_ql_io_orc_Type_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor,
              new java.lang.String[] { "Kind", "Subtypes", "FieldNames", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Type.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor =
            getDescriptor().getMessageTypes().get(11);
          internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor,
              new java.lang.String[] { "Offset", "IndexLength", "DataLength", "FooterLength", "NumberOfRows", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.StripeInformation.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor =
            getDescriptor().getMessageTypes().get(12);
          internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor,
              new java.lang.String[] { "Name", "Value", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.UserMetadataItem.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor =
            getDescriptor().getMessageTypes().get(13);
          internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor,
              new java.lang.String[] { "HeaderLength", "ContentLength", "Stripes", "Types", "Metadata", "NumberOfRows", "Statistics", "RowIndexStride", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.Footer.Builder.class);
          internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor =
            getDescriptor().getMessageTypes().get(14);
          internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor,
              new java.lang.String[] { "FooterLength", "Compression", "CompressionBlockSize", },
              org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript.class,
              org.apache.hadoop.hive.ql.io.orc.OrcProto.PostScript.Builder.class);
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        }, assigner);
  }
  
  // @@protoc_insertion_point(outer_class_scope)
}
