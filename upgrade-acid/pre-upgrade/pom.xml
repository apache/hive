<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">


    <parent>
        <groupId>org.apache.hive</groupId>
        <artifactId>hive-upgrade-acid</artifactId>
        <version>4.0.0-SNAPSHOT</version>
        <relativePath>../pom.xml</relativePath>
    </parent>


    <modelVersion>4.0.0</modelVersion>
    <!--this module is added to parent pom so that it builds and releases with the reset of Hive-->
    <artifactId>hive-pre-upgrade</artifactId>
    <name>Hive Pre Upgrade Acid</name>
    <packaging>jar</packaging>

    <properties>
        <hive.path.to.root>../..</hive.path.to.root>

        <!-- Test Properties -->
        <test.conf.dir>${project.build.directory}/testconf</test.conf.dir>
        <test.log4j.scheme>file://</test.log4j.scheme>
        <log4j.conf.dir>${project.basedir}/src/test/resources</log4j.conf.dir>
        <test.tmp.dir>${project.build.directory}/tmp</test.tmp.dir>
        <test.warehouse.dir>${project.build.directory}/warehouse</test.warehouse.dir>
        <test.warehouse.scheme>file://</test.warehouse.scheme>
        <test.forkcount>1</test.forkcount>
        <skipITests>true</skipITests>
        <hdp.hive.version>2.3.3</hdp.hive.version>
        <hdp.hadoop.version>2.7.2</hdp.hadoop.version>
    </properties>
    <dependencies>
        <!--scope is 'provided' for all.  The UpgradeTool is provided as part of Hive 3.x and
        supports 2 modes - preUpgrade which runs with 2.x jars on the classpath and postUpgrade
        which runs with 3.x jars.  'provided' should pull these jars for compile/test but not
        for packaging.-->
        <dependency>
            <groupId>commons-cli</groupId>
            <artifactId>commons-cli</artifactId>
            <version>1.2</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hive</groupId>
            <artifactId>hive-metastore</artifactId>
            <version>${hdp.hive.version}</version>
            <scope>provided</scope>
            <exclusions>
              <exclusion>
                <groupId>tomcat</groupId>
                <artifactId>jasper-compiler</artifactId>
              </exclusion>
              <exclusion>
                <groupId>tomcat</groupId>
                <artifactId>jasper-runtime</artifactId>
              </exclusion>
              <exclusion>
                <groupId>org.apache.zookeeper</groupId>
                <artifactId>zookeeper</artifactId>
              </exclusion>
              <exclusion>
                <groupId>org.apache.curator</groupId>
                <artifactId>curator-framework</artifactId>
              </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.hive</groupId>
            <artifactId>hive-exec</artifactId>
            <version>${hdp.hive.version}</version>
            <scope>provided</scope>
            <exclusions>
              <exclusion>
                <groupId>org.codehaus.groovy</groupId>
                <artifactId>groovy-all</artifactId>
              </exclusion>
              <exclusion>
                <groupId>org.apache.zookeeper</groupId>
                <artifactId>zookeeper</artifactId>
              </exclusion>
              <exclusion>
                <groupId>org.apache.curator</groupId>
                <artifactId>curator-framework</artifactId>
              </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <version>${hdp.hadoop.version}</version>
            <scope>provided</scope>
            <exclusions>
              <exclusion>
                <groupId>commons-beanutils</groupId>
                <artifactId>commons-beanutils</artifactId>
              </exclusion>
              <exclusion>
                <groupId>org.apache.zookeeper</groupId>
                <artifactId>zookeeper</artifactId>
              </exclusion>
              <exclusion>
                <groupId>org.apache.curator</groupId>
                <artifactId>curator-client</artifactId>
              </exclusion>
              <exclusion>
                <groupId>org.apache.curator</groupId>
                <artifactId>curator-recipes</artifactId>
              </exclusion>
              <exclusion>
                <groupId>org.apache.curator</groupId>
                <artifactId>curator-framework</artifactId>
              </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <!-- w/o this we get this, even though mapreduce.framework.name=mapred.job.tracker=local
            https://stackoverflow.com/questions/24096834/org-apache-hadoop-mapred-localclientprotocolprovider-not-found

            2018-05-23T13:01:50,122 ERROR [main] exec.Task: Job Submission failed with exception 'java.io.IOException(Cannot initialize Cluster. Please check yo\
ur configuration for mapreduce.framework.name and the correspond server addresses.)'
java.io.IOException: Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.
        at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:120)
        at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:82)
        at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:75)
        at org.apache.hadoop.mapred.JobClient.init(JobClient.java:470)
        at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:449)
        at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:369)
        at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:151)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)

            -->
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-mapreduce-client-common</artifactId>
            <version>2.7.2</version>
            <scope>provided</scope>
            <exclusions>
              <exclusion>
                <groupId>org.apache.zookeeper</groupId>
                <artifactId>zookeeper</artifactId>
              </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.orc</groupId>
            <artifactId>orc-core</artifactId>
            <version>1.3.3</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
          <groupId>org.junit.jupiter</groupId>
          <artifactId>junit-jupiter-engine</artifactId>
          <version>${junit.jupiter.version}</version>
          <scope>test</scope>
        </dependency>
        <dependency>
          <groupId>org.junit.vintage</groupId>
          <artifactId>junit-vintage-engine</artifactId>
          <version>${junit.vintage.version}</version>
          <scope>test</scope>
        </dependency>
    </dependencies>


    <build>
        <resources>
            <resource>
                <directory>${basedir}/src/main/resources</directory>
                <includes>
                    <include>package.jdo</include>
                </includes>
            </resource>
        </resources>

        <pluginManagement>
            <plugins>
                <plugin>
                    <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-antrun-plugin</artifactId>
                    <dependencies>
                        <dependency>
                            <groupId>ant-contrib</groupId>
                            <artifactId>ant-contrib</artifactId>
                            <version>${ant.contrib.version}</version>
                            <exclusions>
                                <exclusion>
                                    <groupId>ant</groupId>
                                    <artifactId>ant</artifactId>
                                </exclusion>
                            </exclusions>
                        </dependency>
                    </dependencies>
                </plugin>
                <plugin>
                    <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-checkstyle-plugin</artifactId>
                    <version>${maven.checkstyle.plugin.version}</version>
                </plugin>
                <plugin>
                    <groupId>org.codehaus.mojo</groupId>
                    <artifactId>exec-maven-plugin</artifactId>
                    <version>${maven.exec.plugin.version}</version>
                </plugin>
                <plugin>
                  <groupId>org.apache.maven.plugins</groupId>
                  <artifactId>maven-surefire-plugin</artifactId>
                  <version>${maven.surefire.plugin.version}</version>
                </plugin>
            </plugins>
        </pluginManagement>
        <plugins>
            <!-- plugins are always listed in sorted order by groupId, artifactId -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-antrun-plugin</artifactId>
                <executions>
                    <execution>
                        <id>setup-test-dirs</id>
                        <phase>process-test-resources</phase>
                        <goals>
                            <goal>run</goal>
                        </goals>
                        <configuration>
                            <target>
                                <delete dir="${test.conf.dir}" />
                                <delete dir="${test.tmp.dir}" />
                                <delete dir="${test.warehouse.dir}" />
                                <mkdir dir="${test.tmp.dir}" />
                                <mkdir dir="${test.warehouse.dir}" />
                                <mkdir dir="${test.conf.dir}" />
                                <!-- copies hive-site.xml so it can be modified -->
                                <copy todir="${test.conf.dir}">
                                    <fileset dir="${basedir}/${hive.path.to.root}/data/conf/"/>
                                </copy>
                            </target>
                        </configuration>
                    </execution>
                    <execution>
                        <id>setup-metastore-scripts</id>
                        <phase>process-test-resources</phase>
                        <goals>
                            <goal>run</goal>
                        </goals>
                        <configuration>
                            <target>
                                <mkdir dir="${test.tmp.dir}/scripts/metastore" />
                                <copy todir="${test.tmp.dir}/scripts/metastore">
                                    <fileset dir="${basedir}/${hive.path.to.root}/metastore/scripts/"/>
                                </copy>
                                <mkdir dir="${test.tmp.dir}/scripts/metastore/upgrade" />
                                <copy todir="${test.tmp.dir}/scripts/metastore/upgrade">
                                    <fileset dir="${basedir}/${hive.path.to.root}/standalone-metastore/metastore-server/src/main/sql/"/>
                                </copy>
                            </target>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-failsafe-plugin</artifactId>
                <executions>
                    <execution>
                        <goals>
                            <goal>integration-test</goal>
                            <goal>verify</goal>
                        </goals>
                    </execution>
                </executions>
                <configuration>
                    <redirectTestOutputToFile>true</redirectTestOutputToFile>
                    <reuseForks>false</reuseForks>
                    <argLine>-Xmx2048m</argLine>
                    <failIfNoTests>false</failIfNoTests>
                    <systemPropertyVariables>
                        <log4j.debug>true</log4j.debug>
                        <java.io.tmpdir>${test.tmp.dir}</java.io.tmpdir>
                        <test.tmp.dir>${test.tmp.dir}</test.tmp.dir>
                        <hive.in.test>true</hive.in.test>
                    </systemPropertyVariables>
                    <additionalClasspathElements>
                        <additionalClasspathElement>${log4j.conf.dir}</additionalClasspathElement>
                    </additionalClasspathElements>
                    <skipITs>${skipITests}</skipITs> <!-- set this to false to run these tests -->
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <configuration>
                    <redirectTestOutputToFile>true</redirectTestOutputToFile>
                    <reuseForks>false</reuseForks>
                    <forkCount>${test.forkcount}</forkCount>
                    <argLine>-Xmx2048m</argLine>
                    <failIfNoTests>false</failIfNoTests>
                    <systemPropertyVariables>
                        <build.dir>${project.build.directory}</build.dir>
                        <datanucleus.schema.autoCreateAll>true</datanucleus.schema.autoCreateAll>
                        <derby.version>${derby.version}</derby.version>
                        <derby.stream.error.file>${test.tmp.dir}/derby.log</derby.stream.error.file>
                        <!--next line needed to get hive.log-->
                        <log4j.configurationFile>${test.log4j.scheme}${test.conf.dir}/hive-log4j2.properties</log4j.configurationFile>
                        <log4j.debug>true</log4j.debug>
                        <java.io.tmpdir>${test.tmp.dir}</java.io.tmpdir>
                        <!--
                        use 'memory' to make it run faster
                        <javax.jdo.option.ConnectionURL>jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true</javax.jdo.option.ConnectionURL>-->
                        <javax.jdo.option.ConnectionURL>jdbc:derby:${test.tmp.dir}/junit_metastore_db;create=true</javax.jdo.option.ConnectionURL>
                        <metastore.schema.verification>false</metastore.schema.verification>
                        <test.tmp.dir>${test.tmp.dir}</test.tmp.dir>
                        <metastore.warehouse.dir>${test.warehouse.scheme}${test.warehouse.dir}</metastore.warehouse.dir>
                        <!-- both default to 'local'
                        <mapred.job.tracker>local</mapred.job.tracker>
                        <mapreduce.framework.name>local</mapreduce.framework.name>-->
                    </systemPropertyVariables>
                    <additionalClasspathElements>
                        <additionalClasspathElement>${log4j.conf.dir}</additionalClasspathElement>
                        <additionalClasspathElement>${test.conf.dir}</additionalClasspathElement>
                        <!--puts hive-site.xml on classpath - w/o HMS tables are not created-->
                        <additionalClasspathElement>${test.conf.dir}/conf</additionalClasspathElement>
                    </additionalClasspathElements>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-jar-plugin</artifactId>
                <executions>
                    <execution>
                        <goals>
                            <goal>test-jar</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>
