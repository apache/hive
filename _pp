diff --git ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRelBuilder.java ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRelBuilder.java
index f50779d8efd..c9f76d09409 100644
--- ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRelBuilder.java
+++ ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRelBuilder.java
@@ -139,6 +139,10 @@ public static SqlFunction getFloorSqlFunction(TimeUnitRange flag) {
   }
 
   public static SqlAggFunction getRollup(SqlAggFunction aggregation) {
+    IRollupableAggregate x = aggregation.unwrap(IRollupableAggregate.class);
+    if (x != null) {
+      return x.getAggregate();
+    }
     if (aggregation instanceof HiveSqlSumAggFunction
         || aggregation instanceof HiveSqlMinMaxAggFunction
         || aggregation instanceof HiveSqlSumEmptyIsZeroAggFunction) {
diff --git ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/IRollupableAggregate.java ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/IRollupableAggregate.java
new file mode 100644
index 00000000000..d83123ce99e
--- /dev/null
+++ ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/IRollupableAggregate.java
@@ -0,0 +1,8 @@
+package org.apache.hadoop.hive.ql.optimizer.calcite;
+
+import org.apache.calcite.sql.SqlAggFunction;
+
+public interface IRollupableAggregate {
+
+  public SqlAggFunction getAggregate();
+}
diff --git ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlSumAggFunction.java ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlSumAggFunction.java
index 468e6f89b20..974dab1f0f6 100644
--- ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlSumAggFunction.java
+++ ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlSumAggFunction.java
@@ -125,5 +125,3 @@ public AggregateCall topSplit(RexBuilder rexBuilder,
     }
   }
 }
-
-// End SqlSumAggFunction.java
diff --git ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlX.java ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlX.java
new file mode 100644
index 00000000000..dadb0a70c97
--- /dev/null
+++ ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlX.java
@@ -0,0 +1,125 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.ql.optimizer.calcite.functions;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.calcite.rel.core.AggregateCall;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeFactory;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlAggFunction;
+import org.apache.calcite.sql.SqlFunctionCategory;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlSplittableAggFunction;
+import org.apache.calcite.sql.SqlSplittableAggFunction.SumSplitter;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlOperandTypeChecker;
+import org.apache.calcite.sql.type.SqlOperandTypeInference;
+import org.apache.calcite.sql.type.SqlReturnTypeInference;
+import org.apache.calcite.sql.type.SqlTypeName;
+import org.apache.calcite.util.ImmutableIntList;
+import org.apache.hadoop.hive.ql.optimizer.calcite.IRollupableAggregate;
+
+import com.google.common.collect.ImmutableList;
+
+public class HiveSqlX extends SqlAggFunction implements IRollupableAggregate {
+
+  public HiveSqlX(String string, SqlKind kind, SqlReturnTypeInference returnTypeInference,
+      SqlOperandTypeInference operandTypeInference,
+      SqlOperandTypeChecker operandTypeChecker) {
+    super(
+        string, kind,
+        returnTypeInference,
+        operandTypeInference,
+        operandTypeChecker,
+        SqlFunctionCategory.NUMERIC);
+  }
+
+
+//  @Override
+//  public <T> T unwrap(Class<T> clazz) {
+//    if (clazz == SqlSplittableAggFunction.class) {
+//      return clazz.cast(SelfSplitter.INSTANCE);
+//    }
+//    return super.unwrap(clazz);
+//  }
+
+  @Override
+  public <T> T unwrap(Class<T> clazz) {
+    if (clazz == SqlSplittableAggFunction.class) {
+      return clazz.cast(new HiveSumSplitter());
+    }
+    return super.unwrap(clazz);
+  }
+
+  class HiveSumSplitter extends SumSplitter {
+
+    @Override
+    public AggregateCall other(RelDataTypeFactory typeFactory, AggregateCall e) {
+      RelDataType countRetType = typeFactory.createTypeWithNullability(typeFactory.createSqlType(SqlTypeName.BIGINT), true);
+      return AggregateCall.create(
+          new HiveSqlCountAggFunction(false, ReturnTypes.explicit(countRetType), getOperandTypeInference(),
+              getOperandTypeChecker()),
+        false, ImmutableIntList.of(), -1, countRetType, "count");
+    }
+
+    @Override
+    public AggregateCall topSplit(RexBuilder rexBuilder,
+        Registry<RexNode> extra, int offset, RelDataType inputRowType,
+        AggregateCall aggregateCall, int leftSubTotal, int rightSubTotal) {
+      final List<RexNode> merges = new ArrayList<>();
+      final List<RelDataTypeField> fieldList = inputRowType.getFieldList();
+      if (leftSubTotal >= 0) {
+        final RelDataType type = fieldList.get(leftSubTotal).getType();
+        merges.add(rexBuilder.makeInputRef(type, leftSubTotal));
+      }
+      if (rightSubTotal >= 0) {
+        final RelDataType type = fieldList.get(rightSubTotal).getType();
+        merges.add(rexBuilder.makeInputRef(type, rightSubTotal));
+      }
+      RexNode node;
+      switch (merges.size()) {
+      case 1:
+        node = merges.get(0);
+        break;
+      case 2:
+        node = rexBuilder.makeCall(SqlStdOperatorTable.MULTIPLY, merges);
+        node = rexBuilder.makeAbstractCast(aggregateCall.type, node);
+        break;
+      default:
+        throw new AssertionError("unexpected count " + merges);
+      }
+      int ordinal = extra.register(node);
+      return AggregateCall
+          .create(
+              new HiveSqlSumAggFunction(false, getReturnTypeInference(), getOperandTypeInference(),
+                  getOperandTypeChecker()),
+          false, ImmutableList.of(ordinal), -1, aggregateCall.type, aggregateCall.name);
+    }
+  }
+
+  @Override
+  public SqlAggFunction getAggregate() {
+    return this;
+  }
+}
diff --git ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
index a555749fb98..de0ec32e6e4 100644
--- ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
+++ ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
@@ -49,6 +49,7 @@
 import org.apache.hadoop.hive.ql.optimizer.calcite.functions.HiveSqlMinMaxAggFunction;
 import org.apache.hadoop.hive.ql.optimizer.calcite.functions.HiveSqlSumAggFunction;
 import org.apache.hadoop.hive.ql.optimizer.calcite.functions.HiveSqlVarianceAggFunction;
+import org.apache.hadoop.hive.ql.optimizer.calcite.functions.HiveSqlX;
 import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveBetween;
 import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveConcat;
 import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveDateAddSqlOperator;
@@ -583,6 +584,24 @@ public static SqlAggFunction getCalciteAggFn(String hiveUdfName, boolean isDisti
       CalciteUDFInfo udfInfo = getUDFInfo(hiveUdfName, calciteArgTypes, calciteRetType);
 
       switch (hiveUdfName.toLowerCase()) {
+      case "sketchtoestimate":
+        calciteAggFn =
+            new HiveSqlX(
+                "sketchtoestimate",
+                SqlKind.REGR_SXX,
+            udfInfo.returnTypeInference,
+            udfInfo.operandTypeInference,
+                udfInfo.operandTypeChecker);
+        break;
+      case "datatosketch2":
+        calciteAggFn =
+            new HiveSqlX(
+                "datatosketch2",
+                SqlKind.REGR_SYY,
+            udfInfo.returnTypeInference,
+            udfInfo.operandTypeInference,
+                udfInfo.operandTypeChecker);
+        break;
       case "sum":
         calciteAggFn = new HiveSqlSumAggFunction(
             isDistinct,
diff --git ql/src/test/queries/clientpositive/sketches1.q ql/src/test/queries/clientpositive/sketches1.q
new file mode 100644
index 00000000000..6c9cf391d78
--- /dev/null
+++ ql/src/test/queries/clientpositive/sketches1.q
@@ -0,0 +1,20 @@
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-hive-1.1.0-incubating-SNAPSHOT.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/sketches-core-0.9.0.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-java-1.2.0-incubating.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-memory-1.2.0-incubating.jar
+
+create temporary table sketch_input (id int, category char(1));
+insert into table sketch_input values
+  (1, 'a'), (2, 'a'), (3, 'a'), (4, 'a'), (5, 'a'), (6, 'a'), (7, 'a'), (8, 'a'), (9, 'a'), (10, 'a'),
+  (6, 'b'), (7, 'b'), (8, 'b'), (9, 'b'), (10, 'b'), (11, 'b'), (12, 'b'), (13, 'b'), (14, 'b'), (15, 'b');
+
+-- build sketches per category
+create table sketch_intermediate (category char(1), sketch binary);
+insert into sketch_intermediate select category, datatosketch(id) from sketch_input group by category;
+
+-- get unique count estimates per category
+select category, SketchToEstimate(sketch) from sketch_intermediate;
+
+-- union sketches across categories and get overall unique count estimate
+select SketchToEstimate(unionSketch(sketch)) from sketch_intermediate;
+
diff --git ql/src/test/queries/clientpositive/sketches2.q ql/src/test/queries/clientpositive/sketches2.q
new file mode 100644
index 00000000000..747becb84ef
--- /dev/null
+++ ql/src/test/queries/clientpositive/sketches2.q
@@ -0,0 +1,45 @@
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-hive-1.1.0-incubating-SNAPSHOT.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/sketches-core-0.9.0.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-java-1.2.0-incubating.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-memory-1.2.0-incubating.jar
+
+
+set hive.support.concurrency=true;
+set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
+set hive.strict.checks.cartesian.product=false;
+set hive.stats.fetch.column.stats=true;
+set hive.materializedview.rewriting=true;
+
+
+create table sketch_input (id int, category char(1))
+STORED AS ORC
+TBLPROPERTIES ('transactional'='true');
+
+insert into table sketch_input values
+  (1, 'a'), (2, 'a'), (3, 'a'), (4, 'a'), (5, 'a'), (6, 'a'), (7, 'a'), (8, 'a'), (9, 'a'), (10, 'a'),
+  (6, 'b'), (7, 'b'), (8, 'b'), (9, 'b'), (10, 'b'), (11, 'b'), (12, 'b'), (13, 'b'), (14, 'b'), (15, 'b')
+; 
+
+-- build sketches per category
+create table sketch_intermediate (category char(1), sketch binary)
+STORED AS ORC
+TBLPROPERTIES ('transactional'='true');
+ 
+insert into sketch_intermediate select category, datatosketch(id) from sketch_input group by category;
+
+-- create an mv for the intermediate results
+create  materialized view mv_1 as
+  select category, SketchToEstimate(sketch) from sketch_intermediate;
+
+-- see if we use the mv
+explain
+select category, SketchToEstimate(sketch) from sketch_intermediate;
+
+select category, SketchToEstimate(sketch) from sketch_intermediate;
+
+-- union sketches across categories and get overall unique count estimate
+
+explain
+select SketchToEstimate(unionSketch(sketch)) from sketch_intermediate;
+select SketchToEstimate(unionSketch(sketch)) from sketch_intermediate;
+
diff --git ql/src/test/queries/clientpositive/sketches3.q ql/src/test/queries/clientpositive/sketches3.q
new file mode 100644
index 00000000000..bed395630f6
--- /dev/null
+++ ql/src/test/queries/clientpositive/sketches3.q
@@ -0,0 +1,60 @@
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-hive-1.1.0-incubating-SNAPSHOT.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/sketches-core-0.9.0.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-java-1.2.0-incubating.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-memory-1.2.0-incubating.jar
+
+
+set hive.support.concurrency=true;
+set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
+set hive.strict.checks.cartesian.product=false;
+set hive.stats.fetch.column.stats=true;
+set hive.materializedview.rewriting=true;
+set hive.fetch.task.conversion=none;
+
+create table sketch_input (id int, category char(1))
+STORED AS ORC
+TBLPROPERTIES ('transactional'='true');
+
+insert into table sketch_input values
+  (1,'a'),(1, 'a'), (2, 'a'), (3, 'a'), (4, 'a'), (5, 'a'), (6, 'a'), (7, 'a'), (8, 'a'), (9, 'a'), (10, 'a'),
+  (6,'b'),(6, 'b'), (7, 'b'), (8, 'b'), (9, 'b'), (10, 'b'), (11, 'b'), (12, 'b'), (13, 'b'), (14, 'b'), (15, 'b')
+; 
+
+-- build sketches per category
+create table sketch_intermediate (category char(1), sketch binary)
+STORED AS ORC
+TBLPROPERTIES ('transactional'='true');
+ 
+insert into sketch_intermediate select category, datatosketch(id) from sketch_input group by category;
+
+-- create an mv for the intermediate results
+create  materialized view mv_1 as
+  select category, datatosketch(id),count(id) from sketch_input group by category;
+
+-- see if we use the mv
+explain
+select category, SketchToEstimate(datatosketch(id)) from sketch_input group by category;
+
+select category, SketchToEstimate(datatosketch(id)) from sketch_input group by category;
+
+-- union sketches across categories and get overall unique count estimate
+-- FIXME: this is currently not supported UDF(UDAF(UDAF(x)))
+--explain
+--select SketchToEstimate(unionSketch(datatosketch(id))) from sketch_input group by category;
+--select SketchToEstimate(unionSketch(datatosketch(id))) from sketch_input group by category;
+
+explain
+select SketchToEstimate(unionSketch(sketch)) from 
+	(select datatosketch(id) as sketch from sketch_input group by category) s;
+
+select SketchToEstimate(unionSketch(sketch)) from 
+	(select datatosketch(id) as sketch from sketch_input group by category) s;
+
+
+
+
+
+select category,count(distinct id),count(id) from sketch_input group by category;
+
+explain
+select category,count(id) from sketch_input group by category;
diff --git ql/src/test/queries/clientpositive/sketches4.q ql/src/test/queries/clientpositive/sketches4.q
new file mode 100644
index 00000000000..c5e04ba0a8e
--- /dev/null
+++ ql/src/test/queries/clientpositive/sketches4.q
@@ -0,0 +1,50 @@
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-hive-1.1.0-incubating-SNAPSHOT.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/sketches-core-0.9.0.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-java-1.2.0-incubating.jar;
+-- add jar /home/dev/hive/packaging/target/apache-hive-4.0.0-SNAPSHOT-bin/apache-hive-4.0.0-SNAPSHOT-bin/lib/datasketches-memory-1.2.0-incubating.jar
+
+
+set hive.support.concurrency=true;
+set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
+set hive.strict.checks.cartesian.product=false;
+set hive.stats.fetch.column.stats=true;
+set hive.materializedview.rewriting=true;
+set hive.fetch.task.conversion=none;
+
+create table sketch_input (id int, category char(1))
+STORED AS ORC
+TBLPROPERTIES ('transactional'='true');
+
+insert into table sketch_input values
+  (1,'a'),(1, 'a'), (2, 'a'), (3, 'a'), (4, 'a'), (5, 'a'), (6, 'a'), (7, 'a'), (8, 'a'), (9, 'a'), (10, 'a'),
+  (6,'b'),(6, 'b'), (7, 'b'), (8, 'b'), (9, 'b'), (10, 'b'), (11, 'b'), (12, 'b'), (13, 'b'), (14, 'b'), (15, 'b')
+; 
+
+-- build sketches per category
+create table sketch_intermediate (category char(1), sketch binary)
+STORED AS ORC
+TBLPROPERTIES ('transactional'='true');
+ 
+-- create an mv for the intermediate results
+create  materialized view mv_1 as
+  select category, datatosketch2(id),count(id) from sketch_input group by category;
+
+-- see if we use the mv
+explain
+select category, SketchToEstimate2(datatosketch2(id)) from sketch_input group by category;
+
+select category, SketchToEstimate2(datatosketch2(id)) from sketch_input group by category;
+
+-- union sketches across categories and get overall unique count estimate
+explain
+select SketchToEstimate2(datatosketch2(id)) from sketch_input group by category;
+select SketchToEstimate2(datatosketch2(id)) from sketch_input group by category;
+
+-- see how well mv/count works
+explain
+select count(id) from sketch_input;
+
+explain
+select SketchToEstimate2(datatosketch2(id)) from sketch_input;
+select SketchToEstimate2(datatosketch2(id)) from sketch_input;
+
